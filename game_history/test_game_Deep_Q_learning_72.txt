 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.017494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     120       0       0      20       0       0
       0       0    -100       0    -300       0       0] 
sum of rewards: 2999735 

action type: buy - action 6.0
Learning step: 119989.6875
desired expected reward: 119982.34375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[103.97367 ]
 [114.16644 ]
 [107.80619 ]
 [ 87.71709 ]
 [112.04435 ]
 [116.17494 ]
 [112.123116]
 [120.10408 ]
 [ 95.707535]
 [105.76284 ]
 [105.12742 ]
 [108.25556 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.77745056152344



buy possibilites: [-1] 
expected returns: [[95.00628]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 120.10407257080078






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.  0.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[87.94639]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.00627899169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[83.98814 ]
 [94.430595]
 [87.94664 ]
 [67.92846 ]
 [96.48636 ]
 [92.24055 ]
 [85.86309 ]
 [88.890785]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.26932525634766



buy possibilites: [-1] 
expected returns: [[106.03488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 96.4863510131836






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 29. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 93.86798 ]
 [105.479065]
 [101.76969 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.03488159179688



action possibilites: [-1. 11.] 
expected returns: [[87.60197]
 [95.77089]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.63812255859375



action possibilites: [-1] 
expected returns: [[114.94189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 109.47313690185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[109.51241 ]
 [119.22446 ]
 [113.39924 ]
 [ 93.49284 ]
 [117.136696]
 [121.091995]
 [117.20516 ]
 [124.36727 ]
 [101.14369 ]
 [111.379974]
 [110.836586]
 [114.830246]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.94188690185547



buy possibilites: [-1] 
expected returns: [[111.974014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 124.36725616455078






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [ 0.  3.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[122.915565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.97401428222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[117.48782 ]
 [127.660805]
 [122.113106]
 [ 99.05564 ]
 [126.01595 ]
 [129.32364 ]
 [126.01295 ]
 [132.08707 ]
 [107.935165]
 [119.75526 ]
 [119.17253 ]
 [124.062126]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 123.04192352294922



buy possibilites: [-1] 
expected returns: [[119.921684]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 132.0870361328125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[125.091286]
 [132.16882 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.92168426513672



action possibilites: [-1] 
expected returns: [[131.85333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 138.8223876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[126.45725 ]
 [136.70004 ]
 [130.6756  ]
 [110.543396]
 [138.77557 ]
 [134.55722 ]
 [128.53278 ]
 [132.55408 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.85333251953125



buy possibilites: [-1] 
expected returns: [[109.41755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 138.77554321289062






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 98.22187]
 [108.97277]
 [ 90.99167]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0.  3.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.41754913330078



action possibilites: [-1. 10.] 
expected returns: [[131.50381]
 [126.60825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 110.7108383178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[128.63629 ]
 [139.04227 ]
 [132.89801 ]
 [111.3709  ]
 [136.84714 ]
 [141.13528 ]
 [136.87354 ]
 [144.5563  ]
 [119.696014]
 [130.72928 ]
 [130.20111 ]
 [134.82245 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 131.5037841796875



buy possibilites: [-1] 
expected returns: [[107.87798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 144.5562744140625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[134.47269]
 [139.22229]
 [141.96756]
 [141.96756]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 15. 10.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.87798309326172



action possibilites: [-1. 11. 29.] 
expected returns: [[142.67285]
 [148.75717]
 [151.90549]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 15. 10.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 140.71884155273438



action possibilites: [-1. 11. 29.] 
expected returns: [[149.1513 ]
 [155.69373]
 [159.53018]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 15. 10.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 151.90548706054688



action possibilites: [-1. 11.] 
expected returns: [[139.09744]
 [143.06082]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 15. 10.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 159.53018188476562



action possibilites: [-1] 
expected returns: [[167.92868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 15. 10.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 149.84091186523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[164.90378]
 [173.88583]
 [159.28018]
 [168.84064]
 [154.82617]
 [149.18964]
 [172.0162 ]
 [175.66306]
 [172.0849 ]
 [189.36887]
 [178.46951]
 [156.77597]
 [166.24945]
 [166.85355]
 [156.68903]
 [166.3364 ]
 [170.69022]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 15. 10.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.92868041992188



buy possibilites: [-1] 
expected returns: [[133.4667]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 15. 10.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 137.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 189.36886596679688






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 15. 10.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[137.95187]
 [143.48999]
 [146.74408]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.46670532226562



action possibilites: [-1. 11.] 
expected returns: [[126.23762]
 [130.70425]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 145.91192626953125



action possibilites: [-1] 
expected returns: [[118.83502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 135.81829833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[112.75882 ]
 [124.0257  ]
 [117.475006]
 [ 87.806885]
 [126.41445 ]
 [121.60094 ]
 [115.072464]
 [119.78431 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.83502197265625



buy possibilites: [-1] 
expected returns: [[153.19919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 25. 29. 29. 29. 11.  3.  0.  0.  0. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6. 10.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 126.41443634033203






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6. 10.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6. 10.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6. 10.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 10. 15. 11.  0. 10. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6. 10.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[159.54779]
 [153.04617]
 [153.04617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6. 10.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 153.19918823242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[151.14029]
 [156.44373]
 [131.42545]
 [159.99347]
 [159.71326]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6. 10.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 156.76028442382812



buy possibilites: [-1] 
expected returns: [[133.24515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.  0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 159.99346923828125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 29.  0.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 29.  0.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[147.24283]
 [156.254  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 470   0] 
sum of rewards: 465 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 192.67291259765625



action possibilites: [-1.] 
expected returns: [[168.60767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 157.20501708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[161.02502]
 [175.71506]
 [167.15222]
 [136.77603]
 [178.72458]
 [172.59705]
 [164.03415]
 [171.2829 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 168.607666015625



buy possibilites: [-1] 
expected returns: [[154.62683]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 178.724609375






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[181.63245]
 [187.63708]
 [176.07904]
 [176.07904]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 10.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  1.] 
adversary cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3. 10. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 154.6268310546875



action possibilites: [-1] 
expected returns: [[196.41592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  9.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  1.] 
adversary cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3. 10. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 193.99459838867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[192.73029]
 [196.51901]
 [178.081  ]
 [199.88858]
 [198.7879 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  9.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  1.] 
adversary cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3. 10. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 196.41592407226562



buy possibilites: [-1] 
expected returns: [[228.29822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  1.] 
adversary cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3. 10. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 199.88861083984375






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  1.] 
cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3. 10. 15.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 29. 29. 29.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3. 10.  8. 11.  0.  0.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  1.] 
cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3. 10. 15.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  5.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 29. 29. 29.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3. 10.  8. 11.  0.  0.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  1.] 
cards in discard: [ 0. 16. 10. 14. 11.  0.  0.  3. 10. 15.  3.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 29. 29. 29.] 
adversary cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3. 10.  8. 11.  0.  0.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 25. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29. 29. 29.] 
expected returns: [[220.73886]
 [223.50241]
 [237.8193 ]
 [226.77518]
 [226.77518]
 [226.77518]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29. 29. 29.] 
cards in discard: [ 8.  3. 10. 10.  0.  0.  3. 11. 11. 29.  0.  0.  3. 10.  8. 11.  0.  0.
 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 228.2982177734375



action possibilites: [-1] 
expected returns: [[129.52585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 237.81927490234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[124.80605]
 [110.49119]
 [131.24182]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.52584838867188






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 10.  0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 10.  0.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 5 
card supply: [26. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[109.14255]
 [104.20898]
 [104.20898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 16.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 478   0] 
sum of rewards: 503 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 170.37615966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[102.303024]
 [ 90.300255]
 [108.85012 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 16.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.79429626464844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 16.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11. 11.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[106.27116]
 [110.09861]
 [110.09861]
 [102.95584]
 [102.95584]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10. 10.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 11.  1.  3. 15.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.85010528564453



action possibilites: [-1] 
expected returns: [[139.16562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11.  1.  3. 15.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.55722045898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[133.4928 ]
 [118.41221]
 [140.69986]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 10.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11.  1.  3. 15.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.16561889648438






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  1.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  3. 15.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29. 10.  0.  8.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15. 11. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  3. 15.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29. 10.  0.  8.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15. 11. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  3. 15.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29. 10.  0.  8.] 
adversary cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15. 11. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15] -> size -> 27 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[186.65775]
 [193.58667]
 [184.15121]
 [188.41876]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0.  8.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15. 11. 11.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  0. 10. 11.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.  0.  3. 11.  1.
  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 140.69989013671875



action possibilites: [-1. 10.] 
expected returns: [[170.81311]
 [166.32843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15. 11. 11.  0. 10. 10.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  0. 10. 11.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.  0.  3. 11.  1.
  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 189.91085815429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[166.49707]
 [173.79135]
 [169.67557]
 [156.6012 ]
 [172.17746]
 [175.38629]
 [172.2078 ]
 [177.58972]
 [160.65472]
 [167.79355]
 [172.57672]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15. 11. 11.  0. 10. 10.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  0. 10. 11.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.  0.  3. 11.  1.
  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 170.8131103515625



buy possibilites: [-1] 
expected returns: [[151.27048]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 11. 29. 29. 29.  3.  0.  0.  0.  3. 10. 10. 15. 11. 11.  0. 10. 10.
  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  5.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  0. 10. 11.] 
adversary cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.  0.  3. 11.  1.
  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 177.5897216796875






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [10.  3.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 10. 11.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.  0.  3. 11.  1.
  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  5.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 10. 11.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.  0.  3. 11.  1.
  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  5.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 10. 11.] 
cards in discard: [ 6.  0. 14.  0.  0. 10.  0.  0. 10. 10. 16.  0.  0.  0.  0.  3. 11.  1.
  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  5.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29] -> size -> 28 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[142.30408]
 [137.95554]
 [142.97284]
 [146.41187]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8. 11.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  5.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 151.27047729492188



action possibilites: [-1] 
expected returns: [[149.97174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 148.726806640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[141.68881]
 [124.76081]
 [150.35901]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  3.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.97174072265625






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 6. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.  0. 10.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.  0. 10.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.  0. 10.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[149.39755]
 [157.82596]
 [157.82596]
 [141.65533]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0. 10.] 
cards in discard: [15. 11. 10.  3.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  0. 10.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.35897827148438



action possibilites: [-1. 10. 29.] 
expected returns: [[166.57462]
 [161.64825]
 [175.84479]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  0. 10.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 151.37542724609375



action possibilites: [-1. 10.] 
expected returns: [[158.07025]
 [150.83768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  0. 10.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 170.1990966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[149.3912 ]
 [161.4064 ]
 [154.55875]
 [130.29388]
 [158.7031 ]
 [164.02048]
 [158.80283]
 [167.63464]
 [139.569  ]
 [151.44125]
 [159.49576]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  0. 10.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 158.07028198242188



buy possibilites: [-1] 
expected returns: [[196.34778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  0. 10.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 167.6346435546875






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  0.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15.  3.  0.  0. 29.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15.  3.  0.  0. 29.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 14.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15.  3.  0.  0. 29.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 14.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15.  3.  0.  0. 29.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 14.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15.  3.  0.  0. 29.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [15.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[182.78745]
 [175.15216]
 [192.21295]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0. 29.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0. 11. 16.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 196.3477783203125



action possibilites: [-1. 15. 11.] 
expected returns: [[202.52112]
 [199.051  ]
 [207.53247]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 11.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0. 11. 16.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 185.48745727539062



action possibilites: [-1] 
expected returns: [[192.3157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 11. 16.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 212.56704711914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[183.90308]
 [191.19266]
 [187.10959]
 [172.52542]
 [192.78659]
 [189.58011]
 [190.54587]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 11. 16.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 192.31570434570312



buy possibilites: [-1] 
expected returns: [[220.3107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  3.  8.  9.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 11. 16.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 192.78662109375






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [10.  0. 11. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 16.  0.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10
  0  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  3.  8.  9.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11.  8.  0. 10. 25.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15. 11. 29.
 11. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [11.  8.  0. 10. 25.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15. 11. 29.
 11. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [11.  8.  0. 10. 25.] 
adversary cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15. 11. 29.
 11. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  8.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 25.] 
expected returns: [[251.20416]
 [253.24893]
 [248.06558]
 [241.9635 ]
 [268.10727]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 10. 25.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15. 11. 29.
 11. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  8.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14. 14. 16.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 220.31069946289062



action possibilites: [-1] 
expected returns: [[210.36993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 10. 29. 10.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15. 11. 29.
 11. 15.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14. 14. 16.  0. 11.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 268.1072998046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[201.45569]
 [189.98544]
 [211.09116]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0. 10. 29. 10.] 
cards in discard: [15. 11. 10.  3.  8.  3. 29. 10. 29. 29. 29.  0.  0. 10.  3. 15. 11. 29.
 11. 15.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14. 14. 16.  0. 11.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 210.36993408203125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [15.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14. 14. 16.  0. 11.
  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14. 14. 16.  0. 11.
  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [ 6. 11.  6. 10.  0.  0.  0. 10. 10.  0. 10.  0.  3. 14. 14. 16.  0. 11.
  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[142.41946]
 [148.99844]
 [146.17474]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 211.09115600585938



action possibilites: [-1. 11.] 
expected returns: [[151.05289]
 [155.05167]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 144.03805541992188



action possibilites: [-1] 
expected returns: [[178.18848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 159.96270751953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[169.55307]
 [181.42911]
 [174.58243]
 [148.74084]
 [183.94424]
 [178.91495]
 [177.97311]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  3.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 178.1884765625



buy possibilites: [-1] 
expected returns: [[134.24377]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 15. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  2.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 183.94424438476562






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  2.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [25. 10. 10.  3. 15.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  2.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [25. 10. 10.  3. 15.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  1.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [25. 10. 10.  3. 15.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [25. 10. 10.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10. 15.] 
expected returns: [[179.88974]
 [199.26117]
 [174.38492]
 [174.38492]
 [173.92584]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 10.  3. 15.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  7.  9.  1.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.2437744140625



action possibilites: [-1] 
expected returns: [[231.63257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 15. 10. 29.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  1.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 199.26116943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[224.39441]
 [208.60211]
 [232.1774 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 15. 10. 29.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  1.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 231.632568359375






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  1.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 29.  0. 15. 11.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  1.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 29.  0. 15. 11.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11.] 
expected returns: [[173.88217]
 [178.06879]
 [162.51215]
 [174.78067]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 15. 11.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  1.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [11. 16.  0.  6.  0.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 232.17742919921875



action possibilites: [-1. 15. 11.] 
expected returns: [[190.19537]
 [183.4888 ]
 [193.45062]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 11.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  1.  8.  9.  4.  8. 10.  0. 10.  5.] 
adversary cards in hand: [11. 16.  0.  6.  0.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 171.89935302734375



action possibilites: [-1] 
expected returns: [[261.10107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  1.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 16.  0.  6.  0.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 199.293701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[252.47858]
 [261.99573]
 [256.5191 ]
 [237.04938]
 [263.9946 ]
 [259.95407]
 [259.4312 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  1.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 16.  0.  6.  0.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 261.10107421875



buy possibilites: [-1] 
expected returns: [[203.58969]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  0.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 16.  0.  6.  0.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 263.99462890625






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11. 16.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0.  6.  0.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  0.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [15. 29.  0. 11.  8.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11] -> size -> 36 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0.  6.  0.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 30. 30.  8.  6.  9.  0.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [15. 29.  0. 11.  8.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11] -> size -> 36 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0.  6.  0.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  6.  9.  0.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [15. 29.  0. 11.  8.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [15. 29.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.  8.] 
expected returns: [[296.67236]
 [292.13486]
 [302.5899 ]
 [300.19492]
 [296.90656]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  0. 11.  8.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  6.  9.  0.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  0. 10. 14.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 203.58969116210938



action possibilites: [-1. 15. 29.] 
expected returns: [[261.04807]
 [254.60583]
 [262.73328]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 29.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 29. 30.  8.  6.  9.  0.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  0. 10. 14.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 304.6365966796875



action possibilites: [-1. 15.] 
expected returns: [[351.27734]
 [346.97717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 29. 30.  8.  6.  9.  0.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  0. 10. 14.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 259.439453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[345.88617]
 [349.2874 ]
 [334.31488]
 [352.25146]
 [351.47232]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11] -> size -> 36 
action values: 1 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 29. 30.  8.  6.  9.  0.  8.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  0. 10. 14.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 351.2773742675781



buy possibilites: [-1] 
expected returns: [[310.1876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  0. 10. 14.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 352.25152587890625






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 10. 14.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10. 10. 29.  8.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.  8. 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 10. 14.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 29. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10. 10. 29.  8.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.  8. 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 10. 14.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10. 10. 29.  8.] 
adversary cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.  8. 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8] -> size -> 37 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11. 10. 10. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 29.  8.] 
expected returns: [[203.84625]
 [206.75864]
 [201.27536]
 [201.27536]
 [208.44702]
 [204.4621 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 29.  8.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.  8. 29. 29. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [14. 11.  3. 10.  6.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 310.1875915527344



action possibilites: [-1. 10.  8. 11.] 
expected returns: [[209.08652]
 [206.03528]
 [209.17197]
 [211.52039]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.  8. 29. 29. 15. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [14. 11.  3. 10.  6.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 205.61288452148438



action possibilites: [-1] 
expected returns: [[200.67685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.  8. 29. 29. 15. 11. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [14. 11.  3. 10.  6.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 210.33352661132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[196.6323 ]
 [189.51529]
 [200.67688]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [ 0. 15. 11. 29. 11.  3.  0.  0. 25. 10. 10.  3. 15. 10. 29.  3. 15. 11.
 29. 11.  0.  0. 15. 11.  8.  0.  0.  8. 29. 29. 15. 11. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [14. 11.  3. 10.  6.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 200.67684936523438






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [14. 11.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  3. 10.  6.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  8. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  3. 10.  6.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  8. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  3. 10.  6.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  8. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11. 10.  8. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 25. 10.] 
expected returns: [[149.8894 ]
 [151.19772]
 [141.65622]
 [146.75638]
 [163.96313]
 [141.65622]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 25. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  6.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.  0. 14. 11.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 200.67684936523438



action possibilites: [-1] 
expected returns: [[141.44131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.  0. 14. 11.  3. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 163.96316528320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[135.25943 ]
 [123.369484]
 [142.443   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.  0. 14. 11.  3. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.44131469726562






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 10.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.  0. 14. 11.  3. 10.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 15. 10. 29. 11.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 10.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.  0. 14. 11.  3. 10.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 28. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 15. 10. 29. 11.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 10.] 
cards in discard: [11.  6.  0.  0.  1.  3.  6.  0.  0.  3.  0.  0.  3. 11. 16.  0.  6.  0.
  3.  0. 15.  0. 10. 14.  0. 14. 11.  3. 10.  6.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 27. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 15. 10. 29. 11.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 15. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 29. 11.] 
expected returns: [[173.78812]
 [166.87195]
 [166.59863]
 [166.87195]
 [177.66623]
 [175.27472]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 29. 11.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 142.44302368164062



action possibilites: [-1. 10. 10.] 
expected returns: [[150.00137]
 [142.33646]
 [142.33646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 27. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 173.35043334960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[141.33362]
 [145.21857]
 [128.33212]
 [147.67926]
 [150.98349]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 27. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 150.00137329101562






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 29. 11.  0.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 27. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 29. 11.  0.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 29. 11.  0.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 15. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.] 
expected returns: [[143.45334]
 [137.73416]
 [148.82361]
 [146.36584]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 11.  0.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [3. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.98348999023438



action possibilites: [-1. 15. 11. 15.] 
expected returns: [[187.67465]
 [180.75363]
 [190.34668]
 [180.75363]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [3. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 144.54104614257812



action possibilites: [-1] 
expected returns: [[160.24152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [3. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 188.22686767578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[151.50839]
 [140.30496]
 [159.91504]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [3. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.24151611328125






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6.  0.] 
cards in discard: [3. 0. 6. 0. 3. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  0. 11.  3. 15.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.  0.] 
cards in discard: [3. 0. 6. 0. 3. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  7.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  0. 11.  3. 15.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.  0.] 
cards in discard: [3. 0. 6. 0. 3. 0. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  0. 11.  3. 15.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  0. 11.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.] 
expected returns: [[239.29095]
 [239.02396]
 [237.54218]
 [231.88113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3. 15.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [14.  3. 11. 14.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 159.91510009765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[228.91391]
 [219.17773]
 [237.88611]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  3. 15.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [14.  3. 11. 14.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 239.29095458984375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [14.  3. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11. 14.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 29. 10. 11. 11.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 14.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 11. 11.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 14.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 26. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 11. 11.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 14.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 11. 11.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[219.06396]
 [222.62888]
 [220.82065]
 [220.82065]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 11. 11.  3.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 111.93060302734375



action possibilites: [-1. 29.] 
expected returns: [[211.75708]
 [215.6347 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 11. 11.  3.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 219.38970947265625



action possibilites: [-1.] 
expected returns: [[178.63129]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10. 11. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 11. 11.  3.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 205.42904663085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[172.35913]
 [174.85797]
 [164.67389]
 [176.36356]
 [178.86282]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10. 11. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 1 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 11. 11.  3.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 178.63128662109375






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 15. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 11.  3.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [0. 1. 3. 0. 8.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10. 11. 11.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11. 11.  3.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [0. 1. 3. 0. 8.] 
adversary cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10. 11. 11.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 1. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[162.10382]
 [161.84381]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 8.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10. 11. 11.  3. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 178.86285400390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[156.51593]
 [163.32385]
 [159.46988]
 [145.68423]
 [161.80661]
 [161.84381]
 [166.84552]
 [150.893  ]
 [157.7009 ]
 [162.10382]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 8.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10. 11. 11.  3. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 162.10382080078125



buy possibilites: [-1] 
expected returns: [[158.09384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 8.] 
cards in discard: [25. 11. 10.  8. 10.  8. 29. 15. 11. 29. 10. 10.  0.  0.  0.  1. 29. 11.
 15. 15. 29.  0. 11.  3. 15. 11. 10. 11. 11.  3. 29. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 73 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 166.84555053710938






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 15. 25. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29] -> size -> 40 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 15. 25. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29] -> size -> 40 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 25. 30.  8.  5.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 15. 25. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29] -> size -> 40 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 24. 30.  8.  5.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 15. 25. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29] -> size -> 40 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 1. 15. 25. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 15.] 
expected returns: [[171.02005]
 [164.07196]
 [180.19907]
 [164.07196]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 25. 15.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  5.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  6. 10.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 158.09384155273438



action possibilites: [-1] 
expected returns: [[97.370415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15.  0. 29. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  6. 10.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 180.19906616210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[89.742004]
 [99.32537 ]
 [94.02811 ]
 [75.81949 ]
 [97.32242 ]
 [97.70761 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.  0. 29. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  6. 10.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.37041473388672



buy possibilites: [-1] 
expected returns: [[148.99258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.  0. 29. 15.] 
cards in discard: [1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  6. 10.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 99.32538604736328






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10.  3.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6. 10.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  3. 10.  1.  8.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1] -> size -> 41 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6. 10.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  3. 10.  1.  8.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1] -> size -> 41 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  3. 10.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[195.534  ]
 [200.21985]
 [191.23822]
 [196.44345]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  1.  8.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  6. 16.  3.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6. 10.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.99258422851562



action possibilites: [-1] 
expected returns: [[156.64282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  8.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  6. 16.  3.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6. 10.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 198.36721801757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[148.58734]
 [152.34222]
 [136.20898]
 [154.72665]
 [157.88763]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  8.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  6. 16.  3.  0.] 
adversary cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6. 10.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 156.642822265625






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 1.  6. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 16.  3.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6. 10.  3.  6. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 11.  0.  0.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 16.  3.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6. 10.  3.  6. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 11.  0.  0.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 16.  3.  0.] 
cards in discard: [ 3.  0.  6.  0.  3.  0.  8.  0.  3. 10.  6.  0.  3. 14.  3. 11. 14.  0.
  0. 15. 11. 11.  3.  3. 10.  6.  0.  0.  0.  0.  6. 10.  3.  6. 10.  0.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 11.  0.  0.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[134.48535 ]
 [126.725044]
 [126.725044]
 [135.51215 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  0.  0.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 157.88763427734375



action possibilites: [-1] 
expected returns: [[125.19805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -38 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 133.38058471679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[121.40646]
 [124.18244]
 [110.60492]
 [127.02262]
 [125.50332]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  6.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.19805145263672



buy possibilites: [-1] 
expected returns: [[164.75027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -90   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 127.02263641357422






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 29. 29. 11. 10.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 29. 29. 11. 10.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 29. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29. 11. 10.] 
expected returns: [[169.87592]
 [170.11816]
 [174.74597]
 [174.74597]
 [172.83807]
 [166.65637]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29. 11. 10.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 164.75027465820312



action possibilites: [-1. 29. 10.] 
expected returns: [[262.18903]
 [267.34348]
 [254.87183]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 176.2889404296875



action possibilites: [-1.] 
expected returns: [[197.62311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 263.41815185546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[189.83112]
 [193.05145]
 [179.74463]
 [195.86731]
 [197.62317]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 1 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 197.62310791015625






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  0.] 
cards in discard: [ 3. 10.  6.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 29. 11. 11.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.  0.] 
cards in discard: [ 3. 10.  6.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 29. 11. 11.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.  0.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 29. 11. 11.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[127.39817]
 [133.61429]
 [131.40286]
 [131.40286]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 11. 11.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  1. 15.  6.  6.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 197.62310791015625



action possibilites: [-1. 11.] 
expected returns: [[153.20187]
 [151.45062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  1. 15.  6.  6.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 129.95816040039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[143.63379]
 [146.8003 ]
 [132.11444]
 [148.28378]
 [153.20187]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  1. 15.  6.  6.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 153.20187377929688






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 15.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  6.  6.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  8. 15. 11. 15.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15.  6.  6.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  8. 15. 11. 15.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15.  6.  6.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  8. 15. 11. 15.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  8. 15. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15. 11. 15.] 
expected returns: [[145.42508]
 [139.73666]
 [145.1352 ]
 [139.39825]
 [149.69504]
 [139.39825]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15. 11. 15.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  8.  6. 10.  3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.20187377929688



action possibilites: [-1] 
expected returns: [[161.10999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15. 15.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  8.  6. 10.  3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -58 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 147.36965942382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[155.66733]
 [139.5198 ]
 [161.10995]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 15. 15.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  8.  6. 10.  3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 161.1099853515625






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  6. 10.  3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.  1. 11.
 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1] -> size -> 45 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  6. 10.  3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 22. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.  1. 11.
 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1] -> size -> 45 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  6. 10.  3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.  1. 11.
 10.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1] -> size -> 45 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[123.6495  ]
 [126.6486  ]
 [125.448006]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  0.] 
cards in discard: [ 1. 25.  1. 15. 15.  0. 29. 15.  1. 11.  3. 10.  1.  8.  1.  8. 11. 10.
 10.  0.  0.  8. 11. 10. 29. 29. 29.  3. 11. 29. 29.  3.  0. 11.  1. 11.
 10.  8. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 16. 14.  3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.1099853515625



action possibilites: [-1. 11.] 
expected returns: [[ 98.5901  ]
 [100.462425]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 22. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 16. 14.  3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 124.62413787841797



action possibilites: [-1] 
expected returns: [[75.62395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0. 29.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 16. 14.  3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   40    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: -48 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 98.6043472290039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[66.72785 ]
 [76.63488 ]
 [71.482086]
 [51.59452 ]
 [74.341286]
 [78.457   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 29.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 16. 14.  3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.62394714355469






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 14.  3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  8. 10. 10. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 14.  3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  8. 10. 10. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 14.  3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  8. 10. 10. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  8. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 10. 11.] 
expected returns: [[159.02429]
 [163.94257]
 [157.90988]
 [153.38684]
 [153.38684]
 [161.53046]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10. 10. 11.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0] -> size -> 47 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.45701599121094



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[138.95633]
 [137.78177]
 [133.41623]
 [133.41623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0] -> size -> 47 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 159.70028686523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[132.05737 ]
 [120.191605]
 [139.08972 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0] -> size -> 47 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 138.95632934570312






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [25.  1. 10. 15.  0.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 21. 30. 24. 30.  8.  4.  9.  0.  5.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [25.  1. 10. 15.  0.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 21. 30. 24. 30.  8.  4.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [25.  1. 10. 15.  0.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  1. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 15.] 
expected returns: [[118.71284]
 [127.09788]
 [113.69335]
 [113.58633]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 10. 15.  0.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 24. 30.  8.  4.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.0897216796875



action possibilites: [-1] 
expected returns: [[113.624115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 15.  0. 15.  8.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 24. 30.  8.  3.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6] -> size -> 49 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 127.0978775024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[108.53526 ]
 [114.918434]
 [111.15571 ]
 [ 98.79084 ]
 [113.48981 ]
 [113.4003  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 15.  0. 15.  8.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 21. 30. 24. 30.  8.  3.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6] -> size -> 49 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.62411499023438



buy possibilites: [-1] 
expected returns: [[131.05212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 15.  0. 15.  8.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 30.  8.  3.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6] -> size -> 49 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -120    0    0
   54    0] 
sum of rewards: -51 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 114.91844940185547






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 30.  8.  3.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 30. 24. 30.  8.  3.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[87.313965]
 [86.38218 ]
 [83.96772 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 10.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 30.  8.  3.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.
  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.0521240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[83.08714 ]
 [84.81927 ]
 [77.006645]
 [86.38218 ]
 [87.31396 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  0. 10.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 30. 24. 30.  8.  3.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.
  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.31394958496094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [11.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0. 11.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.
  3. 14.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 30.  8.  3.  9.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 29.  3. 15.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.
  3. 14.  6.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 29.  3. 15.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.
  3. 14.  6.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 29.  3. 15.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  0. 11. 10.  0.  0.  0.  3.  1. 15.  6.  6.  0.
  1.  8.  6. 10.  3.  0.  3.  0. 16. 14.  3.  8.  3.  0.  0.  0.  3.  6.
  3. 14.  6.  0.  0. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 29.  3. 15.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 1. 29. 29.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15.] 
expected returns: [[117.04551 ]
 [116.82613 ]
 [116.82613 ]
 [110.162254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  3. 15.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 16.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0] -> size -> 51 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.31394958496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[108.68998]
 [111.41326]
 [100.9162 ]
 [112.70047]
 [117.0455 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29.  3. 15.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 16.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0] -> size -> 51 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 117.04549407958984



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [11. 16.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 15.  1.  3. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 15.  1.  3. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0.  3. 10.] 
cards in discard: [0.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29. 15.  1.  3. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 15.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11.] 
expected returns: [[119.181076]
 [121.59382 ]
 [115.805824]
 [120.32435 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  1.  3. 11.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  6. 14.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.04549407958984



action possibilites: [-1. 15. 11.] 
expected returns: [[152.51706]
 [150.3215 ]
 [155.68753]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 20. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  6. 14.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 119.21552276611328



action possibilites: [-1] 
expected returns: [[110.6625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  6. 14.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: -38 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 154.67730712890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.31815 ]
 [ 86.216064]
 [110.6625  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  6. 14.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.6624984741211






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 14.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 11. 10.  1.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.] 
cards in deck: 41 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  1.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.] 
cards in deck: 41 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  1.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  1.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[151.85898]
 [149.79553]
 [145.0758 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3. 15. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  3. 15.  6.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 64.30906677246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[143.72406]
 [146.24423]
 [137.00381]
 [147.27539]
 [151.85898]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  1.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3. 15. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  3. 15.  6.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 151.8590087890625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 6.  3. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.  6.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29.  1.  8. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3. 15. 11. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15.  6.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29.  1.  8. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3. 15. 11. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 29.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[67.44725]
 [68.62905]
 [63.16671]
 [66.69392]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  1.  8. 11.] 
cards in discard: [ 0. 29.  1. 29. 11.  0.  0. 11.  0. 29.  8. 10. 10.  1. 25.  1. 10. 15.
  0. 15.  8.  3.  0.  8.  0. 10.  1. 29. 29.  3. 15.  1. 11.  1. 29. 11.
 15.  3. 15. 11. 11. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.8590087890625



action possibilites: [-1.  8.] 
expected returns: [[77.20024]
 [75.23766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 8.] 
cards in discard: [11. 29.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 64.83159637451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[70.82394 ]
 [78.75002 ]
 [74.51239 ]
 [62.696297]
 [58.48253 ]
 [76.97862 ]
 [76.94894 ]
 [91.82401 ]
 [82.89072 ]
 [64.48063 ]
 [72.39874 ]
 [64.46349 ]
 [72.40351 ]
 [80.17235 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 8.] 
cards in discard: [11. 29.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  9.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.20024871826172



buy possibilites: [-1] 
expected returns: [[79.94654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 8.] 
cards in discard: [11. 29. 25.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -140    0    0
  250    0] 
sum of rewards: 155 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 91.82401275634766






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29.  1. 11. 25.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 19. 30. 24. 30.  8.  3.  8.  0.  4.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29.  1. 11. 25.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 19. 30. 24. 30.  8.  3.  8.  0.  4.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29.  1. 11. 25.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 1. 29.  1. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.] 
expected returns: [[102.97698 ]
 [104.51922 ]
 [103.06698 ]
 [110.498314]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  1. 11. 25.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  3.  8.  0.  4.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  0.  1.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0] -> size -> 54 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.94654083251953



action possibilites: [-1] 
expected returns: [[91.34224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  1. 11. 11.  1.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  0.  1.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6] -> size -> 55 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 110.4983139038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 84.4791  ]
 [ 92.1194  ]
 [ 80.68678 ]
 [ 87.54298 ]
 [ 77.64896 ]
 [ 74.232414]
 [ 90.37102 ]
 [ 90.43389 ]
 [104.23377 ]
 [ 96.268654]
 [ 79.04512 ]
 [ 85.543434]
 [ 78.99952 ]
 [ 85.605675]
 [ 90.03176 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  1. 11. 11.  1.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25] -> size -> 49 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  0.  1.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6] -> size -> 55 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.34223937988281



buy possibilites: [-1] 
expected returns: [[122.09912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  1. 11. 11.  1.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  0.  1.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6] -> size -> 55 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.    20.     0.     0.     0.
    0.  -150.     0.     0.    62.5    0. ] 
sum of rewards: -42.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 104.2337875366211






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  1.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  8. 29. 29. 29.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6] -> size -> 55 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  8. 29. 29. 29.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  8. 29. 29. 29.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [11.  8. 29. 29. 29.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  8. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 29. 29.] 
expected returns: [[142.07434]
 [143.20538]
 [140.50577]
 [144.78378]
 [144.78378]
 [144.78378]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29. 29. 29.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 6. 8. 0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14] -> size -> 56 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.09912109375



action possibilites: [-1.  8. 29.] 
expected returns: [[161.54953]
 [162.31879]
 [167.08167]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 6. 8. 0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14] -> size -> 56 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 141.83895874023438



action possibilites: [-1.  8.] 
expected returns: [[117.373535]
 [113.24937 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 2 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 6. 8. 0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14] -> size -> 56 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 163.6595458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[107.559135]
 [111.09942 ]
 [ 96.0946  ]
 [113.249374]
 [117.373535]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
action values: 1 
buys: 1 
player value: 2 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 6. 8. 0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14] -> size -> 56 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 117.37354278564453






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  1.  0. 15. 10.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  4.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  1.  0. 15. 10.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  3.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  1.  0. 15. 10.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 1.  1.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[145.62238]
 [141.42639]
 [141.50406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 15. 10.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  3.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8] -> size -> 57 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.37354278564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[140.4403 ]
 [144.74313]
 [142.49121]
 [136.05981]
 [134.14963]
 [143.78714]
 [143.75601]
 [152.39844]
 [147.02518]
 [137.12357]
 [141.45752]
 [137.15466]
 [141.42639]
 [145.62238]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 15. 10.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  3.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8] -> size -> 57 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 145.62237548828125



buy possibilites: [-1] 
expected returns: [[148.07965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 15. 10.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8] -> size -> 57 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0    0    0 -160    0    0
  250    0] 
sum of rewards: 145 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 152.3984375






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 15.  3.  1.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 15.  3.  1.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 15.  3.  1.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 10. 15.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15.] 
expected returns: [[100.313225]
 [ 97.86503 ]
 [ 97.86503 ]
 [ 97.710915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.  3.  1.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8  0] -> size -> 58 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.07965087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 97.00866]
 [ 98.72814]
 [ 90.69409]
 [100.11   ]
 [100.31323]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.  3.  1.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8  0] -> size -> 58 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.313232421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 8.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0
  0  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8
  6 16  0  0  0  0  6 14  8  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  3. 29. 11.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  3. 29. 11.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0] -> size -> 57 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 19. 30. 24. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  3. 29. 11.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 19. 30. 23. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  3. 29. 11.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11. 10.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[128.49908]
 [129.9401 ]
 [126.61445]
 [130.85437]
 [129.9401 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 29. 11.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 23. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3] -> size -> 58 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 100.313232421875



action possibilites: [-1. 11.] 
expected returns: [[100.26324]
 [102.07793]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 19. 30. 23. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3] -> size -> 58 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 129.13192749023438



action possibilites: [-1] 
expected returns: [[79.91639]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 18. 30. 23. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3] -> size -> 58 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0   40    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: -48 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 101.0599365234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.42878 ]
 [67.31189 ]
 [53.554863]
 [68.54957 ]
 [79.91635 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 18. 30. 23. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3] -> size -> 58 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.91638946533203






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 18. 30. 23. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 18. 30. 23. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[69.73004 ]
 [63.735085]
 [63.728645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3. 10.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [14. 11.  0. 16.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.  3.  0.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3] -> size -> 59 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.91638946533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.643562]
 [64.80942 ]
 [57.508263]
 [65.872734]
 [69.730034]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3. 10.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [14. 11.  0. 16.  0.] 
adversary cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.  3.  0.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3] -> size -> 59 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 69.73004913330078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [14. 11.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0. 16.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.  3.  0.  0. 11. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  8. 11.  0.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.  0.  0. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0. 16.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.  3.  0.  0. 11. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3] -> size -> 59 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  3.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  8. 11.  0.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.  0.  0. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0. 16.  0.] 
cards in discard: [ 0. 11. 16.  0.  3. 10.  0. 14.  3.  3.  6.  0.  6.  3. 15.  6.  0.  0.
  3.  0. 10.  3.  0.  6. 14. 10.  0.  0.  0.  1.  6.  8.  6.  0.  6.  8.
  0.  0.  6.  0.  3.  0.  3.  3.  8.  0.  0.  1.  3.  0.  0. 11. 10.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  8. 11.  0.] 
adversary cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.  0.  0. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 15.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
expected returns: [[-0.8078089]
 [-6.210796 ]
 [-3.8717928]
 [-2.8410783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8. 11.  0.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.  0.  0. 15.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [16.  6. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8] -> size -> 60 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 69.73004913330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -9.18337  ]
 [ -4.1518154]
 [-31.300032 ]
 [ -3.8717928]
 [ -0.8078079]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8. 11.  0.] 
cards in discard: [11. 29. 25. 29.  1.  1.  8. 25. 25.  1. 29.  1. 11. 11.  1. 11. 29.  0.
 15. 29. 29.  8. 25.  1.  1.  0. 15. 10. 10. 10. 15.  3.  1. 11. 10.  1.
 29. 11.  3.  0.  0.  0. 15.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [16.  6. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8] -> size -> 60 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.8077764511108398



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [16.  6. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 15.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 10.  0.] 
cards in discard: [14.] 
cards in deck: 55 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8 14] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 15.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6. 10.  0.] 
cards in discard: [14.] 
cards in deck: 55 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8 14] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 18. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 15.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6. 10.  0.] 
cards in discard: [14.  0.] 
cards in deck: 55 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8 14  0] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 18. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 15.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [15. 11. 15.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15.  8.] 
expected returns: [[98.46447 ]
 [89.707344]
 [99.081825]
 [89.707344]
 [94.73985 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.  1.  8.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 18. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8 14  0] -> size -> 62 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.8077764511108398



action possibilites: [-1] 
expected returns: [[34.04399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  1.  8.] 
cards in discard: [1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8 14  0] -> size -> 62 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -180    0    0
   27    0] 
sum of rewards: -108 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 96.84430694580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.241352]
 [30.371658]
 [13.176235]
 [33.487785]
 [35.690304]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  1.  8.] 
cards in discard: [1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8 14  0] -> size -> 62 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.04399108886719






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  8.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0
  6  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6
 16  0  0  0  0  6 14  8  0  3  3  8 14  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0.] 
cards in deck: 50 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0] -> size -> 61 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0.] 
cards in deck: 50 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0] -> size -> 61 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  6. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14.] 
cards in deck: 50 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  5. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  0. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
expected returns: [[39.29161 ]
 [29.22013 ]
 [28.74184 ]
 [36.774273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  0.  8.] 
cards in discard: [ 1. 11. 15. 15.  1.  8.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  5. 10.  0. 10.  4.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14] -> size -> 62 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.6903076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.037407]
 [30.676796]
 [ 5.960044]
 [35.269264]
 [35.800255]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  0.  8.] 
cards in discard: [ 1. 11. 15. 15.  1.  8.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  5. 10.  0. 10.  4.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14] -> size -> 62 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.29161834716797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  5. 10.  0. 10.  4.] 
adversary cards in hand: [11.  1.  1.  0.  3.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14] -> size -> 62 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  5. 10.  0. 10.  4.] 
adversary cards in hand: [11.  1.  1.  0.  3.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14 14] -> size -> 63 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [11.  1.  1.  0.  3.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  1.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 97.577415]
 [100.240746]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1.  0.  3.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 17. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  8.  0.  0. 14.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14 14] -> size -> 63 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.800270080566406



action possibilites: [-1] 
expected returns: [[94.224205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 3.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  8.  0.  0. 14.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14 14] -> size -> 63 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -190    0    0
   27    0] 
sum of rewards: -118 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 98.80370330810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 91.84852 ]
 [ 96.63316 ]
 [ 93.80754 ]
 [ 86.8182  ]
 [ 83.99259 ]
 [ 95.57442 ]
 [ 95.60899 ]
 [109.24258 ]
 [100.26211 ]
 [ 87.753075]
 [ 92.50313 ]
 [ 87.7185  ]
 [ 92.53772 ]
 [ 94.73716 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 3.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 16. 30. 22. 30.  8.  2.  8.  0.  2.  6.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  8.  0.  0. 14.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14 14] -> size -> 63 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.22420501708984



buy possibilites: [-1] 
expected returns: [[111.397484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 3.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 22. 30.  8.  2.  8.  0.  2.  5.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  8.  0.  0. 14.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14 14] -> size -> 63 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -200    0    0
  250    0] 
sum of rewards: 95 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 109.24260711669922






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  0. 14.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  6  0  0 10  0  0  6
  0 14  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16
  0  0  0  0  6 14  8  0  3  3  8 14  0 14 14] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 22. 30.  8.  2.  8.  0.  2.  5.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 25. 11. 29.  1.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25] -> size -> 55 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 22. 30.  8.  2.  8.  0.  2.  5.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 25. 11. 29.  1.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25] -> size -> 55 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 16. 30. 22. 30.  8.  2.  8.  0.  2.  5.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 25. 11. 29.  1.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25] -> size -> 55 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 16. 30. 22. 30.  8.  2.  8.  0.  2.  5.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 25. 11. 29.  1.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25] -> size -> 55 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 1. 25. 11. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[181.95361]
 [192.71194]
 [184.18307]
 [186.12924]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 11. 29.  1.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 16. 30. 22. 30.  8.  2.  8.  0.  2.  5.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0] -> size -> 62 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.3974838256836



action possibilites: [-1] 
expected returns: [[85.21956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.  1.  1.  1.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 16. 30. 22. 30.  8.  1.  8.  0.  2.  5.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6] -> size -> 63 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 192.71197509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 74.9275  ]
 [ 83.11197 ]
 [ 70.61071 ]
 [ 78.79519 ]
 [ 66.532295]
 [ 74.71481 ]
 [ 62.21814 ]
 [ 81.24148 ]
 [ 81.255875]
 [100.29614 ]
 [ 88.5761  ]
 [ 68.541954]
 [ 76.71203 ]
 [ 68.52755 ]
 [ 76.72642 ]
 [ 85.21954 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 29.  1.  1.  1.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25] -> size -> 55 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 9. 16. 30. 22. 30.  8.  1.  8.  0.  2.  5.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6] -> size -> 63 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.21955871582031



buy possibilites: [-1] 
expected returns: [[122.17713]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 29.  1.  1.  1.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25] -> size -> 56 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 16. 30. 22. 30.  8.  1.  8.  0.  2.  4.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6] -> size -> 63 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.    20.     0.     0.     0.
    0.  -210.     0.     0.    62.5    0. ] 
sum of rewards: -132.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 100.29617309570312






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 16. 30. 22. 30.  8.  1.  8.  0.  2.  4.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  8.  3.  0.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25] -> size -> 56 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6] -> size -> 63 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 16. 30. 22. 30.  8.  1.  8.  0.  2.  4.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  8.  3.  0.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25] -> size -> 56 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3] -> size -> 64 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 16. 30. 21. 30.  8.  1.  8.  0.  2.  4.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  8.  3.  0.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25] -> size -> 56 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 15.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8.] 
expected returns: [[142.2496 ]
 [143.55069]
 [136.67072]
 [140.26978]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  8.  3.  0.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 16. 30. 21. 30.  8.  1.  8.  0.  2.  4.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  0. 11. 16.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3] -> size -> 64 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.17713165283203



action possibilites: [-1] 
expected returns: [[125.06043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  0.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  0. 11. 16.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3] -> size -> 64 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: -178 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 141.90142822265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[118.345985]
 [109.01843 ]
 [125.06043 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  3.  0.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  0. 11. 16.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3] -> size -> 64 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.06043243408203






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 11. 16.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  3.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 29.  0.  0. 29.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 16.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 29.  0.  0. 29.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 16.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 29.  0.  0. 29.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 8. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[135.75955]
 [133.59872]
 [136.272  ]
 [136.272  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0. 29.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  6. 10.  0. 14.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.06043243408203



action possibilites: [-1.  8. 11.] 
expected returns: [[108.17611]
 [106.77128]
 [108.01273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  6. 10.  0. 14.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 134.44155883789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[104.81686 ]
 [106.058334]
 [100.89458 ]
 [106.77128 ]
 [108.1761  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 6.  6. 10.  0. 14.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.17610931396484






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 6.  6. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  0. 14.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [29.  1.  3.  1. 29.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  0. 14.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [29.  1.  3.  1. 29.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  1.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[158.49472]
 [152.974  ]
 [152.974  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  1. 29.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  0. 10.  3.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.  6.
  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.17610931396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[143.14346]
 [149.44739]
 [147.08698]
 [134.44067]
 [147.91412]
 [147.73596]
 [152.974  ]
 [139.39383]
 [145.69775]
 [158.49472]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  1. 29.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  0. 10.  3.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.  6.
  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 158.49472045898438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  3.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.  6.
  6. 10.  0. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 10. 25. 15.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11. 29.  1.  3.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 6.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.  6.
  6. 10.  0. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 10. 25. 15.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11. 29.  1.  3.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 6.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.  6.
  6. 10.  0. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29] -> size -> 65 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 10. 25. 15.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11. 29.  1.  3.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 6.] 
cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.  6.
  6. 10.  0. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29  0] -> size -> 66 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 10. 25. 15.] 
adversary cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11. 29.  1.  3.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 1. 29. 10. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25. 15.] 
expected returns: [[75.039345]
 [75.13633 ]
 [68.52749 ]
 [80.68273 ]
 [68.530846]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 10. 25. 15.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11. 29.  1.  3.  1. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 15. 30. 21. 30.  8.  1.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [14.  0.  3.  3.  8.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.  6.
  6. 10.  0. 14.  0. 10.  3.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29  0] -> size -> 66 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.49472045898438



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 2 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 4 
Witch: 6 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 29. 10. 15.  0. 25.] 
cards in discard: [ 1. 11. 15. 15.  1.  8. 10.  0. 15.  0.  8.  1. 25. 11.  1.  1.  0.  3.
 25. 25.  1. 11. 29.  1.  1.  1.  1. 11. 15.  8.  3.  0.  0. 29. 29.  8.
  0. 11. 29.  1.  3.  1. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 11 29 10 25 10 11  8 11
 10  8 15 29 15 29 15 11 15 11 15 11  8  1  1 29  1  1  1  8  1  1  1  1
 25 25 25  1  1  1 25 25  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 15. 30. 21. 30.  8.  0.  8.  0.  2.  4.  2.  4. 10.  0. 10.  4.] 
adversary cards in hand: [14.  0.  3.  3.  8.] 
adversary cards in discard: [14.  0. 11. 16.  6. 10.  0. 14. 15.  0.  0.  8. 14.  3.  1.  0.  0.  0.
  0.  8.  0. 14.  6.  3.  6.  0.  0.  0.  3. 29. 11.  3.  0. 11. 16.  6.
  6. 10.  0. 14.  0. 10.  3.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  3  0  0 10 15 11  1 10 14  0 16 10 11  0  0 10  0  0  6  0 14
  6  0 11  6  3  3  0  6  3  3  8  3  3  6  1  0  0  0  0  8  6 16  0  0
  0  0  6 14  8  0  3  3  8 14  0 14 14  0  6  3 29  0  6] -> size -> 67 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0       0       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000015 

action type: take_action - action 25.0
Learning step: 119997.3671875
desired expected reward: 120078.046875



