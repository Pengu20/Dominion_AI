 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.600143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 3.217759132385254
desired expected reward: -62.226219177246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.417104]
 [22.352207]
 [18.119583]
 [-4.679221]
 [26.571705]
 [19.869225]
 [15.636603]
 [17.21048 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.86258316040039



buy possibilites: [-1] 
expected returns: [[17.868732]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 26.571693420410156






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.636444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.868732452392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[15.204968  ]
 [25.187607  ]
 [21.353252  ]
 [ 0.60329485]
 [22.910149  ]
 [29.027233  ]
 [22.878956  ]
 [29.786701  ]
 [ 8.264835  ]
 [19.04461   ]
 [18.247154  ]
 [20.607735  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.162471771240234



buy possibilites: [-1] 
expected returns: [[18.70536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.786685943603516






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[24.416775]
 [32.4159  ]
 [31.65472 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.705360412597656



action possibilites: [-1. 11.] 
expected returns: [[21.705841]
 [28.446712]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.487464904785156



action possibilites: [-1] 
expected returns: [[35.247826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.367427825927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.74681 ]
 [40.39602 ]
 [36.364227]
 [14.350949]
 [37.97459 ]
 [44.596157]
 [37.97875 ]
 [45.45791 ]
 [22.549137]
 [33.94695 ]
 [33.198338]
 [36.57066 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.247825622558594



buy possibilites: [-1] 
expected returns: [[24.279243]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 45.45790481567383






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.097187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.27924346923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.933388 ]
 [36.34187  ]
 [30.886028 ]
 [ 2.6042743]
 [33.15212  ]
 [41.64161  ]
 [33.16486  ]
 [42.709873 ]
 [12.301934 ]
 [27.709026 ]
 [26.710407 ]
 [31.77327  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.70718002319336



buy possibilites: [-1] 
expected returns: [[74.80108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.70987319946289






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[38.404137]
 [46.092   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.80107879638672



action possibilites: [-1] 
expected returns: [[40.57788]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.55305862426758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.534134]
 [43.202778]
 [21.156887]
 [44.787018]
 [43.808464]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.577880859375



buy possibilites: [-1] 
expected returns: [[19.596077]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 44.787017822265625






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.904968]
 [29.039997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [10.  8. 11.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.59607696533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.054699]
 [34.085594]
 [30.60645 ]
 [12.979909]
 [37.564228]
 [32.01104 ]
 [28.531895]
 [30.2887  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [10.  8. 11.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.84122085571289



buy possibilites: [-1] 
expected returns: [[27.251194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [10.  8. 11.  0.  0.  3.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 37.56422805786133






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  3.  3. 11.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  3.  3. 11.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  3.  3. 11.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[71.706276]
 [79.23951 ]
 [79.23951 ]
 [79.23951 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [10.  8. 11.  0.  0.  3.  3. 11.  0.  0.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.25119400024414



action possibilites: [-1. 29. 29.] 
expected returns: [[58.87106 ]
 [65.293304]
 [65.293304]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 79.31459045410156



action possibilites: [-1. 29.] 
expected returns: [[60.70133]
 [69.61537]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 65.29331970214844



action possibilites: [-1. 11.] 
expected returns: [[67.801125]
 [75.249115]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 69.61537170410156



action possibilites: [-1] 
expected returns: [[77.26291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.3971939086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[68.10687 ]
 [79.07015 ]
 [64.09538 ]
 [75.058655]
 [56.65351 ]
 [52.65142 ]
 [76.53292 ]
 [83.53695 ]
 [76.58517 ]
 [95.974495]
 [84.52115 ]
 [61.12032 ]
 [72.03136 ]
 [72.573685]
 [61.068073]
 [72.083595]
 [76.94477 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.26290893554688



buy possibilites: [-1] 
expected returns: [[54.87635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 137.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 95.97450256347656






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[71.04393 ]
 [76.60332 ]
 [65.321175]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.  0. 10.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.87635040283203



action possibilites: [-1] 
expected returns: [[62.56484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.  0. 10.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 81.32701873779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[51.40573 ]
 [58.00841 ]
 [37.69424 ]
 [59.376507]
 [62.650005]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.  0. 10.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.56483840942383






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 10.] 
cards in discard: [10.  0.  0.  0.  0.  3.  0. 10.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8.  0.  3.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  0.  0.  0.  0.  3.  0. 10.  0.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  9.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8.  0.  3.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  0.  0.  0.  0.  3.  0. 10.  0.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  9.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8.  0.  3.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  0.  0.  0.  0.  3.  0. 10.  0.  0.  3.  0. 16.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8.  0.  3.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[59.204067]
 [56.23155 ]
 [59.877506]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  3.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10. 11.  3. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 10  8 11 10 25 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 62.650020599365234



action possibilites: [-1] 
expected returns: [[78.64554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10. 11.  3. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29 10  8 11 10 25 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 72.36564636230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.01624]
 [53.23744]
 [80.42151]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  3. 10. 11.  3. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29 10  8 11 10 25 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.64553833007812






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29 10  8 11 10 25 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29 10  8 11 10 25 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29 10  8 11 10 25 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[55.20227 ]
 [55.715714]
 [52.187172]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29 10  8 11 10 25 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  3. 10.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.4215087890625



action possibilites: [-1] 
expected returns: [[57.95377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  3. 10.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 55.30186080932617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.65906 ]
 [59.057182]
 [55.2439  ]
 [34.84021 ]
 [63.410603]
 [56.731907]
 [52.91863 ]
 [57.71557 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  7.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  3. 10.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.95376968383789



buy possibilites: [-1] 
expected returns: [[57.838337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  3. 10.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 63.41061782836914






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  3. 10.] 
cards in discard: [10.  0. 11.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  3. 29. 10. 10.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  3.  0.] 
cards in discard: [10.  0. 11.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  3. 29. 10. 10.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  3.  0.] 
cards in discard: [10.  0. 11.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  3. 29. 10. 10.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  3. 29. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10.] 
expected returns: [[73.672325]
 [79.30338 ]
 [80.498375]
 [68.08722 ]
 [68.08722 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29. 10. 10.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.83833694458008



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[66.79173]
 [72.77568]
 [64.59665]
 [64.59665]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 10.  0.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  8.  9.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 78.07404327392578



action possibilites: [-1] 
expected returns: [[34.96268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [11.  8.  0.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  8.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 75.92119598388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.94281 ]
 [37.51374 ]
 [22.427551]
 [38.540157]
 [37.38426 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [11.  8.  0.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  8.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.96268081665039



buy possibilites: [-1] 
expected returns: [[39.728542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [11.  8.  0.  0.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  7.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 38.540164947509766






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  7.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0. 10.  8. 29. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  7.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0. 10.  8. 29. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  7.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0. 10.  8. 29. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 11.  0.  0. 10. 10.  3. 16.  0.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0. 10.  8. 29. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[15.266667]
 [27.532318]
 [19.851463]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  3. 29.] 
cards in discard: [11.  8.  0.  0.  0. 10.  8. 29. 11.  3. 10. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.72854232788086



action possibilites: [-1] 
expected returns: [[80.0072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29. 11. 29.] 
cards in discard: [11.  8.  0.  0.  0. 10.  8. 29. 11.  3. 10. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16. 10.  0.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10  8  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.111434936523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.73333 ]
 [58.022194]
 [80.34899 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29. 11. 29.] 
cards in discard: [11.  8.  0.  0.  0. 10.  8. 29. 11.  3. 10. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16. 10.  0.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10  8  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.0072021484375






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [16. 10.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0.  8.  3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  0 11 10 10  0 16  8 10  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.] 
cards in discard: [6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.] 
cards in discard: [6. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[57.515568]
 [54.297462]
 [63.81165 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.34898376464844



action possibilites: [-1] 
expected returns: [[47.6338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.46841430664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[41.58268 ]
 [50.478485]
 [47.223343]
 [30.256256]
 [54.05035 ]
 [48.409687]
 [48.39292 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  6.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.6338005065918



buy possibilites: [-1] 
expected returns: [[41.73011]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 54.050350189208984






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  8.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  8.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 11.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  8.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
action values: 4 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  8.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 30. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  8.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  8.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[43.665295]
 [51.670155]
 [44.996906]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  8.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3. 10. 10. 10.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.73011016845703



action possibilites: [-1. 10.] 
expected returns: [[38.21738 ]
 [36.713646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3. 10. 10. 10.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.02962112426758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[32.537075]
 [39.273384]
 [36.761124]
 [22.913097]
 [41.8775  ]
 [37.65346 ]
 [36.644947]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  5.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3. 10. 10. 10.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.21738052368164



buy possibilites: [-1] 
expected returns: [[27.252712]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3. 10. 10. 10.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.877498626708984






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3. 10. 10. 10.  0.  0.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 10. 25.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.  8. 11. 29.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3. 10. 10. 10.  0.  0.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 10. 25.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.  8. 11. 29.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3. 10. 10. 10.  0.  0.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  6.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 10. 25.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.  8. 11. 29.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  0. 16. 10.  0.  8.  3. 10. 10. 10.  0.  0.  0. 11.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  5.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 10. 25.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.  8. 11. 29.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 8.  3. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 25.] 
expected returns: [[36.81637 ]
 [37.761368]
 [43.34008 ]
 [34.67333 ]
 [54.081944]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11. 10. 25.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0.  8. 11. 29.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  5.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.25271224975586



action possibilites: [-1] 
expected returns: [[46.956036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11. 10.  3. 11.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0.  8. 11. 29.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.08195114135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.966793]
 [27.24364 ]
 [47.19156 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11. 10.  3. 11.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0.  8. 11. 29.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.95603561401367






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10. 10. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10. 10. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 6. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10. 10. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 10. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 29.] 
expected returns: [[74.294556]
 [66.862915]
 [66.862915]
 [75.84139 ]
 [75.84139 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 29. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [16. 10.  3.  0. 10.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.19156265258789



action possibilites: [-1. 10. 10. 29. 10.] 
expected returns: [[44.17576 ]
 [41.458683]
 [41.458683]
 [47.377274]
 [41.458683]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 10.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [16. 10.  3.  0. 10.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.31661224365234



action possibilites: [-1. 10. 10.] 
expected returns: [[69.97137]
 [64.41944]
 [64.41944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [16. 10.  3.  0. 10.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.749454498291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[62.32417 ]
 [69.9132  ]
 [67.23728 ]
 [54.100567]
 [73.31573 ]
 [68.01953 ]
 [70.895515]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  4.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [16. 10.  3.  0. 10.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 69.97135925292969



buy possibilites: [-1] 
expected returns: [[38.20393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [16. 10.  3.  0. 10.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 73.31573486328125






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [16. 10.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  3.  0. 10.] 
cards in discard: [ 6. 14.  6.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  3.  0. 10.] 
cards in discard: [ 6. 14.  6.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[57.030727]
 [50.829136]
 [54.59359 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  8.] 
cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.20392990112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.900776]
 [54.857372]
 [33.244286]
 [56.162968]
 [58.670944]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  8.] 
cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.166744232177734



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [11.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 25. 29.] 
adversary cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.  3.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 25. 29.] 
adversary cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.  3.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 25. 29.] 
adversary cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.  3.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 8.  3. 11. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25. 29.] 
expected returns: [[61.627666]
 [59.50576 ]
 [66.24152 ]
 [77.963196]
 [67.30336 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11. 25. 29.] 
cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.  3.  0.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.  1. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.67095947265625



action possibilites: [-1] 
expected returns: [[62.682346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11. 29.  0. 11.] 
cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.  3.  0.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.  1. 11.  0. 10.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.96320343017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.68247 ]
 [45.58662 ]
 [63.944126]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11. 29.  0. 11.] 
cards in discard: [ 3. 10. 11. 29. 29. 10. 10.  0.  3.  0.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.  1. 11.  0. 10.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.68234634399414






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.  1. 11.  0. 10.  0.  0.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.  1. 11.  0. 10.  0.  0.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  5.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [ 6. 14.  6.  0.  0.  0.  0. 16. 10.  3.  0. 10.  1. 11.  0. 10.  0.  0.
  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [11. 11. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 11.] 
expected returns: [[39.509876]
 [43.32407 ]
 [43.32407 ]
 [43.32407 ]
 [43.32407 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.94414138793945



action possibilites: [-1] 
expected returns: [[21.022236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.32005310058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.448761]
 [10.709821]
 [20.74767 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.022235870361328






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  0 11 10 10  0 16  8 10  8  6  0  0  3  8
  6 14  1  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  8. 10.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  8. 10.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  8. 10.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15] -> size -> 25 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  8. 10.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15] -> size -> 25 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3.  3. 29.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[12.171535 ]
 [17.27045  ]
 [13.227618 ]
 [11.0845785]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  8. 10.] 
cards in discard: [15. 11. 11. 11. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  3.  8.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8  1] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.7476806640625



action possibilites: [-1. 10. 11.] 
expected returns: [[10.801376]
 [ 9.688685]
 [15.493047]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  3.  8.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8  1] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.67031192779541



action possibilites: [-1] 
expected returns: [[10.577109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  3.  8.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8  1] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 17.643104553222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 7.3274946]
 [-1.4178452]
 [10.451923 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  3.  8.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8  1] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.577109336853027






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3.  8.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10. 11.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15] -> size -> 26 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 6.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0 11 10 10  0 16  8 10  8  6  0  0  3  8  6
 14  1  6  8  1] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10. 11.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15] -> size -> 26 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10. 11.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15] -> size -> 26 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10. 11.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15] -> size -> 26 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [1. 8. 0. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10. 11.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15] -> size -> 26 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 8.  3.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[28.21745 ]
 [27.949463]
 [25.60699 ]
 [31.767681]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10. 11.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  8.] 
adversary cards in hand: [1. 6. 0. 6. 0.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.451926231384277



action possibilites: [-1] 
expected returns: [[32.33796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [1. 6. 0. 6. 0.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.96110153198242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.115192]
 [13.711074]
 [31.024204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 10.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [1. 6. 0. 6. 0.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.33795928955078






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [1. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 6. 0.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 29. 10. 29.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 6. 0.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  4.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 29. 10. 29.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 6. 0.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 29. 10. 29.] 
adversary cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 10. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 29.] 
expected returns: [[ -9.04054 ]
 [-10.072046]
 [ -4.688212]
 [-10.072046]
 [ -4.688212]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 10. 29.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3.  0.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [14. 10.  3. 16.  8.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.024211883544922



action possibilites: [-1. 10. 10.] 
expected returns: [[8.320619]
 [7.624913]
 [7.624913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3.  0.
 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [14. 10.  3. 16.  8.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -6.90185022354126





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 5.1665125]
 [12.064998 ]
 [ 9.428988 ]
 [-4.850582 ]
 [14.657334 ]
 [10.394867 ]
 [ 8.454559 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3.  0.
 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  3.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [14. 10.  3. 16.  8.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.320615768432617



buy possibilites: [-1] 
expected returns: [[6.2484426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [15. 11. 11. 11. 11.  0.  8. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3.  0.
 10. 29. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [14. 10.  3. 16.  8.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 14.657349586486816






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [14. 10.  3. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 16.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  3. 16.  8.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 15. 11. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 16.  8.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 25.  0.] 
adversary cards in discard: [15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 16.  8.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  7.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 25.  0.] 
adversary cards in discard: [15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 16.  8.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  7.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 25.  0.] 
adversary cards in discard: [15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[25.508217]
 [22.865044]
 [32.63792 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  0.] 
cards in discard: [15. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  7.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.  3. 14. 10.  3.
 16.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0   0   0   0 714   0] 
sum of rewards: 799 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 116.57201385498047



action possibilites: [-1] 
expected returns: [[32.475384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8. 29.] 
cards in discard: [15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.  3. 14. 10.  3.
 16.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.1692008972168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.824997]
 [17.292183]
 [33.24613 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8. 29.] 
cards in discard: [15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.  3. 14. 10.  3.
 16.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.47538375854492






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.  3. 14. 10.  3.
 16.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.  3. 14. 10.  3.
 16.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1.  8.  0.  0.  0.  0. 10.  8.  8.  1.  6.  0.  6.  0.  3. 14. 10.  3.
 16.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 4.142644]
 [ 4.592223]
 [10.126027]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  3.  9.  7.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  6.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.24612045288086



action possibilites: [-1] 
expected returns: [[9.086958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  3.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  6.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 12.311966896057129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 6.814166 ]
 [10.41018  ]
 [-1.6810355]
 [11.170215 ]
 [ 9.107312 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  3.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  6.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.086957931518555



buy possibilites: [-1] 
expected returns: [[6.114855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  6.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 11.170211791992188






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [10.  6.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15. 11.  0. 29. 11.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8] -> size -> 30 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.  0.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15. 11.  0. 29. 11.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  8.  0.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15. 11.  0. 29. 11.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  8.  0.] 
cards in discard: [15.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15. 11.  0. 29. 11.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8] -> size -> 30 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [15. 11.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29. 11.] 
expected returns: [[53.607037]
 [48.482895]
 [57.832775]
 [58.823277]
 [57.832775]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 29. 11.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.11485481262207



action possibilites: [-1. 15. 11. 11. 11.] 
expected returns: [[2.579689  ]
 [0.66317844]
 [6.2496367 ]
 [6.2496367 ]
 [6.2496367 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11. 11.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.91967010498047



action possibilites: [-1] 
expected returns: [[13.952083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 8.5233736038208





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 6.7060843]
 [-4.3759108]
 [14.565793 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 11.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.952082633972168






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10.  8. 11.  0.  3.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15] -> size -> 31 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10.  8. 11.  0.  3.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15] -> size -> 31 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  8. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[4.775462 ]
 [1.5234175]
 [4.041507 ]
 [8.712277 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  0.  3.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  0.  8. 14.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.565808296203613



action possibilites: [-1] 
expected returns: [[7.753976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  3.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10.  0.  0.  8. 14.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 11.233325958251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.9881611]
 [-7.01315  ]
 [ 7.644822 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  3.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10.  0.  0.  8. 14.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.753975868225098






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8. 14.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  0 11 10 10  0 16 10  8  0  0  3  8  6 14  1  6  8
  1  0  8  3  6 15  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 11. 10. 29.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11. 15. 11. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 11. 10. 29.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11. 15. 11. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 11. 10. 29.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11. 15. 11. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 11. 10. 29.] 
adversary cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11. 15. 11. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15] -> size -> 32 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 10. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[-1.8951962]
 [-2.7846985]
 [ 2.519699 ]
 [-2.7846985]
 [ 2.9994106]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10. 29.] 
cards in discard: [15. 11. 25. 15.  0.  8. 29. 15.  8. 11. 10.  3.  0.  0.  0. 15. 29. 11.
 15. 11. 11. 15. 11. 10.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 16.  0.  3.  0.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 7.644808769226074



action possibilites: [-1. 10. 11. 10. 11.] 
expected returns: [[4.7312574]
 [2.2478838]
 [7.07001  ]
 [2.2478838]
 [7.07001  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 11.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 16.  0.  3.  0.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 0.5222382545471191



action possibilites: [-1] 
expected returns: [[18.57891]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [ 3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8. 16.  0.  3.  0.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 8.713410377502441





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.993815 ]
 [ 5.7453327]
 [18.119083 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.] 
cards in discard: [ 3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8. 16.  0.  3.  0.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.57891082763672






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  3.  0.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8. 15.  0.  0. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.  3.  0.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  2.  9.  7.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8. 15.  0.  0. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.  3.  0.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  1.  9.  7.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8. 15.  0.  0. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 8. 15.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
expected returns: [[-2.1745877 ]
 [-0.32133675]
 [-3.2949154 ]
 [ 3.7364497 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  0. 11.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  1.  9.  7.  9. 10.  0. 10.  2.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.  8.  8. 16.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.119091033935547



action possibilites: [-1] 
expected returns: [[2.4112568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  0.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  1.  9.  7.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.  8.  8. 16.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 6.2343244552612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.67389035]
 [ 2.9736228 ]
 [-9.229969  ]
 [ 3.73244   ]
 [ 2.2530918 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  0.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  1.  9.  7.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.  8.  8. 16.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.411256790161133



buy possibilites: [-1] 
expected returns: [[6.5294647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  0.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  7.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.  8.  8. 16.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 3.732449531555176






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.  8.  8. 16.  0.
  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  7.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 29. 11. 11. 15.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.  8.  8. 16.  0.
  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  7.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 29. 11. 11. 15.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [15.  0. 11. 10.  6.  8.  0.  3.  0.  0.  0.  8.  0.  8.  8.  8. 16.  0.
  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 29. 11. 11. 15.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10. 29. 11. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 11. 15.] 
expected returns: [[ 7.9783325]
 [ 4.4371023]
 [12.005414 ]
 [11.3530245]
 [11.3530245]
 [ 4.2911415]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 11. 15.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.5294647216796875



action possibilites: [-1. 11. 15. 29.] 
expected returns: [[ 6.8109226]
 [ 9.576995 ]
 [ 4.0106897]
 [10.140168 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 29.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.588469505310059



action possibilites: [-1.  8.] 
expected returns: [[20.69643 ]
 [20.280972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.323117256164551





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[14.207049 ]
 [19.356102 ]
 [ 3.1825695]
 [20.836979 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.696449279785156






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10. 15.  8. 15.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10. 15.  8. 15.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10. 15.  8. 15.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 10. 15.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8. 15.] 
expected returns: [[-5.3879566]
 [-7.7083745]
 [-7.6169853]
 [-6.18764  ]
 [-7.6169853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  8. 15.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 8. 8. 8. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.836997985839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -9.431349]
 [-16.635193]
 [ -5.145022]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  8. 15.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 8. 8. 8. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.387960433959961



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8. 6.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  8  0  0  3  8  6  1  6  8  1  0  8  3
  6 15  0  0  8 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3. 25. 11.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.  0. 10. 15.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3. 25. 11.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.  0. 10. 15.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3. 25. 11.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.  0. 10. 15.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[35.789318]
 [50.27882 ]
 [40.32676 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 11.  0.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.  0. 10. 15.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  6.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 16.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -5.145021915435791



action possibilites: [-1] 
expected returns: [[35.673653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0. 11. 15.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.  0. 10. 15.  8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 16.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6] -> size -> 29 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.27883529663086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[29.308727]
 [34.682915]
 [17.99987 ]
 [36.740204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0. 11. 15.] 
cards in discard: [ 3. 15. 29. 11. 10. 10. 11. 15.  8. 11.  8. 15.  0.  0. 10. 11. 11. 15.
 29. 29.  8.  0. 10. 15.  8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 28. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 16.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6] -> size -> 29 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.67365264892578






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [11.  0. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  8.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 15.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.  8.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 28. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 15.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.  8.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 15.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 15.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 15.] 
expected returns: [[23.980003]
 [21.108192]
 [22.91864 ]
 [21.108192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8. 15.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.74020004272461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.669151 ]
 [11.4171295]
 [23.79562  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8. 15.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.98000717163086



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 11. 11.  8. 25.] 
adversary cards in discard: [ 0. 15.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 27. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 11. 11.  8. 25.] 
adversary cards in discard: [ 0. 15.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 27. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 11. 11.  8. 25.] 
adversary cards in discard: [ 0. 15.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [15. 11. 11.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.  8. 25.] 
expected returns: [[-3.7534802]
 [-5.9711685]
 [ 1.3723869]
 [ 1.3723869]
 [-3.0677466]
 [10.3500185]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11.  8. 25.] 
cards in discard: [ 0. 15.  8. 15.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  5.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10.  1.  6.  1. 29.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3  0] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.79562759399414



action possibilites: [-1] 
expected returns: [[-3.0754972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11.  8. 11. 15.] 
cards in discard: [ 0. 15.  8. 15.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10.  1.  6.  1. 29.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.350015640258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -6.230879 ]
 [-14.8772335]
 [ -2.9889386]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 11.  8. 11. 15.] 
cards in discard: [ 0. 15.  8. 15.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10.  1.  6.  1. 29.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.0754971504211426






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [10.  1.  6.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  6.  1. 29.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  1. 29.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3  0  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.  6.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0
  0  8 29  0  6  3  0  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.  6.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0
  8 29  0  6  3  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 4 
card supply: [20. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.  6.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0
  8 29  0  6  3  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  8.  0.  6.  3. 11.  0. 16.  8.  0.  0.  0.  8.
  3.  3.  0.  6.  6.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0
  8 29  0  6  3  0  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 6 
card supply: [19. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10. 10. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11. 11.] 
expected returns: [[-10.05756  ]
 [-10.774092 ]
 [-10.774092 ]
 [ -5.9687266]
 [ -5.9687266]
 [ -5.9687266]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11. 11.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0
  8 29  0  6  3  0  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.9889395236968994



action possibilites: [-1] 
expected returns: [[-5.600813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0
  8 29  0  6  3  0  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -7.725053787231445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -7.321259 ]
 [-14.11658  ]
 [ -5.6036916]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0
  8 29  0  6  3  0  6  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.600812911987305






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0
  8 29  0  6  3  0  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10.  0. 29.  0. 29.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0
  8 29  0  6  3  0  6  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10.  0. 29.  0. 29.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0  8 29  0  6
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10.  0. 29.  0. 29.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0  8 29  0  6
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10.  0. 29.  0. 29.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0  8 29  0  6
  3  0  6  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10.  0. 29.  0. 29.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[-13.428706]
 [-15.747885]
 [ -9.889555]
 [ -9.889555]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0. 29.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  8. 16.  1.  8.] 
adversary cards in discard: [ 0. 10.  8.] 
adversary owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0  8 29  0  6
  3  0  6  0  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -5.603687763214111



action possibilites: [-1. 10. 29. 15.] 
expected returns: [[12.825423]
 [ 7.510892]
 [16.556175]
 [ 7.496002]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 15.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  8. 16.  1.  8.] 
adversary cards in discard: [ 0. 10.  8.] 
adversary owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0  8 29  0  6
  3  0  6  0  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -12.521296501159668



action possibilites: [-1. 10.] 
expected returns: [[-1.9497988]
 [-4.6595674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  8. 16.  1.  8.] 
adversary cards in discard: [ 0. 10.  8.] 
adversary owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0  8 29  0  6
  3  0  6  0  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.192378044128418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ -6.976242 ]
 [ -3.4524593]
 [-13.643097 ]
 [ -2.1369276]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  8. 16.  1.  8.] 
adversary cards in discard: [ 0. 10.  8.] 
adversary owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0  8 29  0  6
  3  0  6  0  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.9497921466827393






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 16.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 16.  1.  8.] 
cards in discard: [ 0. 10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  8  1  0  8  3  6 15  0  0  8 29  0  6
  3  0  6  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 29. 15.  3. 15.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8.] 
cards in discard: [ 0. 10.  8.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3
  0  6  0  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 29. 15.  3. 15.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8.] 
cards in discard: [ 0. 10.  8.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3
  0  6  0  0  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 29. 15.  3. 15.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8.] 
cards in discard: [ 0. 10.  8.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3
  0  6  0  0  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 29. 15.  3. 15.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [11. 29. 15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15. 15.] 
expected returns: [[-7.121542 ]
 [-3.1626306]
 [-2.8311863]
 [-8.318331 ]
 [-8.318331 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 15.  3. 15.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15.  0.  3. 10.  3.] 
adversary cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8.] 
adversary owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3
  0  6  0  0  1  0] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.136913299560547



action possibilites: [-1. 15. 15. 10.] 
expected returns: [[-5.674572]
 [-8.127207]
 [-8.127207]
 [-8.092286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15.  0.  3. 10.  3.] 
adversary cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8.] 
adversary owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3
  0  6  0  0  1  0] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.021256446838379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.876896]
 [-18.209278]
 [ -6.266581]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15.  0.  3. 10.  3.] 
adversary cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8.] 
adversary owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3
  0  6  0  0  1  0] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.674567222595215






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [15.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 10.  3.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3
  0  6  0  0  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3. 29. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3. 11.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3
  0  6  0  0  1  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3. 29. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 3 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3. 29. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3. 29. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  2.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3. 29. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3. 29. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  3.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[-0.16984367]
 [-3.5071461 ]
 [-1.7232342 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.  8.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3. 29. 15. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  6.  1. 29.  0.] 
adversary cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -6.266576766967773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ -5.9946575]
 [ -2.1555157]
 [-13.512343 ]
 [ -0.1904409]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 15.  8.] 
cards in discard: [ 0. 15.  8. 15.  3. 25. 15. 11. 11.  8. 11. 15.  1. 11. 10. 10. 11. 11.
  0.  0. 15.  8. 29. 29. 10. 11.  3. 29. 15. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  6.  1. 29.  0.] 
adversary cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.16983270645141602



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1. 29.  0.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11. 15. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11. 15. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 26. 30. 27. 30.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11. 15. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.
  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11. 15. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3. 11. 15. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15.  8.] 
expected returns: [[4.6584663]
 [6.9794207]
 [1.9018178]
 [1.9018178]
 [3.5846148]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15. 15.  8.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.
  4. 29.  1.  0.  0.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.1904301643371582



action possibilites: [-1] 
expected returns: [[20.500519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.  8.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.
  4. 29.  1.  0.  0.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 4.896130561828613





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.328628]
 [ 6.820237]
 [20.395485]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 15.  8.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 25. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.
  4. 29.  1.  0.  0.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.500518798828125






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.
  4. 29.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [11.  3.  8. 11.  8.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.
  4. 29.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [11.  3.  8. 11.  8.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 0. 10.  8.  1.  0. 16.  3.  1.  8. 14. 11. 10. 15. 11.  3.  3.  6.  0.
  4. 29.  1.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [11.  3.  8. 11.  8.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.  8.] 
expected returns: [[-6.707515 ]
 [-1.1904945]
 [-4.831808 ]
 [-1.1904945]
 [-4.831808 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 11.  8.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.395496368408203



action possibilites: [-1] 
expected returns: [[0.23357439]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  8.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -3.3499157428741455





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -3.1538038 ]
 [-12.16253   ]
 [  0.51765776]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  8.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.23357439041137695






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 8.009149]
 [11.193141]
 [11.193141]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  0.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 0. 6. 6.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.5176610946655273



action possibilites: [-1. 15.] 
expected returns: [[10.119733]
 [ 9.054757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 0. 6. 6.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.472792625427246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 7.729639 ]
 [10.324162 ]
 [ 1.5645566]
 [10.237014 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 27. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 0. 6. 6.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.119745254516602



buy possibilites: [-1] 
expected returns: [[22.869362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 26. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 0. 6. 6.] 
adversary owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 51 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 10.324166297912598






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [0. 0. 0. 6. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0 16 10  0  0  3  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0
  6  0  0  1  0 14 11  4  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 26. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 25.  1.  0. 29.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3] -> size -> 39 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 0. 0. 6. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 26. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 25.  1.  0. 29.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3] -> size -> 39 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 0. 0. 6. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 26. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 25.  1.  0. 29.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3] -> size -> 39 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 0. 0. 6. 6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 25.  1.  0. 29.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3] -> size -> 39 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [15. 25.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 29.] 
expected returns: [[15.359399]
 [12.576219]
 [22.11977 ]
 [18.515636]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  1.  0. 29.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  4.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11.  1. 15. 11.] 
adversary cards in discard: [0. 0. 0. 6. 6. 0. 8.] 
adversary owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0] -> size -> 30 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.869361877441406



action possibilites: [-1] 
expected returns: [[-8.227831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0. 29. 10.  0.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  3.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11.  1. 15. 11.] 
adversary cards in discard: [0. 0. 0. 6. 6. 0. 8. 6.] 
adversary owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.11977767944336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
expected returns: [[-19.215042 ]
 [-14.202668 ]
 [-15.7806425]
 [-25.41949  ]
 [-15.546979 ]
 [-12.157822 ]
 [-11.693205 ]
 [-21.939392 ]
 [-17.048775 ]
 [-13.75607  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0. 29. 10.  0.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 23. 30. 26. 29.  8.  3.  9.  1.  0.  9.  6.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11.  1. 15. 11.] 
adversary cards in discard: [0. 0. 0. 6. 6. 0. 8. 6.] 
adversary owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.22783088684082



buy possibilites: [-1] 
expected returns: [[-8.429342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0. 29. 10.  0.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  3.  9.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11.  1. 15. 11.] 
adversary cards in discard: [0. 0. 0. 6. 6. 0. 8. 6.] 
adversary owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -11.693212509155273






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  1. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1. 15. 11.] 
cards in discard: [0. 0. 0. 6. 6. 0. 8. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  3.  9.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10. 11. 11. 10.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29] -> size -> 40 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15. 11.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10. 11. 11. 10.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29] -> size -> 40 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15. 11.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10. 11. 11. 10.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29] -> size -> 40 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15. 11.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6 16  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10. 11. 11. 10.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29] -> size -> 40 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [15. 10. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 11. 10.] 
expected returns: [[24.486965]
 [22.239841]
 [22.322758]
 [27.53759 ]
 [27.53759 ]
 [22.322758]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 11. 10.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [10.  0.  6.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11.] 
adversary owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6 16  0] -> size -> 33 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.429342269897461



action possibilites: [-1] 
expected returns: [[-3.511208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 10.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [10.  0.  6.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11.] 
adversary owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6 16  0] -> size -> 33 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 102 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 25.486953735351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -8.479076 ]
 [-15.978341 ]
 [ -3.5112088]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 11. 10.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 22. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [10.  0.  6.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11.] 
adversary owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6 16  0] -> size -> 33 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.5112080574035645






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [10.  0.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  8.  0.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6 16  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10.  0. 11. 15.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1. 11. 15. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 4.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 16 10  1  6  1  0  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1
  0 14 11  4  1  0  6 16  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10.  0. 11. 15.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1. 11. 15. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10.  0. 11. 15.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1. 11. 15. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1] -> size -> 41 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 22. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10.  0. 11. 15.] 
adversary cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1. 11. 15. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1] -> size -> 41 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [15. 10.  0. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 15.] 
expected returns: [[18.652214]
 [13.555118]
 [13.667954]
 [22.258526]
 [13.555118]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 11. 15.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1. 11. 15. 10. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [29. 10.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.] 
adversary owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.5112080574035645



action possibilites: [-1] 
expected returns: [[-3.024509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 15.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1. 11. 15. 10. 11. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [29. 10.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.] 
adversary owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 18.669498443603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -9.263002 ]
 [-19.209953 ]
 [ -3.0245152]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0. 15.] 
cards in discard: [ 1. 11.  3. 15. 15.  8.  1. 11.  3.  8. 11.  8.  0. 29.  3. 29.  3.  0.
 15. 29. 25. 15.  1.  0. 29. 10.  0.  1. 11. 15. 10. 11. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [29. 10.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.] 
adversary owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.0245089530944824






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [29. 10.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  1.  0.  0.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 15.  8. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 15.  8. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 15.  8. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 21. 30. 26. 29.  8.  3.  8.  1.  0.  9.  5.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 15.  8. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 26. 29.  8.  3.  8.  1.  0.  9.  4.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 15.  8. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [ 1. 15.  8. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 15. 11.] 
expected returns: [[12.63149 ]
 [ 9.722616]
 [11.03039 ]
 [ 9.722616]
 [14.106793]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  8. 15. 11.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 26. 29.  8.  3.  8.  1.  0.  9.  4.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  6. 14. 16.  1.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0. 29. 10. 29.  1.  0.  0.] 
adversary owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0 29] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.0245089530944824



action possibilites: [-1] 
expected returns: [[11.552913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  8. 15.] 
cards in discard: [1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 26. 29.  8.  3.  8.  1.  0.  9.  4.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  6. 14. 16.  1.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0. 29. 10. 29.  1.  0.  0.] 
adversary owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0 29] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 142 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 12.230475425720215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 6.3139524 ]
 [ 9.915183  ]
 [-0.99780416]
 [11.453408  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  8. 15.] 
cards in discard: [1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 20. 30. 26. 29.  8.  3.  8.  1.  0.  9.  4.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  6. 14. 16.  1.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0. 29. 10. 29.  1.  0.  0.] 
adversary owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0 29] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.552912712097168






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 1.  6. 14. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 14. 16.  1.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0. 29. 10. 29.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 26. 29.  8.  3.  8.  1.  0.  9.  4.  8. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 15.  3. 15. 29.] 
adversary cards in discard: [ 1. 11.  1. 15.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 16.  1.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0. 29. 10. 29.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 20. 30. 26. 29.  8.  3.  8.  1.  0.  9.  4.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 29.] 
adversary cards in discard: [ 1. 11.  1. 15.  8. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 16.  1.] 
cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0. 29. 10. 29.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 20. 30. 26. 29.  8.  3.  8.  1.  0.  9.  4.  8. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 29.] 
adversary cards in discard: [ 1. 11.  1. 15.  8. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 4 
Witch: 1 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 15. 29.] 
cards in discard: [ 1. 11.  1. 15.  8. 15.  3.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 29  8 11 10 25 10 11 10  8 10 11 11 11
 15 15 15 11 15  8 15 15 15 15  8  1  1  1  3 29  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 26. 29.  8.  3.  8.  1.  0.  9.  4.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 1.  6. 16.  1.] 
adversary cards in discard: [ 0.  0.  0.  6.  6.  0.  8.  6. 16.  0. 11.  3.  1. 15. 11. 10.  8.  0.
  3.  0. 29. 10. 29.  1.  0.  0. 15.] 
adversary owned cards: [11 10 16 10  1  1  8  3  6 15  0  0  8 29  0  6  3  0  6  0  0  1  0 14
 11  1  0  6 16  0 29 15] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0     -80       0       0     976       0] 
sum of rewards: 3001071 

action type: discard_down_to_3_cards - action 1
Learning step: 120043.90625
desired expected reward: 120017.1796875



