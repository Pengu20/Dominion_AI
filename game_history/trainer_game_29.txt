 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.23654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0 -230    0   -5    0  -30    0    0    0    0  -50    0
    0    0] 
sum of rewards: -820 

action type: buy - action 0.0
Learning step: -40.92142868041992
desired expected reward: -42.49287033081055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[316.26273]
 [322.97   ]
 [322.56546]
 [311.93988]
 [310.47342]
 [322.13916]
 [330.49213]
 [323.9509 ]
 [337.01166]
 [331.86542]
 [318.40012]
 [323.53424]
 [323.54636]
 [316.58844]
 [325.34592]
 [340.4679 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.678740501403809
desired expected reward: 330.129150390625



buy possibilites: [-1] 
expected returns: [[334.96545]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -8.041550636291504
desired expected reward: 314.5238952636719






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[334.3776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -8.745125770568848
desired expected reward: 326.2203369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[311.90475]
 [318.80725]
 [306.17584]
 [320.27115]
 [338.997  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.998917579650879
desired expected reward: 326.6965026855469



buy possibilites: [-1] 
expected returns: [[327.35556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -23.043292999267578
desired expected reward: 283.1325378417969






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.0786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.461109161376953
desired expected reward: 317.8944396972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[286.26   ]
 [291.8801 ]
 [280.98898]
 [293.19217]
 [308.1315 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.974047660827637
desired expected reward: 302.4334411621094



buy possibilites: [-1] 
expected returns: [[330.03152]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.487290382385254
desired expected reward: 277.7726745605469






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  3.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[323.05417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.292344093322754
desired expected reward: 320.7391662597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[305.81744]
 [313.11166]
 [312.72473]
 [299.95554]
 [312.22827]
 [321.38058]
 [314.1876 ]
 [322.8539 ]
 [308.19077]
 [313.8007 ]
 [315.77063]
 [332.34604]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.130219459533691
desired expected reward: 315.72454833984375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 14 
action values: 3 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.63925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [10. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.825547218322754
desired expected reward: 323.5204772949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[320.277  ]
 [326.62003]
 [314.49738]
 [327.9808 ]
 [343.47565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [10. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.158415794372559
desired expected reward: 340.58624267578125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [10. 10.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 10.  8.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 10.  8.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[341.97488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.53222370147705
desired expected reward: 333.94342041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[320.54712]
 [327.83408]
 [327.36255]
 [314.44238]
 [326.91983]
 [336.00372]
 [328.89188]
 [337.52213]
 [322.83847]
 [328.42038]
 [330.37912]
 [347.37418]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.75793743133545
desired expected reward: 334.3113708496094



buy possibilites: [-1] 
expected returns: [[377.62863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -7.770060062408447
desired expected reward: 320.06402587890625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[355.36032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.892284393310547
desired expected reward: 366.7363586425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[322.22903]
 [329.35672]
 [328.99686]
 [316.11545]
 [328.4933 ]
 [337.62616]
 [330.3915 ]
 [339.08426]
 [324.5489 ]
 [330.03165]
 [331.94757]
 [348.77115]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 0 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.193035125732422
desired expected reward: 343.26324462890625



buy possibilites: [-1] 
expected returns: [[312.56985]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -8.064558982849121
desired expected reward: 323.883056640625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.  0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  1.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  1.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  0.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  1.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[342.3721]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  1.  6.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -8.55990219116211
desired expected reward: 304.00994873046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[321.6198 ]
 [327.52884]
 [327.08237]
 [316.45966]
 [334.01468]
 [328.36765]
 [327.92114]
 [342.62192]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  1.  6.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.145038604736328
desired expected reward: 330.68121337890625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[328.8021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [10.  3. 10. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -10.784494400024414
desired expected reward: 331.8374938964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[304.31424]
 [311.03262]
 [310.69315]
 [298.55118]
 [310.21942]
 [319.06308]
 [312.0079 ]
 [320.50513]
 [306.50012]
 [311.6684 ]
 [313.48074]
 [329.96744]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [10.  3. 10. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.483872413635254
desired expected reward: 320.4763488769531



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [10.  3. 10. 11.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [10.  3. 10. 11.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [10.  3. 10. 11.  0.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[373.12073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -9.261900901794434
desired expected reward: 320.7055969238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[348.77713]
 [355.22617]
 [354.79425]
 [343.3032 ]
 [362.87582]
 [356.2074 ]
 [355.77548]
 [373.0444 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -11.479737281799316
desired expected reward: 359.03021240234375



buy possibilites: [-1] 
expected returns: [[341.4451]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -4 

action type: buy - action 1.0
Learning step: -10.278794288635254
desired expected reward: 344.9473571777344






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  6. 15.  0.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1] -> size -> 16 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  6. 15.  0.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1] -> size -> 16 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  6. 15.  0.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1] -> size -> 16 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 1.  6. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[357.719 ]
 [345.7965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 15.  0.  3.] 
cards in discard: [0. 0. 3. 0. 0. 1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -10.180185317993164
desired expected reward: 331.2649230957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[341.1272 ]
 [346.2701 ]
 [345.82855]
 [336.51083]
 [351.85272]
 [347.00217]
 [346.56064]
 [359.3977 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 15.  0.  3.] 
cards in discard: [0. 0. 3. 0. 0. 1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -11.15468692779541
desired expected reward: 347.956787109375



buy possibilites: [-1] 
expected returns: [[350.621]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 15.  0.  3.] 
cards in discard: [0. 0. 3. 0. 0. 1. 0. 0. 3. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -20.0 

action type: buy - action 8.0
Learning step: -10.461133003234863
desired expected reward: 336.5409851074219






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [8. 3. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [1. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[309.75186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  3.  0. 11.  3.] 
adversary cards in discard: [ 8.  3.  8.  0. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -11.66300106048584
desired expected reward: 338.9580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[288.08356]
 [294.70517]
 [294.34595]
 [283.86526]
 [282.44244]
 [293.89676]
 [302.17548]
 [295.66312]
 [308.59784]
 [303.51334]
 [290.21942]
 [295.32462]
 [295.3039 ]
 [288.4531 ]
 [297.09094]
 [312.10178]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  3.  0. 11.  3.] 
adversary cards in discard: [ 8.  3.  8.  0. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.80921459197998
desired expected reward: 299.88189697265625



buy possibilites: [-1] 
expected returns: [[294.27817]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 3. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  0. 11.  3.] 
adversary cards in discard: [ 8.  3.  8.  0. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -17.5 

action type: buy - action 10.0
Learning step: -9.018939018249512
desired expected reward: 286.2850036621094






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [10.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.  3.] 
cards in discard: [ 8.  3.  8.  0. 10.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [ 8.  3.  8.  0. 10.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8.  3.  8.  0. 10.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8.  3.  8.  0. 10.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8.  3.  8.  0. 10.  0.  3.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[303.37857]
 [289.28964]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [10.  1.  3.  1.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -10.093103408813477
desired expected reward: 284.18505859375



action possibilites: [-1] 
expected returns: [[301.5058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  1.  3.  1.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: trash_cards_n_from_hand - action 5
Learning step: -8.062169075012207
desired expected reward: 266.85882568359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[277.0294 ]
 [272.22382]
 [298.3655 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  1.  3.  1.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1
Learning step: -9.695525169372559
desired expected reward: 291.8102722167969



buy possibilites: [-1] 
expected returns: [[318.59576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  1.  3.  1.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action 0.0
Learning step: -9.283066749572754
desired expected reward: 267.746337890625






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 11. 10.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.] 
cards in discard: [11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [10.  1.  3.  1.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0] -> size -> 16 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [15.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[243.55608]
 [229.73616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  3.] 
cards in discard: [10.  1.  3.  1.  3.  0.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  3.  3.] 
adversary cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -12.690630912780762
desired expected reward: 305.9051208496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[222.72273]
 [228.16998]
 [227.86357]
 [218.02312]
 [234.8232 ]
 [228.95372]
 [228.64731]
 [243.96907]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  3.] 
cards in discard: [10.  1.  3.  1.  3.  0.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  3.  3.] 
adversary cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -8.92066478729248
desired expected reward: 232.90557861328125



buy possibilites: [-1] 
expected returns: [[234.65488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  3.] 
cards in discard: [10.  1.  3.  1.  3.  0.  0.  8.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  3.  3.] 
adversary cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -24 

action type: buy - action 10.0
Learning step: -7.35263204574585
desired expected reward: 221.29469299316406






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  3.  3.] 
cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 1. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[239.174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -7.465926647186279
desired expected reward: 227.18894958496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[225.55879]
 [228.73933]
 [225.17177]
 [228.43683]
 [223.52234]
 [222.79396]
 [228.24385]
 [232.8021 ]
 [229.26143]
 [236.87015]
 [233.64185]
 [226.41293]
 [228.926  ]
 [228.95894]
 [225.5514 ]
 [229.94357]
 [238.92935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -7.7961626052856445
desired expected reward: 230.72906494140625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [0. 1. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [0. 1. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [11.  0. 10. 11.  3.  0. 10.  8.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [0. 1. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[311.99017]
 [298.47452]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [0. 1. 1. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -6.602575778961182
desired expected reward: 232.32676696777344



action possibilites: [-1.  8.] 
expected returns: [[287.28888]
 [272.7735 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [0. 1. 1. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action 10.0
Learning step: -9.205985069274902
desired expected reward: 290.05242919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[274.25766]
 [279.75543]
 [279.3713 ]
 [269.56674]
 [285.94638]
 [280.54764]
 [280.1635 ]
 [294.16623]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [0. 1. 1. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.54771900177002
desired expected reward: 278.74114990234375



buy possibilites: [-1] 
expected returns: [[252.45668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [ 0.  1.  1.  0.  6. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 6 

action type: buy - action 11.0
Learning step: -8.317042350769043
desired expected reward: 277.6293029785156






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  0. 15.  3.] 
adversary cards in discard: [ 0.  1.  1.  0.  6. 11. 10.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  0. 15.  3.] 
adversary cards in discard: [ 0.  1.  1.  0.  6. 11. 10.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  0. 15.  3.] 
adversary cards in discard: [ 0.  1.  1.  0.  6. 11. 10.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [10.  3.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[226.50655]
 [209.8386 ]
 [211.52754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 15.  3.] 
cards in discard: [ 0.  1.  1.  0.  6. 11. 10.  0.  0.  0.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0. 11.] 
adversary cards in discard: [10.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -9.340883255004883
desired expected reward: 243.1157989501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[202.8287 ]
 [197.58904]
 [226.53328]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 15.  3.] 
cards in discard: [ 0.  1.  1.  0.  6. 11. 10.  0.  0.  0.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0. 11.] 
adversary cards in discard: [10.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -7.954373359680176
desired expected reward: 215.8953399658203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0. 11.] 
cards in discard: [10.  3.  3.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  0. 11.] 
cards in discard: [10.  3.  3.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[214.6957]
 [200.1742]
 [205.8329]
 [200.1742]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [10.  3.  3.  3.  0. 10.  3.  8. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -8.30526065826416
desired expected reward: 218.22801208496094



action possibilites: [-1] 
expected returns: [[233.9301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [10.  3.  3.  3.  0. 10.  3.  8. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -40    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -323 

action type: gain_card_n - action 3
Learning step: -20.481964111328125
desired expected reward: 171.4258575439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[219.36302]
 [214.93065]
 [237.28304]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [10.  3.  3.  3.  0. 10.  3.  8. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -7.705665588378906
desired expected reward: 226.22442626953125






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [10.  3.  3.  3.  0. 10.  3.  8. 11.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 1. 8. 0.] 
adversary cards in discard: [ 6. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 19 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [10.  3.  3.  3.  0. 10.  3.  8. 11.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 1. 8. 0.] 
adversary cards in discard: [ 6. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 19 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [10.  3.  3.  3.  0. 10.  3.  8. 11.  0. 11.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 1. 8. 0.] 
adversary cards in discard: [ 6. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 19 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[192.803 ]
 [178.9981]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 8. 0.] 
cards in discard: [ 6. 11. 10.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -9.8157958984375
desired expected reward: 227.4672393798828



action possibilites: [-1] 
expected returns: [[214.98656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 6. 11. 10.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 6
Learning step: -5.031380653381348
desired expected reward: 158.34017944335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[190.98624]
 [197.36923]
 [197.07373]
 [185.50735]
 [204.6355 ]
 [198.2873 ]
 [197.99179]
 [214.28827]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 6. 11. 10.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -7.864176273345947
desired expected reward: 207.12237548828125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [ 6. 11. 10.  0. 10.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [ 6. 11. 10.  0. 10.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [ 6. 11. 10.  0. 10.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [ 6. 11. 10.  0. 10.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[218.29097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [ 6. 11. 10.  0. 10.  3.  8.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3. 11.] 
adversary cards in discard: [ 0.  8. 10.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -8.047060012817383
desired expected reward: 206.24122619628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[198.80202]
 [204.29073]
 [204.03992]
 [194.09029]
 [210.54587]
 [205.0852 ]
 [204.83438]
 [219.15321]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [ 6. 11. 10.  0. 10.  3.  8.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3. 11.] 
adversary cards in discard: [ 0.  8. 10.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.292628288269043
desired expected reward: 208.03424072265625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [10.  3.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  3. 11.] 
cards in discard: [ 0.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8.  1. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  3. 11.] 
cards in discard: [ 0.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8.  1. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  3. 11.] 
cards in discard: [ 0.  8. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8.  1. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 3.  8.  1. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[155.59863]
 [142.77211]
 [143.8328 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  1. 15.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [ 0.  8. 10.  0. 10.  3.  3.  3. 11.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -9.79150104522705
desired expected reward: 209.36170959472656



action possibilites: [-1] 
expected returns: [[205.97697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [ 0.  8. 10.  0. 10.  3.  3.  3. 11.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 15.0
Learning step: -3.7302768230438232
desired expected reward: 139.56491088867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[189.97253]
 [193.96536]
 [186.30708]
 [194.86464]
 [205.82787]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [ 0.  8. 10.  0. 10.  3.  3.  3. 11.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -7.039436340332031
desired expected reward: 198.93753051757812



buy possibilites: [-1] 
expected returns: [[209.94362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 3.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [ 0.  8. 10.  0. 10.  3.  3.  3. 11.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -7.474896430969238
desired expected reward: 182.49765014648438






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  8.] 
cards in discard: [ 0.  8. 10.  0. 10.  3.  3.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 0.  8. 10.  0. 10.  3.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 0.  8. 10.  0. 10.  3.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 24. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 0.  8. 10.  0. 10.  3.  3.  3. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[216.84227]
 [211.24307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 0. 15.  3.  8.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -8.385915756225586
desired expected reward: 201.55770874023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[202.3639 ]
 [207.20055]
 [206.87013]
 [198.15292]
 [212.21704]
 [207.83833]
 [207.48933]
 [218.10707]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 0. 15.  3.  8.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 23. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -8.730000495910645
desired expected reward: 206.8975830078125



buy possibilites: [-1] 
expected returns: [[212.01012]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 0. 15.  3.  8.  1.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -41.0 

action type: buy - action 3.0
Learning step: -7.34902811050415
desired expected reward: 199.52110290527344






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 6.] 
adversary cards in discard: [ 0. 15.  3.  8.  1.  3.  3.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 6.] 
adversary cards in discard: [ 0. 15.  3.  8.  1.  3.  3.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 22. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 6.] 
adversary cards in discard: [ 0. 15.  3.  8.  1.  3.  3.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 6.] 
adversary cards in discard: [ 0. 15.  3.  8.  1.  3.  3.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [0. 1. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[145.31056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 6.] 
cards in discard: [ 0. 15.  3.  8.  1.  3.  3.  3.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -9.567883491516113
desired expected reward: 202.44223022460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[128.76166]
 [134.79486]
 [134.51707]
 [123.55286]
 [134.08844]
 [141.93167]
 [135.67967]
 [143.14037]
 [130.70535]
 [135.39801]
 [137.05417]
 [151.41454]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 6.] 
cards in discard: [ 0. 15.  3.  8.  1.  3.  3.  3.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -6.044238567352295
desired expected reward: 135.4056396484375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 10.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8. 15. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  3.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8. 15. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8. 15. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8. 15. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 0.  8. 15. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10. 10.] 
expected returns: [[158.2626 ]
 [145.31155]
 [146.31274]
 [145.1055 ]
 [145.1055 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15. 10. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 10.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  8. 10. 10.  3.  3.  0.  3.  3.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -6.316369533538818
desired expected reward: 145.0981903076172



action possibilites: [-1.  8. 15. 10.] 
expected returns: [[109.597176]
 [ 99.36599 ]
 [100.06716 ]
 [ 99.049904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15. 10.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 10.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  8. 10. 10.  3.  3.  0.  3.  3.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -21 

action type: take_action - action 10.0
Learning step: -5.932394504547119
desired expected reward: 138.79872131347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 95.21756 ]
 [ 99.10095 ]
 [ 98.80292 ]
 [ 92.169464]
 [103.64115 ]
 [ 99.65188 ]
 [ 99.353836]
 [109.93672 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15. 10.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 10.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  8. 10. 10.  3.  3.  0.  3.  3.] 
adversary owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -4.30678653717041
desired expected reward: 105.2904052734375






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 10.  0.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  8. 10. 10.  3.  3.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [10.  0.  8. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  8. 10. 10.  3.  3.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [10.  0.  8. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  8. 10. 10.  3.  3.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [10.  0.  8. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [3. 6. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[151.67722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 3. 0.] 
cards in discard: [10.  0.  8. 15. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 20 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -4.257622241973877
desired expected reward: 105.67910766601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[138.98512]
 [142.7601 ]
 [142.47542]
 [135.66081]
 [146.91257]
 [143.29642]
 [143.01173]
 [151.50488]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 3. 0.] 
cards in discard: [10.  0.  8. 15. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 20 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -6.397069931030273
desired expected reward: 144.2346954345703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  6. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [10.  0.  8. 15. 10.  1.  3.  6.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [10.  0.  8. 15. 10.  1.  3.  6.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [10.  0.  8. 15. 10.  1.  3.  6.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[184.6537 ]
 [177.19885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [10.  0.  8. 15. 10.  1.  3.  6.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.  3.  8.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -5.700746536254883
desired expected reward: 145.8041229248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[165.70914]
 [170.49864]
 [170.2528 ]
 [161.64996]
 [175.93428]
 [171.1952 ]
 [170.94936]
 [183.24243]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [10.  0.  8. 15. 10.  1.  3.  6.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.  3.  8.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -7.267475128173828
desired expected reward: 173.98199462890625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  3.  8.] 
cards in discard: [ 8. 11.  3.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 1. 15.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.  3.  8.] 
cards in discard: [ 8. 11.  3.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 1. 15.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 15.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[162.4684 ]
 [151.68451]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  3.  0.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 11.  0.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -7.734499454498291
desired expected reward: 175.50794982910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[149.95818]
 [154.69829]
 [154.4581 ]
 [145.99263]
 [160.1584 ]
 [155.39134]
 [155.15114]
 [167.63025]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  3.  0.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 21. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 11.  0.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -6.689088344573975
desired expected reward: 155.92674255371094



buy possibilites: [-1] 
expected returns: [[194.00233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  3.  0.  6.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 20. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 11.  0.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -30.0 

action type: buy - action 3.0
Learning step: -4.857851982116699
desired expected reward: 149.60023498535156






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 11.  0.] 
cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [ 3.  1. 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3] -> size -> 20 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 11.  0.] 
cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 20. 30.  8.  7. 10.  7.  5. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [ 3.  1. 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3] -> size -> 20 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 11.  0.] 
cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [ 3.  1. 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3] -> size -> 20 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3. 10. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[185.65611]
 [170.84273]
 [170.84273]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.  3.] 
cards in discard: [ 3.  1. 15.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  3.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.  8.  0.  6.  3. 11.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -7.411838054656982
desired expected reward: 186.5904998779297



action possibilites: [-1. 10.  8.] 
expected returns: [[152.40468]
 [140.45387]
 [140.70055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  8.] 
cards in discard: [ 3.  1. 15.  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  3.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.  8.  0.  6.  3. 11.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action 10.0
Learning step: -5.510898590087891
desired expected reward: 158.9628448486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[139.85197]
 [136.53523]
 [157.42632]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  8.] 
cards in discard: [ 3.  1. 15.  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  3.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.  8.  0.  6.  3. 11.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -4.867284774780273
desired expected reward: 147.5373992919922



buy possibilites: [-1] 
expected returns: [[169.89273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  8.] 
cards in discard: [ 3.  1. 15.  3.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  3.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.  8.  0.  6.  3. 11.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -4.9910197257995605
desired expected reward: 134.8609619140625






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  3.] 
cards in discard: [ 8. 11.  3.  3.  0.  8.  8. 10. 10.  3.  8.  8.  0.  6.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 3.  1. 15.  3.  0.  6.  0. 10.  3. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 3.  1. 15.  3.  0.  6.  0. 10.  3. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 3.  1. 15.  3.  0.  6.  0. 10.  3. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[173.13051]
 [165.80273]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 3.  1. 15.  3.  0.  6.  0. 10.  3. 10.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -6.280450820922852
desired expected reward: 163.61227416992188



action possibilites: [-1] 
expected returns: [[154.3177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  1. 15.  3.  0.  6.  0. 10.  3. 10.  0.  3.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -3 

action type: gain_card_n - action 9
Learning step: -4.915853977203369
desired expected reward: 159.8441925048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[136.94016]
 [140.8104 ]
 [140.55556]
 [133.91711]
 [146.79126]
 [141.47229]
 [141.22519]
 [154.26842]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  1. 15.  3.  0.  6.  0. 10.  3. 10.  0.  3.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 20. 30.  8.  7. 10.  7.  4. 10. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -5.025861740112305
desired expected reward: 149.29183959960938



buy possibilites: [-1] 
expected returns: [[124.07049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  1. 15.  3.  0.  6.  0. 10.  3. 10.  0.  3.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  4. 10. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -20.054269790649414
desired expected reward: 113.86284637451172






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  8.  0.] 
cards in discard: [10.  0.  3.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  4. 10. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  8.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 23 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  4. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  8.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 23 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  4. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  8.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 23 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  8.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 23 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [11.  8.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[106.854324]
 [101.16089 ]
 [ 97.83511 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0  1 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10.  3. 10.  6.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -6.087959289550781
desired expected reward: 117.98252868652344



action possibilites: [-1] 
expected returns: [[86.88052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10.  3. 10.  6.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.8107292652130127
desired expected reward: 88.50009155273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.11775]
 [75.9397 ]
 [88.51834]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 10.  3. 10.  6.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -3.6153576374053955
desired expected reward: 83.26516723632812






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3. 10.  6.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 15.  3.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3. 10.  6.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 15.  3.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3. 10.  6.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 15.  3.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [10.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[114.25226 ]
 [103.816345]
 [104.88106 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  3.  0.] 
cards in discard: [ 8. 11.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 11.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.  0.  8. 10.  3. 10.
  6.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -4.200436115264893
desired expected reward: 84.31790161132812



action possibilites: [-1. 15.] 
expected returns: [[104.938736]
 [ 98.304375]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  3.] 
cards in discard: [ 8. 11.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 11.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.  0.  8. 10.  3. 10.
  6.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action 10.0
Learning step: -3.8115127086639404
desired expected reward: 95.6624984741211



action possibilites: [-1.] 
expected returns: [[119.868256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8. 11.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 11.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.  0.  8. 10.  3. 10.
  6.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 15.0
Learning step: -2.368183135986328
desired expected reward: 95.93618774414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[107.87153 ]
 [111.51956 ]
 [111.21975 ]
 [104.45132 ]
 [111.04748 ]
 [115.516365]
 [112.044106]
 [116.274956]
 [108.903076]
 [111.744286]
 [112.67517 ]
 [120.904465]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8. 11.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 20. 30.  8.  6. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 11.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.  0.  8. 10.  3. 10.
  6.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -3.5542068481445312
desired expected reward: 116.31404876708984



buy possibilites: [-1] 
expected returns: [[125.615524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8. 11.  6.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  3. 11.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.  0.  8. 10.  3. 10.
  6.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -18.09621810913086
desired expected reward: 86.35511779785156






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  3. 11.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.  0.  8. 10.  3. 10.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  1.] 
adversary cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  3. 11.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  8. 11.  0.  3.  8.  0.  0.  8. 10.  3. 10.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  1.] 
adversary cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[75.921646]
 [67.017235]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  1.] 
cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -7.360081672668457
desired expected reward: 118.25543975830078



action possibilites: [-1.] 
expected returns: [[79.57788]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action 10.0
Learning step: -3.0694737434387207
desired expected reward: 62.97601318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[72.971466]
 [76.18974 ]
 [75.996346]
 [70.17445 ]
 [75.80512 ]
 [80.48512 ]
 [76.662186]
 [81.23126 ]
 [73.94049 ]
 [76.468796]
 [77.35516 ]
 [86.50267 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -3.8730316162109375
desired expected reward: 75.70484924316406






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3. 10.  6.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3. 10.  6.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[50.08532 ]
 [41.934242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3. 10.  6.  0.  0.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  8.  0.  0.  8.] 
adversary cards in discard: [ 3.  0. 11. 10.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -5.9583353996276855
desired expected reward: 80.5443344116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.831043]
 [42.72505 ]
 [37.389576]
 [43.317623]
 [51.206142]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 8. 11.  6.  0.  6. 10. 15.  3.  0.  3. 10.  6.  0.  0.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  8.  0.  0.  8.] 
adversary cards in discard: [ 3.  0. 11. 10.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -4.174747467041016
desired expected reward: 45.91057586669922



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [11.  8.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  8.] 
cards in discard: [ 3.  0. 11. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10. 11.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  8.] 
cards in discard: [ 3.  0. 11. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10. 11.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 11.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[128.92743]
 [119.7972 ]
 [123.43283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  6.  0.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3. 14.  3.  8.] 
adversary cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -2.472578525543213
desired expected reward: 48.73356628417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.66861]
 [112.99471]
 [127.81305]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6.  0.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3. 14.  3.  8.] 
adversary cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -6.306584358215332
desired expected reward: 120.68932342529297



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 14.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  3.  8.] 
cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [10. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8.] 
cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 8.] 
cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[85.429596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [10. 11.  6.  0.  6.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  8.] 
adversary cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8. 14.  3.  3.  3.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: discard_down_to_3_cards - action 1
Learning step: -2.0266828536987305
desired expected reward: 22.609046936035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.5692 ]
 [70.77937]
 [86.09447]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [10. 11.  6.  0.  6.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  8.] 
adversary cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8. 14.  3.  3.  3.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -5.133336067199707
desired expected reward: 79.5379409790039



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  6.  8.] 
cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8. 14.  3.  3.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10. 15.  6.  0.  3.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6.  8.] 
cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8. 14.  3.  3.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10. 15.  6.  0.  3.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6.  8.] 
cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8. 14.  3.  3.  3.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10. 15.  6.  0.  3.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [10. 15.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[93.90918]
 [85.33151]
 [86.18125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  6.  0.  3.] 
cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  3.  3.] 
adversary cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8. 14.  3.  3.  3.  8.  0.  3.  0.
 10.  6.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -4.9969096183776855
desired expected reward: 81.0975570678711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[82.0394 ]
 [79.17745]
 [94.14177]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  6.  0.  3.] 
cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  3.  3.] 
adversary cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8. 14.  3.  3.  3.  8.  0.  3.  0.
 10.  6.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -5.3511762619018555
desired expected reward: 87.37428283691406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3.  3.] 
cards in discard: [ 3.  0. 11. 10.  8. 11.  8.  0.  0.  8. 14.  3.  3.  3.  8.  0.  3.  0.
 10.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 8.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0. 10. 15.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 8.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0. 10. 15.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 1. 3. 0. 8.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0. 10. 15.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 1. 3. 0. 8.] 
adversary cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0. 10. 15.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [0. 1. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[105.78212]
 [ 97.11143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 8.] 
cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0. 10. 15.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  3.  6.] 
adversary cards in discard: [15. 10. 11.  8.  0.  3.  3.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -5.090944290161133
desired expected reward: 89.05082702636719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 98.46333 ]
 [101.67931 ]
 [101.45379 ]
 [ 95.64718 ]
 [101.28016 ]
 [105.25894 ]
 [102.147125]
 [105.86017 ]
 [ 99.400665]
 [101.9216  ]
 [102.73801 ]
 [109.81212 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 8.] 
cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0. 10. 15.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  3.  6.] 
adversary cards in discard: [15. 10. 11.  8.  0.  3.  3.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -5.63153076171875
desired expected reward: 100.15058135986328



buy possibilites: [-1] 
expected returns: [[35.777866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 8.] 
cards in discard: [10. 11.  6.  0.  6.  0.  3.  6.  3.  0. 10. 15.  6.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  3.  6.] 
adversary cards in discard: [15. 10. 11.  8.  0.  3.  3.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -49.5 

action type: buy - action 10.0
Learning step: -6.766078472137451
desired expected reward: 95.15553283691406






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3.  6.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  6. 10.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 8.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
action values: 3 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 8.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 8.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[86.09059 ]
 [75.843636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 3. 8. 3. 8.] 
adversary cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -2.6543657779693604
desired expected reward: 33.12350082397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.35228 ]
 [75.023735]
 [68.12353 ]
 [75.82749 ]
 [85.918785]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 3. 8. 3. 8.] 
adversary cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.] 
adversary owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -5.168281078338623
desired expected reward: 79.71289825439453



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 8.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0  3 10  3 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8
  0  0 15  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6. 10.  6.  3.  8.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6. 10.  6.  3.  8.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6. 10.  6.  3.  8.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 6. 10.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[73.02975 ]
 [66.140175]
 [66.334694]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  3.  8.] 
cards in discard: [ 0.  0.  3. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  6  0 15  1  8 10  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.  8.  0.  8.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -4.470860481262207
desired expected reward: 81.44791412353516



action possibilites: [-1] 
expected returns: [[80.75959]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  0.  3. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.  8.  0.  8.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.8685534000396729
desired expected reward: 57.844329833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.57665 ]
 [70.27105 ]
 [83.423485]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  0.  3. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.  8.  0.  8.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -2.9789609909057617
desired expected reward: 77.78063201904297






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  3.  0.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6. 10.  3.  0. 10.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  8.  6.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 20 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0. 10.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 20 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10. 10.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0. 10.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 20 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [15. 10. 11.  8.  0.  3.  3.  0. 10. 10.  8.  0.  3.  6.  8.  8.  0.  8.
 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0. 10.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 20 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[82.75944]
 [74.52654]
 [74.52654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: discard_down_to_3_cards - action 8
Learning step: -2.7011637687683105
desired expected reward: 52.70713806152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[70.654015]
 [68.050865]
 [82.34921 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -4.086554050445557
desired expected reward: 78.14533996582031



buy possibilites: [-1] 
expected returns: [[96.94933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -64.0 

action type: buy - action 0.0
Learning step: -4.551340579986572
desired expected reward: 66.10266876220703






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 20. 30.  8.  5. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 15.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 15.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 15.  1.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3. 15.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[89.22718]
 [82.5973 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  0.  0.] 
cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.  0. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  6.  3.  3. 10.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -4.088756084442139
desired expected reward: 92.86058044433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[79.33319 ]
 [82.336365]
 [82.11672 ]
 [76.703415]
 [81.96376 ]
 [85.67066 ]
 [82.772835]
 [86.26796 ]
 [80.18596 ]
 [82.553185]
 [83.303444]
 [90.05408 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  0.  0.] 
cards in discard: [ 0.  0.  3. 10.  3.  8.  6.  6.  3.  0. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  6.  3.  3. 10.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -3.742567539215088
desired expected reward: 85.48460388183594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  3. 10.] 
cards in discard: [ 6. 11.  0.  3.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 10.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  3. 15.] 
cards in discard: [ 6. 11.  0.  3.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 10.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  3. 15.] 
cards in discard: [ 6. 11.  0.  3.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 10.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [10. 10.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[88.531044]
 [76.94694 ]
 [76.94694 ]
 [81.56628 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [29.  8. 11.  3.  0.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.890727996826172
desired expected reward: 86.16334533691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[69.546616]
 [65.787796]
 [85.97937 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 20. 30.  8.  4. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [29.  8. 11.  3.  0.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -3.724752902984619
desired expected reward: 81.85922241210938



buy possibilites: [-1] 
expected returns: [[60.674797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  6. 11.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [29.  8. 11.  3.  0.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -335.0 

action type: buy - action 6.0
Learning step: -18.67420768737793
desired expected reward: 47.11359405517578






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [29.  8. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11.  3.  0.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 11.  3.  0.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 11.  3.  0.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[74.80183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 6. 10. 10.  0.  6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  8. 10. 14.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -3.0998175144195557
desired expected reward: 57.57497787475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[64.265274]
 [66.576614]
 [66.3698  ]
 [62.254646]
 [69.09011 ]
 [66.907814]
 [66.70098 ]
 [72.39927 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 6. 10. 10.  0.  6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  8. 10. 14.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.] 
adversary owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -3.945361375808716
desired expected reward: 70.89563751220703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10. 14.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  6.  0.  8.  0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 14.  8.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8 14  8  0  0
 15  0 29  6  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  6.  0.  8.  0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  6.  0.  8.  0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  6.  0.  8.  0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [10.  6.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[84.95302 ]
 [79.59562 ]
 [79.753914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  8.  0.] 
cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3. 10.  0.  8.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.
 10.  8.  0.  0.] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -3.5104293823242188
desired expected reward: 68.88883972167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[81.11539]
 [82.88933]
 [79.41192]
 [83.33276]
 [88.69595]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  8.  0.] 
cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3. 10.  0.  8.] 
adversary cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.
 10.  8.  0.  0.] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -4.084702968597412
desired expected reward: 80.86832427978516



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  0.  8.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.
 10.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  3.  3.  1.  0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0. 10.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  0.  8.] 
cards in discard: [ 6. 11.  0.  3.  0.  8. 10.  0.  6.  3.  3. 15.  0. 29.  8. 11.  3.  0.
 10.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  3.  3.  1.  0.] 
adversary cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0. 10.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15.  3.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[31.938543]
 [24.559223]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  1.  0.] 
cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0. 10.  6.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -5.2010979652404785
desired expected reward: 77.10462951660156



action possibilites: [-1] 
expected returns: [[77.70372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0. 10.  6.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 15.0
Learning step: -0.22962771356105804
desired expected reward: 24.329601287841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[67.5744  ]
 [70.26573 ]
 [70.08616 ]
 [65.82158 ]
 [65.23041 ]
 [69.93838 ]
 [73.28127 ]
 [70.66031 ]
 [76.02478 ]
 [73.80599 ]
 [68.35029 ]
 [70.42765 ]
 [70.480736]
 [67.62835 ]
 [71.14958 ]
 [77.604645]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0. 10.  6.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 28. 30. 20. 30.  8.  3. 10.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -2.9935824871063232
desired expected reward: 74.71013641357422



buy possibilites: [-1] 
expected returns: [[42.69539]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 6. 10. 10.  0.  6. 11.  3.  0.  0.  6.  0. 10.  6.  0.  8.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 20. 30.  8.  3.  9.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -7.0 

action type: buy - action 16.0
Learning step: -2.8862721920013428
desired expected reward: 67.0521011352539






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3.  9.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 28. 30. 20. 30.  8.  3.  9.  7.  3. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16] -> size -> 22 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16] -> size -> 22 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [6. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[54.560894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  8. 11.  3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0  8] -> size -> 28 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -2.716937780380249
desired expected reward: 39.978450775146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.9974  ]
 [38.48567 ]
 [52.251884]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  8. 11.  3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0  8] -> size -> 28 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -3.292546510696411
desired expected reward: 48.611083984375



buy possibilites: [-1] 
expected returns: [[88.992035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 3.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  8. 11.  3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0  8] -> size -> 28 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -3.2975494861602783
desired expected reward: 37.69985580444336






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [10.  3.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8. 11.  3.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  0 10 10  8  3  3 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0
 29  6  0  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  6.] 
adversary cards in discard: [0. 6. 3. 0. 6. 3.] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  6.] 
adversary cards in discard: [0. 6. 3. 0. 6. 3.] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  6.] 
adversary cards in discard: [0. 6. 3. 0. 6. 3.] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[93.46095 ]
 [87.059326]
 [87.41566 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  6.] 
cards in discard: [0. 6. 3. 0. 6. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8. 15.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -3.193969964981079
desired expected reward: 85.79806518554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[83.93757 ]
 [85.432274]
 [82.31537 ]
 [86.03181 ]
 [91.56667 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  0.  6.] 
cards in discard: [0. 6. 3. 0. 6. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8. 15.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -3.3456246852874756
desired expected reward: 88.08724975585938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  0.  0.] 
cards in discard: [8. 3. 0. 0. 0. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 16. 10.  1.  3.] 
adversary cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6.] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3.  0.  0.] 
cards in discard: [8. 3. 0. 0. 0. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 20. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 16. 10.  1.  3.] 
adversary cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6.] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3.  0.  0.] 
cards in discard: [8. 3. 0. 0. 0. 0. 8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 19. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 16. 10.  1.  3.] 
adversary cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6.] 
adversary owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 0. 16. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[114.00109]
 [102.98663]
 [103.80751]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  1.  3.] 
cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  1  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 19. 30.  8.  3.  9.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8.  8.  0.  8.] 
adversary cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.] 
adversary owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8
  3] -> size -> 25 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -3.3675925731658936
desired expected reward: 88.19905090332031



action possibilites: [-1] 
expected returns: [[57.583614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.] 
cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8.  8.  0.  8.] 
adversary cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.] 
adversary owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8
  3] -> size -> 25 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 11 

action type: gain_card_n - action 5
Learning step: -1.0849800109863281
desired expected reward: 57.527244567871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.10113 ]
 [49.209904]
 [59.782146]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8.  8.  0.  8.] 
adversary cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.] 
adversary owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8
  3] -> size -> 25 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -1.8787552118301392
desired expected reward: 55.70486068725586






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [10.  8.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  0.  8.] 
cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10  8 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  3.  6. 11.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6. 16. 16.  0. 10.  3.] 
adversary owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  3.  6. 11.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6. 16. 16.  0. 10.  3.] 
adversary owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  3.  6. 11.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6. 16. 16.  0. 10.  3.] 
adversary owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  3.  6. 11.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6. 16. 16.  0. 10.  3.] 
adversary owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [15.  3.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[26.202951]
 [21.211548]
 [22.973448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6. 11.  0.] 
cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6. 16. 16.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  6. 11. 10.] 
adversary cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.  0.  8. 10.  8.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -3.6899659633636475
desired expected reward: 56.09219741821289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.08602 ]
 [16.485985]
 [25.978336]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6. 11.  0.] 
cards in discard: [ 0.  6.  3.  0.  6.  3. 10.  0.  8.  0.  6. 16. 16.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  6. 11. 10.] 
adversary cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.  0.  8. 10.  8.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -2.061119556427002
desired expected reward: 24.141836166381836



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  6. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 11. 10.] 
cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.  0.  8. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11. 10.] 
cards in discard: [ 8.  3.  0.  0.  0.  0.  8.  3.  8. 15.  3.  0.  0.  0.  8. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
adversary victory points: 0
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 16.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[37.22974 ]
 [31.13036 ]
 [31.569393]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -1.632663607597351
desired expected reward: 21.062789916992188



action possibilites: [-1. 16.] 
expected returns: [[40.87954 ]
 [34.863567]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 19. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 10.0
Learning step: -0.8914194107055664
desired expected reward: 29.44530487060547



action possibilites: [-1.] 
expected returns: [[57.37791]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 18. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  40   0   0   0   0   0   0   0   4   0] 
sum of rewards: 30 

action type: gain_card_n - action 1
Learning step: 0.784981369972229
desired expected reward: 40.90541458129883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.520184]
 [46.500782]
 [59.644604]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 18. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: -0.3462243974208832
desired expected reward: 57.03168487548828






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  6. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 18. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  6. 10.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3] -> size -> 23 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 18. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  6. 10.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3] -> size -> 23 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 18. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  6. 10.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3] -> size -> 23 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 6.  0. 10.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[53.75325]
 [48.37891]
 [48.37891]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  6. 10.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 18. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -2.5663583278656006
desired expected reward: 57.07823181152344



action possibilites: [-1. 10.] 
expected returns: [[58.898746]
 [55.39188 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 10.  3.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 18. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 10.0
Learning step: -0.7295989990234375
desired expected reward: 45.84949493408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.19244 ]
 [52.892063]
 [59.21342 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 10.  3.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 18. 30.  8.  3.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -1.368407964706421
desired expected reward: 57.530330657958984



buy possibilites: [-1] 
expected returns: [[28.125427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 10.  3.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 18. 30.  8.  2.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -17.261781692504883
desired expected reward: 35.630287170410156






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  0.] 
cards in discard: [29.  3.  3.  0.  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 18. 30.  8.  2.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  0.  6.  8. 11.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [29.  3.  3.  0.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 18. 30.  8.  2.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  0.  6.  8. 11.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [29.  3.  3.  0.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 28. 30. 18. 30.  8.  2.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  0.  6.  8. 11.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 18. 30.  8.  2.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  0.  6.  8. 11.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [15.  0.  6.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
expected returns: [[43.25526 ]
 [36.736225]
 [36.374992]
 [38.9356  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  8. 11.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  2.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0
  1] -> size -> 25 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -1.7483742237091064
desired expected reward: 26.377052307128906



action possibilites: [-1] 
expected returns: [[28.195467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  8.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  1.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0
  1] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -316 

action type: gain_card_n - action 3
Learning step: -17.319265365600586
desired expected reward: 25.753999710083008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.68814 ]
 [22.805904]
 [27.589832]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  8.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 18. 30.  8.  1.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0
  1] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -1.6317112445831299
desired expected reward: 26.56375503540039



buy possibilites: [-1] 
expected returns: [[0.6644255]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  8.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 18. 30.  8.  0.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.] 
adversary owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0
  1] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -327.0 

action type: buy - action 6.0
Learning step: -17.4753475189209
desired expected reward: 5.330556869506836






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 6.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  0  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6. 11. 15.  0.
  6.  8.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6. 11. 15.  0.
  6.  8.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 18. 30.  8.  0.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6. 11. 15.  0.
  6.  8.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 18. 30.  8.  0.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6. 11. 15.  0.
  6.  8.] 
adversary owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 





Player: 0 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[46.2495 ]
 [41.76614]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6. 11. 15.  0.
  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 18. 30.  8.  0.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  8. 15.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.  8.  0.  3.  6.] 
adversary owned cards: [10 10 11  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -1.3756760358810425
desired expected reward: -0.7112505435943604



action possibilites: [-1] 
expected returns: [[65.79108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6. 11. 15.  0.
  6.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 18. 30.  8.  0.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  8. 15.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.  8.  0.  3.  6.] 
adversary owned cards: [10 10 11  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: gain_card_n - action 0
Learning step: -1.8240406513214111
desired expected reward: 7.262754440307617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[53.257412]
 [54.581917]
 [54.393993]
 [55.925423]
 [54.77284 ]
 [54.584908]
 [57.68055 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6. 11. 15.  0.
  6.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 18. 30.  8.  0.  8.  7.  2. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  8. 15.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.  8.  0.  3.  6.] 
adversary owned cards: [10 10 11  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -3.380868911743164
desired expected reward: 62.41020965576172



buy possibilites: [-1] 
expected returns: [[37.239426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 10. 16.  3.  3.  3.  6. 10.  6.  0.  6. 10.  3.  6.  6. 11. 15.  0.
  6.  8.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 18. 30.  8.  0.  8.  7.  1. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  8. 15.] 
adversary cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.  8.  0.  3.  6.] 
adversary owned cards: [10 10 11  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -40.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -25.0 

action type: buy - action 8.0
Learning step: -3.1507554054260254
desired expected reward: 51.622093200683594






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  8. 15.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.  8.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  8  0  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 18. 30.  8.  0.  8.  7.  1. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8] -> size -> 27 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.  8.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 11  3  8  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 27. 30. 18. 30.  8.  0.  8.  7.  1. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8] -> size -> 27 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.  8.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 11  3  8  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 18. 30.  8.  0.  8.  7.  1. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8] -> size -> 27 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.] 
cards in discard: [29.  3.  3.  0.  6. 11.  1. 10.  0.  0.  8.  0.  0.  0.  8.  0.  3.  6.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 11  3  8  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 17. 30.  8.  0.  8.  7.  1. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8] -> size -> 27 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.403623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 17. 30.  8.  0.  8.  7.  1. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  3  8  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -4.458194732666016
desired expected reward: 32.78123092651367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 7.855036 ]
 [ 8.530848 ]
 [ 8.7625265]
 [11.175626 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 17. 30.  8.  0.  8.  7.  1. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  3  8  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -3.1933951377868652
desired expected reward: 8.085556030273438



buy possibilites: [-1] 
expected returns: [[50.56805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 6.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  3  8  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: -1.7503454685211182
desired expected reward: 7.012184143066406






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  8  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  6.  3.] 
adversary cards in discard: [8. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  6.  3.] 
adversary cards in discard: [8. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  6.  3.] 
adversary cards in discard: [8. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  6.  3.] 
adversary cards in discard: [8. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0. 16.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[58.164993]
 [53.687923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  6.  3.] 
cards in discard: [8. 0. 6. 0. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [8. 3. 0. 1. 3.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -4.102712154388428
desired expected reward: 46.46533966064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.067963]
 [56.818336]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  6.  3.] 
cards in discard: [8. 0. 6. 0. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [8. 3. 0. 1. 3.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -4.522250652313232
desired expected reward: 53.64274215698242



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 1. 3.] 
cards in discard: [0. 8. 3. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 15.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3.] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 1. 3.] 
cards in discard: [0. 8. 3. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 15.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3.] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 1. 3.] 
cards in discard: [0. 8. 3. 0. 3. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 15.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3.] 
adversary owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [10. 15.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[53.586327]
 [51.671066]
 [51.825195]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  6.  0.  0.] 
cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6
  6  0  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [0. 8. 3. 0. 3. 0. 8. 3. 0. 1. 3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -4.503302097320557
desired expected reward: 52.31502914428711



action possibilites: [-1] 
expected returns: [[60.39556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.] 
cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [0. 8. 3. 0. 3. 0. 8. 3. 0. 1. 3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 15.0
Learning step: -3.082359552383423
desired expected reward: 48.74283218383789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[50.193176]
 [53.15513 ]
 [52.94864 ]
 [52.788425]
 [56.468723]
 [57.061012]
 [51.03868 ]
 [53.382187]
 [54.12521 ]
 [61.229343]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [0. 8. 3. 0. 3. 0. 8. 3. 0. 1. 3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -3.595236301422119
desired expected reward: 56.800323486328125






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [10. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0. 10.] 
cards in discard: [0. 8. 3. 0. 3. 0. 8. 3. 0. 1. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  6.  3.  6. 10.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8] -> size -> 27 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0. 10.] 
cards in discard: [0. 8. 3. 0. 3. 0. 8. 3. 0. 1. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 17. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  6.  3.  6. 10.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8] -> size -> 27 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0. 10.] 
cards in discard: [0. 8. 3. 0. 3. 0. 8. 3. 0. 1. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  6.  3.  6. 10.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8] -> size -> 27 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [ 3.  6.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[47.931435]
 [43.803837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3.  6. 10.] 
cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  8. 15. 11.  3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0  3] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -5.363454818725586
desired expected reward: 55.86589813232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[42.76696]
 [48.82023]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3.  6. 10.] 
cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  8. 15. 11.  3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0  3] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.692764759063721
desired expected reward: 43.238670349121094



buy possibilites: [-1] 
expected returns: [[0.9149463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3.  6. 10.] 
cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  8. 15. 11.  3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0  3] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action 0.0
Learning step: -6.859736919403076
desired expected reward: 35.907230377197266






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 15. 11.  3.] 
cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3
  0  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0. 16.  8.  8.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.  0.  3.  6.
  3.  6. 10.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3.] 
cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0. 16.  8.  8.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.  0.  3.  6.
  3.  6. 10.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  3.] 
cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0. 16.  8.  8.] 
adversary cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.  0.  3.  6.
  3.  6. 10.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [10.  0. 16.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.  8.] 
expected returns: [[62.9749  ]
 [58.68229 ]
 [58.437866]
 [58.876125]
 [58.876125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.  8.  8.] 
cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.  0.  3.  6.
  3.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.  8.
 15. 11.  3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -2.029048204421997
desired expected reward: -1.1141018867492676





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[58.182083]
 [63.824318]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16.  8.  8.] 
cards in discard: [ 8.  0.  6.  0.  3.  6.  6.  0. 16.  6.  3. 15. 10.  6.  0.  0.  3.  6.
  3.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.  8.
 15. 11.  3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -5.104313850402832
desired expected reward: 57.87057876586914



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [0. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.  8.
 15. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.  8.
 15. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 16. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  0.  8.  3.  0.  1.  3.  3. 10. 29.  0.  0. 10.  8.
 15. 11.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 8.  3.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
expected returns: [[22.578966]
 [19.816236]
 [19.816236]
 [20.919176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3] -> size -> 27 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -6.589396953582764
desired expected reward: 57.23491287231445





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.198792]
 [21.274618]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3] -> size -> 27 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.46423864364624
desired expected reward: 16.79286766052246



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 15.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 15.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 15.  8.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[7.3050623]
 [2.935164 ]
 [2.8322186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [ 8.  3.  8.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -4.792849063873291
desired expected reward: 16.481769561767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[1.3551897]
 [2.887578 ]
 [2.7731795]
 [4.915071 ]
 [3.0395188]
 [7.5599365]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [ 8.  3.  8.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.101282596588135
desired expected reward: 3.2037787437438965



buy possibilites: [-1] 
expected returns: [[52.478523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -107.0 

action type: buy - action 0.0
Learning step: -4.236992835998535
desired expected reward: -2.881803035736084






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 10.] 
cards in discard: [ 0.  3.  3.  1. 15.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  6. 10.  6. 16.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [ 0.  3.  3.  1. 15.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  6. 10.  6. 16.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [ 0.  3.  3.  1. 15.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [15.  6. 10.  6. 16.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [15.  6. 10.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 16.] 
expected returns: [[25.480799]
 [24.158049]
 [24.04685 ]
 [24.036547]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 10.  6. 16.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  0. 29.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -5.916100978851318
desired expected reward: 46.56242370605469



action possibilites: [-1. 15. 16.] 
expected returns: [[23.476908]
 [23.00859 ]
 [22.937868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  6. 16.  3.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  0. 29.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action 10.0
Learning step: -3.529064893722534
desired expected reward: 20.517770767211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.080362]
 [23.821827]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  6. 16.  3.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  0. 29.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -3.4933228492736816
desired expected reward: 19.983579635620117






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  0. 29.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  3. 16.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  3. 16.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  3. 16.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  3. 16.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.] 
adversary owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 6.  6.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[24.827696]
 [19.678608]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  3. 16.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  0  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6
  0  8  8  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -4.52044677734375
desired expected reward: 19.301374435424805



action possibilites: [-1] 
expected returns: [[62.350754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: gain_card_n - action 0
Learning step: -3.1612937450408936
desired expected reward: 1.1224191188812256





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[59.30088]
 [62.482  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -4.585156440734863
desired expected reward: 57.76559829711914



buy possibilites: [-1] 
expected returns: [[-1.6074313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.] 
adversary owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action 0.0
Learning step: -7.349571228027344
desired expected reward: 51.951316833496094






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 10.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 11  3  0  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0
  0  3  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.
  0. 16.  6.  6.  3.] 
adversary owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.
  0. 16.  6.  6.  3.] 
adversary owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.
  0. 16.  6.  6.  3.] 
adversary owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.
  0. 16.  6.  6.  3.] 
adversary owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [0. 6. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[41.814472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 3.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.
  0. 16.  6.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.  0.  8.  0.] 
adversary owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -2.3288028240203857
desired expected reward: -3.9362339973449707





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.81071]
 [41.46727]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 3.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.
  0. 16.  6.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.  0.  8.  0.] 
adversary owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.549431800842285
desired expected reward: 37.26504135131836



buy possibilites: [-1] 
expected returns: [[55.77718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 3.] 
cards in discard: [ 8.  3.  8.  3. 11.  0.  0.  0.  8.  0. 10. 10. 15.  6.  6. 16.  3.  0.
  0. 16.  6.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.  0.  8.  0.] 
adversary owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -97.0 

action type: buy - action 0.0
Learning step: -5.385550022125244
desired expected reward: 30.4251766204834






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  7.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 0.  3.  3.  1. 15.  8. 10.  3.  0.  8.  0.  3.  3.  0.  0. 29.  6.  3.
  6.  0.  8.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [ 8.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[3.7974582]
 [3.0233583]
 [2.9643369]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -6.061318874359131
desired expected reward: 49.71586227416992



action possibilites: [-1.  8. 15.] 
expected returns: [[1.8645265]
 [2.0206852]
 [1.9209571]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 15  8 10 11  6  3  3  0 10  6  6 10  0  6 16  0 16  3  6  6  6  0
  8  8  0  0  0  0  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 10.0
Learning step: -2.454009771347046
desired expected reward: 0.510329008102417



action possibilites: [-1. 15.] 
expected returns: [[28.917019]
 [28.235363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0 11] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: trash_cards_n_from_hand - action 6
Learning step: -1.4981486797332764
desired expected reward: 3.3769261837005615





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.834917]
 [29.14262 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0 11] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1.0
Learning step: -2.6997876167297363
desired expected reward: 26.217233657836914



buy possibilites: [-1] 
expected returns: [[-0.4902109]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0 11] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -70.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -68.0 

action type: buy - action 0.0
Learning step: -4.802776336669922
desired expected reward: 23.032150268554688






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3  6  3  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3
  0  0  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0. 10.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0. 10.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0. 10.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0. 10.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  3. 16.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[31.651764]
 [29.08815 ]
 [29.269587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0. 10.] 
cards in discard: [ 0. 10.  8.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  8. 11. 11.  3.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -2.1876444816589355
desired expected reward: -2.6778554916381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.652203]
 [30.061613]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0. 10.] 
cards in discard: [ 0. 10.  8.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  8. 11. 11.  3.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -3.8313491344451904
desired expected reward: 27.820419311523438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 11.  3.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  8.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.  3.  3. 16.  0. 10.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  3.] 
cards in discard: [ 0.  8.  0.  0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.  3.  3. 16.  0. 10.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  3.] 
cards in discard: [ 0.  8.  0.  0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.  3.  3. 16.  0. 10.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [6. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[3.5543427]
 [1.4099884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 0. 10.  8.  0. 15.  3.  3. 16.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 15.  0.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 16. 11.  0.  8. 11.  3.] 
adversary owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0 16] -> size -> 28 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1.0
Learning step: -4.338924407958984
desired expected reward: 25.722686767578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.0388962]
 [3.232885 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 0. 10.  8.  0. 15.  3.  3. 16.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 15.  0.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 16. 11.  0.  8. 11.  3.] 
adversary owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0 16] -> size -> 28 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -3.0285356044769287
desired expected reward: 0.5258080959320068



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [10. 15.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  3.  3.] 
cards in discard: [ 0.  8.  0.  0. 16. 11.  0.  8. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.  3.  3. 16.  0. 10.  6.  6.  8.  6.  0.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  3.  3.] 
cards in discard: [ 0.  8.  0.  0. 16. 11.  0.  8. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0. 10.  8.  0. 15.  3.  3. 16.  0. 10.  6.  6.  8.  6.  0.] 
adversary owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 


Player 1 won the game! 



Player 0 bought cards:
Copper: 11 
Silver: 2 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 1 
Workshop: 1 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [ 0. 10.  8.  0. 15.  3.  3. 16.  0. 10.  6.  6.  8.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8 10 11  6  3  3 10  6  6 10  0  6 16  0 16  3  6  6  6  0  8  8
  0  0  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  0.  7.  6.  0. 10.  9.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10. 15.  0.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 16. 11.  0.  8. 11.  3.  0.] 
adversary owned cards: [10 11  6  8  8  0  0 15  0 29  6  0  8  3  0  1  0  3  0  0  3  3  0  0
  0 11  0 16  0] -> size -> 29 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[  -5 -500   -3  -50    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -558 

action type: buy - action -1.0
Learning step: -28.0616455078125
desired expected reward: -24.828760147094727



