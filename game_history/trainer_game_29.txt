 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.62638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   40    0    0    0    0  -17    0    0
    4    0] 
sum of rewards: -478 

action type: buy - action 8.0
Learning step: -14.899070739746094
desired expected reward: 3.736642837524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.52928 ]
 [20.6713  ]
 [19.483017]
 [15.695706]
 [22.405725]
 [21.442396]
 [20.24989 ]
 [20.926664]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5667957663536072
desired expected reward: 20.473936080932617



buy possibilites: [-1] 
expected returns: [[22.232082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.048734892159700394
desired expected reward: 22.356990814208984






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.769857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5753609538078308
desired expected reward: 21.656721115112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.191256]
 [23.379124]
 [22.1606  ]
 [18.318146]
 [21.807564]
 [25.143486]
 [24.16549 ]
 [25.2614  ]
 [21.232204]
 [22.946966]
 [23.420479]
 [23.640928]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5963736176490784
desired expected reward: 22.41329002380371



buy possibilites: [-1] 
expected returns: [[24.207561]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5151251554489136
desired expected reward: 24.628360748291016






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.107534]
 [25.577837]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6107354760169983
desired expected reward: 23.596826553344727



action possibilites: [-1] 
expected returns: [[24.829504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.2783386707305908
desired expected reward: 23.690710067749023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.560827]
 [24.725264]
 [23.517403]
 [19.692245]
 [26.509863]
 [25.519798]
 [24.293102]
 [24.988764]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.03781682997941971
desired expected reward: 24.79168701171875



buy possibilites: [-1] 
expected returns: [[23.981539]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.0249814223498106
desired expected reward: 22.585805892944336






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 0. 0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.76115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.629090428352356
desired expected reward: 23.352447509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.915344]
 [23.03918 ]
 [21.854412]
 [18.116457]
 [24.759789]
 [23.806053]
 [22.617767]
 [23.29454 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5974113941192627
desired expected reward: 22.293609619140625



buy possibilites: [-1] 
expected returns: [[23.941612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.10140678286552429
desired expected reward: 24.658384323120117






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  0 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.746784]
 [23.22102 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [11.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  0 11] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6277127861976624
desired expected reward: 23.313899993896484



action possibilites: [-1] 
expected returns: [[23.50691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [11.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  0 11] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.10811588168144226
desired expected reward: 19.7493896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.62644 ]
 [23.801573]
 [22.582123]
 [18.75217 ]
 [25.556028]
 [24.5866  ]
 [23.367146]
 [24.033033]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [11.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  0 11] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.008019275031983852
desired expected reward: 23.498891830444336



buy possibilites: [-1] 
expected returns: [[25.538698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [11.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  0 11] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.10069272667169571
desired expected reward: 22.68281364440918






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [11.  8.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  0 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  1.  3.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  8.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  8  0 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  1.  3.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  8.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  8  0 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  1.  3.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  8.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  8  0 11  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  1.  3.  0.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [11. 11.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[21.95339]
 [23.40747]
 [23.40747]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.  3.  0.] 
cards in discard: [ 0.  3. 11.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  0 11  3] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6733497977256775
desired expected reward: 24.86534881591797



action possibilites: [-1] 
expected returns: [[23.629473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0.] 
cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  0 11  3] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.10505813360214233
desired expected reward: 19.873435974121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.779366]
 [23.897165]
 [22.714172]
 [18.953718]
 [25.616049]
 [24.667194]
 [23.475708]
 [24.123388]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.] 
cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  0 11  3] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.010602436028420925
desired expected reward: 23.61886978149414



buy possibilites: [-1] 
expected returns: [[23.950418]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.] 
cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  0 11  3] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.5245643854141235
desired expected reward: 24.421730041503906






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  8  0 11  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.  1. 11. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1] -> size -> 19 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  8  0 11  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.  1. 11. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1] -> size -> 19 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  8  0 11  3  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.  1. 11. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1] -> size -> 19 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.944658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.  1. 11. 11.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 11.  8.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  0 11  3  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6162084937095642
desired expected reward: 23.334209442138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.024544]
 [24.171444]
 [22.9734  ]
 [19.172098]
 [22.630533]
 [25.896473]
 [24.942652]
 [26.008787]
 [22.05121 ]
 [23.744606]
 [24.19811 ]
 [24.39884 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.  1. 11. 11.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 11.  8.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  0 11  3  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6187013387680054
desired expected reward: 23.410253524780273



buy possibilites: [-1] 
expected returns: [[23.471262]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3. 11.  0.  3.  0.  0.  0.  1. 11. 11.  1.  3.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 11.  8.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  0 11  3  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.3305049538612366
desired expected reward: 24.528615951538086






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 11.  8.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  8  0 11  3  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15] -> size -> 20 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8 0 3 1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8 0 3 1] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15] -> size -> 20 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 1. 11.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[20.279388]
 [21.775915]
 [20.078127]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 8 8 0 3 1] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6325762867927551
desired expected reward: 22.838685989379883



action possibilites: [-1] 
expected returns: [[24.115107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  3.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 8 8 0 3 1] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.36668258905410767
desired expected reward: 20.584217071533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.29109 ]
 [24.48194 ]
 [23.256935]
 [19.410463]
 [26.249992]
 [25.274664]
 [24.043222]
 [24.715658]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  3.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 8 8 0 3 1] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.01911809854209423
desired expected reward: 24.095989227294922



buy possibilites: [-1] 
expected returns: [[24.096045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  3.] 
cards in discard: [ 1. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 8 8 0 3 1] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.5217118263244629
desired expected reward: 24.56493377685547






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 8 8 0 3 1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 8 8 0 3 1] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 8 8 0 3 1 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.718008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [8. 3. 3. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 3 8 8 0 3 1 8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6234691143035889
desired expected reward: 23.472576141357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.721949]
 [23.862503]
 [22.65095 ]
 [18.894964]
 [22.312748]
 [25.57511 ]
 [24.63629 ]
 [25.675432]
 [21.724005]
 [23.42474 ]
 [23.864594]
 [24.026268]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [8. 3. 3. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 3 8 8 0 3 1 8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6016706228256226
desired expected reward: 22.746585845947266



buy possibilites: [-1] 
expected returns: [[26.062689]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [8. 3. 3. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 3 8 8 0 3 1 8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.313395231962204
desired expected reward: 25.988826751708984






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 8.] 
cards in discard: [8. 3. 3. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 8 8 0 3 1 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [8. 3. 3. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 8 8 0 3 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8. 3. 3. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 8 8 0 3 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8. 3. 3. 0. 8. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 8 8 0 3 8 8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.31001 ]
 [24.802053]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 8 8 0 3 8 8] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6772494316101074
desired expected reward: 25.385438919067383



action possibilites: [-1] 
expected returns: [[21.888819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 8 8 0 3 8 8] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.1692313849925995
desired expected reward: 26.189271926879883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.004185]
 [22.009531]
 [20.879713]
 [17.316582]
 [23.632124]
 [22.742414]
 [21.60134 ]
 [22.164267]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 28. 30.  8. 10. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 8 8 0 3 8 8] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.02183057740330696
desired expected reward: 21.9106502532959



buy possibilites: [-1] 
expected returns: [[20.364082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 8 8 0 3 8 8] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.855673789978027
desired expected reward: 8.460907936096191






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 8 8 0 3 8 8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  1.  0.  3.  0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6. 11.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0 3 8 8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  1.  0.  3.  0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6. 11.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0 3 8 8] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  1.  0.  3.  0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6. 11.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0 3 8 8 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  1.  0.  3.  0.] 
adversary cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6. 11.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  1.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.727371]
 [22.20986 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  3.  0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6. 11.  0.  0.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [0 0 8 0 3 8 8 0] -> size -> 8 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5335958003997803
desired expected reward: 19.830486297607422



action possibilites: [-1] 
expected returns: [[16.29215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6. 11.  0.  0.
  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [0 0 8 0 3 8 8 0] -> size -> 8 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.96255111694336
desired expected reward: 10.491390228271484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.450702]
 [16.048489]
 [15.1385  ]
 [12.34685 ]
 [14.8897  ]
 [17.444279]
 [16.668709]
 [17.527191]
 [14.45216 ]
 [15.717885]
 [16.05004 ]
 [16.174314]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6. 11.  0.  0.
  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  6. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [0 0 8 0 3 8 8 0] -> size -> 8 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12887878715991974
desired expected reward: 16.421030044555664



buy possibilites: [-1] 
expected returns: [[19.2258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 1. 10. 11.  1.  0. 15.  3. 29.  3.  0.  0.  0.  0. 10.  6. 11.  0.  0.
  3.  0.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  6. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [0 0 8 0 3 8 8 0] -> size -> 8 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 10.0
Learning step: 0.3153343200683594
desired expected reward: 16.033220291137695






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 3 8 8 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  6. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 3 8 8 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  6. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [0. 8. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 3 8 8 0 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 3. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.051907]
 [22.604704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0 3 8 8 0 8] -> size -> 9 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49481070041656494
desired expected reward: 18.730989456176758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.90452 ]
 [16.080008]
 [21.186296]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0 3 8 8 0 8] -> size -> 9 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5830321907997131
desired expected reward: 20.577024459838867



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 3 8 8 0 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 10.  0. 11.  6.] 
adversary cards in discard: [ 3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0 3 8 8 0 8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 10.  0. 11.  6.] 
adversary cards in discard: [ 3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0 3 8 8 0 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 10.  0. 11.  6.] 
adversary cards in discard: [ 3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10. 10.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[21.46197 ]
 [20.874413]
 [20.874413]
 [23.000872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.  6.] 
cards in discard: [ 3. 11.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 3 8 8 0 8] -> size -> 8 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5559114813804626
desired expected reward: 20.630382537841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.215631]
 [16.378065]
 [21.476004]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 11.  6.] 
cards in discard: [ 3. 11.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 3 8 8 0 8] -> size -> 8 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5899229049682617
desired expected reward: 20.90399932861328



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0 3 8 8 0 8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 8 8 0 8] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 8 8 0 8] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.507956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8 8 0 8] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5654935240745544
desired expected reward: 20.48719596862793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.79596 ]
 [20.760843]
 [19.642666]
 [16.14777 ]
 [19.33843 ]
 [22.357431]
 [21.482073]
 [22.448402]
 [18.779478]
 [20.352303]
 [20.744179]
 [20.861649]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8 8 0 8] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5510523319244385
desired expected reward: 20.028675079345703



buy possibilites: [-1] 
expected returns: [[23.09272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8 8 0 8] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.4301481544971466
desired expected reward: 21.174327850341797






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [8. 8. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 8 8 0 8] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  6.  1.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 8] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  6.  1.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 8] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  6.  1.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 8 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  6.  1.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [15.  1.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[18.151955]
 [18.03838 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  6.  1.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 8 0] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6518505811691284
desired expected reward: 22.44087028503418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.36801 ]
 [18.28712 ]
 [17.195103]
 [14.831651]
 [13.746873]
 [16.89794 ]
 [19.826006]
 [18.983826]
 [21.505692]
 [19.914589]
 [16.351933]
 [16.188677]
 [17.888292]
 [14.269564]
 [18.271044]
 [18.38459 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.  6.  1.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 8 0] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.50531405210495
desired expected reward: 17.72482681274414



buy possibilites: [-1] 
expected returns: [[22.1829]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.  6.  1.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  9.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 8 0] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 25.0
Learning step: 0.9377496242523193
desired expected reward: 22.443443298339844






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0 8 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  9.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  0. 29.  1.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25. 15.
  1.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25] -> size -> 29 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  9.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  0. 29.  1.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25. 15.
  1.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25] -> size -> 29 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  9.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  0. 29.  1.] 
adversary cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25. 15.
  1.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25] -> size -> 29 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[16.042639]
 [15.600539]
 [17.407099]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  1.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25. 15.
  1.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  9.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6412414312362671
desired expected reward: 21.541658401489258



action possibilites: [-1. 10. 11.] 
expected returns: [[19.31787 ]
 [18.842632]
 [20.680729]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1. 11.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25. 15.
  1.  0.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  9.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.13501235842704773
desired expected reward: 17.574098587036133



action possibilites: [-1] 
expected returns: [[20.693314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25. 15.
  1.  0.  6.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  9.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0.8852462768554688
desired expected reward: 22.61969757080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.697424]
 [20.537903]
 [19.490728]
 [17.245895]
 [16.254313]
 [19.205664]
 [22.043613]
 [21.221113]
 [23.656239]
 [22.128391]
 [18.681936]
 [18.525326]
 [20.155579]
 [16.73203 ]
 [20.522415]
 [20.63248 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25. 15.
  1.  0.  6.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  9.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6446374654769897
desired expected reward: 21.33795166015625



buy possibilites: [-1] 
expected returns: [[23.01194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [ 3. 11.  3.  3.  0. 10. 10.  0. 11.  6. 15.  3.  0.  0.  0.  0. 25. 15.
  1.  0.  6.  1. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 50  0] 
sum of rewards: 85 

action type: buy - action 25.0
Learning step: 2.0819380283355713
desired expected reward: 25.738176345825195






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25] -> size -> 31 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25] -> size -> 31 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25] -> size -> 31 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 6. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[24.334988]
 [23.78156 ]
 [23.78156 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5867595076560974
desired expected reward: 22.425180435180664



action possibilites: [-1. 10. 15.] 
expected returns: [[27.547405]
 [27.016224]
 [27.425987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.02060079574584961
desired expected reward: 23.91459083557129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.408028]
 [26.293407]
 [22.602213]
 [28.204391]
 [27.5666  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.09866763651371002
desired expected reward: 27.448741912841797



buy possibilites: [-1] 
expected returns: [[27.082424]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0. 15.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.021956175565719604
desired expected reward: 25.386072158813477






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 25. 11.  0.  1.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  5.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 25. 11.  0.  1.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 25. 11.  0.  1.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[18.305828]
 [21.346123]
 [19.733082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  0.  1.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7506649494171143
desired expected reward: 26.331758499145508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.549028]
 [18.350454]
 [17.313948]
 [14.101918]
 [17.04199 ]
 [19.812859]
 [19.016325]
 [19.894169]
 [16.514944]
 [17.967213]
 [18.316368]
 [18.383558]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  0.  1.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5098351240158081
desired expected reward: 17.8533935546875



buy possibilites: [-1] 
expected returns: [[21.497992]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  0.  1.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.43890380859375
desired expected reward: 20.333072662353516






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  3. 11.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29] -> size -> 33 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  3. 11.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  3. 11.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29] -> size -> 33 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  3. 11.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29] -> size -> 33 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[19.43475 ]
 [20.899315]
 [20.899315]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  3. 11.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 28. 30.  8.  8. 10.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5788835883140564
desired expected reward: 20.91910743713379



action possibilites: [-1] 
expected returns: [[21.052727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.665793776512146
desired expected reward: 16.841121673583984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.035976]
 [16.523548]
 [20.936703]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.020574701949954033
desired expected reward: 21.073301315307617



buy possibilites: [-1] 
expected returns: [[19.77518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.08656013011932373
desired expected reward: 19.122535705566406






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0] -> size -> 35 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0] -> size -> 35 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0] -> size -> 35 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[18.77155]
 [18.7156 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5462214350700378
desired expected reward: 19.228960037231445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.175667]
 [18.679266]
 [17.814137]
 [15.183428]
 [19.872068]
 [19.224512]
 [18.359383]
 [18.706785]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5196282267570496
desired expected reward: 18.26789093017578



buy possibilites: [-1] 
expected returns: [[18.202185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -1  0  0 18  0] 
sum of rewards: 12 

action type: buy - action 10.0
Learning step: 0.0003414916864130646
desired expected reward: 18.359724044799805






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [10.  1.  0. 29.  3.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [10.  1.  0. 29.  3.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [10.  1.  0. 29.  3.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [10.  1.  0. 29.  3.] 
adversary cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [10.  1.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[17.132261]
 [16.773687]
 [18.439384]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 29.  3.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5107759237289429
desired expected reward: 17.691408157348633



action possibilites: [-1. 10.] 
expected returns: [[20.485332]
 [20.067331]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  3.  0.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.11015882343053818
desired expected reward: 18.549543380737305



action possibilites: [-1. 25.] 
expected returns: [[20.447838]
 [23.313204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 25.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
action values: 2 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.6807341575622559
desired expected reward: 20.748064041137695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.887676]
 [20.59778 ]
 [19.61123 ]
 [17.570847]
 [16.66034 ]
 [19.352139]
 [21.9786  ]
 [21.227821]
 [23.513664]
 [22.055677]
 [18.856691]
 [18.710598]
 [20.232937]
 [17.081362]
 [20.565392]
 [20.62907 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 25.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  8.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6526477932929993
desired expected reward: 21.100482940673828



buy possibilites: [-1] 
expected returns: [[17.096737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 25.] 
cards in discard: [ 0. 10.  6.  0. 10.  0. 15. 29.  0. 25. 11.  0.  1. 16.  0. 11.  6.  0.
  3. 11. 10.  3.  0.  0. 15.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -2  0  0 50  0] 
sum of rewards: 83 

action type: buy - action 25.0
Learning step: 1.9589457511901855
desired expected reward: 25.472610473632812






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11. 25. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25] -> size -> 37 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11. 25. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25] -> size -> 37 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  8.  9.  6.  4.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11. 25. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25] -> size -> 37 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  8.  9.  6.  4.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11. 25. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25] -> size -> 37 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11. 25. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[25.761967]
 [27.389194]
 [29.161905]
 [25.374859]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10.  1.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  8.  9.  6.  4.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.37499192357063293
desired expected reward: 16.721744537353516



action possibilites: [-1] 
expected returns: [[28.797798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1.  3. 29. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  6.  4.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.12380601465702057
desired expected reward: 29.082290649414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.885958]
 [27.713634]
 [24.161026]
 [29.59892 ]
 [28.825459]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  1.  3. 29. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  6.  4.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1213054284453392
desired expected reward: 28.67649269104004



buy possibilites: [-1] 
expected returns: [[28.830898]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  1.  3. 29. 10.] 
cards in discard: [8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  6.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 20 

action type: buy - action 8.0
Learning step: 0.014756755903363228
desired expected reward: 29.613679885864258






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  6.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [10.  1.  0. 15.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8] -> size -> 38 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  6.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [10.  1.  0. 15.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8] -> size -> 38 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  6.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [10.  1.  0. 15.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8] -> size -> 38 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [10.  1.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[20.939188]
 [20.608887]
 [20.925392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 15.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  6.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7956113219261169
desired expected reward: 28.035287857055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.644419]
 [21.325375]
 [20.338364]
 [17.402597]
 [20.092876]
 [22.687141]
 [21.95577 ]
 [22.760727]
 [19.590767]
 [20.953957]
 [21.269646]
 [21.283442]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0. 15.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  6.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5570715069770813
desired expected reward: 20.422348022460938



buy possibilites: [-1] 
expected returns: [[19.197313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0. 15.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  -4.   0.   0.
  4.5  0. ] 
sum of rewards: -4.5 

action type: buy - action 11.0
Learning step: -0.6140424609184265
desired expected reward: 22.07309913635254






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  6.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  6.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  6.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 3.  0. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[16.830788]
 [15.750148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  6.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5533519387245178
desired expected reward: 18.64396095275879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.48992 ]
 [16.128399]
 [13.469207]
 [17.600761]
 [16.988066]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  6.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4851997196674347
desired expected reward: 16.382055282592773



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[14.518874]
 [14.246741]
 [16.86464 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 25.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.49646151065826416
desired expected reward: 16.49160385131836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[13.177563]
 [14.563098]
 [13.751068]
 [11.28951 ]
 [15.658387]
 [15.074414]
 [14.255615]
 [14.528668]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 25.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 28. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4347703754901886
desired expected reward: 14.08410358428955



buy possibilites: [-1] 
expected returns: [[14.386062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 25.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 27. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  2.  0.] 
sum of rewards: -8.0 

action type: buy - action 3.0
Learning step: -0.5014784336090088
desired expected reward: 13.249590873718262






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3] -> size -> 40 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3] -> size -> 40 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3] -> size -> 40 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[17.925262]
 [19.19495 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 11.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  7.  9.  5.  3.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.38536757230758667
desired expected reward: 14.000694274902344



action possibilites: [-1] 
expected returns: [[23.4799]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  7.  9.  5.  2.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  4  0] 
sum of rewards: 13 

action type: gain_card_n - action 6
Learning step: 0.20636269450187683
desired expected reward: 14.545570373535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.829994]
 [23.521395]
 [22.53309 ]
 [19.59012 ]
 [22.286854]
 [24.851025]
 [24.140093]
 [24.921467]
 [21.775944]
 [23.150328]
 [23.46639 ]
 [23.4799  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 27. 30.  8.  7.  9.  5.  2.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.009179306216537952
desired expected reward: 23.470720291137695



buy possibilites: [-1] 
expected returns: [[22.719795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 26. 30. 27. 30.  8.  7.  9.  5.  2.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -7.  0.  0.  0.  0.] 
sum of rewards: 8.0 

action type: buy - action 0.0
Learning step: -0.18931660056114197
desired expected reward: 22.073165893554688






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  7.  9.  5.  2.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  6. 10. 29.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0] -> size -> 42 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  7.  9.  5.  2.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  6. 10. 29.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0] -> size -> 42 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[12.274569]
 [12.032326]
 [13.604828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 29.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  7.  9.  5.  2.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6968709230422974
desired expected reward: 22.022924423217773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.882085 ]
 [11.48787  ]
 [ 8.908383 ]
 [12.9233055]
 [12.274569 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10. 29.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 27. 30.  8.  7.  9.  5.  2.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.39621803164482117
desired expected reward: 11.878349304199219



buy possibilites: [-1] 
expected returns: [[14.7194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10. 29.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -8  0  0  8  0] 
sum of rewards: -5 

action type: buy - action 8.0
Learning step: -0.3831454813480377
desired expected reward: 12.540162086486816






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 11. 15. 25.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.  8.  0.  6. 10.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 43 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 11. 15. 25.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.  8.  0.  6. 10.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 43 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 11. 15. 25.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.  8.  0.  6. 10.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 43 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 25.] 
expected returns: [[12.567728]
 [13.858988]
 [12.593003]
 [15.266024]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15. 25.  0.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.  8.  0.  6. 10.
 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10
  6  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.44552329182624817
desired expected reward: 14.273877143859863



action possibilites: [-1] 
expected returns: [[11.615738]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.  8.  0.  6. 10.
 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.19417516887187958
desired expected reward: 12.787177085876465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.445535]
 [11.697304]
 [10.953738]
 [ 8.734855]
 [12.772761]
 [12.20034 ]
 [11.410468]
 [11.615738]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 25.] 
cards in discard: [ 8. 25. 11. 10.  1.  3. 29. 10. 11. 10.  1.  0. 15.  0.  3.  0. 16.  6.
  0.  3.  0.  0.  0. 10. 25.  8.  0. 11.  0.  3.  1.  0.  8.  0.  6. 10.
 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2226729542016983
desired expected reward: 11.838411331176758






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [25. 11.  8. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [25. 11.  8. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [25. 11.  8. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [25. 11.  8. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [25. 11.  8. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.  8. 10. 15.] 
expected returns: [[23.459553]
 [26.72455 ]
 [25.068626]
 [24.283716]
 [23.15368 ]
 [23.491816]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  8. 10. 15.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.23630386590957642
desired expected reward: 11.379433631896973



action possibilites: [-1. 25. 11.  8. 15.] 
expected returns: [[23.879776]
 [27.145103]
 [25.489178]
 [24.704266]
 [23.912369]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  8. 15.  3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 27. 30.  8.  7.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.018783587962388992
desired expected reward: 23.300140380859375



action possibilites: [-1. 11.  8. 15. 10.] 
expected returns: [[29.858616]
 [31.5406  ]
 [30.720007]
 [29.892433]
 [29.53385 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6
  6 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0.5564785599708557
desired expected reward: 27.701581954956055



action possibilites: [-1] 
expected returns: [[21.292543]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10. 25. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6
 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 15.0
Learning step: 0.9767987728118896
desired expected reward: 30.869230270385742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.4679  ]
 [21.440264]
 [20.272823]
 [16.836432]
 [22.968615]
 [22.163694]
 [20.996254]
 [21.318213]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10. 25. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6
 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.233195185661316
desired expected reward: 22.525737762451172



buy possibilites: [-1] 
expected returns: [[24.499443]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3. 10.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10. 25. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6
 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 60.  0.  0.  0.  0. -7.  0.  0.  0.  0.] 
sum of rewards: 48.0 

action type: buy - action 0.0
Learning step: 1.1132071018218994
desired expected reward: 20.58110809326172






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 15.  0.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6
 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0] -> size -> 42 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 15.  0.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6
 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0] -> size -> 42 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 15.  0.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6
 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0] -> size -> 42 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 8.  6.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[14.614521]
 [15.206877]
 [14.63714 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 15.  0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6
 10 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7282017469406128
desired expected reward: 23.771242141723633



action possibilites: [-1] 
expected returns: [[19.629263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.21605518460273743
desired expected reward: 14.884458541870117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.91698 ]
 [19.660267]
 [18.628347]
 [15.665817]
 [18.38597 ]
 [21.024134]
 [20.299854]
 [21.098373]
 [17.83959 ]
 [19.267658]
 [19.581842]
 [19.552357]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 27. 30.  8.  6.  9.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06567346304655075
desired expected reward: 19.694936752319336



buy possibilites: [-1] 
expected returns: [[18.38804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -7  0  0 32  0] 
sum of rewards: 40 

action type: buy - action 16.0
Learning step: 0.8449512124061584
desired expected reward: 19.115724563598633






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [29.  0. 29. 25. 11.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16] -> size -> 42 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [29.  0. 29. 25. 11.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16] -> size -> 42 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [29.  0. 29. 25. 11.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16] -> size -> 42 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29.  0. 29. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 11.] 
expected returns: [[17.060656]
 [18.274181]
 [18.274181]
 [19.391088]
 [18.220173]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 25. 11.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5073186159133911
desired expected reward: 17.880722045898438



action possibilites: [-1. 29. 25. 11.] 
expected returns: [[17.894518]
 [19.1584  ]
 [20.342548]
 [19.100744]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 11.  1.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.10415078699588776
desired expected reward: 18.411170959472656



action possibilites: [-1. 25. 11.] 
expected returns: [[18.368238]
 [20.783424]
 [19.53298 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  1.  0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 2 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.6832101345062256
desired expected reward: 19.841609954833984



action possibilites: [-1] 
expected returns: [[16.1804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0 -8  0  0  9  0] 
sum of rewards: 56 

action type: gain_card_n - action 9
Learning step: 1.238166093826294
desired expected reward: 21.629100799560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.2988615]
 [16.59602  ]
 [14.546337 ]
 [15.818001 ]
 [14.264669 ]
 [13.579959 ]
 [15.643922 ]
 [17.605467 ]
 [17.079    ]
 [18.762352 ]
 [17.658209 ]
 [15.228029 ]
 [15.100418 ]
 [16.294258 ]
 [13.851653 ]
 [16.522573 ]
 [16.470264 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10] -> size -> 43 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  7.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.3375587463378906
desired expected reward: 17.517959594726562



buy possibilites: [-1] 
expected returns: [[18.653625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.  -9.   0.   0.
 12.5  0. ] 
sum of rewards: 58.5 

action type: buy - action 25.0
Learning step: 1.38799250125885
desired expected reward: 20.150346755981445






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 6.  1. 25.  1.  3.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25] -> size -> 44 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 6.  1. 25.  1.  3.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25] -> size -> 44 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  6.  8.  5.  1.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 6.  1. 25.  1.  3.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25] -> size -> 44 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  6.  8.  5.  1.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 6.  1. 25.  1.  3.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25] -> size -> 44 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 6.  1. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[19.935064]
 [22.495558]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 25.  1.  3.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  6.  8.  5.  1.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4841594696044922
desired expected reward: 18.169466018676758



action possibilites: [-1] 
expected returns: [[20.245905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  1.  3. 11.  0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  5.  8.  5.  1.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.01228471752256155
desired expected reward: 22.483272552490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.966486]
 [20.385485]
 [19.528685]
 [17.847088]
 [17.10736 ]
 [19.337881]
 [21.549263]
 [20.934092]
 [22.897812]
 [21.611717]
 [18.889574]
 [18.75028 ]
 [20.050602]
 [17.400427]
 [20.303904]
 [20.245903]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  1.  3. 11.  0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 26. 30. 27. 30.  8.  5.  8.  5.  1.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0565066896378994
desired expected reward: 20.302412033081055



buy possibilites: [-1] 
expected returns: [[19.641348]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  1.  3. 11.  0.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 26. 30. 27. 30.  8.  5.  8.  5.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -10.   0.   0.
   2.   0.] 
sum of rewards: 7.0 

action type: buy - action 8.0
Learning step: -0.2117885947227478
desired expected reward: 20.72230339050293






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  5.  8.  5.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11. 16.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8] -> size -> 45 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 27. 30.  8.  5.  8.  5.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11. 16.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8] -> size -> 45 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 10. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 16.] 
expected returns: [[16.727436]
 [16.521217]
 [18.063675]
 [15.752809]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11. 16.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  5.  8.  5.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.560469925403595
desired expected reward: 19.08087730407715



action possibilites: [-1] 
expected returns: [[14.862493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 16.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  5.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -11   0   0   9   0] 
sum of rewards: 13 

action type: gain_card_n - action 5
Learning step: 0.07769196480512619
desired expected reward: 15.689833641052246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[13.637147]
 [14.163516]
 [11.884789]
 [14.862493]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 16.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 27. 30.  8.  5.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.14988712966442108
desired expected reward: 15.01237964630127



buy possibilites: [-1] 
expected returns: [[13.786649]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 16.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -12.
    0. -300.    0.    0.] 
sum of rewards: -297.0 

action type: buy - action 6.0
Learning step: -9.121045112609863
desired expected reward: 2.7391366958618164






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 47 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 47 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.325779]
 [21.131542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3404945731163025
desired expected reward: 13.446154594421387





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[19.815145]
 [20.491945]
 [17.541847]
 [21.325779]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.578722357749939
desired expected reward: 20.74705696105957



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 47 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 47 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[18.927227]
 [19.732513]
 [18.747856]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  0. 10.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10
 15 25 10 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5875937938690186
desired expected reward: 20.73818588256836



action possibilites: [-1] 
expected returns: [[19.521317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10
 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.012832431122660637
desired expected reward: 21.417545318603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.951937]
 [15.542897]
 [19.521317]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10
 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  4.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.05380050465464592
desired expected reward: 19.575117111206055



buy possibilites: [-1] 
expected returns: [[20.767994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0. 10. 25. 15. 11.  8.  3. 10. 16. 15.  8.  6.  0. 10. 25. 29. 29. 11.
  0. 25.  1.  0.  8. 25.  6.  1.  1.  3. 11.  0. 11.  6. 11.  0.  0. 10.
 16.  3.  0.  0.  3. 10.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10
 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  3.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0  -10    0 -300
    0    0] 
sum of rewards: -295 

action type: buy - action 6.0
Learning step: -9.098222732543945
desired expected reward: 6.444674491882324






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  3.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [15.  3.  1.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10
 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6] -> size -> 45 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 27. 30.  8.  3.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [15.  3.  1.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10
 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6] -> size -> 45 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 27. 30.  8.  3.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [15.  3.  1.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10
 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6] -> size -> 45 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [15.  3.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[16.402895]
 [16.509804]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  1.  0.  6.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10
 25  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  3.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5994167923927307
desired expected reward: 20.168577194213867



action possibilites: [-1] 
expected returns: [[23.233063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 26. 30. 27. 30.  8.  3.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.19659855961799622
desired expected reward: 16.774885177612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.75007 ]
 [23.58975 ]
 [22.477333]
 [20.249733]
 [19.266134]
 [22.23811 ]
 [25.01435 ]
 [26.6401  ]
 [25.089779]
 [21.629192]
 [21.443096]
 [23.154907]
 [19.636547]
 [23.468388]
 [23.357807]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 26. 30. 27. 30.  8.  3.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0012047195341438055
desired expected reward: 23.231857299804688



buy possibilites: [-1] 
expected returns: [[17.745222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [6.] 
cards in deck: 40 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 5 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -10.
    0. -300.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 6.0
Learning step: -9.241660118103027
desired expected reward: 10.0244722366333






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [16. 29.  1.  0.  0.] 
adversary cards in discard: [ 6. 15.  3.  1.  6.] 
adversary owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6] -> size -> 45 
adversary victory points: -1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [16. 29.  1.  0.  0.] 
adversary cards in discard: [ 6. 15.  3.  1.  6.] 
adversary owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6] -> size -> 45 
adversary victory points: -1
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[13.801882]
 [12.793315]
 [15.387618]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  1.  0.  0.] 
cards in discard: [ 6. 15.  3.  1.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.532019317150116
desired expected reward: 17.21320343017578



action possibilites: [-1. 25.] 
expected returns: [[14.475207]
 [17.228043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 25.] 
cards in discard: [ 6. 15.  3.  1.  6. 16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 3
Learning step: 0.22787924110889435
desired expected reward: 13.276321411132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[13.27018  ]
 [14.801086 ]
 [13.872143 ]
 [12.026948 ]
 [11.2172785]
 [13.674016 ]
 [15.986586 ]
 [17.362785 ]
 [16.049204 ]
 [13.169769 ]
 [13.012778 ]
 [14.434081 ]
 [11.5225315]
 [14.698712 ]
 [14.605183 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 25.] 
cards in discard: [ 6. 15.  3.  1.  6. 16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  6.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.1696394830942154
desired expected reward: 14.644845962524414



buy possibilites: [-1] 
expected returns: [[21.429655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 25.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6 0] -> size -> 4 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -11   0   0  50   0] 
sum of rewards: 54 

action type: buy - action 25.0
Learning step: 1.3209501504898071
desired expected reward: 18.789653778076172






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0.  6.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.] 
adversary owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25] -> size -> 46 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0.  6.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.] 
adversary owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25] -> size -> 46 
adversary victory points: -1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0.  6.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.] 
adversary owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25] -> size -> 46 
adversary victory points: -1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0.  6.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.] 
adversary owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25] -> size -> 46 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 8. 10.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[14.035083]
 [14.757222]
 [13.893544]
 [14.757222]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  0.  6.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25
  0 29 16  0 10 25  8 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6412689685821533
desired expected reward: 20.78838539123535



action possibilites: [-1] 
expected returns: [[17.8139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.24526751041412354
desired expected reward: 13.304549217224121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.571205]
 [14.540856]
 [17.840887]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09011712670326233
desired expected reward: 17.904016494750977



buy possibilites: [-1] 
expected returns: [[13.616336]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -10   0   0   0   0] 
sum of rewards: 5 

action type: buy - action 0.0
Learning step: -0.2041645348072052
desired expected reward: 16.36703872680664






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 11. 11.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0] -> size -> 45 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 11. 11.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0] -> size -> 45 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 11. 11.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0] -> size -> 45 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 11. 11.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0] -> size -> 45 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[14.354834]
 [16.93428 ]
 [15.621197]
 [15.621197]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 11. 11.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 27. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.39161190390586853
desired expected reward: 13.224723815917969



action possibilites: [-1] 
expected returns: [[19.958757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 11.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -11   0   0   4   0] 
sum of rewards: 8 

action type: gain_card_n - action 2
Learning step: 0.07827841490507126
desired expected reward: 12.45456314086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.63037 ]
 [16.605108]
 [19.90545 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3. 11.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04743329808115959
desired expected reward: 20.00619125366211



buy possibilites: [-1] 
expected returns: [[16.975979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3. 11.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -12.   0.   0.
   0.   0.] 
sum of rewards: 3.0 

action type: buy - action 0.0
Learning step: -0.2906632125377655
desired expected reward: 18.339704513549805






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [16.  0.  3.  1. 29.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0] -> size -> 47 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [16.  0.  3.  1. 29.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0] -> size -> 47 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [16.  0.  3.  1. 29.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0] -> size -> 47 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [16.  0.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[12.610141]
 [11.786807]
 [13.909467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  1. 29.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5228115320205688
desired expected reward: 16.453166961669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[11.421493 ]
 [12.8016615]
 [11.964973 ]
 [ 9.52358  ]
 [13.852347 ]
 [12.471763 ]
 [12.610142 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  1. 29.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3976391553878784
desired expected reward: 12.212501525878906



buy possibilites: [-1] 
expected returns: [[15.439818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  1. 29.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -13.   0.   0.
   0.   0.] 
sum of rewards: -18.0 

action type: buy - action 0.0
Learning step: -0.7205266356468201
desired expected reward: 10.700965881347656






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25. 15.  0. 10. 10.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0] -> size -> 48 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25. 15.  0. 10. 10.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0] -> size -> 48 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 15.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 10. 10.] 
expected returns: [[11.5913725]
 [13.951485 ]
 [11.681997 ]
 [11.4611025]
 [11.4611025]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  0. 10. 10.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4828493297100067
desired expected reward: 14.956969261169434



action possibilites: [-1. 25. 15. 10.] 
expected returns: [[11.338708]
 [13.7426  ]
 [11.435625]
 [11.207544]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  0. 10.  0.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 26. 30.  8.  2.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.2407720386981964
desired expected reward: 11.701874732971191



action possibilites: [-1. 15. 10. 11. 11.] 
expected returns: [[12.166249 ]
 [12.2617445]
 [12.038227 ]
 [13.354136 ]
 [13.354136 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  0. 11. 11.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 26. 30.  8.  1.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0.7718988060951233
desired expected reward: 14.51449966430664



action possibilites: [-1. 15. 11. 11. 25.] 
expected returns: [[10.473823]
 [10.560976]
 [11.566095]
 [11.566095]
 [12.653035]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 11. 11. 25.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 25. 10.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 26. 30.  8.  1.  8.  4.  0.  5.  8. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 1.4108823537826538
desired expected reward: 13.449106216430664



action possibilites: [-1. 15. 11. 25.] 
expected returns: [[13.16817 ]
 [13.269834]
 [14.443718]
 [15.710236]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 11. 25.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 25. 10. 11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 26. 30.  8.  1.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  80   0   0   0   0 -14   0   0  16   0] 
sum of rewards: 77 

action type: gain_card_n - action 9
Learning step: 2.0923516750335693
desired expected reward: 14.408452033996582



action possibilites: [-1] 
expected returns: [[8.971496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 11. 10.  8.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25. 10. 11. 25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 26. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [8 0 0 6 6] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 2.472893476486206
desired expected reward: 18.183128356933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[8.003053]
 [8.443307]
 [8.971496]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 11. 10.  8.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25. 10. 11. 25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 26. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [8 0 0 6 6] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 2.670865058898926
desired expected reward: 11.64236068725586



buy possibilites: [-1] 
expected returns: [[8.690692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 11. 10.  8.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25. 10. 11. 25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [8 0 0 6 6] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0 -15   0   0   8   0] 
sum of rewards: 88 

action type: buy - action 3.0
Learning step: 2.4779529571533203
desired expected reward: 10.921259880065918






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  8.  3. 10.  0.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.  3. 10. 25. 10. 11. 25.
 15.  0.  0. 11. 10.  8.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  8.  3. 10.  0.] 
adversary cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.  3. 10. 25. 10. 11. 25.
 15.  0.  0. 11. 10.  8.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  8.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[16.32092 ]
 [17.078005]
 [16.172989]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 10.  0.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.  3. 10. 25. 10. 11. 25.
 15.  0.  0. 11. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.23605556786060333
desired expected reward: 8.454636573791504



action possibilites: [-1.  8. 11.] 
expected returns: [[16.850847]
 [17.621187]
 [18.237371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3.  0. 11.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.  3. 10. 25. 10. 11. 25.
 15.  0.  0. 11. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.15069517493247986
desired expected reward: 16.32368278503418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.586431]
 [16.850847]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  3.  0. 11.] 
cards in discard: [ 6. 15.  3.  1.  6. 16. 25. 29.  1.  0.  0. 25.  0.  8. 10.  6.  3.  0.
 11.  0. 25.  3. 11.  0. 16.  0.  3.  1. 29. 15.  3. 10. 25. 10. 11. 25.
 15.  0.  0. 11. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.11609796434640884
desired expected reward: 16.96694564819336






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
adversary victory points: 1
player victory points: -2 





Player: 0 
cards in hand: [11.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[16.172188]
 [17.734034]
 [16.003984]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0] -> size -> 6 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4785183370113373
desired expected reward: 16.372329711914062



action possibilites: [-1. 11.] 
expected returns: [[15.702199]
 [17.258234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0] -> size -> 6 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1444513350725174
desired expected reward: 16.15194320678711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[14.387889]
 [16.092573]
 [15.047582]
 [14.830907]
 [17.405441]
 [17.479294]
 [14.27494 ]
 [15.678399]
 [15.975799]
 [15.849409]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  8. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0] -> size -> 6 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.14753925800323486
desired expected reward: 15.849738121032715



buy possibilites: [-1] 
expected returns: [[12.0831995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  1.] 
cards in discard: [29.] 
cards in deck: 44 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [6. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0] -> size -> 6 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -16   0   0  32   0] 
sum of rewards: 31 

action type: buy - action 29.0
Learning step: 0.5324947834014893
desired expected reward: 18.01178741455078






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [25.  0. 10. 10.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [25.  0. 10. 10.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 0.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [25.  0. 10. 10.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
adversary victory points: 1
player victory points: -2 





Player: 0 
cards in hand: [25.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
expected returns: [[16.929247]
 [19.575361]
 [16.783365]
 [16.783365]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10. 10.  0.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3242378830909729
desired expected reward: 11.75896167755127



action possibilites: [-1] 
expected returns: [[16.881641]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0. 15. 10.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.030294571071863174
desired expected reward: 19.605655670166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[15.613729]
 [16.265291]
 [17.01256 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0. 15. 10.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.11617355048656464
desired expected reward: 16.997814178466797






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10.  3.  0. 16. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 25. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10.  3.  0. 16. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10.  3.  0. 16. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
adversary victory points: 1
player victory points: -1 





Player: 0 
cards in hand: [10.  3.  0. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 11.] 
expected returns: [[12.238349]
 [12.128007]
 [11.538635]
 [13.370643]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 16. 11.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  7.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5288195610046387
desired expected reward: 16.48373794555664



action possibilites: [-1] 
expected returns: [[9.509791]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 16.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -17   0   0  16   0] 
sum of rewards: 14 

action type: gain_card_n - action 8
Learning step: 0.13378603756427765
desired expected reward: 13.002677917480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[8.583331]
 [9.509791]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 16.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26066794991493225
desired expected reward: 9.770459175109863



buy possibilites: [-1] 
expected returns: [[10.335254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 16.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -18.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -0.238979771733284
desired expected reward: 8.344351768493652






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [0. 6. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  3. 25.  6.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  3. 25.  6.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
adversary victory points: 1
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3. 25.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[12.92624 ]
 [15.672641]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 25.  6.  0.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.30702975392341614
desired expected reward: 10.028223991394043



action possibilites: [-1] 
expected returns: [[10.803723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6.  0. 11. 25.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.09325987845659256
desired expected reward: 15.765900611877441





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.736028]
 [10.803723]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6.  0. 11. 25.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23484309017658234
desired expected reward: 11.038566589355469






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [8. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 24. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3 3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 23. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[13.424539]
 [14.564836]
 [13.315502]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10.  3.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 23. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  4. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3 3] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3278719186782837
desired expected reward: 10.475851058959961



action possibilites: [-1] 
expected returns: [[10.644225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 23. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3 3] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -19   0   0   9   0] 
sum of rewards: 5 

action type: gain_card_n - action 7
Learning step: -0.09507233649492264
desired expected reward: 11.799484252929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.5887785]
 [10.644226 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 26. 30. 23. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3 3] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23800474405288696
desired expected reward: 10.882229804992676






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3 3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 23. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [29.  0.  1.  3.  8.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3 3] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 23. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [29.  0.  1.  3.  8.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [29.  0.  1.  3.  8.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[14.775632]
 [16.214441]
 [15.534522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  3.  8.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3 3 3] -> size -> 10 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3050075173377991
desired expected reward: 10.339217185974121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[13.529851]
 [14.996392]
 [14.110128]
 [16.143461]
 [14.642728]
 [14.775629]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  3.  8.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 6 0 0 3 3 3] -> size -> 10 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4358901381492615
desired expected reward: 14.339739799499512



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [15.  1. 16. 25. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [15.  1. 16. 25. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [15.  1. 16. 25. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [15.  1. 16. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 25. 11.] 
expected returns: [[12.630992]
 [12.739623]
 [11.864757]
 [15.056517]
 [13.841806]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 16. 25. 11.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [1. 0. 3. 0. 0. 6.] 
adversary owned cards: [8 0 0 6 6 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4505455791950226
desired expected reward: 14.325084686279297



action possibilites: [-1] 
expected returns: [[11.006308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 16. 11.  3.  0.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [1. 0. 3. 0. 0. 6.] 
adversary owned cards: [8 0 0 6 6 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.1159641221165657
desired expected reward: 15.102700233459473





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 9.995552]
 [11.223133]
 [10.471381]
 [12.215326]
 [10.908965]
 [11.006308]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 16. 11.  3.  0.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  3. 10.  6.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [1. 0. 3. 0. 0. 6.] 
adversary owned cards: [8 0 0 6 6 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23761190474033356
desired expected reward: 11.243919372558594



buy possibilites: [-1] 
expected returns: [[13.336276]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 16. 11.  3.  0.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10 10] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  2. 10.  6.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [1. 0. 3. 0. 0. 6.] 
adversary owned cards: [8 0 0 6 6 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -20   0   0  18   0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: 0.20276188850402832
desired expected reward: 11.111727714538574






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 8.] 
cards in discard: [1. 0. 3. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 6 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  2. 10.  6.] 
adversary cards in hand: [29.  0. 25. 15.  6.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8. 10. 25. 15.  1. 16. 11.  3.  0.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10 10] -> size -> 55 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [1. 0. 3. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 6 0 0 3 1] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  2. 10.  6.] 
adversary cards in hand: [29.  0. 25. 15.  6.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8. 10. 25. 15.  1. 16. 11.  3.  0.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10 10] -> size -> 55 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [1. 0. 3. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 6 0 0 3 1] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  2. 10.  6.] 
adversary cards in hand: [29.  0. 25. 15.  6.] 
adversary cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8. 10. 25. 15.  1. 16. 11.  3.  0.] 
adversary owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10 10] -> size -> 55 
adversary victory points: 1
player victory points: 0 


Player 0 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 1 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 4 
Chapel: 3 
Witch: 5 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  0. 25. 15.  6.] 
cards in discard: [29. 10. 11.  0.  0.  6.  1. 25.  0. 10. 10.  0. 15. 10. 15.  0. 11. 10.
  3.  0. 16. 25.  6.  3.  6.  0. 11. 25. 10. 11.  3.  0. 10.  3. 29.  0.
  1.  3.  8. 10. 25. 15.  1. 16. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 11  1  0 11  0  3  0  1 15  1 10 29 10  6  6 10 15 25 10 25  0
 29 16  0 10 25 11  3  8  0  8  0 16 10 25  8 11  6  6  6 25  0  3  0  0
 15  3 29 15  0 10 10] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 30.  8.  0.  8.  4.  0.  5.  7. 10. 10.  2. 10.  6.] 
adversary cards in hand: [0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 6. 0.] 
adversary owned cards: [8 0 0 6 0 0 3 1 0] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.449911117553711
desired expected reward: 27.78618621826172



