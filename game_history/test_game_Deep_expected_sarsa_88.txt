 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.87236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0       20        0
        0        0        0     -140        0     -300        0        0] 
sum of rewards: -3000665 

action type: buy - action 6.0
Learning step: -120021.5234375
desired expected reward: -120148.265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 62.238842]
 [ 94.221   ]
 [ 74.357315]
 [ 12.642659]
 [ 86.20582 ]
 [ 95.36159 ]
 [ 83.42924 ]
 [109.50249 ]
 [ 33.68956 ]
 [ 63.379787]
 [ 65.47348 ]
 [ 77.720406]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.73014831542969



buy possibilites: [-1] 
expected returns: [[75.94586]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.50244903564453






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[77.78191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.94586181640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[64.67108 ]
 [94.056755]
 [75.69724 ]
 [20.310635]
 [95.11191 ]
 [84.083145]
 [65.723656]
 [78.81189 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.37716674804688



buy possibilites: [-1] 
expected returns: [[67.89146]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 95.11193084716797






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[64.87823 ]
 [94.89624 ]
 [81.640625]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.8914566040039



action possibilites: [-1. 11.] 
expected returns: [[64.37116 ]
 [80.054695]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 95.06197357177734



action possibilites: [-1] 
expected returns: [[48.444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.21920013427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 34.194756]
 [ 63.689472]
 [ 45.380005]
 [-12.320486]
 [ 56.298717]
 [ 64.74277 ]
 [ 53.744522]
 [ 77.74991 ]
 [  7.373227]
 [ 35.256985]
 [ 37.189976]
 [ 48.502716]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.444000244140625



buy possibilites: [-1] 
expected returns: [[66.48491]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 103 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 77.74992370605469






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0. 10.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.09441]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.48490905761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 27.738354 ]
 [ 55.237526 ]
 [ 38.055805 ]
 [-14.722766 ]
 [ 48.296314 ]
 [ 56.232002 ]
 [ 45.898697 ]
 [ 68.30849  ]
 [  3.0319395]
 [ 28.728348 ]
 [ 30.51973  ]
 [ 40.990868 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.274410247802734



buy possibilites: [-1] 
expected returns: [[84.310936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 63 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 68.30850219726562






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[13.84571 ]
 [43.456264]
 [29.9893  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.3109359741211



action possibilites: [-1. 11. 29.] 
expected returns: [[32.8596  ]
 [47.50815 ]
 [59.158276]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.94874954223633



action possibilites: [-1. 11. 29.] 
expected returns: [[43.144756]
 [56.327763]
 [68.17372 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 59.15829086303711



action possibilites: [-1. 11.] 
expected returns: [[79.476036]
 [92.02514 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.17373657226562



action possibilites: [-1] 
expected returns: [[92.79902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 106.6961669921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 83.93601 ]
 [107.45843 ]
 [ 69.29297 ]
 [ 92.8154  ]
 [ 62.019382]
 [ 47.64342 ]
 [101.52707 ]
 [108.38744 ]
 [ 99.50806 ]
 [140.62157 ]
 [118.70492 ]
 [ 62.9484  ]
 [ 88.48981 ]
 [ 84.86503 ]
 [ 64.967384]
 [ 86.47081 ]
 [ 95.83836 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.79901885986328



buy possibilites: [-1] 
expected returns: [[147.64821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 140.62155151367188






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25] -> size -> 17 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.2736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 147.64820861816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 87.41149 ]
 [111.61254 ]
 [ 96.18147 ]
 [ 51.591454]
 [105.16615 ]
 [112.62284 ]
 [103.018776]
 [123.87005 ]
 [ 66.84531 ]
 [ 88.3183  ]
 [ 89.8852  ]
 [ 99.19247 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.76116180419922



buy possibilites: [-1] 
expected returns: [[107.21095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 63 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.87007904052734






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  3.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[55.22124]
 [45.0167 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.21095275878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[46.01811 ]
 [54.380436]
 [11.475022]
 [60.70136 ]
 [57.070225]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.2512092590332



buy possibilites: [-1] 
expected returns: [[79.81421]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 60.70137405395508






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 29.  0. 25.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 29.  0. 25.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 29.  0. 25.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8] -> size -> 19 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [10. 29.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[121.2174 ]
 [109.44061]
 [146.3897 ]
 [170.34889]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 25.  0.] 
cards in discard: [ 8.  0.  0.  3. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.814208984375



action possibilites: [-1] 
expected returns: [[128.86723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0. 29.  0.] 
cards in discard: [ 8.  0.  0.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.  8.  3.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 167.67649841308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[126.05253]
 [150.13307]
 [135.12656]
 [ 90.64282]
 [151.05957]
 [141.98553]
 [126.97903]
 [138.04788]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0. 29.  0.] 
cards in discard: [ 8.  0.  0.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.  8.  3.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.8672332763672



buy possibilites: [-1] 
expected returns: [[110.18491]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0. 29.  0.] 
cards in discard: [ 8.  0.  0.  3. 10.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.  8.  3.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 151.0595703125






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.  8.  3.  0.  3.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  3. 11. 25. 10. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.  8.  3.  0.  3.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  3. 11. 25. 10. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.  8.  3.  0.  3.  0.  0.  6. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  3. 11. 25. 10. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[110.51273]
 [138.60493]
 [125.46516]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 11.] 
cards in discard: [ 8.  0.  0.  3. 10.  3. 11. 25. 10. 29.  0.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.1849136352539



action possibilites: [-1. 11. 29.] 
expected returns: [[115.06347]
 [130.38876]
 [143.65538]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 29.] 
cards in discard: [ 8.  0.  0.  3. 10.  3. 11. 25. 10. 29.  0.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 135.7126922607422



action possibilites: [-1. 11.  8.] 
expected returns: [[110.99218 ]
 [121.70971 ]
 [114.094246]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 143.65536499023438



action possibilites: [-1] 
expected returns: [[105.76933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 134.9928436279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 99.613075]
 [120.818085]
 [107.61973 ]
 [ 66.66111 ]
 [115.47107 ]
 [121.65942 ]
 [113.65281 ]
 [130.96152 ]
 [ 80.7002  ]
 [100.454445]
 [101.9052  ]
 [110.367424]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.76933288574219



buy possibilites: [-1] 
expected returns: [[167.29057]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 130.9615478515625






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [10. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
action values: 3 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[125.60894]
 [147.22128]
 [116.29643]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 167.2905731201172



action possibilites: [-1. 10. 10.] 
expected returns: [[183.63287]
 [173.65103]
 [173.65103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 142.4200897216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[175.60176]
 [183.7093 ]
 [142.49612]
 [189.82507]
 [186.436  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 183.63287353515625



buy possibilites: [-1] 
expected returns: [[192.40024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  7.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 189.82501220703125






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 6. 0.] 
cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  7.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.  8. 29.  3.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 0.] 
cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  7.  9.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.  8. 29.  3.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 0.] 
cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  7.  9.  4. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.  8. 29.  3.  0.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[53.28819]
 [91.87374]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  0.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.  8. 29.  3.  0.  3. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  8.  7.  9.  4. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  8.] 
adversary cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3. 29.  1.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0 29] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 192.40023803710938



action possibilites: [-1] 
expected returns: [[77.525536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11. 29.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.  8. 29.  3.  0.  3. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  4. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  8.] 
adversary cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3. 29.  1.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0 29  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.87377166748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[63.634594]
 [84.076096]
 [71.61828 ]
 [30.836403]
 [79.15303 ]
 [84.883316]
 [77.475464]
 [93.49148 ]
 [44.821926]
 [64.49033 ]
 [65.94582 ]
 [74.39769 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11. 29.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.  8. 29.  3.  0.  3. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  4. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  8.] 
adversary cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3. 29.  1.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0 29  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.5255355834961



buy possibilites: [-1] 
expected returns: [[75.879776]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11. 29.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  8.  8. 29.  3.  0.  3. 10. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  8.] 
adversary cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3. 29.  1.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0 29  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 93.49150848388672






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 23.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  0.  8.] 
cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3. 29.  1.  0.  3.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6 23  0 29  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3. 29.  1.  0.  3.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10. 10.  0.  3.  0.  3.  3. 29.  1.  0.  3.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  0. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 29.] 
expected returns: [[ 87.88481]
 [ 77.93022]
 [ 77.93022]
 [ 91.27035]
 [109.58776]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.87977600097656



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[131.80998]
 [122.03298]
 [122.03298]
 [135.14359]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 10 25 29  8 11 10 29  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.5737075805664



action possibilites: [-1] 
expected returns: [[24.485405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 153.54486083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 16.55439 ]
 [ 24.013638]
 [-12.731998]
 [ 29.624954]
 [ 26.63271 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.48540496826172



buy possibilites: [-1] 
expected returns: [[33.588745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 29.624980926513672






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 11. 29.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  8.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 11. 29.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  8.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 11. 29.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[118.0958 ]
 [108.50047]
 [129.21278]
 [138.30066]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11. 29.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  8.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.5887451171875



action possibilites: [-1. 10. 11. 25.] 
expected returns: [[145.6518 ]
 [135.78755]
 [157.49837]
 [187.53987]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11. 25.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  8.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 133.667724609375



action possibilites: [-1] 
expected returns: [[191.66125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.  3.  0.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  8.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 187.53988647460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[182.34947]
 [202.52385]
 [189.69745]
 [152.03224]
 [203.34523]
 [195.3252 ]
 [183.10693]
 [192.09   ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 11.  3.  0.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  8.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 191.6612548828125



buy possibilites: [-1] 
expected returns: [[167.88506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 11.  3.  0.] 
cards in discard: [ 8. 29.  8.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 203.3452606201172






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  3. 10.] 
cards in discard: [ 3.  3.  0. 10.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 29.  0. 11.  3.] 
adversary cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  3.  6.] 
cards in discard: [ 3.  3.  0. 10.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  6  0 29  6  3  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 29.  0. 11.  3.] 
adversary cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  3.  0. 10.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 29.  0. 11.  3.] 
adversary cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  3.  0. 10.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 29.  0. 11.  3.] 
adversary cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29. 29.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[119.143745]
 [137.32106 ]
 [137.32106 ]
 [128.96567 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 11.  3.] 
cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 167.8850555419922



action possibilites: [-1. 29. 11. 29.] 
expected returns: [[143.63918]
 [162.0947 ]
 [153.69897]
 [162.0947 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3. 29.] 
cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 135.5867156982422



action possibilites: [-1. 11. 29.] 
expected returns: [[ 95.98702]
 [105.57905]
 [113.77985]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29.  0.] 
cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 162.0947265625



action possibilites: [-1. 11. 29.] 
expected returns: [[140.61992]
 [150.68369]
 [159.0776 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 29.] 
cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 113.77983093261719



action possibilites: [-1. 11.  8.] 
expected returns: [[137.61446]
 [147.6164 ]
 [140.40704]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  8.] 
cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 159.07760620117188



action possibilites: [-1] 
expected returns: [[141.50357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 160.12118530273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[130.76414 ]
 [149.53859 ]
 [119.33917 ]
 [137.6957  ]
 [113.66003 ]
 [102.22862 ]
 [144.61214 ]
 [150.3471  ]
 [142.92682 ]
 [177.22527 ]
 [158.97594 ]
 [114.418846]
 [134.3676  ]
 [131.51956 ]
 [115.99908 ]
 [132.79314 ]
 [140.16899 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  9.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.50357055664062



buy possibilites: [-1] 
expected returns: [[130.16144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 8. 29.  8.  0. 11. 29. 25.  3.  0. 10. 11.  3.  0. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 127.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 177.22528076171875






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [11.  3.  8. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  7.  6.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [11.  3.  8. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0. 10.  0.  3.  6. 10.  8.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  6.  6.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [11.  3.  8. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  3.  8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 25.] 
expected returns: [[ 73.23594 ]
 [ 83.800095]
 [ 76.30973 ]
 [110.983086]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 25.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  6.  6.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.16143798828125



action possibilites: [-1] 
expected returns: [[110.55571]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  6.  6.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.88705444335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[105.19687 ]
 [112.07696 ]
 [ 77.16398 ]
 [117.751854]
 [114.64979 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  6.  6.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.55570983886719



buy possibilites: [-1] 
expected returns: [[125.24024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  0.  0. 29.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 117.75186920166016






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 8. 25.  8. 10. 11.] 
adversary cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 8. 25.  8. 10. 11.] 
adversary cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  6. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 8. 25.  8. 10. 11.] 
adversary cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 8. 25.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8. 10. 11.] 
expected returns: [[128.42793]
 [131.8293 ]
 [169.5071 ]
 [131.8293 ]
 [118.83649]
 [139.96307]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8. 10. 11.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  6. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [3. 8. 6. 3. 3.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.24024200439453



action possibilites: [-1] 
expected returns: [[107.51521]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 11.  0. 10.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [3. 8. 6. 3. 3.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 168.01693725585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[88.95438 ]
 [58.182476]
 [98.82417 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10. 11.  0. 10.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [3. 8. 6. 3. 3.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.51521301269531






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 8. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 3. 3.] 
cards in discard: [6. 3. 0. 3. 0. 0. 1. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0. 29.] 
adversary cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29. 25.  8.  8. 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 3. 3.] 
cards in discard: [6. 3. 0. 3. 0. 0. 1. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0. 29.] 
adversary cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29. 25.  8.  8. 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[74.96847]
 [94.42234]
 [94.42234]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 29.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29. 25.  8.  8. 10. 11.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 98.82418060302734



action possibilites: [-1. 29.] 
expected returns: [[67.323875]
 [90.03269 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29. 25.  8.  8. 10. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 94.4223403930664



action possibilites: [-1. 11.] 
expected returns: [[77.39332]
 [89.21807]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29. 25.  8.  8. 10. 11.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 90.0326919555664



action possibilites: [-1] 
expected returns: [[51.323658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29. 25.  8.  8. 10. 11.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 103.22884368896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[40.342564]
 [60.028797]
 [47.783894]
 [ 9.428603]
 [55.073742]
 [60.82549 ]
 [53.384148]
 [69.74724 ]
 [20.952374]
 [41.13924 ]
 [42.4982  ]
 [50.39495 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29. 25.  8.  8. 10. 11.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.32365798950195



buy possibilites: [-1] 
expected returns: [[79.325294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 8. 25. 11.  3.  8.  0.  0. 29. 25.  8.  8. 10. 11.  0. 10. 10. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 69.74724578857422






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 10.] 
cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  5.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 8. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 8. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 8. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [6. 3. 0. 3. 0. 0. 1. 6. 3. 8. 6. 3. 3. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 8. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 8. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29. 29.] 
expected returns: [[40.992836]
 [43.97473 ]
 [59.88905 ]
 [59.88905 ]
 [59.88905 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  1.  6.  3.  8.  6.  3.  3.  8.  3. 11.  0.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.3252944946289



action possibilites: [-1.  8. 29. 29. 11.] 
expected returns: [[ 84.92257]
 [ 88.14381]
 [103.55921]
 [103.55921]
 [ 95.66001]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29.  0. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  1.  6.  3.  8.  6.  3.  3.  8.  3. 11.  0.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.17782974243164



action possibilites: [-1.  8. 29. 11.] 
expected returns: [[ 97.33171]
 [100.5313 ]
 [116.80859]
 [108.05547]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  1.  6.  3.  8.  6.  3.  3.  8.  3. 11.  0.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 103.55923461914062



action possibilites: [-1.  8. 11.] 
expected returns: [[118.08744]
 [121.3543 ]
 [129.289  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  1.  6.  3.  8.  6.  3.  3.  8.  3. 11.  0.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 116.80862426757812



action possibilites: [-1] 
expected returns: [[117.9242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  1.  6.  3.  8.  6.  3.  3.  8.  3. 11.  0.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 142.5301513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[108.65979 ]
 [128.65695 ]
 [116.03126 ]
 [ 78.12747 ]
 [123.41178 ]
 [129.48859 ]
 [121.62858 ]
 [138.62068 ]
 [ 90.75658 ]
 [109.438736]
 [110.77772 ]
 [118.579796]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  2. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  1.  6.  3.  8.  6.  3.  3.  8.  3. 11.  0.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.92420196533203



buy possibilites: [-1] 
expected returns: [[171.46254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [10. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  1.  6.  3.  8.  6.  3.  3.  8.  3. 11.  0.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 138.62069702148438






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  0.  3.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  1.  6.  3.  8.  6.  3.  3.  8.  3. 11.  0.  0.
  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [25. 25.  0. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29] -> size -> 30 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [25. 25.  0. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [25. 25.  0. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [25. 25.  0. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29] -> size -> 30 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [25. 25.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 10. 10.] 
expected returns: [[ 97.35727]
 [134.29996]
 [134.29996]
 [ 88.41792]
 [ 88.41792]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 10. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  5. 10.  6.  4.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3.  1.  0.  3. 11.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 171.46253967285156



action possibilites: [-1] 
expected returns: [[141.12222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10. 10.  8.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  4. 10.  6.  4.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3.  1.  0.  3. 11.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.29995727539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[131.39236]
 [138.15485]
 [104.14245]
 [143.24432]
 [140.52533]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 10. 10.  8.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  4. 10.  6.  4.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3.  1.  0.  3. 11.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.12222290039062



buy possibilites: [-1] 
expected returns: [[121.60058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 10. 10.  8.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3.  1.  0.  3. 11.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 143.24435424804688






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  3. 11.] 
cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8] -> size -> 31 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  3. 11.] 
cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8] -> size -> 31 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  3. 11.] 
cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8] -> size -> 31 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[51.70594 ]
 [71.004585]
 [62.241726]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  0.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.60057830810547



action possibilites: [-1. 11.] 
expected returns: [[60.598995]
 [72.20895 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  1. 10.  9.  2. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.00459289550781



action possibilites: [-1] 
expected returns: [[66.481766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  1. 10.  9.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.71014404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[57.203796]
 [82.17243 ]
 [66.337395]
 [22.535786]
 [75.763916]
 [83.187614]
 [73.578255]
 [95.7285  ]
 [36.842316]
 [58.150684]
 [59.77634 ]
 [69.63219 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  1. 10.  9.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.48176574707031



buy possibilites: [-1] 
expected returns: [[45.720676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  0. 10.  9.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 95.72850799560547






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [6. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 8.] 
cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  0. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 29.  8.  8. 29.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 8.] 
cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  0. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 29.  8.  8. 29.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 29.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.  8. 29.] 
expected returns: [[40.903282]
 [35.771236]
 [52.037346]
 [42.821594]
 [42.821594]
 [52.037346]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  8.  8. 29.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  0. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.  6.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.72067642211914



action possibilites: [-1. 10.  8. 29. 29.] 
expected returns: [[10.009452 ]
 [ 4.1314363]
 [11.712367 ]
 [20.3325   ]
 [20.3325   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 29.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29. 29. 11.  3.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  0. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.  6.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 46.64714431762695



action possibilites: [-1. 10.  8. 11.] 
expected returns: [[20.525867]
 [14.897035]
 [22.450363]
 [27.029564]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29. 29. 11.  3.  0.  0.  0.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  0. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.  6.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.282076835632324



action possibilites: [-1] 
expected returns: [[20.213326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29. 29. 11.  3.  0.  0.  0.  8. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  0. 10.  9.  1. 10.  9.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.  6.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 64  0] 
sum of rewards: 119 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.5828971862793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.197331 ]
 [18.811577 ]
 [-4.8129196]
 [22.293892 ]
 [20.34467  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29. 29. 11.  3.  0.  0.  0.  8. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  3.  8.  0. 10.  9.  1. 10.  9.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.  6.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.21332550048828



buy possibilites: [-1] 
expected returns: [[-28.480087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [10. 29. 29. 29. 29. 11.  8.  0.  3.  3.  8. 25. 25.  0. 10. 10.  8.  0.
 10. 29. 29. 11.  3.  0.  0.  0.  8. 29. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  2.  8.  0. 10.  9.  1. 10.  9.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.  6.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 16  0] 
sum of rewards: 71 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 22.293899536132812






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [10.  6.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  8.  3.] 
cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.  6.  3.  6.  0.
  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  2.  8.  0. 10.  9.  1. 10.  9.] 
adversary cards in hand: [29. 10. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  8.  3.] 
cards in discard: [ 0. 10.  3.  6.  0.  3.  0.  6.  0.  3.  1.  0.  3. 11.  6.  3.  6.  0.
  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  2.  8.  0. 10.  9.  1. 10.  9.] 
adversary cards in hand: [29. 10. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 10. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 29. 11.] 
expected returns: [[106.130714]
 [125.63947 ]
 [ 97.13282 ]
 [ 97.13282 ]
 [125.63947 ]
 [116.889534]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 29. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  2.  8.  0. 10.  9.  1. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -28.480087280273438



action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[ 85.85921 ]
 [ 78.190796]
 [ 78.190796]
 [ 94.51234 ]
 [102.91286 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 29.] 
cards in discard: [29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  2.  8.  0. 10.  9.  1. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 116.12010192871094



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[125.88555]
 [118.49573]
 [118.49573]
 [134.27876]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [29.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  2.  8.  0. 10.  9.  1. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.85517120361328



action possibilites: [-1] 
expected returns: [[114.6594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [29.  8. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  2.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 144.1971435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.95931 ]
 [113.21399 ]
 [ 81.555595]
 [117.938   ]
 [115.28168 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [29.  8. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  2.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.6594009399414



buy possibilites: [-1] 
expected returns: [[128.55977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [29.  8. 15.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 117.93800354003906






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [29. 11. 15.  8. 25.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [29. 11. 15.  8. 25.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [29. 11. 15.  8. 25.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 11. 15.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.  8. 25.] 
expected returns: [[152.4632 ]
 [170.43242]
 [162.26804]
 [144.97893]
 [155.24188]
 [187.72151]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 15.  8. 25.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8. 10.  3.  3.  3.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.5597686767578



action possibilites: [-1] 
expected returns: [[103.291756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 15.  8. 10.  0.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8. 10.  3.  3.  3.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 187.72152709960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 95.474205]
 [ 70.870995]
 [103.71258 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 15.  8. 10.  0.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8. 10.  3.  3.  3.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.29175567626953






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  3.  3.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 8.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 8.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6] -> size -> 30 
action values: 2 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  3. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 8.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 97.96702 ]
 [117.920555]
 [ 89.202736]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0.  0.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.71253204345703



action possibilites: [-1. 10. 25.] 
expected returns: [[104.07961 ]
 [ 97.909195]
 [132.0552  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 25.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 108.23918151855469



action possibilites: [-1] 
expected returns: [[98.55341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  8.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.05520629882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 87.455345]
 [109.28356 ]
 [ 95.67447 ]
 [ 53.478554]
 [110.11112 ]
 [101.892006]
 [ 88.282936]
 [ 98.27594 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 29.  8.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  5.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.55341339111328



buy possibilites: [-1] 
expected returns: [[76.033905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 29.  8.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  4.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 110.11116027832031






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  4.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  4.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11] -> size -> 38 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  2. 10.  4.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11] -> size -> 38 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[47.087936]
 [60.913395]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  2. 10.  4.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 10.  6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.03390502929688



action possibilites: [-1.] 
expected returns: [[57.304974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  2. 10.  4.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 10.  6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 54.1768684387207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[50.849598]
 [65.2939  ]
 [56.29508 ]
 [30.031578]
 [61.660175]
 [65.85603 ]
 [60.41055 ]
 [38.526657]
 [51.411747]
 [52.385685]
 [58.053654]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 25. 30.  8.  2. 10.  4.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 10.  6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.30497360229492



buy possibilites: [-1] 
expected returns: [[40.587147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 10.  6.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.   60.    0.    0.   20.    0.    0.    0.    0.  -40.
   0.    0.   13.5   0. ] 
sum of rewards: 48.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 65.85607147216797






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  6.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8.  8. 29. 11.  3.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 6.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8.  8. 29. 11.  3.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 6.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8.  8. 29. 11.  3.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 6.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8.  8. 29. 11.  3.] 
adversary cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11] -> size -> 39 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 8.  8. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29. 11.] 
expected returns: [[ 8.7591095]
 [10.735862 ]
 [10.735862 ]
 [20.805447 ]
 [15.390868 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29. 11.  3.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11. 29.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.  0. 10.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.5871467590332



action possibilites: [-1.  8.  8. 11.] 
expected returns: [[18.727467]
 [20.793102]
 [20.793102]
 [26.168602]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  3.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11. 29.  0.  0.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.  0. 10.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.90622615814209



action possibilites: [-1] 
expected returns: [[5.4407215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11. 29.  0.  0.  0.  3. 29. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.  0. 10.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 35.29342269897461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -0.82540417]
 [-20.929592  ]
 [  5.4407206 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [29.  8. 15.  8. 29. 29. 11. 10. 10. 25. 29. 11. 15.  8. 10.  0.  3. 11.
 29. 25. 10.  0.  0. 29.  8.  8. 11. 29.  0.  0.  0.  3. 29. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.  0. 10.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.44072151184082






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.  0. 10.  3.  0.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  7.] 
adversary cards in hand: [29. 11.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15] -> size -> 40 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.  0. 10.  3.  0.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 25. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  7.] 
adversary cards in hand: [29. 11.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15] -> size -> 40 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [11.  6.  0.  0.  3.  0.  6.  0. 10.  8.  3.  3.  3.  8.  6.  1.  0.  0.
  6.  0.  6.  0. 10.  3.  0.  3.  6.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  7.] 
adversary cards in hand: [29. 11.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15] -> size -> 40 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 10.] 
expected returns: [[77.15548 ]
 [95.791756]
 [87.350876]
 [87.350876]
 [69.52853 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 5.44072151184082



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[72.700165]
 [82.61605 ]
 [82.61605 ]
 [64.41924 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 86.60211181640625



action possibilites: [-1] 
expected returns: [[100.639595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [29. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.39212799072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 92.035545]
 [ 98.171715]
 [ 66.81026 ]
 [103.120125]
 [100.3807  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [29. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  3.  1.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.63959503173828



buy possibilites: [-1] 
expected returns: [[139.56282]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [29. 15.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  3.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 103.1201400756836






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  3.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [29. 29. 29.  0.  8.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [29. 29. 29.  0.  8.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [29. 29. 29.  0.  8.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [29. 29. 29.  0.  8.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 29. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.  8.] 
expected returns: [[127.28071]
 [143.7384 ]
 [143.7384 ]
 [143.7384 ]
 [129.87617]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  8.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 139.5628204345703



action possibilites: [-1. 29.  8.] 
expected returns: [[138.30093]
 [154.93097]
 [140.89333]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 135.59866333007812



action possibilites: [-1.  8.] 
expected returns: [[133.13925]
 [135.8196 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 146.68304443359375



action possibilites: [-1] 
expected returns: [[133.78046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 135.81964111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[125.156136]
 [131.933   ]
 [ 97.24272 ]
 [134.19756 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.78045654296875






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  6.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0. 10.  9.  1. 10.  6.] 
adversary cards in hand: [11.  0.  8.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [11.  0.  8.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [11.  0.  8.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 10.] 
expected returns: [[69.014854]
 [77.647766]
 [71.768364]
 [71.768364]
 [60.20313 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  8. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 134.19757080078125



action possibilites: [-1] 
expected returns: [[23.321705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -38 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 77.04933166503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 13.26854 ]
 [-29.86576 ]
 [ 22.662045]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.321704864501953






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [ 8. 10.  8. 25. 29.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [ 8. 10.  8. 25. 29.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [ 8. 10.  8. 25. 29.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 8. 10.  8. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 25. 29.] 
expected returns: [[105.32291 ]
 [108.225235]
 [ 97.71065 ]
 [108.225235]
 [137.68858 ]
 [121.9499  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8. 25. 29.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  2. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [8. 1. 3. 0. 0.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.662033081054688



action possibilites: [-1] 
expected returns: [[49.940018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8. 29.  3. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  1. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [8. 1. 3. 0. 0.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.68858337402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.78425 ]
 [25.219849]
 [49.833233]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8. 29.  3. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  1. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [8. 1. 3. 0. 0.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.94001770019531






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [8. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3. 0. 0.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8
  3  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  1. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [11.  0.  0. 10. 15.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  1. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [11.  0.  0. 10. 15.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 23. 30.  8.  1. 10.  2.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [11.  0.  0. 10. 15.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 23. 30.  8.  1. 10.  1.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [11.  0.  0. 10. 15.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[-20.498089]
 [-13.621033]
 [-26.41312 ]
 [-25.543362]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 15.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  1. 10.  1.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6 11] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 49.83321762084961



action possibilites: [-1] 
expected returns: [[-42.80749]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 15.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  1. 10.  1.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6 11] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -14.119269371032715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-49.927013]
 [-44.53275 ]
 [-72.214165]
 [-42.807487]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 15.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  1. 10.  1.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6 11] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -42.807491302490234






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  8.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  1. 10.  1.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [15. 11.  0. 25. 29.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.  1. 11.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  8.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  1. 10.  1.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [15. 11.  0. 25. 29.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.  1. 11.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15. 11.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 25. 29.] 
expected returns: [[-14.06334 ]
 [-22.146242]
 [ -2.912158]
 [ 20.047482]
 [  6.117549]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 25. 29.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.  1. 11.  0.  0. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  1. 10.  1.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [3. 3. 1. 8. 3.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  8.  1.  0.  0.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6 11] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -42.807491302490234



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 8 
Witch: 2 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 11.  0. 29. 29.  8.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.  0.  8.  3. 29. 29.  8.  1. 11.  0.
  8.  8. 10. 25.  8. 10.  8. 29.  3. 10.  1. 11.  0.  0. 10. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 29 25 29  8 11 10 29  8 29  8 11 10
 25  8 10 29 10 29  8 10 29 15  8 15  8 11 11 15 15  8  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  0. 10.  1.  0.  8.  0.  9.  9.  1. 10.  6.] 
adversary cards in hand: [3. 3. 1. 8. 3.] 
adversary cards in discard: [11.  3. 11. 10.  0.  3.  0. 14. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  8.  1.  0.  0.  0.  3.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3 10  1  0  8  0  6  3  6 11  6  3  6  8  3
  0  6  0 11  6  0  6  1  0  3 11  3 14  0  6 11  6] -> size -> 41 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      60       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000075 

action type: take_action - action 25.0
Learning step: 120002.1953125
desired expected reward: 120022.2421875



