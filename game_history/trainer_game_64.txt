 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[325.19388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0 -130    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -665 

action type: buy - action 0.0
Learning step: -32.61119079589844
desired expected reward: -45.387351989746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[302.6574 ]
 [314.30466]
 [310.59552]
 [279.492  ]
 [307.72836]
 [322.60858]
 [311.4664 ]
 [313.41455]
 [291.45285]
 [309.04916]
 [304.77502]
 [328.44086]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.4596586227417
desired expected reward: 319.4346008300781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.4623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.175166130065918
desired expected reward: 319.26568603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[318.4826 ]
 [331.47208]
 [326.63257]
 [292.40265]
 [340.57767]
 [328.18732]
 [324.76608]
 [346.82474]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.542010307312012
desired expected reward: 338.20806884765625



buy possibilites: [-1] 
expected returns: [[327.6742]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 3.0
Learning step: -8.908961296081543
desired expected reward: 317.7236328125






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.85974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -9.48398494720459
desired expected reward: 318.1902160644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[291.615  ]
 [301.3544 ]
 [297.5307 ]
 [271.88815]
 [307.57803]
 [299.15173]
 [296.28912]
 [311.9465 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.695418357849121
desired expected reward: 300.1812438964844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  0. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  0. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  0. 11.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.0893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.491419792175293
desired expected reward: 303.455078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[297.58124]
 [311.62393]
 [307.92838]
 [271.65216]
 [322.37247]
 [307.8696 ]
 [305.79288]
 [330.14087]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.870891571044922
desired expected reward: 309.16937255859375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.40952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -10.4519681930542
desired expected reward: 319.68890380859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[274.35867]
 [283.49915]
 [279.8828 ]
 [255.68752]
 [289.9264 ]
 [281.44354]
 [278.73874]
 [295.54675]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.811708450317383
desired expected reward: 284.7471923828125



buy possibilites: [-1] 
expected returns: [[292.50546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -9.0 

action type: buy - action 8.0
Learning step: -7.940805912017822
desired expected reward: 273.5027770996094






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [16. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  0.  0.] 
cards in discard: [3. 3. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  0.  0.  0.] 
cards in discard: [3. 3. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[302.48962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -8.393092155456543
desired expected reward: 284.11236572265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[275.25806]
 [287.39474]
 [283.659  ]
 [253.24625]
 [296.12057]
 [284.30286]
 [281.80914]
 [302.53937]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -9.105165481567383
desired expected reward: 292.32513427734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [11.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 16  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.12042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.955674171447754
desired expected reward: 294.5837097167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[293.1062 ]
 [304.03845]
 [299.41937]
 [270.82242]
 [297.77808]
 [310.4922 ]
 [301.56216]
 [302.6217 ]
 [281.31833]
 [297.70477]
 [293.34198]
 [314.26746]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.280753135681152
desired expected reward: 311.6657409667969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8. 11.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[347.70416]
 [327.61346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  3.  3.] 
adversary cards in discard: [ 8. 11.  0.  0.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.118180274963379
desired expected reward: 306.1492004394531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[300.5952 ]
 [310.61572]
 [272.32703]
 [311.1145 ]
 [330.12277]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  3.  3.] 
adversary cards in discard: [ 8. 11.  0.  0.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.412834167480469
desired expected reward: 318.89227294921875



buy possibilites: [-1] 
expected returns: [[313.5543]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  3.  3.] 
adversary cards in discard: [ 8. 11.  0.  0.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 7 

action type: buy - action 8.0
Learning step: -8.150755882263184
desired expected reward: 302.9637756347656






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [16.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.  3.] 
cards in discard: [ 8. 11.  0.  0.  1.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.  3.] 
cards in discard: [ 8. 11.  0.  0.  1.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.30402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -9.281176567077637
desired expected reward: 304.2731018066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[256.19336]
 [268.08398]
 [264.11182]
 [232.06941]
 [276.03442]
 [265.19128]
 [262.1689 ]
 [282.385  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.306903839111328
desired expected reward: 278.20587158203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[297.18533]
 [279.28586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.657254219055176
desired expected reward: 274.72772216796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.46103]
 [285.6376 ]
 [281.8696 ]
 [249.6165 ]
 [294.38043]
 [282.56363]
 [280.08585]
 [300.2341 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.349569320678711
desired expected reward: 287.0045166015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [15.  1. 11.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [15.  1. 11.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[280.9432]
 [264.3406]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16.  3.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  8.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.844520568847656
desired expected reward: 291.38958740234375



action possibilites: [-1] 
expected returns: [[271.24802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16.  3.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  8.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 0
Learning step: -5.58010196685791
desired expected reward: 247.0835418701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[244.67276]
 [222.61626]
 [267.36606]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16.  3.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  8.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -6.931936740875244
desired expected reward: 264.3160705566406



buy possibilites: [-1] 
expected returns: [[252.41048]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 3 8 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16.  3.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  8.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   4   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action 0.0
Learning step: -7.104405403137207
desired expected reward: 237.5684051513672






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 16.  3.] 
cards in discard: [15.  1. 11.  0.  0.  0.  8.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [0. 8. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 3 8 8 0] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16.  3.] 
cards in discard: [15.  1. 11.  0.  0.  0.  8.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [0. 8. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 3 8 8 0] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16.  3.] 
cards in discard: [15.  1. 11.  0.  0.  0.  8.  0.  3.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [0. 8. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 3 8 8 0] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[251.17972]
 [237.61003]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [0. 8. 3. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 3 8 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.175686836242676
desired expected reward: 245.2347869873047



action possibilites: [-1] 
expected returns: [[278.19864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [0. 8. 3. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.556509494781494
desired expected reward: 230.76307678222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[249.4403 ]
 [257.86584]
 [224.83852]
 [258.59662]
 [275.45776]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0. 8. 3. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -7.093480587005615
desired expected reward: 271.10516357421875






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0] -> size -> 11 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[274.69257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [25. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.631333827972412
desired expected reward: 267.826416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[240.92418]
 [252.53923]
 [247.96022]
 [217.09132]
 [245.88988]
 [259.4833 ]
 [249.83572]
 [251.1943 ]
 [228.72542]
 [246.31714]
 [241.78345]
 [263.52014]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [25. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -7.66961669921875
desired expected reward: 257.9136047363281



buy possibilites: [-1] 
expected returns: [[219.58441]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [25. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 12.0 

action type: buy - action 3.0
Learning step: -6.85736083984375
desired expected reward: 241.10284423828125






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [25. 15.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 8. 3. 8.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [25. 15.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 8. 3. 8.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[246.32764]
 [230.13408]
 [230.13408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 8.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 16. 11.] 
adversary cards in discard: [25. 15.  3.  0.  0.  0.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: -5.165968418121338
desired expected reward: 214.41844177246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[223.0932 ]
 [206.56807]
 [246.1221 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 8.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 16. 11.] 
adversary cards in discard: [25. 15.  3.  0.  0.  0.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -6.436526775360107
desired expected reward: 236.8267364501953



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 16. 11.] 
cards in discard: [25. 15.  3.  0.  0.  0.  8.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 16  8  3  1 15  8 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [25. 15.  3.  0.  0.  0.  8.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [25. 15.  3.  0.  0.  0.  8.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  6.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [25. 15.  3.  0.  0.  0.  8.  3.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  5.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[241.46088]
 [229.1745 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  5.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: -6.468367099761963
desired expected reward: 239.65374755859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[221.25072]
 [227.6792 ]
 [200.4771 ]
 [229.02856]
 [241.29973]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8. 10.  9.  9.  5.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -6.39478063583374
desired expected reward: 234.909912109375



buy possibilites: [-1] 
expected returns: [[177.83516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8.  9.  9.  9.  5.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -301.0 

action type: buy - action 6.0
Learning step: -21.07256317138672
desired expected reward: 179.40451049804688






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9.  9.  9.  5.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6. 3. 0. 8. 0. 3.] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 26. 30.  8.  9.  9.  9.  5.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6. 3. 0. 8. 0. 3.] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6] -> size -> 13 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[216.1168]
 [201.7192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6. 3. 0. 8. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9.  9.  9.  5.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  3.  8.] 
adversary cards in discard: [25.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -4.248416423797607
desired expected reward: 173.5867462158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[195.99666]
 [206.55197]
 [202.9466 ]
 [174.78835]
 [213.48221]
 [203.91586]
 [201.30754]
 [218.13919]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6. 3. 0. 8. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 26. 30.  8.  9.  9.  9.  5.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  3.  8.] 
adversary cards in discard: [25.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -6.056265354156494
desired expected reward: 207.45989990234375



buy possibilites: [-1] 
expected returns: [[227.2943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6. 3. 0. 8. 0. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6 8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  3.  8.] 
adversary cards in discard: [25.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 8.0
Learning step: -5.03167200088501
desired expected reward: 198.8842010498047






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 16.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  3.  8.] 
cards in discard: [25.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6 8] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  3.  8.] 
cards in discard: [25.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6 8] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  3.  8.] 
cards in discard: [25.  0.  0.  1.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6 8] -> size -> 14 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[181.80518]
 [169.74625]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 3 8 8 0 3 6 8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  8.  0.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.  8.  0. 16.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.447262763977051
desired expected reward: 219.84703063964844



action possibilites: [-1] 
expected returns: [[180.68825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 3 8 8 0 3 6 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  8.  0.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.  8.  0. 16.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 0
Learning step: -3.053556203842163
desired expected reward: 158.3272705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[159.9011 ]
 [133.72726]
 [180.95285]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 3 8 8 0 3 6 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  8.  0.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.  8.  0. 16.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -4.352392673492432
desired expected reward: 176.3358612060547



buy possibilites: [-1] 
expected returns: [[202.32208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 3 8 8 0 3 6 8 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  8.  0.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.  8.  0. 16.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   4   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action 0.0
Learning step: -3.9928085803985596
desired expected reward: 155.90829467773438






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  8.  0.] 
cards in discard: [25.  0.  0.  1.  3.  0.  8.  0. 16.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 3. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 8 8 0 3 6 8 0] -> size -> 14 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [25.  0.  0.  1.  3.  0.  8.  0. 16.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 3. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 8 8 0 3 6 8 0] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [25.  0.  0.  1.  3.  0.  8.  0. 16.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 3. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 8 8 0 3 6 8 0] -> size -> 14 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[192.69128]
 [177.32681]
 [177.32681]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 8.] 
cards in discard: [0. 8. 3. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 8 8 0 3 6 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -5.997313976287842
desired expected reward: 196.32476806640625



action possibilites: [-1] 
expected returns: [[173.36133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [0. 8. 3. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.9968297481536865
desired expected reward: 153.95236206054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[155.67422]
 [133.32872]
 [175.82886]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [0. 8. 3. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -4.073385715484619
desired expected reward: 169.28794860839844



buy possibilites: [-1] 
expected returns: [[188.98465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [0. 8. 3. 3. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -292.0 

action type: buy - action 6.0
Learning step: -17.0142822265625
desired expected reward: 116.31443786621094






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 26. 30.  8.  8.  9.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[187.78189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 25.  8.  0.  8.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0 16] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.876391887664795
desired expected reward: 183.10826110839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[171.47299]
 [179.33363]
 [176.8701 ]
 [154.82458]
 [184.98303]
 [177.35953]
 [175.80508]
 [189.27682]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 25.  8.  0.  8.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0 16] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -5.808665752410889
desired expected reward: 179.6509246826172



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8. 25.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8.  0.  8.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  8  3  1 15  8 25  8  0 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 8. 6. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  3  1 15  8 25  8  0 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 8. 6. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  3  1 15  8 25  8  0 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 8. 6. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  3  1 15  8 25  8  0 16  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 8. 6. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 8. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[224.63518]
 [210.81677]
 [210.81677]
 [210.81677]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 6. 8.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 8 0 3 6 8 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.  0.  8. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  3  1 15  8 25  8  0 16  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -5.216012477874756
desired expected reward: 184.06080627441406



action possibilites: [-1] 
expected returns: [[237.32642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.  0.  8. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  3  1 15  8 25  8  0 16  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.448354244232178
desired expected reward: 199.31561279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[212.77081]
 [188.55402]
 [237.7397 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.  0.  8. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  3  1 15  8 25  8  0 16  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -6.485814094543457
desired expected reward: 230.84060668945312



buy possibilites: [-1] 
expected returns: [[184.60254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8.] 
cards in discard: [0. 0. 3. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.  0.  8. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  3  1 15  8 25  8  0 16  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -303 

action type: buy - action 6.0
Learning step: -20.424144744873047
desired expected reward: 168.12986755371094






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.  3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.  8. 25.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  3  1 15  8 25  8  0 16  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7.  8.  9.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.  8. 25.  0.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.  8. 25.  0.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.  8. 25.  0.  8. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[143.34743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.641859531402588
desired expected reward: 177.96067810058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[127.458206]
 [108.64083 ]
 [145.09299 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -4.850434303283691
desired expected reward: 139.07257080078125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 6. 0. 3. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 6. 0. 3. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 29. 30. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 6. 0. 3. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [2.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 29. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 6. 0. 3. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[236.88577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 6. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 29. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8. 16.] 
adversary cards in discard: [ 2. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -2.589266300201416
desired expected reward: 142.50372314453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[217.25917]
 [229.09671]
 [224.18172]
 [193.37396]
 [235.69633]
 [226.35507]
 [222.42294]
 [239.21782]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 6. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 29. 26. 30.  8.  7.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8. 16.] 
adversary cards in discard: [ 2. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.314709663391113
desired expected reward: 228.92454528808594



buy possibilites: [-1] 
expected returns: [[199.35384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 6. 0. 3. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 29. 26. 30.  8.  6.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8. 16.] 
adversary cards in discard: [ 2. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 19 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -21.124860763549805
desired expected reward: 172.24911499023438






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 25.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  8. 16.] 
cards in discard: [ 2. 15.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 29. 26. 30.  8.  6.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 16.] 
cards in discard: [ 2. 15.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 29. 26. 30.  8.  6.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 16.] 
cards in discard: [ 2. 15.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 29. 26. 30.  8.  6.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [3. 6. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[153.35266]
 [142.08545]
 [142.08545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 29. 26. 30.  8.  6.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  8.] 
adversary cards in discard: [ 2. 15.  0.  0.  1.  8.  0. 25. 16.] 
adversary owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.848767280578613
desired expected reward: 191.50506591796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[135.12321]
 [116.1383 ]
 [153.9736 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 29. 26. 30.  8.  6.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  8.] 
adversary cards in discard: [ 2. 15.  0.  0.  1.  8.  0. 25. 16.] 
adversary owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -5.640239238739014
desired expected reward: 146.81675720214844



buy possibilites: [-1] 
expected returns: [[135.79396]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 8. 8.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  8.] 
adversary cards in discard: [ 2. 15.  0.  0.  1.  8.  0. 25. 16.] 
adversary owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: buy - action 6.0
Learning step: -19.50155258178711
desired expected reward: 96.63674926757812






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  8.] 
cards in discard: [ 2. 15.  0.  0.  1.  8.  0. 25. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6. 3. 6. 6. 8. 8.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [ 2. 15.  0.  0.  1.  8.  0. 25. 16. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6. 3. 6. 6. 8. 8.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [ 2. 15.  0.  0.  1.  8.  0. 25. 16. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6. 3. 6. 6. 8. 8.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [ 2. 15.  0.  0.  1.  8.  0. 25. 16. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6. 3. 6. 6. 8. 8.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[177.51683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6. 3. 6. 6. 8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0] -> size -> 20 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -4.567425727844238
desired expected reward: 131.22653198242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[162.63394]
 [167.2404 ]
 [146.12239]
 [169.10321]
 [177.33836]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6. 3. 6. 6. 8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0] -> size -> 20 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -6.77880859375
desired expected reward: 169.76663208007812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [6. 3. 6. 6. 8. 8. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [6. 3. 6. 6. 8. 8. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [6. 3. 6. 6. 8. 8. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [6. 3. 6. 6. 8. 8. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[162.92346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [6. 3. 6. 6. 8. 8. 0. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  0.  2. 15.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -7.061351299285889
desired expected reward: 170.27699279785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[142.76497]
 [148.30844]
 [123.21057]
 [150.43706]
 [160.29013]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [6. 3. 6. 6. 8. 8. 0. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 29. 26. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  0.  2. 15.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -6.2727274894714355
desired expected reward: 151.75244140625



buy possibilites: [-1] 
expected returns: [[134.03407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [6. 3. 6. 6. 8. 8. 0. 3. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  0.  2. 15.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -16 

action type: buy - action 3.0
Learning step: -5.199655055999756
desired expected reward: 143.1087646484375






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [25.  3.  0.  2. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  2. 15.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  2. 15.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  2. 15.] 
cards in discard: [ 0.  0. 16.  3.  0.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [6. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.54337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 16.  0. 15. 11.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.] 
adversary owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -6.219606876373291
desired expected reward: 127.81446838378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[55.01624 ]
 [40.82436 ]
 [73.392624]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 16.  0. 15. 11.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.] 
adversary owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -3.539914846420288
desired expected reward: 71.21995544433594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 15. 11.] 
cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [6. 3. 0. 6. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0. 15. 11.] 
cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  4.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [6. 3. 0. 6. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0. 15. 11.] 
cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [6. 3. 0. 6. 3.] 
adversary owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[126.959496]
 [119.94098 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 8.] 
cards in discard: [6. 3. 0. 6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 8 0 3 6 8 0 6 6 6 6 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [1. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.  8.  0. 16.  0. 15. 11.] 
adversary owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -2.0712687969207764
desired expected reward: 71.32136535644531



action possibilites: [-1] 
expected returns: [[121.2815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6. 3. 0. 6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [1. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.  8.  0. 16.  0. 15. 11.] 
adversary owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   3   0   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -12 

action type: trash_cards_n_from_hand - action 10
Learning step: -3.9752914905548096
desired expected reward: 118.10721588134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.20605 ]
 [ 88.20754 ]
 [120.689926]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 3. 0. 6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [1. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.  8.  0. 16.  0. 15. 11.] 
adversary owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   3   0   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -4.1870012283325195
desired expected reward: 117.09449768066406






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [1. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 8. 0. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.  8.  0. 16.  0. 15. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  3  1 15  8 25  8  0 16  0 11  0  2 15  0  0  0 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 8.] 
adversary cards in discard: [6. 3. 0. 6. 3. 8.] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.  8.  0. 16.  0. 15. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 8.] 
adversary cards in discard: [6. 3. 0. 6. 3. 8.] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.  8.  0. 16.  0. 15. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 8.] 
adversary cards in discard: [6. 3. 0. 6. 3. 8.] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0. 16.  3.  0.  3. 10. 25.  3.  0.  2. 15.  8.  0. 16.  0. 15. 11.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 8.] 
adversary cards in discard: [6. 3. 0. 6. 3. 8.] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[110.70722]
 [101.31118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 8.] 
cards in discard: [6. 3. 0. 6. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  0.  3. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   3   0   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -5.2548651695251465
desired expected reward: 115.4350814819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 92.38633 ]
 [ 74.490486]
 [108.38301 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 8.] 
cards in discard: [6. 3. 0. 6. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 29. 25. 30.  8.  5.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  0.  3. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   3   0   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -4.8428239822387695
desired expected reward: 103.82583618164062



buy possibilites: [-1] 
expected returns: [[86.68831]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 8.] 
cards in discard: [6. 3. 0. 6. 3. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 29. 25. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  0.  3. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.  -30.    0.
    0. -300.    0.    0.] 
sum of rewards: -343.0 

action type: buy - action 6.0
Learning step: -18.534337997436523
desired expected reward: 48.16217041015625






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 25.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 29. 25. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 25.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 29. 25. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 25.  8.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 29. 25. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [6. 3. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.43406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 25. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15. 11. 16.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 25.  8.] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -3.89920973777771
desired expected reward: 82.78910064697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 99.6368 ]
 [ 82.07913]
 [115.07208]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 29. 29. 25. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15. 11. 16.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 25.  8.] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -5.546525478363037
desired expected reward: 109.35150909423828



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [15. 11. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 16.  3.  0.] 
cards in discard: [ 0.  8.  0.  3. 25.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 25. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 3. 3. 0. 8.] 
adversary cards in discard: [6. 3. 6. 3. 3.] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  3.  0.] 
cards in discard: [ 0.  8.  0.  3. 25.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 3. 3. 0. 8.] 
adversary cards in discard: [6. 3. 6. 3. 3.] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  3.  0.] 
cards in discard: [ 0.  8.  0.  3. 25.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 3. 3. 0. 8.] 
adversary cards in discard: [6. 3. 6. 3. 3.] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  3.  0.] 
cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 3. 3. 0. 8.] 
adversary cards in discard: [6. 3. 6. 3. 3.] 
adversary owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [8. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[82.61992 ]
 [76.019394]
 [76.019394]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 8.] 
cards in discard: [6. 3. 6. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 8 0 3 8 0 6 6 6 3 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [2. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -6.605448246002197
desired expected reward: 108.46662139892578



action possibilites: [-1] 
expected returns: [[109.9116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6. 3. 6. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 0 3 8 0 6 6 6 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [2. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.509852409362793
desired expected reward: 80.14741516113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 89.09368 ]
 [ 73.08457 ]
 [102.514565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 3. 6. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 0 3 8 0 6 6 6 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [2. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -6.152021884918213
desired expected reward: 103.75957489013672






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [2. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 7 
card supply: [19. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 7 
card supply: [18. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [6. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[70.30362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 0 3 8 0 6 6 6 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 16. 10. 15.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.  0.  2.  0.  0.  0.
  0.] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -7.175022125244141
desired expected reward: 95.33952331542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.378918]
 [43.073174]
 [69.39312 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 0 3 8 0 6 6 6 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 29. 24. 30.  8.  4.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 16. 10. 15.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.  0.  2.  0.  0.  0.
  0.] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -6.158566474914551
desired expected reward: 69.42833709716797



buy possibilites: [-1] 
expected returns: [[56.964542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 0 3 8 0 6 6 6 3 6 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 16. 10. 15.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.  0.  2.  0.  0.  0.
  0.] 
adversary owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.  -30.    0.
    0. -300.    0.    0.] 
sum of rewards: -386.0 

action type: buy - action 6.0
Learning step: -20.17195701599121
desired expected reward: 22.901201248168945






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3. 16. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 10. 15.  0.] 
cards in discard: [ 0.  8.  0.  3. 25.  8.  3.  0. 11. 15. 16.  3.  0.  0.  2.  0.  0.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [6. 6. 6. 3. 6. 0.] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6 6] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 16  3 15 25  8  0 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [6. 6. 6. 3. 6. 0.] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6 6] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  8.  3.  9. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [6. 6. 6. 3. 6. 0.] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6 6] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  8.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [6. 6. 6. 3. 6. 0.] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6 6] -> size -> 12 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  8.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [6. 6. 6. 3. 6. 0.] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6 6] -> size -> 12 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  7.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [6. 6. 6. 3. 6. 0.] 
adversary owned cards: [3 3 0 3 8 0 6 6 6 3 6 6] -> size -> 12 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[57.687428]
 [50.24679 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 6.] 
cards in discard: [6. 6. 6. 3. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 0 3 8 0 6 6 6 3 6 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  7.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15. 11. 10. 15. 16.  0.] 
adversary owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -5.441768646240234
desired expected reward: 51.52277374267578



action possibilites: [-1] 
expected returns: [[97.4346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [6. 6. 6. 3. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  7.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15. 11. 10. 15. 16.  0.] 
adversary owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -86 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.883324146270752
desired expected reward: 50.628726959228516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[77.97843 ]
 [61.373894]
 [92.15895 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6. 6. 6. 3. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  7.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15. 11. 10. 15. 16.  0.] 
adversary owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1
Learning step: -7.321685791015625
desired expected reward: 90.1129150390625






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15. 11. 10. 15. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  7.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15. 11. 10. 15. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  7.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [6. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[142.13466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 16.  3.  0.  2.] 
adversary cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -106 

action type: buy - action -1.0
Learning step: -6.740948677062988
desired expected reward: 85.41799926757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[127.40336]
 [108.81165]
 [139.84375]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 16.  3.  0.  2.] 
adversary cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -9.407401084899902
desired expected reward: 131.34811401367188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  3.  0.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  2.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  0 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  3.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 2.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 15 25  8 16 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 2.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 15 25  8 16 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 2.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 15 25  8 16 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [3. 6. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[108.72928 ]
 [103.513214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 8.  8.  0. 25.  0.] 
adversary cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.  0. 16.  3.  0.  2.] 
adversary owned cards: [ 3 16  3 15 25  8 16 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -8.796433448791504
desired expected reward: 118.59935760498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 96.32711]
 [ 81.73105]
 [108.6297 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 8.  8.  0. 25.  0.] 
adversary cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.  0. 16.  3.  0.  2.] 
adversary owned cards: [ 3 16  3 15 25  8 16 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -7.93887186050415
desired expected reward: 99.82439422607422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 25.  0.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.  0. 16.  3.  0.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16 11  0  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.  0. 16.  3.  0.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.  0. 16.  3.  0.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0.] 
cards in discard: [15. 11. 10. 15. 16.  0. 11.  3.  0.  3.  0.  0.  6.  0. 16.  3.  0.  2.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [3. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[70.48513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -8.64038372039795
desired expected reward: 99.98932647705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.612614]
 [47.038452]
 [65.77935 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -6.994481086730957
desired expected reward: 63.72116470336914



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [0. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 29. 24. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [0. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11. 15.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [0. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[68.665535]
 [61.831566]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 3 6 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [16.  8.  0. 15. 11.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15.] 
adversary owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0  3] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -106 

action type: buy - action -1.0
Learning step: -7.038956642150879
desired expected reward: 58.740386962890625



action possibilites: [-1] 
expected returns: [[18.905972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 6 3 6 6] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [16.  8.  0. 15. 11.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15.] 
adversary owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0  3] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -66 

action type: trash_cards_n_from_hand - action 9
Learning step: -6.283092021942139
desired expected reward: 61.88643264770508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 4.502356 ]
 [-3.4926405]
 [14.330759 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 6 3 6 6] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [16.  8.  0. 15. 11.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15.] 
adversary owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0  3] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -4.060318946838379
desired expected reward: 14.84565258026123






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [16.  8.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0. 15. 11.] 
cards in discard: [ 3.  3.  0.  0. 11. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16 11  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6
  0  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9. 10.  7.] 
adversary cards in hand: [8. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [8. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[108.727875]
 [ 99.24883 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 3 6 6] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [25.  0. 15.  3. 11.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -2.677295446395874
desired expected reward: 11.653463363647461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 93.14025 ]
 [ 75.509514]
 [108.65156 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 3 6 6] -> size -> 6 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [25.  0. 15.  3. 11.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -7.454447269439697
desired expected reward: 99.69039916992188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [25.  0. 15.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 15.  3. 11.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 23. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 15.  3.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 29. 22. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 15.  3.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 29. 22. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 15.  3.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 29. 22. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [6. 8. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[98.87037]
 [90.69623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 3 6 6] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 29. 22. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0. 16.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22  3  0] -> size -> 29 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -8.084311485290527
desired expected reward: 100.56724548339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[86.62977]
 [74.3482 ]
 [99.83089]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 3 6 6] -> size -> 6 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 29. 29. 22. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0. 16.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22  3  0] -> size -> 29 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -7.657224178314209
desired expected reward: 90.56507110595703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  6.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0  0 10  8  0  0  3  0  0 15 11 11  6  0
  0  3 22  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 29. 22. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 6. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 3 6 6] -> size -> 6 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [6. 6. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[89.9631 ]
 [81.93166]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 3 6 6] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 10.  2.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3. 16.  0.  0.  6.] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3] -> size -> 29 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -106 

action type: buy - action -1.0
Learning step: -8.355000495910645
desired expected reward: 91.47587585449219



action possibilites: [-1] 
expected returns: [[44.214058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 10.  2.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3. 16.  0.  0.  6.] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -97 

action type: trash_cards_n_from_hand - action 1
Learning step: -8.362391471862793
desired expected reward: 81.7817611694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.060791]
 [21.880192]
 [39.097855]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 10.  2.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3. 16.  0.  0.  6.] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1
Learning step: -6.31151819229126
desired expected reward: 37.90253829956055



buy possibilites: [-1] 
expected returns: [[32.504185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 3 6 6 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 10.  2.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3. 16.  0.  0.  6.] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20 -30   0   0 -60   0   0   0   0   0] 
sum of rewards: -147 

action type: buy - action 0.0
Learning step: -7.811173915863037
desired expected reward: 16.039188385009766






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  2.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  2.  0.  3.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3. 16.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0] -> size -> 6 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  2.  0.  3.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3. 16.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0] -> size -> 6 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  2.  0.  3.] 
cards in discard: [ 3.  3.  0.  0. 11. 15. 22. 16.  8.  0. 15.  3.  0. 11. 25.  0. 15.  3.
  3. 16.  0.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 5 
card supply: [13. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0] -> size -> 6 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [8. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[67.73332 ]
 [54.652596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -137 

action type: buy - action -1
Learning step: -7.060801982879639
desired expected reward: 25.443382263183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.247887]
 [27.833359]
 [62.38739 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 29. 21. 30.  8.  2.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -9.068117141723633
desired expected reward: 58.12956237792969



buy possibilites: [-1] 
expected returns: [[68.14181]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 6. 6.] 
cards in discard: [6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3  0] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -80.    0.    0.    0.    0.    0.    0.  -60.    0.
    0. -300.    0.    0.] 
sum of rewards: -448.0 

action type: buy - action 6.0
Learning step: -22.25847816467285
desired expected reward: 5.57490348815918






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 15.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1. 15.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  8. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 16  3 15 25  8 16  2 15  0  0 10  8  0  0  3  0  0 15 11 11  6  0  0
  3 22  3  0  3  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[37.514862]
 [30.766665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 16. 22.  2.  0.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -138 

action type: buy - action -1
Learning step: -9.512245178222656
desired expected reward: 58.62956237792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.534979]
 [14.903962]
 [34.25286 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 16. 22.  2.  0.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -138 

action type: take_action - action -1.0
Learning step: -8.145720481872559
desired expected reward: 29.292552947998047



buy possibilites: [-1] 
expected returns: [[51.340866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 3.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 16. 22.  2.  0.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -70.   0.   0.   0. -30.   0.   0. -30.   0.   0.   0.
   0.   0.] 
sum of rewards: -138.0 

action type: buy - action 0.0
Learning step: -6.971579074859619
desired expected reward: 17.563392639160156






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 22.  2.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 22.  2.  0.] 
cards in discard: [10.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0] -> size -> 8 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 22.  2.  0.] 
cards in discard: [10.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0] -> size -> 8 
adversary victory points: -3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 6. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.38574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [10.  8.  0. 16. 22.  2.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -6.669780254364014
desired expected reward: 44.671085357666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.53893]
 [38.96114]
 [53.13508]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [10.  8.  0. 16. 22.  2.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -7.190521240234375
desired expected reward: 50.46564865112305



buy possibilites: [-1] 
expected returns: [[88.02472]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [10.  8.  0. 16. 22.  2.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -108.0 

action type: buy - action 0.0
Learning step: -5.746390342712402
desired expected reward: 40.79253387451172






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 3. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 29. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 3. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 3. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[76.26837]
 [68.64723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  3. 16. 15.] 
adversary cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1] -> size -> 27 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -6.665687561035156
desired expected reward: 81.3590316772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.60298]
 [49.49985]
 [74.25067]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  3. 16. 15.] 
adversary cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1] -> size -> 27 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -6.172614574432373
desired expected reward: 68.97418212890625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  3. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 16. 15.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 16.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 16.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 16.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.81209]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  8.  3. 15.] 
adversary cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.  0. 15.  3.  6.  3.
 16.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -5.601959705352783
desired expected reward: 68.64868927001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[72.44193 ]
 [76.245445]
 [60.864433]
 [77.45099 ]
 [84.104294]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  8.  3. 15.] 
adversary cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.  0. 15.  3.  6.  3.
 16.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -6.622982025146484
desired expected reward: 82.73580932617188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  3. 15.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.  0. 15.  3.  6.  3.
 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  3. 15.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.  0. 15.  3.  6.  3.
 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  3. 15.] 
cards in discard: [10.  8.  0. 16. 22.  2.  0.  1. 11.  0.  0.  3.  0.  0. 15.  3.  6.  3.
 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[77.11336]
 [69.27945]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6 0 6 0 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [15.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -6.496880531311035
desired expected reward: 77.60741424560547



action possibilites: [-1] 
expected returns: [[49.993458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 6 0 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [15.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -88 

action type: trash_cards_n_from_hand - action 9
Learning step: -6.3239006996154785
desired expected reward: 54.65116882324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.515896]
 [28.647951]
 [47.276745]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 6 0 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [15.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -5.977076053619385
desired expected reward: 44.016380310058594



buy possibilites: [-1] 
expected returns: [[9.536974]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 6 0 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [15.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action 0.0
Learning step: -6.061212539672852
desired expected reward: 31.454679489135742






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 29. 21. 30.  8.  1.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0] -> size -> 7 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 0 0 0 6] -> size -> 8 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 28. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 0 0 0 6] -> size -> 8 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  8.  3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 28. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 0 0 0 6] -> size -> 8 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[53.176495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0.  3. 22.  8.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -80    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -389 

action type: buy - action -1
Learning step: -18.72968864440918
desired expected reward: -9.19271469116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[35.71361 ]
 [40.875763]
 [38.716537]
 [43.899796]
 [39.691437]
 [37.9925  ]
 [45.56578 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 28. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0.  3. 22.  8.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -6.162899494171143
desired expected reward: 47.04420852661133



buy possibilites: [-1] 
expected returns: [[88.91722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [6. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0.  3. 22.  8.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0] -> size -> 30 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -71 

action type: buy - action 1.0
Learning step: -3.593151569366455
desired expected reward: 37.28262710571289






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [10.  0.  3. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 22.  8.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 22.  8.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 22.  8.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [0. 6. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[52.637966]
 [48.030636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  1.  0. 16.  0.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -7.784247875213623
desired expected reward: 81.13297271728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[41.19649]
 [49.32477]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  1.  0. 16.  0.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -5.951095104217529
desired expected reward: 45.05473709106445



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 16.  0.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 1. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 16.  0.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 1. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 16.  0.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [6. 1. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [6. 1. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[81.22438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  2.  0.  0. 11.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15] -> size -> 32 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -5.135584831237793
desired expected reward: 44.18916702270508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[56.375908]
 [61.6695  ]
 [59.05134 ]
 [58.491123]
 [64.726105]
 [60.480297]
 [60.856388]
 [50.124714]
 [58.222042]
 [55.99665 ]
 [66.18334 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 27. 29. 21. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  2.  0.  0. 11.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15] -> size -> 32 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -7.020703315734863
desired expected reward: 72.11943054199219



buy possibilites: [-1] 
expected returns: [[93.50205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 27. 29. 20. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  2.  0.  0. 11.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -76.0 

action type: buy - action 3.0
Learning step: -4.648770809173584
desired expected reward: 54.402565002441406






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  2.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2.  0.  0. 11.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 20. 30.  8.  0.  8.  6.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3] -> size -> 10 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 0. 0.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 20. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3] -> size -> 10 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0. 0.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 6. 27. 29. 20. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3] -> size -> 10 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0. 0.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 6. 27. 29. 19. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3] -> size -> 10 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [0. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[84.88465]
 [78.41779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 19. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [16. 15.  3.  3.  6.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.  3. 11.  0.  2.  0.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3] -> size -> 34 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1
Learning step: -7.2546210289001465
desired expected reward: 86.24742889404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[70.42187]
 [74.33857]
 [75.31495]
 [81.93983]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 27. 29. 19. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [16. 15.  3.  3.  6.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.  3. 11.  0.  2.  0.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3] -> size -> 34 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -6.805011749267578
desired expected reward: 76.24845886230469



buy possibilites: [-1] 
expected returns: [[119.96014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 8.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [16. 15.  3.  3.  6.] 
adversary cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.  3. 11.  0.  2.  0.  0.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3] -> size -> 34 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -69 

action type: buy - action 3.0
Learning step: -4.467825412750244
desired expected reward: 69.87074279785156






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [16. 15.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  3.  3.  6.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.  3. 11.  0.  2.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 8.] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3] -> size -> 11 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  6.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.  3. 11.  0.  2.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 8.] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3] -> size -> 11 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  6.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.  3. 11.  0.  2.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 8.] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3] -> size -> 11 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  6.] 
cards in discard: [ 0. 25. 15.  0.  0.  0.  8.  3.  0. 10.  0.  3. 22.  8. 15.  0.  1.  0.
 16.  0. 11.  3. 11.  0.  2.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 8.] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3] -> size -> 11 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [3. 6. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.356056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [3. 0. 6. 0. 6. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [16.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3  0] -> size -> 35 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -9.201460838317871
desired expected reward: 110.75867462158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[21.537361]
 [25.220053]
 [23.68736 ]
 [27.950176]
 [24.428194]
 [23.27567 ]
 [29.260408]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [3. 0. 6. 0. 6. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [16.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3  0] -> size -> 35 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.691184043884277
desired expected reward: 24.044227600097656



buy possibilites: [-1] 
expected returns: [[11.080962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [3. 0. 6. 0. 6. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [16.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3  0] -> size -> 35 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -107.0 

action type: buy - action 0.0
Learning step: -5.881101608276367
desired expected reward: 9.727364540100098






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [16.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15 11  6  0  0  3 22  3  0
  3  0  1  0  0  0  0 15 11  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 29. 18. 30.  8.  0.  8.  5.  3.  9. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [6. 6. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [6. 6. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [6. 6. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [25.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [6. 6. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [6. 6. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.74252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 22. 15.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0] -> size -> 36 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -1.779981255531311
desired expected reward: 9.300980567932129





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[104.63951]
 [117.69236]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 22. 15.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0] -> size -> 36 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -7.130513668060303
desired expected reward: 109.49468231201172



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  8. 22. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 22. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 22. 15.] 
cards in discard: [25.  0. 16.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [0. 1. 0. 6. 8.] 
adversary cards in discard: [6. 6. 6. 3. 3.] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8. 22. 15.] 
cards in discard: [25.  0. 16.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [0. 1. 0. 6. 8.] 
adversary cards in discard: [6. 6. 6. 3. 3.] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8. 22. 15.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [0. 1. 0. 6. 8.] 
adversary cards in discard: [6. 6. 6. 3. 3.] 
adversary owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [0. 1. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[59.935215]
 [58.77274 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6. 8.] 
cards in discard: [6. 6. 6. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0  0] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -8.367473602294922
desired expected reward: 109.32487487792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[52.258644]
 [54.757072]
 [53.650146]
 [53.291092]
 [56.465557]
 [54.2319  ]
 [54.58857 ]
 [49.347176]
 [53.361046]
 [52.23102 ]
 [56.37531 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 8.] 
cards in discard: [6. 6. 6. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 0 0 0 6 1 3 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  8.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0  0] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -5.6862640380859375
desired expected reward: 55.61976623535156



buy possibilites: [-1] 
expected returns: [[10.584489]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 8.] 
cards in discard: [ 6.  6.  6.  3.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15.] 
adversary owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0  0] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -45 

action type: buy - action 16.0
Learning step: -4.676402568817139
desired expected reward: 48.61466979980469






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  0.  0.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15  0 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3
  0  1  0  0  0  0 15 11  3  0 25  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3  0
  1  0  0  0  0 15 11  3  0 25  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3  0
  1  0  0  0  0 15 11  3  0 25  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3  0
  1  0  0  0  0 15 11  3  0 25  0  0 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [3. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[105.67012 ]
 [ 99.989075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  1.  0. 16. 15.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3  0
  1  0  0  0  0 15 11  3  0 25  0  0 10] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -2.1095211505889893
desired expected reward: 8.474967956542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 93.739365]
 [ 95.91501 ]
 [ 95.543724]
 [100.971176]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  1.  0. 16. 15.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3  0
  1  0  0  0  0 15 11  3  0 25  0  0 10] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -6.778164863586426
desired expected reward: 95.90116119384766



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 16. 15.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  0  3  0  0 15  6  0  0  3 22  3  0  3  0
  1  0  0  0  0 15 11  3  0 25  0  0 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [3. 6. 8. 0. 0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [3. 6. 8. 0. 0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  7.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [3. 6. 8. 0. 0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [3. 6. 8. 0. 0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [6. 1. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.375225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 0. 6.] 
cards in discard: [3. 6. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -8.178633689880371
desired expected reward: 92.79254150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[23.937298]
 [26.461128]
 [25.32906 ]
 [28.849422]
 [26.117905]
 [25.564285]
 [31.130112]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 6.] 
cards in discard: [3. 6. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.814432621002197
desired expected reward: 27.1822452545166



buy possibilites: [-1] 
expected returns: [[19.16869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 6.] 
cards in discard: [ 3.  6.  8.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -59 

action type: buy - action 10.0
Learning step: -3.7969186305999756
desired expected reward: 21.76735496520996






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 10. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 29. 18. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 10. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 10. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 0. 10. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[83.570755]
 [77.97914 ]
 [77.064606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 11.  2.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3] -> size -> 38 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -3.5639336109161377
desired expected reward: 15.604756355285645





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[69.43585]
 [71.97772]
 [71.55009]
 [77.15773]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 11.  2.] 
adversary cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3] -> size -> 38 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -6.693042278289795
desired expected reward: 73.50857543945312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 25. 11.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 11.  2.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.  3.  0.  0.  3.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [6. 6. 0. 1. 0.] 
adversary cards in discard: [ 0. 10. 16.  0.  3.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  2.  0. 10.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.  3.  0.  0.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [6. 6. 0. 1. 0.] 
adversary cards in discard: [ 0. 10. 16.  0.  3.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  2.  0. 10.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.  3.  0.  0.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  7.  9.  6.] 
adversary cards in hand: [6. 6. 0. 1. 0.] 
adversary cards in discard: [ 0. 10. 16.  0.  3.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  2.  0. 10.] 
cards in discard: [25.  0. 16.  0.  0.  3.  0.  8.  3.  8. 22. 15. 10. 15.  3.  3.  0. 16.
 15.  1.  0. 16.  3.  0.  0.  3.  6.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  6.  9.  6.] 
adversary cards in hand: [6. 6. 0. 1. 0.] 
adversary cards in discard: [ 0. 10. 16.  0.  3.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [6. 6. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.431751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 1. 0.] 
cards in discard: [ 0. 10. 16.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -7.5681962966918945
desired expected reward: 69.58953857421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.896763]
 [24.085339]
 [23.082706]
 [22.274807]
 [26.291595]
 [23.29692 ]
 [23.690498]
 [18.063602]
 [22.670052]
 [21.377224]
 [27.668621]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 1. 0.] 
cards in discard: [ 0. 10. 16.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8. 10. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.218078136444092
desired expected reward: 23.21263885498047



buy possibilites: [-1] 
expected returns: [[11.0492735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 1. 0.] 
cards in discard: [ 0. 10. 16.  0.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -55 

action type: buy - action 29.0
Learning step: -3.6365325450897217
desired expected reward: 20.053974151611328






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [6. 3. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29] -> size -> 15 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 27. 29. 17. 30.  8.  0.  6.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [6. 3. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29] -> size -> 15 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 29. 17. 30.  8.  0.  6.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [6. 3. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29] -> size -> 15 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [6. 3. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-10.785794 ]
 [-10.4908285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 29. 17. 30.  8.  0.  6.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [22. 11. 25.  8.  8.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1] -> size -> 40 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.144600868225098
desired expected reward: 5.904672622680664





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -9.092411]
 [-10.330536]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 26. 29. 17. 30.  8.  0.  6.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [22. 11. 25.  8.  8.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1] -> size -> 40 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -4.026678562164307
desired expected reward: -14.769336700439453



buy possibilites: [-1] 
expected returns: [[88.92572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 8.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 29. 17. 30.  8.  0.  6.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [22. 11. 25.  8.  8.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1] -> size -> 40 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -117 

action type: buy - action 0.0
Learning step: -3.3945510387420654
desired expected reward: -12.486961364746094






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [22. 11. 25.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11. 25.  8.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 11. 25.  8.  8.] 
cards in discard: [ 1.  3. 15.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 29. 17. 30.  8.  0.  6.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [0. 6. 3. 6. 6. 8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0] -> size -> 16 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 25.  8.  8.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [0. 6. 3. 6. 6. 8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0] -> size -> 16 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 25.  8.  8.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [0. 6. 3. 6. 6. 8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0] -> size -> 16 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 25.  8.  8.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [0. 6. 3. 6. 6. 8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0] -> size -> 16 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 10.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[33.38099 ]
 [25.610992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  1.  0.] 
cards in discard: [0. 6. 3. 6. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [16.  0.  3. 10.  0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -8.10315227508545
desired expected reward: 80.82257080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[26.037006]
 [24.764893]
 [23.576305]
 [29.232277]
 [24.856361]
 [25.414433]
 [18.455135]
 [24.085129]
 [22.380604]
 [31.397442]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  1.  0.] 
cards in discard: [0. 6. 3. 6. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  9. 10. 10.  6.  9.  6.] 
adversary cards in hand: [16.  0.  3. 10.  0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.407718181610107
desired expected reward: 27.973270416259766



buy possibilites: [-1] 
expected returns: [[43.99404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  1.  0.] 
cards in discard: [ 0.  6.  3.  6.  6.  8. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10. 10.  6.  9.  6.] 
adversary cards in hand: [16.  0.  3. 10.  0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -55 

action type: buy - action 29.0
Learning step: -3.030856132507324
desired expected reward: 22.383583068847656






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [16.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3. 10.  0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 29.  3.  0. 16.] 
adversary cards in discard: [ 0.  6.  3.  6.  6.  8. 29.  6. 10.  0.  1.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3. 10.  0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 29.  3.  0. 16.] 
adversary cards in discard: [ 0.  6.  3.  6.  6.  8. 29.  6. 10.  0.  1.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
expected returns: [[18.12828 ]
 [15.008937]
 [14.091992]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 16.] 
cards in discard: [ 0.  6.  3.  6.  6.  8. 29.  6. 10.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 10.  0. 16.  0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.177387714385986
desired expected reward: 37.816654205322266



action possibilites: [-1.  8.] 
expected returns: [[62.070633]
 [57.1326  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [ 0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 10.  0. 16.  0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: discard_n_cards - action 1
Learning step: -2.7480366230010986
desired expected reward: 12.408041000366211





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[55.9207  ]
 [56.026596]
 [60.607216]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [ 0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 10.  0. 16.  0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.] 
adversary owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -5.135939121246338
desired expected reward: 56.934715270996094






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 16.  0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 6. 29.  1.  0.  6.] 
adversary cards in discard: [ 0. 16. 29.  3.  0.  8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  2.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  3 25  8 16  2 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1
  0  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10. 10.  6.  9.  6.] 
adversary cards in hand: [ 6. 29.  1.  0.  6.] 
adversary cards in discard: [ 0. 16. 29.  3.  0.  8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 6. 29.  1.  0.  6.] 
adversary cards in discard: [ 0. 16. 29.  3.  0.  8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 26. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 6. 29.  1.  0.  6.] 
adversary cards in discard: [ 0. 16. 29.  3.  0.  8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 6. 29.  1.  0.  6.] 
adversary cards in discard: [ 0. 16. 29.  3.  0.  8.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 29.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[37.547665]
 [29.187462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  1.  0.  6.] 
cards in discard: [ 0. 16. 29.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1] -> size -> 43 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -6.597879886627197
desired expected reward: 54.00935745239258





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[28.812027]
 [27.605434]
 [33.244507]
 [27.176697]
 [26.660988]
 [36.235664]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  1.  0.  6.] 
cards in discard: [ 0. 16. 29.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 25. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1] -> size -> 43 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.505734443664551
desired expected reward: 32.04191970825195



buy possibilites: [-1] 
expected returns: [[102.222565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  1.  0.  6.] 
cards in discard: [ 0. 16. 29.  3.  0.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1] -> size -> 43 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -69 

action type: buy - action 1.0
Learning step: -2.5905933380126953
desired expected reward: 26.221426010131836






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [10.  0.  3.  6.  0.] 
adversary cards in discard: [ 0. 16. 29.  3.  0.  8.  1.  6. 29.  1.  0.  6.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1] -> size -> 18 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  5.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [10.  0.  3.  6.  0.] 
adversary cards in discard: [ 0. 16. 29.  3.  0.  8.  1.  6. 29.  1.  0.  6.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1] -> size -> 18 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [10.  0.  3.  6.  0.] 
adversary cards in discard: [ 0. 16. 29.  3.  0.  8.  1.  6. 29.  1.  0.  6.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1] -> size -> 18 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [10.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-0.89528847]
 [-5.774331  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  6.  0.] 
cards in discard: [ 0. 16. 29.  3.  0.  8.  1.  6. 29.  1.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3. 15.  3. 25.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -9.517654418945312
desired expected reward: 92.70491027832031



action possibilites: [-1.] 
expected returns: [[-6.3224163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [ 0. 16. 29.  3.  0.  8.  1.  6. 29.  1.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3. 15.  3. 25.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 10.0
Learning step: -3.2035374641418457
desired expected reward: -8.977874755859375





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[-5.3083653]
 [-5.6751804]
 [-7.1810517]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [ 0. 16. 29.  3.  0.  8.  1.  6. 29.  1.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  3.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3. 15.  3. 25.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.1644504070281982
desired expected reward: -9.48686695098877



buy possibilites: [-1] 
expected returns: [[4.859732]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [ 0. 16. 29.  3.  0.  8.  1.  6. 29.  1.  0.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3. 15.  3. 25.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: -2.527346134185791
desired expected reward: -8.79354476928711






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3. 25.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 1.  8.  8. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3. 16.  3.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 1.  8.  8. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3. 16.  3.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 1.  8.  8. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 1.  8.  8. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
expected returns: [[29.828844]
 [25.346718]
 [25.346718]
 [24.287426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8. 16.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0. 25.  0.  3. 15.  3.
 16.  3.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -3.9759204387664795
desired expected reward: 0.8838117122650146





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[25.873064]
 [26.174948]
 [30.584448]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  8. 16.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0. 25.  0.  3. 15.  3.
 16.  3.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.198634147644043
desired expected reward: 24.630218505859375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0. 25.  0.  3. 15.  3.
 16.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  6. 29.  0.  0.] 
adversary cards in discard: [ 1.  8.  8. 16.  3.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0. 25.  0.  3. 15.  3.
 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  6. 29.  0.  0.] 
adversary cards in discard: [ 1.  8.  8. 16.  3.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0. 25.  0.  3. 15.  3.
 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  2.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  6. 29.  0.  0.] 
adversary cards in discard: [ 1.  8.  8. 16.  3.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [ 1.  3. 15.  0.  0.  0. 16.  0. 11. 22. 25.  8.  8. 16.  0.  3. 10.  0.
 23.  1. 10. 16.  0.  0.  0. 16.  0.  3.  6.  1.  0. 25.  0.  3. 15.  3.
 16.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  6. 29.  0.  0.] 
adversary cards in discard: [ 1.  8.  8. 16.  3.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[59.95576 ]
 [52.015488]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  0.  0.] 
cards in discard: [ 1.  8.  8. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 1.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -4.589426517486572
desired expected reward: 25.995018005371094



action possibilites: [-1.] 
expected returns: [[31.67745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  8.  8. 16.  3.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 1.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: discard_n_cards - action 2
Learning step: -5.074157238006592
desired expected reward: 43.663841247558594





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.966055]
 [28.643858]
 [28.303982]
 [31.33042 ]
 [29.43627 ]
 [29.486158]
 [24.082047]
 [28.305794]
 [27.109875]
 [31.464388]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  8.  8. 16.  3.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  8. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 1.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.265467166900635
desired expected reward: 27.411983489990234



buy possibilites: [-1] 
expected returns: [[44.98952]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  8.  8. 16.  3.  6.  6. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  7. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 1.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -35 

action type: buy - action 29.0
Learning step: -2.2120444774627686
desired expected reward: 27.274126052856445






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  7. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [ 1.  8.  8. 16.  3.  6.  6. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  7. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [ 1.  8.  8. 16.  3.  6.  6. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 16.] 
cards in discard: [29.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3. 10.  6.  0.] 
adversary cards in discard: [ 1.  8.  8. 16.  3.  6.  6. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 0.  3. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[35.830048]
 [31.185747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6.  0.] 
cards in discard: [ 1.  8.  8. 16.  3.  6.  6. 29. 29.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 3.  8. 23.  1. 25.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29] -> size -> 46 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.8279314041137695
desired expected reward: 39.161590576171875





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[32.169365]
 [33.245396]
 [36.332302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.  0.] 
cards in discard: [ 1.  8.  8. 16.  3.  6.  6. 29. 29.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 3.  8. 23.  1. 25.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29] -> size -> 46 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.3600664138793945
desired expected reward: 30.469993591308594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 23.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 23.  1. 25.] 
cards in discard: [29.  1.  3.  0.  0. 16.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 8. 10. 29.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 23.  1. 25.] 
cards in discard: [29.  1.  3.  0.  0. 16.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 29. 17. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 8. 10. 29.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 23.  1. 25.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 16. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 8. 10. 29.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 8. 10. 29.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
expected returns: [[5.4118543]
 [3.2595525]
 [3.835679 ]
 [4.026219 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29.  1.  6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 16. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3.  0. 16.  0.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -6.563916206359863
desired expected reward: 29.76839828491211





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[3.4501262]
 [3.5079532]
 [5.0247517]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29.  1.  6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 29. 16. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3.  0. 16.  0.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -5.0229034423828125
desired expected reward: 0.3889498710632324



buy possibilites: [-1] 
expected returns: [[11.741493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29.  1.  6.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  3.  0. 16.  0.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3] -> size -> 47 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -78 

action type: buy - action 3.0
Learning step: -3.8083229064941406
desired expected reward: -0.3581972122192383






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 16.  0.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  8. 16.  3.  0.] 
adversary cards in discard: [ 3.  8. 10. 29.  1.  6.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29  3] -> size -> 21 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16.  0.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  6.  9.  6.] 
adversary cards in hand: [ 0.  8. 16.  3.  0.] 
adversary cards in discard: [ 3.  8. 10. 29.  1.  6.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29  3] -> size -> 21 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16.  0.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  6.] 
adversary cards in hand: [ 0.  8. 16.  3.  0.] 
adversary cards in discard: [ 3.  8. 10. 29.  1.  6.] 
adversary owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29  3] -> size -> 21 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [ 0.  8. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[-0.96361613]
 [-1.9112538 ]
 [-2.033254  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  3.  0.] 
cards in discard: [ 3.  8. 10. 29.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  0  6  1  3  3  0 16 10 29  0 29  1  8 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  6.] 
adversary cards in hand: [10.  0.  0. 22. 15.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10] -> size -> 48 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.9187846183776855
desired expected reward: 6.822708606719971



action possibilites: [-1] 
expected returns: [[0.4930799]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  8. 10. 29.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  6.] 
adversary cards in hand: [10.  0.  0. 22. 15.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10] -> size -> 48 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.725227117538452
desired expected reward: -5.4451904296875





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[0.24710417]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  8. 10. 29.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  6.] 
adversary cards in hand: [10.  0.  0. 22. 15.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.] 
adversary owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10] -> size -> 48 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -3.869094133377075
desired expected reward: -3.376014232635498






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [10.  0.  0. 22. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 22. 15.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  0  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0
  0  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  6.] 
adversary cards in hand: [6. 3. 1. 6. 0.] 
adversary cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3] -> size -> 18 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 22.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16 15 10  8  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0  0
  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  6.] 
adversary cards in hand: [6. 3. 1. 6. 0.] 
adversary cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3] -> size -> 18 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 22.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16 15 10  8  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0  0
  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  6.] 
adversary cards in hand: [6. 3. 1. 6. 0.] 
adversary cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3] -> size -> 18 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 22.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.
 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3 25  8 16 15 10  8  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0  0
  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  5.] 
adversary cards in hand: [6. 3. 1. 6. 0.] 
adversary cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3] -> size -> 18 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [6. 3. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-12.404584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1. 6. 0.] 
cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  5.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.
 15. 15. 10.  0. 22.] 
adversary owned cards: [16  3 25  8 16 15 10  8  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0  0
  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10 15] -> size -> 48 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -5.141458034515381
desired expected reward: -4.894353866577148





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[-12.055937]
 [-10.932796]
 [-12.362159]
 [-11.649255]
 [-10.573571]
 [-12.475765]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 6. 0.] 
cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 29. 15. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  5.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.
 15. 15. 10.  0. 22.] 
adversary owned cards: [16  3 25  8 16 15 10  8  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0  0
  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10 15] -> size -> 48 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.484101295471191
desired expected reward: -16.88868522644043



buy possibilites: [-1] 
expected returns: [[9.46568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 6. 0.] 
cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 24. 29. 14. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  5.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.
 15. 15. 10.  0. 22.] 
adversary owned cards: [16  3 25  8 16 15 10  8  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0  0
  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10 15] -> size -> 48 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -84.0 

action type: buy - action 3.0
Learning step: -3.440382719039917
desired expected reward: -14.373178482055664






         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.
 15. 15. 10.  0. 22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 25  8 16 15 10  8  3  0  0 15  6  0  0  3 22  3  0  3  0  1  0  0
  0  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10 15] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 14. 30.  8.  0.  4.  5.  1.  8.  6. 10.  9.  5.  9.  5.] 
adversary cards in hand: [29.  6. 29.  0.  0.] 
adversary cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.  3.  6.  3.  1.  6.  0.] 
adversary owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3  3] -> size -> 19 
adversary victory points: -1
player victory points: 7 


Player 1 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 2 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 1 
Workshop: 0 
Chapel: 4 
Witch: 0 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  6. 29.  0.  0.] 
cards in discard: [ 3.  8. 10. 29.  1.  6.  8.  0.  3.  6.  3.  1.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  6  6  0  0  6  1  3  0 10 29  0 29  1  8 29  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 14. 30.  8.  0.  4.  5.  0.  8.  6. 10.  9.  5.  9.  5.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [29.  1.  3.  0.  0. 16.  3.  3.  8. 23.  1. 25. 10.  0.  3.  0. 16.  0.
 15. 15. 10.  0. 22.  8.] 
adversary owned cards: [16  3 25  8 16 15 10  8  3  0 15  6  0  0  3 22  3  0  3  0  1  0  0  0
  0 15 11  3  0 25  0  0 10 16  3 10  1 16  0 23  1 16  8 29  3 10 15  8] -> size -> 48 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -80    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -586 

action type: buy - action -1
Learning step: -29.773284912109375
desired expected reward: -20.307605743408203



