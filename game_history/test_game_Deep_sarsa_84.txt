 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[50.14535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7656735181808472
desired expected reward: 1.8910614252090454





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 48.226925]
 [ 82.38604 ]
 [ 69.46506 ]
 [ 29.234459]
 [ 69.78336 ]
 [ 91.04553 ]
 [ 68.41283 ]
 [115.616486]
 [ 43.703495]
 [ 56.134087]
 [ 76.60847 ]
 [ 48.484226]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.894073486328125



buy possibilites: [-1] 
expected returns: [[25.85653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 115.61648559570312






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[39.785328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.856529235839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[36.15752 ]
 [62.539288]
 [52.61485 ]
 [20.340633]
 [70.56067 ]
 [51.44805 ]
 [43.181942]
 [39.10237 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.95400619506836



buy possibilites: [-1] 
expected returns: [[18.527658]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 70.56068420410156






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[34.705215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.527658462524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[35.16003 ]
 [57.722935]
 [49.04996 ]
 [20.882261]
 [48.73611 ]
 [64.20846 ]
 [48.2445  ]
 [81.81755 ]
 [32.059795]
 [40.75168 ]
 [53.845787]
 [35.669685]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.27767562866211



buy possibilites: [-1] 
expected returns: [[14.100124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 81.81755065917969






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[23.104733]
 [45.181004]
 [40.943466]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 11.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 15.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.10012435913086



action possibilites: [-1. 11.] 
expected returns: [[36.16541]
 [67.69006]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 15.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.973873138427734



action possibilites: [-1] 
expected returns: [[34.448505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 15.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 83.53192138671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[43.583477]
 [62.36288 ]
 [54.496098]
 [28.632198]
 [56.536423]
 [66.57426 ]
 [54.44613 ]
 [82.60141 ]
 [39.569267]
 [46.637875]
 [58.290134]
 [39.84554 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 15.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.44850540161133



buy possibilites: [-1] 
expected returns: [[20.103817]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 15.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 82.6014175415039






Player: 1 
cards in hand: [ 0.  0.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 15.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 8.  0.  0.  3.  3.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 8.654973]
 [30.826977]
 [ 8.215996]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.103816986083984



action possibilites: [-1. 10. 11.] 
expected returns: [[15.80444 ]
 [20.121778]
 [38.35366 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.013668060302734



action possibilites: [-1] 
expected returns: [[22.321148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 47.22801971435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.558056]
 [42.94219 ]
 [35.728676]
 [10.273729]
 [49.675377]
 [34.630207]
 [27.6907  ]
 [24.367422]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.321147918701172



buy possibilites: [-1] 
expected returns: [[20.76583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 49.67538070678711






Player: 1 
cards in hand: [ 0.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[14.32188 ]
 [39.306526]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  3.] 
cards in discard: [10. 11. 29. 11.  0. 10.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.76582908630371



action possibilites: [-1. 29.] 
expected returns: [[36.125347]
 [78.939926]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [10. 11. 29. 11.  0. 10.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.065040588378906



action possibilites: [-1.] 
expected returns: [[81.3916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 78.93991088867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 98.86862 ]
 [139.86711 ]
 [124.173546]
 [ 84.8911  ]
 [ 71.010506]
 [124.82002 ]
 [149.6816  ]
 [122.96138 ]
 [187.79277 ]
 [172.57877 ]
 [ 92.25431 ]
 [134.76    ]
 [108.25275 ]
 [ 94.07726 ]
 [132.82625 ]
 [ 96.257324]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.3916015625



buy possibilites: [-1] 
expected returns: [[81.90815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0. 10.  0.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 187.79275512695312






Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [22. 15.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [22. 15.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [22. 15.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[33.47445]
 [67.71533]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  7. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.90814971923828



action possibilites: [-1] 
expected returns: [[73.77982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.40886688232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 69.42378 ]
 [ 98.688934]
 [ 87.88039 ]
 [ 51.122734]
 [ 87.915634]
 [106.38936 ]
 [ 86.6532  ]
 [127.16441 ]
 [ 65.95585 ]
 [ 77.03893 ]
 [ 93.93167 ]
 [ 71.811935]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.77982330322266



buy possibilites: [-1] 
expected returns: [[56.158543]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 127.16441345214844






Player: 1 
cards in hand: [ 0.  3.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 29. 10. 29.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 29. 10. 29.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 29. 10. 29.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[36.531857]
 [73.38509 ]
 [41.342728]
 [73.38509 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10. 29.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 22.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.15854263305664



action possibilites: [-1. 10. 29. 29.] 
expected returns: [[ 69.65817]
 [ 75.60074]
 [111.84042]
 [111.84042]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29. 29.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 22.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.76534271240234



action possibilites: [-1. 10. 29.] 
expected returns: [[155.57002]
 [162.75479]
 [213.75377]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29.  0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 22.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.84042358398438



action possibilites: [-1. 10. 25.] 
expected returns: [[172.35683]
 [180.8697 ]
 [252.04117]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 25.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 22.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 213.75376892089844



action possibilites: [-1] 
expected returns: [[152.6038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 22.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0  6] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 252.04115295410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[163.59523]
 [185.78699]
 [155.35362]
 [177.176  ]
 [155.90202]
 [147.05505]
 [178.21156]
 [190.54321]
 [176.73128]
 [215.17674]
 [205.79688]
 [159.76741]
 [183.22942]
 [168.29985]
 [161.09657]
 [181.73909]
 [161.22969]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 22.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0  6] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.6038055419922



buy possibilites: [-1] 
expected returns: [[112.81683]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 22.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0  6] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 215.17674255371094






Player: 1 
cards in hand: [ 0.  8.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 22.  0.] 
cards in discard: [ 0.  0.  3.  3. 16.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  8 16 22  3  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  3.  3. 16.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  3.  3. 16.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  3. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[19.708797]
 [24.017845]
 [24.017845]
 [42.398533]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.81683349609375



action possibilites: [-1] 
expected returns: [[48.973778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.247554779052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.51186 ]
 [34.161007]
 [50.383865]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.973777770996094



buy possibilites: [-1] 
expected returns: [[61.22755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  3.] 
cards in discard: [10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 50.51186752319336






Player: 1 
cards in hand: [ 0.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 67.10314]
 [109.81923]
 [109.81923]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 29.] 
cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.2275505065918



action possibilites: [-1. 29.] 
expected returns: [[ 96.23184]
 [141.71004]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 103.83758544921875



action possibilites: [-1. 29.] 
expected returns: [[ 73.61104]
 [118.6308 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 141.7100372314453



action possibilites: [-1. 25.] 
expected returns: [[144.34738]
 [221.0124 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 25.] 
cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  9.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 118.63078308105469



action possibilites: [-1] 
expected returns: [[82.36911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 221.01239013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 75.0983  ]
 [ 98.74382 ]
 [ 68.92013 ]
 [ 90.18865 ]
 [ 68.69953 ]
 [ 88.241135]
 [ 62.79935 ]
 [ 88.98515 ]
 [106.48065 ]
 [ 89.068665]
 [134.45486 ]
 [121.82834 ]
 [ 72.55786 ]
 [ 95.24486 ]
 [ 81.0459  ]
 [ 72.450066]
 [ 95.392006]
 [ 77.29747 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 11. 10.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 9 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  8.  9.  8.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.36911010742188



buy possibilites: [-1] 
expected returns: [[115.1911]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0. 0.] 
cards in discard: [10.  0. 11. 10.  3. 10.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3. 15.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 134.45489501953125






Player: 1 
cards in hand: [6. 3. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 8.] 
cards in discard: [ 3. 15.  0.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 11. 10. 29. 25.] 
adversary cards in discard: [10.  0. 11. 10.  3. 10.  3. 25. 29. 29. 29. 25.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 8.] 
cards in discard: [ 3. 15.  0.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 11. 10. 29. 25.] 
adversary cards in discard: [10.  0. 11. 10.  3. 10.  3. 25. 29. 29. 29. 25.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 10. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 25.] 
expected returns: [[ 96.61554 ]
 [110.345474]
 [ 94.71914 ]
 [115.64979 ]
 [122.07833 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 29. 25.] 
cards in discard: [10.  0. 11. 10.  3. 10.  3. 25. 29. 29. 29. 25.  0.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 115.19110107421875



action possibilites: [-1] 
expected returns: [[56.480846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 121.34693145751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.467342]
 [49.68899 ]
 [62.721546]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.4808464050293






Player: 1 
cards in hand: [ 3.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [25.  3. 11. 10. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [25.  3. 11. 10. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [25.  3. 11. 10. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 83.86484 ]
 [126.243484]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [25.  3. 11. 10. 29. 25.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 62.72153854370117



action possibilites: [-1.] 
expected returns: [[109.332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.  3. 11. 10. 29. 25.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 112.40791320800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[114.93525 ]
 [149.28728 ]
 [103.53478 ]
 [137.23196 ]
 [103.12268 ]
 [ 92.47408 ]
 [136.59859 ]
 [158.88878 ]
 [135.93562 ]
 [196.998   ]
 [180.52357 ]
 [109.97319 ]
 [144.91457 ]
 [123.95621 ]
 [110.613235]
 [144.34892 ]
 [115.90264 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.  3. 11. 10. 29. 25.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  7.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 109.33200073242188



buy possibilites: [-1] 
expected returns: [[83.97023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.  3. 11. 10. 29. 25.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 47.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 196.99798583984375






Player: 1 
cards in hand: [ 3. 15.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  6.  3.  8.] 
cards in discard: [ 6.  3.  3.  3.  0. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [10.  0.  3. 25. 29.] 
adversary cards in discard: [25.  3. 11. 10. 29. 25.  0. 25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 8.] 
cards in discard: [ 6.  3.  3.  3.  0. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [10.  0.  3. 25. 29.] 
adversary cards in discard: [25.  3. 11. 10. 29. 25.  0. 25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 8.] 
cards in discard: [ 6.  3.  3.  3.  0. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [10.  0.  3. 25. 29.] 
adversary cards in discard: [25.  3. 11. 10. 29. 25.  0. 25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29.] 
expected returns: [[57.279636]
 [47.699688]
 [78.3093  ]
 [68.91441 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 25. 29.] 
cards in discard: [25.  3. 11. 10. 29. 25.  0. 25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.97023010253906



action possibilites: [-1] 
expected returns: [[25.534742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29.  0. 10.] 
cards in discard: [25.  3. 11. 10. 29. 25.  0. 25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  6.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.6180648803711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.350336  ]
 [23.86821   ]
 [-0.03697467]
 [21.857756  ]
 [21.784643  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29.  0. 10.] 
cards in discard: [25.  3. 11. 10. 29. 25.  0. 25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8.  6.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.53474235534668



buy possibilites: [-1] 
expected returns: [[29.27769]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29.  0. 10.] 
cards in discard: [25.  3. 11. 10. 29. 25.  0. 25. 29.  0.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  6.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 23.86822509765625






Player: 1 
cards in hand: [0. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  6.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [29.  3. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  6.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [29.  3. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  3. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 11.] 
expected returns: [[23.763998]
 [43.291924]
 [26.730263]
 [43.291924]
 [36.697002]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10. 29. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  6.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  6.  3. 16.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.277690887451172



action possibilites: [-1. 10. 29. 11. 25.] 
expected returns: [[50.844204]
 [55.533966]
 [83.16762 ]
 [72.167435]
 [90.64127 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 11. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  6.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  6.  3. 16.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.94016647338867



action possibilites: [-1] 
expected returns: [[102.542336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  5.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  6.  3. 16.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 90.64127349853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[107.44449]
 [117.29948]
 [ 95.89992]
 [117.04278]
 [105.36659]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  5.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  6.  3. 16.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.5423355102539



buy possibilites: [-1] 
expected returns: [[109.16789]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29. 11. 10.  0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  6.  3. 16.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 111 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 117.29949951171875






Player: 1 
cards in hand: [ 3.  3.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  3. 16.] 
cards in discard: [6. 0. 3. 6. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5.  9.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3] -> size -> 27 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3] -> size -> 27 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[68.13196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  6. 15.] 
adversary cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.16789245605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 63.6265  ]
 [ 81.37844 ]
 [ 75.94301 ]
 [ 57.066525]
 [ 50.784065]
 [ 74.133644]
 [ 87.17881 ]
 [ 74.862305]
 [104.95914 ]
 [ 96.295   ]
 [ 61.85641 ]
 [ 78.879715]
 [ 69.426865]
 [ 61.127758]
 [ 79.60837 ]
 [ 67.51231 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  9.  6.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  6. 15.] 
adversary cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 65.17781066894531



buy possibilites: [-1] 
expected returns: [[69.77872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  9.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  6. 15.] 
adversary cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 104.95915222167969






Player: 1 
cards in hand: [ 3.  3.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  6. 15.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16. 16.  3.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  9.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [29. 10. 29.  0.  3.] 
adversary cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16. 16.  3.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  9.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [29. 10. 29.  0.  3.] 
adversary cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16. 16.  3.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  9.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [29. 10. 29.  0.  3.] 
adversary cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  6. 16. 16.  3.  6.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [29. 10. 29.  0.  3.] 
adversary cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 10. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[ 63.804066]
 [109.73808 ]
 [ 67.61238 ]
 [109.73808 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29.  0.  3.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [3. 3. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16  8] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.77871704101562



action possibilites: [-1. 10. 29. 10.] 
expected returns: [[ 87.62254 ]
 [ 76.28409 ]
 [111.067276]
 [ 76.28409 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  3. 10.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [3. 3. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16  8] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 109.73809051513672



action possibilites: [-1. 10. 10. 25.] 
expected returns: [[56.761486]
 [55.78555 ]
 [55.78555 ]
 [97.09665 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10. 25.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 24. 30.  8.  5.  8.  8.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [3. 3. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16  8] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.06727600097656



action possibilites: [-1] 
expected returns: [[26.782305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10. 25. 25.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 24. 30.  8.  4.  8.  8.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [3. 3. 8. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16  8  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 97.09667205810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.627598]
 [33.93513 ]
 [29.860691]
 [10.862511]
 [40.77007 ]
 [28.463428]
 [25.108091]
 [25.835293]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 10. 25. 25.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 24. 30.  8.  4.  8.  8.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [3. 3. 8. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16  8  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.782304763793945



buy possibilites: [-1] 
expected returns: [[64.90311]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 10. 25. 25.] 
cards in discard: [ 3. 29. 25.  3. 10. 29. 11. 10.  0. 25.  0.  0.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [3. 3. 8. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16  8  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.77006912231445






Player: 1 
cards in hand: [3. 3. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 6. 8.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  8 16  3  0  6  3  6  6  3  6  6 16  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11] -> size -> 29 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11] -> size -> 29 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11] -> size -> 29 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11] -> size -> 29 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[133.16562]
 [156.92296]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  6. 15.  0.] 
adversary cards in discard: [6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.90310668945312



action possibilites: [-1] 
expected returns: [[121.8403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  3.  6. 15.  0.] 
adversary cards in discard: [6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 154.10003662109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.49025]
 [141.1755 ]
 [116.64368]
 [140.96724]
 [127.02661]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  3.  6. 15.  0.] 
adversary cards in discard: [6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.84030151367188



buy possibilites: [-1] 
expected returns: [[112.526566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  3.  6. 15.  0.] 
adversary cards in discard: [6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 141.1754913330078






Player: 1 
cards in hand: [ 3.  3.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 15.  0.] 
cards in discard: [6. 0. 8. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [25. 25.  0. 29.  0.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3] -> size -> 31 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 15.  0.] 
cards in discard: [6. 0. 8. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [25. 25.  0. 29.  0.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3] -> size -> 31 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 15.  0.] 
cards in discard: [6. 0. 8. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 23. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [25. 25.  0. 29.  0.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3] -> size -> 31 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [25. 25.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[21.699589]
 [57.14299 ]
 [57.14299 ]
 [48.485203]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 29.  0.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  4.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  6.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  0.  3.  3.  6. 15.  0.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.52656555175781



action possibilites: [-1] 
expected returns: [[68.61821]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  0.  0.  0.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  3.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  6.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  0.  3.  3.  6. 15.  0.  6.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 55.141937255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[50.201256]
 [74.64748 ]
 [69.9475  ]
 [33.310757]
 [64.40902 ]
 [85.895386]
 [67.72608 ]
 [94.90675 ]
 [49.21048 ]
 [60.313423]
 [74.377235]
 [61.616093]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 29.  0.  0.  0.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 23. 30.  8.  3.  8.  7.  8.  5.  6. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  6.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  0.  3.  3.  6. 15.  0.  6.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.61820983886719



buy possibilites: [-1] 
expected returns: [[98.19325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 29.  0.  0.  0.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  3.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  6.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  0.  3.  3.  6. 15.  0.  6.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 94.90673065185547






Player: 1 
cards in hand: [ 0.  6. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  3.  6.] 
cards in discard: [ 6.  0.  8.  3.  3.  0.  3.  3.  6. 15.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  3.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [29.  3. 10.  0. 11.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  3.  6.] 
cards in discard: [ 6.  0.  8.  3.  3.  0.  3.  3.  6. 15.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 23. 30.  8.  3.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [29.  3. 10.  0. 11.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  3.  6.] 
cards in discard: [ 6.  0.  8.  3.  3.  0.  3.  3.  6. 15.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 23. 30.  8.  3.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [29.  3. 10.  0. 11.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29.  3. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[110.920204]
 [122.901245]
 [102.44383 ]
 [121.65972 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0. 11.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 23. 30.  8.  3.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  3.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.19325256347656



action possibilites: [-1. 10. 11. 25.] 
expected returns: [[141.08708]
 [133.24437]
 [155.5386 ]
 [166.6169 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 11. 25.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 23. 30.  8.  3.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  3.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 122.90127563476562



action possibilites: [-1] 
expected returns: [[110.05683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 11.  3. 25.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  3.  6. 16.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 166.6168975830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 88.64354 ]
 [108.97206 ]
 [ 71.300865]
 [105.950516]
 [110.36067 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.  3. 25.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  3.  6. 16.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.05683135986328






Player: 1 
cards in hand: [ 6.  3.  6. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6. 16.  3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  6  3  6  6 16  8  6  0  0  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [10.  0. 11. 10. 29.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [10.  0. 11. 10. 29.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [10.  0. 11. 10. 29.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [6. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [10.  0. 11. 10. 29.] 
adversary cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[42.657177]
 [42.52623 ]
 [56.818993]
 [42.52623 ]
 [63.924534]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10. 29.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 110.36066436767578



action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[55.684666]
 [52.74888 ]
 [67.389534]
 [52.74888 ]
 [52.74888 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10. 10.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.92453384399414



action possibilites: [-1] 
expected returns: [[56.998585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.3035888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.500748]
 [63.08166 ]
 [38.367107]
 [61.246174]
 [54.81615 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 23. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.99858474731445



buy possibilites: [-1] 
expected returns: [[87.27835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10.  3. 11.  0.  3.  3.  0. 29. 25. 25.  0. 29.  0.  0.  0. 29. 25.  3.
 10.  0. 11.  3. 25. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 22. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 63.0816764831543






Player: 1 
cards in hand: [ 3.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 22. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10.  0.  3. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3] -> size -> 34 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 22. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10.  0.  3. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3] -> size -> 34 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 21. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10.  0.  3. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3] -> size -> 34 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[ 95.19375]
 [ 96.71086]
 [118.65453]
 [124.89909]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 21. 30.  8.  2.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.27835083007812



action possibilites: [-1] 
expected returns: [[42.386906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 21. 30.  8.  1.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.21928405761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.442448]
 [46.40072 ]
 [30.731335]
 [46.050392]
 [42.327938]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 21. 30.  8.  1.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.386905670166016



buy possibilites: [-1] 
expected returns: [[76.18955]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29.  0.  3.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 20. 30.  8.  1.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.] 
adversary owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 241 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 46.40071487426758






Player: 1 
cards in hand: [0. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 8.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 20. 30.  8.  1.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 20. 30.  8.  1.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 20. 30.  8.  1.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 20. 30.  8.  1.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[45.162964]
 [59.24981 ]
 [75.33716 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0. 25.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 20. 30.  8.  1.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.  0.  8.  0.  6.
  6.] 
adversary owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0] -> size -> 25 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.1895523071289



action possibilites: [-1] 
expected returns: [[-0.34444952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0. 29. 25.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.  0.  8.  0.  6.
  6.  6.] 
adversary owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 75.33717346191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.7212    ]
 [ -0.44827747]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0. 29. 25.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.  0.  8.  0.  6.
  6.  6.] 
adversary owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.344449520111084






Player: 1 
cards in hand: [3. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 3.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.  0.  8.  0.  6.
  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10. 10. 29.  0. 25.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 3.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.  0.  8.  0.  6.
  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10. 10. 29.  0. 25.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 3.] 
cards in discard: [ 6.  0.  0. 16.  3.  6.  3.  3.  3.  3.  0. 16.  0.  6.  0.  8.  0.  6.
  6.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [10. 10. 29.  0. 25.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10. 10. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 25.] 
expected returns: [[134.3928 ]
 [124.75926]
 [124.75926]
 [155.54555]
 [174.58931]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  0. 25.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.4482717514038086



action possibilites: [-1] 
expected returns: [[85.50157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  0. 11.  3.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 174.58934020996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[72.89113 ]
 [88.870415]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 29.  0. 11.  3.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.50157165527344






Player: 1 
cards in hand: [ 3.  0.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  0  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6
  0  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 29. 11. 10.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 29. 11. 10.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 29. 11. 10.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 29. 11. 10.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[49.525703]
 [82.63989 ]
 [73.1792  ]
 [50.47309 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10.  0.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.87042999267578



action possibilites: [-1. 10.] 
expected returns: [[124.57411]
 [126.54225]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 64.63935852050781



action possibilites: [-1. 10.] 
expected returns: [[122.09515 ]
 [124.979355]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 126.542236328125



action possibilites: [-1.] 
expected returns: [[126.665085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 3 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 124.97935485839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[128.07436]
 [160.89851]
 [150.86955]
 [116.11493]
 [147.27733]
 [171.98146]
 [148.76715]
 [198.2517 ]
 [186.0098 ]
 [124.96344]
 [156.17166]
 [138.78798]
 [123.49031]
 [157.73862]
 [135.61731]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  5.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.66508483886719



buy possibilites: [-1] 
expected returns: [[70.53767]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 565 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 198.25169372558594






Player: 1 
cards in hand: [0. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [ 0. 15.  3.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 25.  3. 29. 10.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11. 25. 29. 10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25] -> size -> 36 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [ 0. 15.  3.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 25.  3. 29. 10.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11. 25. 29. 10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25] -> size -> 36 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 25.  3. 29. 10.] 
adversary cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11. 25. 29. 10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25] -> size -> 36 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[55.8773  ]
 [89.12831 ]
 [75.185776]
 [46.785   ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3. 29. 10.] 
cards in discard: [ 3. 25. 10.  0.  3. 29.  0.  3. 25. 11.  3.  3.  0. 29. 25. 25. 10. 10.
 29.  0. 11.  3. 11. 25. 29. 10. 10.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [6. 6. 0. 6. 6.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10] -> size -> 28 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.53766632080078



action possibilites: [-1] 
expected returns: [[43.3913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 10.  0. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [6. 6. 0. 6. 6.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10] -> size -> 28 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 89.12831115722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[44.122135]
 [43.29414 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29. 10.  0. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [6. 6. 0. 6. 6.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10] -> size -> 28 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.391300201416016



buy possibilites: [-1] 
expected returns: [[164.29933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29. 10.  0. 29.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [6. 6. 0. 6. 6.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10] -> size -> 28 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   0. 270.   0.   0.  20.   0.   0.   0.   0. -20.   0.   0.
   0.   0.] 
sum of rewards: 265.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 44.12213134765625






Player: 1 
cards in hand: [6. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 6.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0] -> size -> 37 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 6.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0] -> size -> 37 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 6.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0] -> size -> 37 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[25.390575]
 [16.535332]
 [50.686535]
 [48.00782 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0. 11.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 164.29933166503906



action possibilites: [-1. 10. 10.] 
expected returns: [[46.332657]
 [28.251774]
 [28.251774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.264266967773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[14.028629]
 [41.324203]
 [38.257183]
 [63.008457]
 [32.67369 ]
 [29.55518 ]
 [47.498962]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 20. 30.  8.  0.  8.  7.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.332679748535156



buy possibilites: [-1] 
expected returns: [[35.494526]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  0.  8.  6.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.] 
adversary owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 63.00847244262695






Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 16  3  3  6  3  6  6 16  8  6  0  0  6  0  6  0  0  3  6  0
  6  0  0 10  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  0.  8.  6.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11] -> size -> 38 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  0.  8.  6.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11] -> size -> 38 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 30. 30. 20. 30.  8.  0.  8.  6.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11] -> size -> 38 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0
 10  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  6.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11] -> size -> 38 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[63.268757]
 [59.85718 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  6.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  6.  0.  3. 16.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.  0.
  8.  0.] 
adversary owned cards: [ 3 15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0
 10  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.49452590942383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[47.40802 ]
 [70.66889 ]
 [65.34508 ]
 [81.73351 ]
 [62.773693]
 [57.76509 ]
 [61.2036  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  6.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  6.  0.  3. 16.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.  0.
  8.  0.] 
adversary owned cards: [ 3 15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0
 10  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.26876449584961



buy possibilites: [-1] 
expected returns: [[65.28717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  6.  0.  3. 16.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.  0.
  8.  0.] 
adversary owned cards: [ 3 15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0
 10  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 339 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 81.73350524902344






Player: 1 
cards in hand: [ 3.  6.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  3. 16.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.  0.
  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0
 10  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 11. 10. 10. 25.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.  0.
  8.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10
  0  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 11. 10. 10. 25.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [ 0. 15.  3.  6.  3. 10.  0.  6.  0.  6.  0.  0.  6.  6.  0.  6.  6.  0.
  8.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10
  0  0 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 11. 10. 10. 25.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 10. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 25.] 
expected returns: [[41.11999 ]
 [53.61261 ]
 [38.133938]
 [38.133938]
 [62.616863]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10. 25.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  8.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10
  0  0 14] -> size -> 27 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.28717041015625



action possibilites: [-1] 
expected returns: [[37.41846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10.  3. 25.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  8.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10
  0  0 14] -> size -> 27 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.616878509521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[32.76344 ]
 [37.396385]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10. 10.  3. 25.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  8.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10
  0  0 14] -> size -> 27 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.418460845947266






Player: 1 
cards in hand: [ 6.  8.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  3. 16.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10
  0  0 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 11. 25.  3.  0.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0. 25.  3. 11. 10. 10.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 3. 11. 25.  3.  0.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0. 25.  3. 11. 10. 10.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
adversary victory points: 8
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 3. 11. 25.  3.  0.] 
adversary cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0. 25.  3. 11. 10. 10.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
adversary victory points: 8
player victory points: -5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 9.406786]
 [19.840733]
 [28.196321]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25.  3.  0.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0. 25.  3. 11. 10. 10.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  6. 14.] 
adversary cards in discard: [15. 16.  6.  8.  6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.3963737487793



action possibilites: [-1] 
expected returns: [[-8.105457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.  0. 29.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0. 25.  3. 11. 10. 10.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  6. 14.] 
adversary cards in discard: [15. 16.  6.  8.  6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 28.196321487426758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-19.568714 ]
 [ -5.5891385]
 [ -7.6354437]
 [ -8.105478 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.  0. 29.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0. 25.  3. 11. 10. 10.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 20. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  6. 14.] 
adversary cards in discard: [15. 16.  6.  8.  6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.105457305908203



buy possibilites: [-1] 
expected returns: [[0.28593135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.  0. 29.] 
cards in discard: [ 0. 25.  3.  3. 29. 10.  0. 29. 11. 11. 29. 10.  0.  0. 10. 11. 10.  0.
  3.  0.  0. 25.  3. 11. 10. 10.  3. 25.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  6. 14.] 
adversary cards in discard: [15. 16.  6.  8.  6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 401 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -5.589134216308594






Player: 1 
cards in hand: [ 6.  0. 16.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  6. 14.] 
cards in discard: [15. 16.  6.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
adversary victory points: 9
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  6. 14.] 
cards in discard: [15. 16.  6.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
adversary victory points: 9
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 90.51402]
 [126.12331]
 [118.99456]
 [126.12331]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25. 29. 25.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.2859313488006592



action possibilites: [-1] 
expected returns: [[48.705627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 25. 10. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.12330627441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[44.41435 ]
 [48.808384]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29. 25. 10. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.70562744140625






Player: 1 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 3. 11.  3. 11. 11.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
adversary victory points: 9
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 3. 11.  3. 11. 11.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
adversary victory points: 9
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  2.  9.  8.] 
adversary cards in hand: [ 3. 11.  3. 11. 11.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
adversary victory points: 9
player victory points: -5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[35.527676]
 [63.224247]
 [63.224247]
 [63.224247]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 11. 11.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  2.  9.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15 10] -> size -> 28 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.80836868286133



action possibilites: [-1] 
expected returns: [[72.52092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 11.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  2.  9.  7.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15 10] -> size -> 28 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 439 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.01573181152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[52.44172]
 [73.1945 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11. 11.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  2.  9.  7.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15 10] -> size -> 28 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 72.52091979980469






Player: 1 
cards in hand: [15.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  0  6  0  6  0  0  3  6  0  6  0  0 10  0
  0 14 15 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  2.  9.  7.] 
adversary cards in hand: [25.  0. 10.  3.  0.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
adversary victory points: 9
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  2.  9.  7.] 
adversary cards in hand: [25.  0. 10.  3.  0.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
adversary victory points: 9
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  9. 10.  2.  9.  7.] 
adversary cards in hand: [25.  0. 10.  3.  0.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
adversary victory points: 9
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [25.  0. 10.  3.  0.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
adversary victory points: 9
player victory points: -5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [25.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[ 79.69977 ]
 [123.14374 ]
 [ 60.617573]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10.  3.  0.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0. 14. 15.
  0.  3.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14] -> size -> 28 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.19449615478516



action possibilites: [-1] 
expected returns: [[58.64794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 11.  0.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0. 14. 15.
  0.  3.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14] -> size -> 28 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.14372253417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[46.333935]
 [66.240364]
 [61.8082  ]
 [75.7353  ]
 [59.631706]
 [55.48541 ]
 [58.765747]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0. 11.  0.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  5.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0. 14. 15.
  0.  3.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14] -> size -> 28 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.64794158935547



buy possibilites: [-1] 
expected returns: [[71.7242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0. 11.  0.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [6. 6. 3. 6. 0.] 
adversary cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0. 14. 15.
  0.  3.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14] -> size -> 28 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 419 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 75.73528289794922






Player: 1 
cards in hand: [6. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0. 14. 15.
  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11] -> size -> 42 
adversary victory points: 9
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0. 14. 15.
  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 19. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11] -> size -> 42 
adversary victory points: 9
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6. 0.] 
cards in discard: [15. 16.  6.  8.  6.  6.  0. 16.  6. 14. 10.  0.  6.  3.  0.  0. 14. 15.
  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 30. 30. 19. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11] -> size -> 42 
adversary victory points: 9
player victory points: -5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[41.331196]
 [51.359226]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  3.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 19. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  7.] 
adversary cards in hand: [14.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14  0] -> size -> 29 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.72419738769531



action possibilites: [-1] 
expected returns: [[39.585514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 19. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [14.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14  0] -> size -> 29 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 419 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.45968246459961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[28.355164]
 [43.842922]
 [41.668575]
 [39.140743]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 30. 30. 19. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [14.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14  0] -> size -> 29 
adversary victory points: -5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.585514068603516



buy possibilites: [-1] 
expected returns: [[67.70857]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 18. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [14.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14  0] -> size -> 29 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 391 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 43.842918395996094






Player: 1 
cards in hand: [14.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 18. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [29. 29.  0.  3. 10.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1. 14.  8. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  0. 16.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 18. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [29. 29.  0.  3. 10.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 16.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  0  6  0  0  3  6  0  6  0  0 10  0  0
 14 15 10 14  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 30. 30. 18. 30.  8.  0.  8.  4.  8.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14. 16.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 30. 30. 18. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14. 16.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 30. 30. 18. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [8. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14. 16.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 30. 30. 18. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[25.779238]
 [32.937992]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 18. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  0. 10.  6.  3.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  450    0    0    0    0    0    0    0  -90    0    0
 1396    0] 
sum of rewards: 1751 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 6.983469009399414



action possibilites: [-1.] 
expected returns: [[27.000393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 18. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  0. 10.  6.  3.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 19.02997589111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[19.73935 ]
 [29.122097]
 [27.854803]
 [27.000406]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 18. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  0. 10.  6.  3.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.00039291381836



buy possibilites: [-1] 
expected returns: [[71.13043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  0. 10.  6.  3.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: 411 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 29.122081756591797






Player: 1 
cards in hand: [ 6.  0. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  6.  3.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [25.  3. 10. 25.  0.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10. 29.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  6.  3.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [25.  3. 10. 25.  0.] 
adversary cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10. 29.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [25.  3. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
expected returns: [[-19.894047 ]
 [  2.5920184]
 [-23.057056 ]
 [  2.5920184]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 10. 25.  0.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10. 29.  3. 29.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 16.  0.  3. 14.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.13043212890625



action possibilites: [-1] 
expected returns: [[53.7457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25.  0. 10.  0.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10. 29.  3. 29.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 16.  0.  3. 14.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.5920021533966064





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[30.403027]
 [50.38873 ]
 [46.794903]
 [53.745686]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 25.  0. 10.  0.] 
cards in discard: [25.  3.  3. 29. 25. 10. 29. 15. 11.  3.  3. 11. 11. 11. 25.  0. 10.  3.
  0. 11.  0. 15.  3. 11.  3.  0.  0.  3. 29. 10. 29.  3. 29.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 16.  0.  3. 14.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.74570083618164






Player: 1 
cards in hand: [ 0. 16.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3. 14.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  0  3  6  0  6  0  0 10  0  0 14
 15 10 14  0  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  7.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10.  0. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10.  0. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10.  0. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10.  0. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25. 10.] 
expected returns: [[ 78.709984]
 [ 92.423065]
 [ 75.863014]
 [103.77058 ]
 [ 75.863014]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 25. 10.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0] -> size -> 31 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 53.74570083618164



action possibilites: [-1] 
expected returns: [[83.66766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10. 29. 10.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0] -> size -> 31 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 103.77055358886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[68.88169 ]
 [85.646095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 10. 29. 10.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0] -> size -> 31 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.66766357421875






Player: 1 
cards in hand: [3. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
adversary victory points: 11
player victory points: -5 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[70.87569]
 [76.63023]
 [53.1012 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  0.  6. 15. 15.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.
  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0] -> size -> 32 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 85.64607238769531



action possibilites: [-1] 
expected returns: [[59.789555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 0.  0.  6. 15. 15.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.
  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0] -> size -> 32 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -110    0    0
   64    0] 
sum of rewards: 449 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 78.00247192382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[14.68033 ]
 [53.556408]
 [48.20197 ]
 [79.435104]
 [41.483173]
 [38.711304]
 [59.698254]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  4.  6.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 0.  0.  6. 15. 15.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.
  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0] -> size -> 32 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.789554595947266



buy possibilites: [-1] 
expected returns: [[49.394947]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  3.  6.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 0.  0.  6. 15. 15.] 
adversary cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.
  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0] -> size -> 32 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -120    0    0
   54    0] 
sum of rewards: 429 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 79.43507385253906






Player: 1 
cards in hand: [ 0.  0.  6. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 15. 15.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.
  0.  3.  6.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  3.  6.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 29.  3.  0. 15.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 15. 15.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.
  0.  3.  6.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  3.  6.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 29.  3.  0. 15.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 15. 15.] 
cards in discard: [ 8.  0. 10. 14. 16.  8.  0.  6.  0. 10.  6.  3.  8.  0. 16.  0.  3. 14.
  0.  3.  6.  6.  0.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  3.  5.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 29.  3.  0. 15.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[ 99.54932 ]
 [104.100746]
 [ 93.23323 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 15.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  3.  5.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8] -> size -> 33 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.39494705200195



action possibilites: [-1. 15.] 
expected returns: [[93.60143 ]
 [94.369446]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  3.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25
 25  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  3.  5.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8] -> size -> 33 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 90.0421142578125



action possibilites: [-1] 
expected returns: [[127.40221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  3.  5.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8] -> size -> 33 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 94.36944580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 72.77754 ]
 [114.253716]
 [112.41267 ]
 [ 88.79018 ]
 [138.85818 ]
 [105.07809 ]
 [134.54941 ]
 [ 79.21436 ]
 [102.42768 ]
 [119.851   ]
 [127.16283 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  3.  5.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8] -> size -> 33 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.40220642089844



buy possibilites: [-1] 
expected returns: [[96.36928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  5.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8] -> size -> 33 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[  -5.     0.     0.   480.     0.     0.    40.     0.     0.     0.
    0.  -120.     0.     0.    13.5    0. ] 
sum of rewards: 408.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 138.858154296875






Player: 1 
cards in hand: [6. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  5.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 25.  3. 25.  3.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  5.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 25.  3. 25.  3.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 25.  3. 25.  3.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-1.0773816]
 [23.723007 ]
 [23.723007 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3. 25.  3.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 6.  0.  3. 10.  6.] 
adversary cards in discard: [8. 6. 0. 0. 6. 6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.36927795410156



action possibilites: [-1] 
expected returns: [[82.57801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  3.  3.  0.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 6.  0.  3. 10.  6.] 
adversary cards in discard: [8. 6. 0. 0. 6. 6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.723011016845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.423256]
 [82.57805 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  3.  3.  0.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 6.  0.  3. 10.  6.] 
adversary cards in discard: [8. 6. 0. 0. 6. 6.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.57801055908203






Player: 1 
cards in hand: [ 6.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 10.  6.] 
cards in discard: [8. 6. 0. 0. 6. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 29.  3.  0. 10.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 8.] 
cards in discard: [8. 6. 0. 0. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 29.  3.  0. 10.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 8.] 
cards in discard: [8. 6. 0. 0. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 29.  3.  0. 10.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-30.107534]
 [-21.04856 ]
 [-31.351162]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 10.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 16.  6. 14.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.57801055908203



action possibilites: [-1. 10. 25.] 
expected returns: [[ -9.324629]
 [-14.261436]
 [ 32.552883]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 25.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 16.  6. 14.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -27.79973602294922



action possibilites: [-1] 
expected returns: [[-54.80283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 25. 11.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 16.  6. 14.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.55287170410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-67.4811  ]
 [-58.441105]
 [-60.809914]
 [-54.802853]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 25. 11.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 16.  6. 14.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.] 
adversary owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action -1
Learning step: 0
desired expected reward: -54.80282974243164






Player: 1 
cards in hand: [ 6. 16.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  6. 14.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  6  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15
 10 14  0  8  0  8  0  0  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 17. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [29.  0.  3. 11.  3.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 16. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [29.  0.  3. 11.  3.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 30. 30. 16. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [29.  0.  3. 11.  3.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 16. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [29.  0.  3. 11.  3.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
adversary victory points: 11
player victory points: -3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[-74.75271 ]
 [-67.23306 ]
 [-68.563255]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 11.  3.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 16. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.] 
adversary owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3  0] -> size -> 35 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -54.80282974243164



action possibilites: [-1. 11. 11.] 
expected returns: [[35.235706]
 [62.985714]
 [62.985714]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 16. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.] 
adversary owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3  0] -> size -> 35 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -74.10856628417969



action possibilites: [-1] 
expected returns: [[141.35779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.
 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 16. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.] 
adversary owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3  0] -> size -> 35 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  420    0    0   40    0    0    0    0 -130    0    0
   64    0] 
sum of rewards: 389 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.11725616455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[116.75726]
 [142.64122]
 [138.3336 ]
 [141.35779]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.
 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 30. 30. 16. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.] 
adversary owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3  0] -> size -> 35 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.3577880859375



buy possibilites: [-1] 
expected returns: [[126.469315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.
 15.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.] 
adversary owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3  0] -> size -> 35 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  450    0    0   40    0    0    0    0 -140    0    0
   16    0] 
sum of rewards: 361 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 142.6412353515625






Player: 1 
cards in hand: [14.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  8.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  3  6  6 16  8  6  6  6  0  3  6  0  6  0  0 10  0  0 14 15 10
 14  0  8  0  8  0  0  8  8  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [29. 25.  0. 10. 15.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.
 15.  3. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 16  3  3  6  6 16  8  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8
  0  8  0  0  8  8  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [29. 25.  0. 10. 15.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.
 15.  3. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 16  3  3  6  6 16  8  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8
  0  8  0  0  8  8  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [29. 25.  0. 10. 15.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.
 15.  3. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 16  3  3  6  6 16  8  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8
  0  8  0  0  8  8  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [29. 25.  0. 10. 15.] 
adversary cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.
 15.  3. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [29. 25.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10. 15.] 
expected returns: [[-53.090206]
 [-48.403767]
 [-43.99691 ]
 [-55.335407]
 [-52.628513]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 10. 15.] 
cards in discard: [25. 11. 10.  0. 10. 29. 10. 15. 11. 11. 10.  0.  0.  0.  3. 11. 29. 15.
  3.  3. 25.  3.  3. 25.  3.  3.  0.  3. 29. 25.  3.  0. 10. 25. 11.  3.
 15.  3. 29. 11.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [ 8.  0. 15. 16.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3.] 
adversary owned cards: [15 16  3  3  6  6 16  8  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8
  0  8  0  0  8  8  3  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1
Learning step: 0
desired expected reward: 126.46931457519531



action possibilites: [-1] 
expected returns: [[27.739092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 15.  0. 11.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [ 8.  0. 15. 16.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3.] 
adversary owned cards: [15 16  3  3  6  6 16  8  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8
  0  8  0  0  8  8  3  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -43.996910095214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 1.6713583]
 [21.970074 ]
 [18.486717 ]
 [26.609344 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 10. 15.  0. 11.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [ 8.  0. 15. 16.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3.] 
adversary owned cards: [15 16  3  3  6  6 16  8  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8
  0  8  0  0  8  8  3  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.739091873168945






Player: 1 
cards in hand: [ 8.  0. 15. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15. 16.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  3  6  6 16  8  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8
  0  8  0  0  8  8  3  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  4.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  3  6  6 16  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8  0
  8  0  0  8  8  3  0  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  3  6  6 16  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8  0
  8  0  0  8  8  3  0  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 16  3  3  6  6 16  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8  0
  8  0  0  8  8  3  0  0 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [29.  0. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[171.9081 ]
 [188.72359]
 [199.16907]
 [185.60413]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 11.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.  0. 16.  0. 15.  0.] 
adversary owned cards: [15 16  3  3  6  6 16  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8  0
  8  0  0  8  8  3  0  0 15  0] -> size -> 34 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.609333038330078



action possibilites: [-1] 
expected returns: [[123.2787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3. 11.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.  0. 16.  0. 15.  0.] 
adversary owned cards: [15 16  3  3  6  6 16  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8  0
  8  0  0  8  8  3  0  0 15  0] -> size -> 34 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 199.16909790039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 94.38143]
 [120.93921]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  3. 11.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.  0. 16.  0. 15.  0.] 
adversary owned cards: [15 16  3  3  6  6 16  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8  0
  8  0  0  8  8  3  0  0 15  0] -> size -> 34 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.27870178222656






Player: 1 
cards in hand: [15.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  3.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.  0. 16.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15 16  3  3  6  6 16  6  6  6  3  6  6  0  0 10  0  0 15 10 14  0  8  0
  8  0  0  8  8  3  0  0 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [ 0. 25.  0. 25.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.  0. 16.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6  0 10  0  0 15 10 14  0  8  0  8  0  0
  8  8  3  0  0 15  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [ 0. 25.  0. 25.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.  0. 16.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6  0 10  0  0 15 10 14  0  8  0  8  0  0
  8  8  3  0  0 15  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [ 0. 25.  0. 25.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  6.  0.  0.  6.  6. 10.  6.  0.  3.  6.  8.  3.  0. 16.  6. 14.  0.
  0.  8.  3. 15.  0. 16.  0. 15.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6  0 10  0  0 15 10 14  0  8  0  8  0  0
  8  8  3  0  0 15  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [ 0. 25.  0. 25.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -4 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 78.86394 ]
 [105.690506]
 [105.690506]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 25.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [ 0.  3.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6  0 10  0  0 15 10 14  0  8  0  8  0  0
  8  8  3  0  0 15  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 120.93922424316406



action possibilites: [-1] 
expected returns: [[91.34088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3. 29.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [ 0.  3.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6  0 10  0  0 15 10 14  0  8  0  8  0  0
  8  8  3  0  0 15  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 105.69050598144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[62.235455]
 [91.17172 ]
 [86.41533 ]
 [92.007195]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  3. 29.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [ 0.  3.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6  0 10  0  0 15 10 14  0  8  0  8  0  0
  8  8  3  0  0 15  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.34088134765625






Player: 1 
cards in hand: [ 0.  3.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6  0 10  0  0 15 10 14  0  8  0  8  0  0
  8  8  3  0  0 15  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [10.  3. 10. 11. 15.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6  0 10  0  0 15 10 14  0  8  0  8  0  0
  8  8  3  0  0 15  0  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [10.  3. 10. 11. 15.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [10.  3. 10. 11. 15.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [10.  3. 10. 11. 15.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [10.  3. 10. 11. 15.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
adversary victory points: 12
player victory points: -4 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [10.  3. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 15.] 
expected returns: [[33.895443]
 [17.547855]
 [17.547855]
 [44.999542]
 [29.145844]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 11. 15.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  3.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.00721740722656



action possibilites: [-1] 
expected returns: [[118.605194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 15.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  2.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -150    0    0
   64    0] 
sum of rewards: 409 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 47.4962043762207





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 82.28763]
 [118.60519]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10. 15.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  2.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.60519409179688






Player: 1 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  2.] 
adversary cards in hand: [11.  3. 10. 10.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15] -> size -> 50 
adversary victory points: 12
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 30. 30. 15. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  2.] 
adversary cards in hand: [11.  3. 10. 10.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15] -> size -> 50 
adversary victory points: 12
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  2.] 
adversary cards in hand: [11.  3. 10. 10.  3.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15] -> size -> 50 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [11.  3. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[-44.165886]
 [-32.270226]
 [-48.750378]
 [-48.750378]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 10.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  2.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 118.60519409179688



action possibilites: [-1] 
expected returns: [[4.298872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  450    0    0   20    0    0    0    0 -160    0    0
   64    0] 
sum of rewards: 369 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -29.02042007446289





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.909514]
 [  4.29889 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  3.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.298871994018555






Player: 1 
cards in hand: [0. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 8.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [ 3.  3. 15. 25. 11.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 8.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [ 3.  3. 15. 25. 11.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 15. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 11.] 
expected returns: [[-24.594818]
 [-27.347395]
 [ -7.224074]
 [-16.337399]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 25. 11.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [ 8.  6. 14. 16. 15.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.298871994018555



action possibilites: [-1] 
expected returns: [[-11.406116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 11. 10. 11.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [ 8.  6. 14. 16. 15.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -7.224064826965332





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-26.44743 ]
 [-11.406114]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 11. 10. 11.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [ 8.  6. 14. 16. 15.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.406115531921387






Player: 1 
cards in hand: [ 8.  6. 14. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 14. 16. 15.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [ 0.  3. 25.  3. 15.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3. 25.  3.  3.
 15. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 14. 16.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [ 0.  3. 25.  3. 15.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3. 25.  3.  3.
 15. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 14. 16.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [ 0.  3. 25.  3. 15.] 
adversary cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3. 25.  3.  3.
 15. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[38.819736]
 [62.572727]
 [40.493694]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  3. 15.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3. 25.  3.  3.
 15. 11. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [10.  3.  0. 15. 16.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -11.406115531921387



action possibilites: [-1] 
expected returns: [[76.01816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 15. 29. 11.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3. 25.  3.  3.
 15. 11. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [10.  3.  0. 15. 16.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.57271957397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.012844]
 [76.01812 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 15. 29. 11.] 
cards in discard: [25. 29.  0. 10. 15.  0. 11. 25. 29.  0. 11.  3. 11.  3. 25.  0.  0. 25.
  3. 29.  3. 15. 11. 10.  3. 10. 15. 15. 11.  3. 10. 10.  3. 25.  3.  3.
 15. 11. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [10.  3.  0. 15. 16.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.] 
adversary owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.01815795898438






Player: 1 
cards in hand: [10.  3.  0. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 15. 16.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [15.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 16.  6.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0  0 15 10 14  0  8  0  8  0  0  8
  8  3  0  0 15  0  0  0  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [15.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [16  3  6  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8
  3  0  0 15  0  0  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 8. 30. 30. 14. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [15.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [15.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [15.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
adversary victory points: 12
player victory points: -1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [15.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[ 94.28351 ]
 [ 92.318954]
 [109.69067 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3. 10. 15. 16.  3.] 
adversary owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.01815795898438



action possibilites: [-1. 15.] 
expected returns: [[129.34135]
 [134.36815]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.] 
cards in discard: [3.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25
  3  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15
  3 15 15] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3. 10. 15. 16.  3.] 
adversary owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 88.75537109375



action possibilites: [-1] 
expected returns: [[37.590862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [3.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15] -> size -> 50 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3. 10. 15. 16.  3.] 
adversary owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 134.36814880371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.382275]
 [42.761856]
 [37.583755]
 [ 8.028576]
 [28.35735 ]
 [58.178127]
 [34.110355]
 [82.50513 ]
 [66.03266 ]
 [16.620998]
 [37.60443 ]
 [29.493732]
 [11.666904]
 [43.43575 ]
 [37.65224 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [3.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  4.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3. 10. 15. 16.  3.] 
adversary owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.59086227416992



buy possibilites: [-1] 
expected returns: [[160.93787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3. 25.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3. 10. 15. 16.  3.] 
adversary owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   40    0    0    0    0 -160    0    0
  250    0] 
sum of rewards: 515 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 82.50508117675781






Player: 1 
cards in hand: [0. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3. 10. 15. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [10. 15. 15. 11. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3. 10. 15. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  2.  9.  1.] 
adversary cards in hand: [10. 15. 15. 11. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.  6.  3.  6.  0.  0.  3.  0.  0.  0.  6.  6.  8. 15.
  8.  6. 14. 16.  3. 10. 15. 16.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [10. 15. 15. 11. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
adversary victory points: 12
player victory points: -1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [10. 15. 15. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15. 11. 25.] 
expected returns: [[ 83.95956 ]
 [ 64.448204]
 [ 81.76694 ]
 [ 81.76694 ]
 [100.77419 ]
 [118.22702 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15. 11. 25.] 
cards in discard: [ 3. 25. 29. 15.  0.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3 10] -> size -> 33 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 160.9378662109375



action possibilites: [-1] 
expected returns: [[45.476498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15. 11. 11. 10.] 
cards in discard: [ 3. 25. 29. 15.  0.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3 10] -> size -> 33 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 118.22704315185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.877893]
 [43.596294]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 15. 11. 11. 10.] 
cards in discard: [ 3. 25. 29. 15.  0.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3 10] -> size -> 33 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.476497650146484






Player: 1 
cards in hand: [0. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6 16  6  6  6  3  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3
  0  0 15  0  0  0  3  3 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [ 0. 29.  0. 11. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
adversary victory points: 12
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [ 0. 29.  0. 11. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [ 0. 29.  0. 11. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.] 
expected returns: [[ 67.549446]
 [ 85.59913 ]
 [ 84.76213 ]
 [102.990295]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11. 25.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [14. 10.  0.  0.  0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10] -> size -> 31 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.59633255004883



action possibilites: [-1] 
expected returns: [[31.313816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11. 29.  0.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [14. 10.  0.  0.  0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10] -> size -> 31 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.99030303955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[12.840897]
 [30.550877]
 [27.80197 ]
 [45.64714 ]
 [24.62683 ]
 [21.877928]
 [30.973988]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 11. 29.  0.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  2.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [14. 10.  0.  0.  0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10] -> size -> 31 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.31381607055664



buy possibilites: [-1] 
expected returns: [[86.41736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 11. 29.  0.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [14. 10.  0.  0.  0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10] -> size -> 31 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  450    0    0   20    0    0    0    0 -170    0    0
   54    0] 
sum of rewards: 349 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.64714431762695






Player: 1 
cards in hand: [14. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  0.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [25.  3. 10. 25.  0.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  0.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 30. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [25.  3. 10. 25.  0.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
adversary victory points: 12
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  0.  0.] 
cards in discard: [8. 0. 0. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [25.  3. 10. 25.  0.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [25.  3. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
expected returns: [[ 5.514776 ]
 [35.076794 ]
 [-7.1714764]
 [35.076794 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 10. 25.  0.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10  1] -> size -> 32 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.4173583984375



action possibilites: [-1] 
expected returns: [[82.10138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25.  0.  3.  0.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10  1] -> size -> 32 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.076786041259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[44.29656 ]
 [70.30142 ]
 [64.58885 ]
 [82.101395]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 25.  0.  3.  0.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10  1] -> size -> 32 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.10137939453125






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  6 16  6  6  6  6  6 10  0 15 10 14  0  8  0  8  0  0  8  8  3  0  0
 15  0  0  0  3  3 10  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [11.  3. 10. 11. 15.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0
  0  3  3 10  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [11.  3. 10. 11. 15.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
adversary victory points: 12
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0
  0  3  3 10  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [11.  3. 10. 11. 15.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
adversary victory points: 12
player victory points: -4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [11.  3. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 15.] 
expected returns: [[17.133858]
 [37.246532]
 [11.210808]
 [37.246532]
 [21.016693]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 11. 15.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  1.] 
adversary cards in hand: [ 0. 16.  8. 16.  6.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0
  0  3  3 10  1] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.10137939453125



action possibilites: [-1] 
expected returns: [[-19.287523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 15.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 16.  8. 16.  6.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0
  0  3  3 10  1] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -180    0    0
   64    0] 
sum of rewards: 379 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.673187255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-29.242039]
 [-19.287523]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 15.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 16.  8. 16.  6.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.] 
adversary owned cards: [16  6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0
  0  3  3 10  1] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.28752326965332






Player: 1 
cards in hand: [ 0. 16.  8. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8. 16.  6.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0
  0  3  3 10  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [10.  3. 29.  0. 15.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0  0
  3  3 10  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [10.  3. 29.  0. 15.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0  0
  3  3 10  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [10.  3. 29.  0. 15.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0  0
  3  3 10  1  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [10.  3. 29.  0. 15.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [10.  3. 29.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15.] 
expected returns: [[24.42613 ]
 [11.604339]
 [28.948395]
 [20.848316]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  0. 15.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0. 10.  8.  6.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6.] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0  0
  3  3 10  1  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -19.28752326965332



action possibilites: [-1. 10. 15.] 
expected returns: [[20.500618]
 [ 6.049079]
 [15.838493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0. 10.  8.  6.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6.] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0  0
  3  3 10  1  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 17.569644927978516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.38147 ]
 [20.500618]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0. 10.  8.  6.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6.] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0  0
  3  3 10  1  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.50064468383789






Player: 1 
cards in hand: [15.  0. 10.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  8.  6.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  0  8  0  0  8  8  0  0 15  0  0  0
  3  3 10  1  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3.  3. 25. 10. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3.  3. 25. 10. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3.  3. 25. 10. 25.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
expected returns: [[ 93.70817 ]
 [127.782135]
 [ 82.685326]
 [127.782135]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25. 10. 25.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 6. 10.  3.  6.  3.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6. 15.
 10.  8.  6.] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.50064468383789



action possibilites: [-1] 
expected returns: [[52.54364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 25.  3.  3.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 6. 10.  3.  6.  3.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6. 15.
 10.  8.  6.] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 127.78215026855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.061205]
 [52.54366 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 25.  3.  3.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 6. 10.  3.  6.  3.] 
adversary cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6. 15.
 10.  8.  6.] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.54364013671875






Player: 1 
cards in hand: [ 6. 10.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  6.  3.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6. 15.
 10.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [11. 11. 11.  3. 29.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3. 25.  3.  3. 10. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6.  3. 15.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6. 15.
 10.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [11. 11. 11.  3. 29.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3. 25.  3.  3. 10. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 3.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6. 15.
 10.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [11. 11. 11.  3. 29.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3. 25.  3.  3. 10. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3.] 
cards in discard: [ 8.  0.  0.  1. 14. 10.  0.  0.  0.  8.  0.  0.  0. 16.  0.  8.  6. 15.
 10.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [11. 11. 11.  3. 29.] 
adversary cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3. 25.  3.  3. 10. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
adversary victory points: 12
player victory points: -4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [11. 11. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 29.] 
expected returns: [[21.66249 ]
 [31.743038]
 [31.743038]
 [31.743038]
 [32.399414]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  3. 29.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3. 25.  3.  3. 10. 25.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 10.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.54364013671875



action possibilites: [-1. 11. 11.] 
expected returns: [[ 6.4776382]
 [17.7137   ]
 [17.7137   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3. 25.  3.  3. 10. 25.  3.  3. 11. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 29. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 10.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.03900718688965



action possibilites: [-1] 
expected returns: [[42.266865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3. 25.  3.  3. 10. 25.  3.  3. 11. 15.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 10.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  480    0    0   40    0    0    0    0 -190    0    0
   27    0] 
sum of rewards: 352 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 4.335178375244141





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.350075]
 [42.26685 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [ 3. 25. 29. 15.  0.  3. 25. 10. 15. 15. 11. 11. 10. 11. 25.  0. 29.  0.
 11. 29.  0. 25.  3. 10. 25.  0.  3.  0. 15. 11.  3. 10. 11. 15.  0.  3.
 29. 10. 15.  3. 25.  3.  3. 10. 25.  3.  3. 11. 15.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 10.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.26686477661133






Player: 1 
cards in hand: [ 0. 10.  8.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  6.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 16  6  6  6  6  6 10 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3
  3 10  1  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25.  3. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25.  3. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25.  3. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [25.  3. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[ 74.00721]
 [107.98259]
 [ 92.00467]
 [ 98.33527]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [3. 6. 0. 8. 8.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.26686477661133



action possibilites: [-1] 
expected returns: [[74.310585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 29. 11. 15.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [3. 6. 0. 8. 8.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.98255920410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[53.737522]
 [73.65436 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 29. 11. 15.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [3. 6. 0. 8. 8.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.31058502197266






Player: 1 
cards in hand: [3. 6. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 8. 8.] 
cards in discard: [8. 0. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25. 15. 15. 11.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 8. 8.] 
cards in discard: [8. 0. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25. 15. 15. 11.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [25. 15. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 15. 11.] 
expected returns: [[10.543004]
 [37.9404  ]
 [10.084234]
 [10.084234]
 [22.793379]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 15. 11.  3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 1. 10. 16.  8.  0.] 
adversary cards in discard: [8. 0. 6. 3. 6. 0. 8. 8.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.65433502197266



action possibilites: [-1] 
expected returns: [[167.22816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11.  3. 29.  3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 1. 10. 16.  8.  0.] 
adversary cards in discard: [8. 0. 6. 3. 6. 0. 8. 8.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.94042205810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[120.45539]
 [164.20155]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 11.  3. 29.  3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 1. 10. 16.  8.  0.] 
adversary cards in discard: [8. 0. 6. 3. 6. 0. 8. 8.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.22816467285156






Player: 1 
cards in hand: [ 1. 10. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 16.  8.  0.] 
cards in discard: [8. 0. 6. 3. 6. 0. 8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6  6 15 10 14  8  8  0  0  8  8  0  0 15  0  0  0  3  3 10
  1  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  4.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15. 25. 29.  0.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.] 
cards in discard: [8. 0. 6. 3. 6. 0. 8. 8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15. 25. 29.  0.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [8. 0. 6. 3. 6. 0. 8. 8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15. 25. 29.  0.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [8. 0. 6. 3. 6. 0. 8. 8. 8. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15. 25. 29.  0.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [15. 25. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 29.] 
expected returns: [[12.514748]
 [11.668183]
 [34.21894 ]
 [21.982624]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 29.  0.  3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 6. 10.  6. 15.  3.] 
adversary cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1] -> size -> 28 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 164.2015380859375



action possibilites: [-1] 
expected returns: [[65.82419]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  0.  3. 10. 29.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 6. 10.  6. 15.  3.] 
adversary cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1] -> size -> 28 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.21895980834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.044456]
 [65.82419 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  0.  3. 10. 29.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 6. 10.  6. 15.  3.] 
adversary cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1] -> size -> 28 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.82418823242188






Player: 1 
cards in hand: [ 6. 10.  6. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6. 15.  3.] 
cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3. 10.  3.  3.  1.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  3.] 
cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3. 10.  3.  3.  1.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  3.] 
cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3. 10.  3.  3.  1.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  3.] 
cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3. 10.  3.  3.  1.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[ -7.6474953]
 [-14.072926 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.  1.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0.  6. 15.  0.  0.] 
adversary cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.  0. 15.  6. 10.
  6.  3.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1  0] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.82418823242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-17.597336 ]
 [ -9.821889 ]
 [-10.506021 ]
 [ -7.6474953]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  3.  1.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0.  6. 15.  0.  0.] 
adversary cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.  0. 15.  6. 10.
  6.  3.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1  0] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -7.6475114822387695



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  6. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  0.  0.] 
cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.  0. 15.  6. 10.
  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  0  8  8  0  0 15  0  0  0  3  3 10  1
  0  0  8  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25. 15.  0. 10.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.  0. 15.  6. 10.
  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25. 15.  0. 10.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.  0. 15.  6. 10.
  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  5.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25. 15.  0. 10.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  6.  3.  6.  0.  8.  8.  8.  1. 16.  1. 10.  0.  0. 15.  6. 10.
  6.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [25. 15.  0. 10.  3.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [25. 15.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 10.] 
expected returns: [[41.135666]
 [58.284264]
 [36.28581 ]
 [25.578705]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  0. 10.  3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -7.6475114822387695



action possibilites: [-1] 
expected returns: [[53.49136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  3. 25. 10.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.28422164916992





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.288021]
 [53.491383]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.  3. 25. 10.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.49135971069336






Player: 1 
cards in hand: [15.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
adversary victory points: 12
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[ 3.670872 ]
 [11.033335 ]
 [ 2.0885317]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3. 10.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3
  3 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3
 15 15 25 11 15  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [16. 10.  6. 10.  8.] 
adversary cards in discard: [15.  0.  0.  0. 14.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 53.49135971069336



action possibilites: [-1] 
expected returns: [[37.04427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [16. 10.  6. 10.  8.] 
adversary cards in discard: [15.  0.  0.  0. 14.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 11.033329963684082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. -1.] 
expected returns: [[ 9.076325]
 [35.136883]
 [31.906464]
 [19.933716]
 [51.95843 ]
 [27.300003]
 [53.048298]
 [10.74015 ]
 [24.069584]
 [37.044296]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  4.  8. 10.  1.  9.  0.] 
adversary cards in hand: [16. 10.  6. 10.  8.] 
adversary cards in discard: [15.  0.  0.  0. 14.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.04426956176758



buy possibilites: [-1] 
expected returns: [[39.76174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [16. 10.  6. 10.  8.] 
adversary cards in discard: [15.  0.  0.  0. 14.] 
adversary owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
adversary victory points: -3
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  450    0    0   20    0    0    0    0 -190    0    0
  128    0] 
sum of rewards: 403 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.048282623291016






Player: 1 
cards in hand: [16. 10.  6. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  6. 10.  8.] 
cards in discard: [15.  0.  0.  0. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 29. 11. 11. 11.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1. 16. 10.  8. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 10.  8. 29.] 
cards in discard: [15.  0.  0.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  6  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0
  0  8  1  0 29] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 29. 11. 11. 11.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
adversary victory points: 12
player victory points: -3 


action possibilites: [-1. 10.  8. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.] 
cards in discard: [15.  0.  0.  0. 14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 29. 11. 11. 11.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
adversary victory points: 12
player victory points: -2 


action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  1.] 
cards in discard: [15.  0.  0.  0. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 16. 10.] 
owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 29. 11. 11. 11.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
adversary victory points: 12
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  1.] 
cards in discard: [15.  0.  0.  0. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 16. 10.] 
owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 13. 30.  8.  0.  8.  1.  3.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 29. 11. 11. 11.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
adversary victory points: 12
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  1.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 16. 10.] 
owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0. 29. 11. 11. 11.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
adversary victory points: 12
player victory points: -2 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 11.] 
expected returns: [[-1.5531969]
 [12.315119 ]
 [ 9.5426655]
 [ 9.5426655]
 [ 9.5426655]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 11. 11.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [6. 8. 8. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.] 
adversary owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0  8] -> size -> 30 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.761741638183594



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[15.183361]
 [28.181786]
 [28.181786]
 [28.181786]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [6. 8. 8. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.] 
adversary owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0  8] -> size -> 30 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.087475061416626



action possibilites: [-1] 
expected returns: [[0.5620668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [6. 8. 8. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.] 
adversary owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0  8] -> size -> 30 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  420    0    0   40    0    0    0    0 -200    0    0
   27    0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 20.230743408203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.460919  ]
 [  0.56206584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [6. 8. 8. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.] 
adversary owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0  8] -> size -> 30 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.5620667934417725






Player: 1 
cards in hand: [6. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 0. 0.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6  6 15 10 14  8  0  8  8  0  0 15  0  0  0  3  3 10  1  0  0
  8  1  0 29  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3. 11. 11. 15.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1] -> size -> 55 
adversary victory points: 12
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  6 15 10 14  8  8  0  0 15  0  0  0  3  3 10  1  0  0  8  1  0
 29  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3. 11. 11. 15.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1] -> size -> 55 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  6 15 10 14  8  8  0  0 15  0  0  0  3  3 10  1  0  0  8  1  0
 29  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3. 11. 11. 15.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1] -> size -> 55 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  6 15 10 14  8  8  0  0 15  0  0  0  3  3 10  1  0  0  8  1  0
 29  0  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 26. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3. 11. 11. 15.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1] -> size -> 55 
adversary victory points: 12
player victory points: -1 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[ 7.275381]
 [18.241375]
 [18.241375]
 [ 7.106142]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 15.  0.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8  0  0 15  0  0  0  3  3 10  1  0  0  8  1  0
 29  0  8  0] -> size -> 28 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.5620667934417725



action possibilites: [-1] 
expected returns: [[99.9628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.  0.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8  0  0 15  0  0  0  3  3 10  1  0  0  8  1  0
 29  0  8  0] -> size -> 28 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -210    0    0
   27    0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 4.601487159729004





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[74.27721 ]
 [99.962814]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 15.  0.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8  0  0 15  0  0  0  3  3 10  1  0  0  8  1  0
 29  0  8  0] -> size -> 28 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.96279907226562






Player: 1 
cards in hand: [0. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0. 0.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6 15 10 14  8  8  0  0 15  0  0  0  3  3 10  1  0  0  8  1  0
 29  0  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [11. 10.  3.  3. 25.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.  1. 11.  3. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [11. 10.  3.  3. 25.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.  1. 11.  3. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [11. 10.  3.  3. 25.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.  1. 11.  3. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [11. 10.  3.  3. 25.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.  1. 11.  3. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [11. 10.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
expected returns: [[36.8549  ]
 [43.556698]
 [21.3418  ]
 [51.650166]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3. 25.] 
cards in discard: [25.  3. 11.  0. 29. 11. 15. 25. 15. 15. 11.  3. 29.  3. 25. 15. 29.  0.
  3. 10. 29.  3. 10.  3.  3.  1. 25. 15.  0. 10.  3. 25. 10. 29. 15.  0.
  3. 10.  0. 25.  1. 29. 11. 11. 11.  1. 11.  3. 11. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [0. 6. 6. 3. 6.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.  0.  8.
  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.96279907226562



action possibilites: [-1] 
expected returns: [[118.25292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [0. 6. 6. 3. 6.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.  0.  8.
  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 51.65017318725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 78.961975]
 [113.90851 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [0. 6. 6. 3. 6.] 
adversary cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.  0.  8.
  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.25292205810547






Player: 1 
cards in hand: [0. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 6.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.  0.  8.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15. 25. 29. 11. 15.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 6.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.  0.  8.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15. 25. 29. 11. 15.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 6.] 
cards in discard: [15.  0.  0.  0. 14.  0.  8. 10. 16. 10.  8. 29.  1.  0.  8.  0.  0.  8.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15. 25. 29. 11. 15.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [15. 25. 29. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 29. 11. 15.] 
expected returns: [[ 73.42763 ]
 [ 74.82167 ]
 [130.07326 ]
 [102.64417 ]
 [ 96.643845]
 [ 74.82167 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 29. 11. 15.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.90852355957031



action possibilites: [-1] 
expected returns: [[2.4389455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 11. 15. 10.  0.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 130.0732879638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-23.635468 ]
 [ -0.5744989]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29. 11. 15. 10.  0.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.4389455318450928






Player: 1 
cards in hand: [15.  0.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3.  3. 29.  1. 10.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 3.  3. 29.  1. 10.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[56.704967]
 [63.196636]
 [32.015186]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  1. 10.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0.  0.  3. 10.  1.] 
adversary cards in discard: [15.  0.  6.  3. 15.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.5745298862457275



action possibilites: [-1. 10.] 
expected returns: [[82.73455 ]
 [59.368332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0.  0.  3. 10.  1.] 
adversary cards in discard: [15.  0.  6.  3. 15.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.334754943847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[33.014297]
 [82.73455 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [ 0.  0.  3. 10.  1.] 
adversary cards in discard: [15.  0.  6.  3. 15.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.73454284667969






Player: 1 
cards in hand: [ 0.  0.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  1.] 
cards in discard: [15.  0.  6.  3. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  3. 11.  1.  0.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15. 29.  3.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [15.  0.  6.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  3. 11.  1.  0.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15. 29.  3.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [15.  0.  6.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  9.  0.] 
adversary cards in hand: [15.  3. 11.  1.  0.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15. 29.  3.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [15.  0.  6.  3. 15. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0 22] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  8.  0.] 
adversary cards in hand: [15.  3. 11.  1.  0.] 
adversary cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15. 29.  3.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
adversary victory points: 12
player victory points: -1 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [15.  3. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[73.445885]
 [73.90008 ]
 [92.42244 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11.  1.  0.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15. 29.  3.
  3. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  8.  0.] 
adversary cards in hand: [ 0. 14.  0. 29. 16.] 
adversary cards in discard: [15.  0.  6.  3. 15. 22. 10.  0.  0.  3.  1.  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0 22] -> size -> 28 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.73454284667969



action possibilites: [-1] 
expected returns: [[71.79108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  1.  0.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15. 29.  3.
  3. 10.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  8.  0.] 
adversary cards in hand: [ 0. 14.  0. 29. 16.] 
adversary cards in discard: [15.  0.  6.  3. 15. 22. 10.  0.  0.  3.  1.  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0 22] -> size -> 28 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 69.841552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[41.11974 ]
 [66.48579 ]
 [65.04436 ]
 [82.78744 ]
 [60.71783 ]
 [58.318928]
 [71.79111 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  0.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15. 29.  3.
  3. 10.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 24. 30. 13. 30.  8.  0.  8.  1.  2.  3.  3.  8. 10.  1.  8.  0.] 
adversary cards in hand: [ 0. 14.  0. 29. 16.] 
adversary cards in discard: [15.  0.  6.  3. 15. 22. 10.  0.  0.  3.  1.  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0 22] -> size -> 28 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.79107666015625



Player 0 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 0 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 10 
Chapel: 0 
Witch: 7 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  3.  1.  0.] 
cards in discard: [25. 11. 10.  3.  3. 10.  0. 25. 15. 29. 11. 15. 10.  0.  1. 15. 29.  3.
  3. 10.  1. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 29 10 11 25 10 29 25 10  0 25 25  3  3
 25 11 10  3 29 10  3  3 25  0 11 11  3 15 11 15  3  3 15 11 11 15  3 15
 15 25 11 15  1 29  1  1  1 11] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 13. 30.  8.  0.  8.  0.  2.  3.  3.  8. 10.  1.  8.  0.] 
adversary cards in hand: [ 0. 14.  0. 29. 16.] 
adversary cards in discard: [15.  0.  6.  3. 15. 22. 10.  0.  0.  3.  1.  0.] 
adversary owned cards: [16  6  6  6 15 10 14  8  8 15  0  0  0  3  3 10  0  0  8  1  0 29  0  8
  0  0  0 22] -> size -> 28 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[     -5 3000000       0     390       0       0      20       0       0
       0       0    -230       0       0      27       0] 
sum of rewards: 3000202 

action type: buy - action 11.0
Learning step: 300011.9375
desired expected reward: 300094.71875



