 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.558088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -450        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000455 

action type: buy - action -1.0
Learning step: -120009.8359375
desired expected reward: -120218.7265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 25.706812 ]
 [ 44.167667 ]
 [ 37.027466 ]
 [-44.67014  ]
 [ 44.57418  ]
 [ 43.814587 ]
 [ 31.996683 ]
 [ 52.400208 ]
 [  1.1094766]
 [ 37.924282 ]
 [ 31.950747 ]
 [ 30.855345 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.36890983581543



buy possibilites: [-1] 
expected returns: [[42.394485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 52.400211334228516






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.721601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.39448547363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 14.476336]
 [ 33.12855 ]
 [ 26.37699 ]
 [-58.90346 ]
 [ 33.960636]
 [ 21.576965]
 [ 28.561247]
 [ 19.031904]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.5242977142334



buy possibilites: [-1] 
expected returns: [[27.818819]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 33.960628509521484






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 7.083055]
 [27.26581 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.818819046020508



action possibilites: [-1.] 
expected returns: [[15.592403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.114309310913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 12.25654 ]
 [ 28.826025]
 [ 20.948599]
 [-56.015755]
 [ 28.523272]
 [ 27.174776]
 [ 17.972176]
 [ 35.3672  ]
 [-11.7481  ]
 [ 21.440449]
 [ 13.540869]
 [ 16.497154]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.592403411865234



buy possibilites: [-1] 
expected returns: [[20.82541]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 35.36720275878906






Player: 1 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.139742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.825410842895508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 32.400707 ]
 [ 50.100994 ]
 [ 44.999977 ]
 [-25.018162 ]
 [ 52.776165 ]
 [ 52.161354 ]
 [ 39.050137 ]
 [ 59.740135 ]
 [ 11.6789055]
 [ 47.04845  ]
 [ 38.942955 ]
 [ 34.553383 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.684722900390625



buy possibilites: [-1] 
expected returns: [[24.847677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 59.740150451660156






Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[34.612556]
 [49.157192]
 [49.157192]
 [40.579796]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.84767723083496



action possibilites: [-1. 29. 11.] 
expected returns: [[36.091305]
 [56.02413 ]
 [46.960987]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.71501541137695



action possibilites: [-1. 11.] 
expected returns: [[48.19438 ]
 [59.786964]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.02414321899414



action possibilites: [-1] 
expected returns: [[44.443775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 65.98872375488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.707115 ]
 [59.513527 ]
 [51.067947 ]
 [27.211744 ]
 [ 1.1220384]
 [60.34987  ]
 [58.101612 ]
 [49.975376 ]
 [69.86261  ]
 [65.73644  ]
 [19.24394  ]
 [52.826054 ]
 [52.91333  ]
 [32.798588 ]
 [43.76092  ]
 [46.683155 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.44377517700195



buy possibilites: [-1] 
expected returns: [[67.257706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 69.86260986328125






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [11. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [11. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [11. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[13.552567]
 [31.112299]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [11. 25. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.25770568847656



action possibilites: [-1.] 
expected returns: [[27.2301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 25. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.240995407104492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 24.639442 ]
 [ 41.517735 ]
 [ 33.398148 ]
 [  9.488604 ]
 [-30.482075 ]
 [ 40.634216 ]
 [ 39.398582 ]
 [ 30.43149  ]
 [ 49.732124 ]
 [ 47.35078  ]
 [  1.4464235]
 [ 35.601536 ]
 [ 34.11726  ]
 [ 14.648071 ]
 [ 27.225847 ]
 [ 28.02904  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 25. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.230100631713867



buy possibilites: [-1] 
expected returns: [[27.833078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 25. 29. 29. 11.  3.  0.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 49.73215103149414






Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  8.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29. 29.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[39.61018 ]
 [57.003326]
 [57.003326]
 [49.76641 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  8.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 1. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.833078384399414



action possibilites: [-1. 29. 11. 25.] 
expected returns: [[48.11939 ]
 [65.64827 ]
 [58.485565]
 [70.013275]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  8.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 1. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.464202880859375



action possibilites: [-1] 
expected returns: [[50.624016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  8.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 1. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.0132827758789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 47.469566]
 [ 65.94618 ]
 [ 57.799255]
 [-24.711287]
 [ 66.96294 ]
 [ 65.79051 ]
 [ 54.444542]
 [ 73.19492 ]
 [ 21.820095]
 [ 59.404274]
 [ 49.11133 ]
 [ 51.51525 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  8.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 1. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.62401580810547



buy possibilites: [-1] 
expected returns: [[57.58326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  3.  0.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 1. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.19491577148438






Player: 1 
cards in hand: [3. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [11. 25.  3. 29.  0.] 
adversary cards in discard: [29. 29. 25. 29.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  9.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [11. 25.  3. 29.  0.] 
adversary cards in discard: [29. 29. 25. 29.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 8.] 
cards in discard: [6. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  8.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [11. 25.  3. 29.  0.] 
adversary cards in discard: [29. 29. 25. 29.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11. 25.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[35.83139 ]
 [52.17521 ]
 [61.642426]
 [56.000015]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3. 29.  0.] 
cards in discard: [29. 29. 25. 29.  0. 11.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7.  8.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 22.] 
adversary cards in discard: [6. 8. 3. 1. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.58325958251953



action possibilites: [-1] 
expected returns: [[24.053879]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  0.  0.  3.] 
cards in discard: [29. 29. 25. 29.  0. 11.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8. 10.  7.  8.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 22.] 
adversary cards in discard: [6. 8. 3. 1. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.43858337402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 23.916412]
 [ 32.13116 ]
 [-10.187203]
 [ 27.961267]
 [ 26.800161]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29.  0.  0.  3.] 
cards in discard: [29. 29. 25. 29.  0. 11.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8. 10.  7.  8.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 22.] 
adversary cards in discard: [6. 8. 3. 1. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.053878784179688



buy possibilites: [-1] 
expected returns: [[34.463696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29.  0.  0.  3.] 
cards in discard: [29. 29. 25. 29.  0. 11.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  8.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 22.] 
adversary cards in discard: [6. 8. 3. 1. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 32.13117980957031






Player: 1 
cards in hand: [ 0.  3.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 22.] 
cards in discard: [6. 8. 3. 1. 0. 0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  8.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0.  0.  3. 11.] 
cards in discard: [6. 8. 3. 1. 0. 0. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  8.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  0.  3. 11.] 
cards in discard: [6. 8. 3. 1. 0. 0. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  8.  8.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  0.  3. 11.] 
cards in discard: [ 6.  8.  3.  1.  0.  0.  8.  6. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  8.  8.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[21.113916]
 [39.584927]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  8.  8.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.46369552612305



action possibilites: [-1. 29.] 
expected returns: [[38.140694]
 [55.320393]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  8.  8.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.86808395385742



action possibilites: [-1. 25.] 
expected returns: [[45.8237  ]
 [66.874664]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  7.  8.  8.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 55.320377349853516



action possibilites: [-1] 
expected returns: [[51.16362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  8.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 66.87464904785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[47.272038 ]
 [61.91784  ]
 [53.432404 ]
 [32.444736 ]
 [-4.3733654]
 [62.75524  ]
 [59.721275 ]
 [53.37267  ]
 [71.32918  ]
 [67.96835  ]
 [24.926413 ]
 [55.535076 ]
 [55.1626   ]
 [37.262062 ]
 [47.18674  ]
 [51.16801  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  8.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.16361999511719



buy possibilites: [-1] 
expected returns: [[72.40797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 395 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 71.32919311523438






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [25. 29. 29. 25.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25] -> size -> 20 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [25. 29. 29. 25.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25] -> size -> 20 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 6. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [25. 29. 29. 25.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25] -> size -> 20 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[63.093445]
 [76.86318 ]
 [71.192856]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 11.] 
cards in discard: [25. 29. 29. 25.  3.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  1. 22.  3.  6.] 
adversary cards in discard: [ 6. 10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.40796661376953



action possibilites: [-1. 11.] 
expected returns: [[42.61789 ]
 [52.675804]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [25. 29. 29. 25.  3.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  1. 22.  3.  6.] 
adversary cards in discard: [ 6. 10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 75.63796997070312



action possibilites: [-1] 
expected returns: [[45.583626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 29. 29. 25.  3.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  1. 22.  3.  6.] 
adversary cards in discard: [ 6. 10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.01210021972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[41.84514 ]
 [56.137005]
 [49.76352 ]
 [ 5.640908]
 [58.043026]
 [56.160793]
 [47.197266]
 [62.41616 ]
 [21.019447]
 [51.080433]
 [42.275463]
 [46.241585]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 29. 29. 25.  3.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  1. 22.  3.  6.] 
adversary cards in discard: [ 6. 10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.58362579345703



buy possibilites: [-1] 
expected returns: [[57.24723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 29. 29. 25.  3.  3.  0.  0.  3.  0. 10. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  1. 22.  3.  6.] 
adversary cards in discard: [ 6. 10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.416175842285156






Player: 1 
cards in hand: [ 0.  1. 22.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 22.  3.  6.] 
cards in discard: [ 6. 10.  8.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 6. 8. 6. 0.] 
cards in discard: [ 6. 10.  8.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [22. 11. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 8. 6. 0.] 
cards in discard: [ 6. 10.  8.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [22. 11. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 29. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 11.] 
expected returns: [[29.946272]
 [45.964626]
 [45.964626]
 [49.530754]
 [39.703712]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 11.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.247230529785156



action possibilites: [-1] 
expected returns: [[41.460976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.497291564941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.087574]
 [53.83937 ]
 [46.63005 ]
 [ 7.649548]
 [50.131176]
 [44.67472 ]
 [45.99691 ]
 [42.23905 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  6. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.460975646972656



buy possibilites: [-1] 
expected returns: [[12.539181]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 11.  0.  0.  0.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 53.839378356933594






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 25. 25.] 
adversary cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1] -> size -> 23 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  7.  8.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 25. 25.] 
adversary cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1] -> size -> 23 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 25. 25.] 
adversary cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1] -> size -> 23 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[10.746901]
 [29.281317]
 [29.281317]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25. 25.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 11.  0.  1.  0.] 
adversary cards in discard: [6. 8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.539180755615234



action possibilites: [-1] 
expected returns: [[-4.7943463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25. 11. 29.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 11.  0.  1.  0.] 
adversary cards in discard: [6. 8. 0. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 28.82195472717285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-10.687548]
 [ -3.126792]
 [-47.217915]
 [ -5.16951 ]
 [ -5.292501]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 25. 11. 29.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 11.  0.  1.  0.] 
adversary cards in discard: [6. 8. 0. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.794346332550049



buy possibilites: [-1] 
expected returns: [[61.97503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 25. 11. 29.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 11.  0.  1.  0.] 
adversary cards in discard: [6. 8. 0. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6] -> size -> 23 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -3.1267950534820557






Player: 1 
cards in hand: [ 8. 11.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  1.  0.] 
cards in discard: [6. 8. 0. 3. 0. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.] 
cards in discard: [6. 8. 0. 3. 0. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [6. 8. 0. 3. 0. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [6. 8. 0. 3. 0. 3. 0. 6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
adversary victory points: 5
player victory points: -1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 98.95734]
 [117.26732]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 29.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 29. 22.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.97502899169922



action possibilites: [-1. 29.] 
expected returns: [[68.20622]
 [84.78659]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 29.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 29. 22.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 117.267333984375



action possibilites: [-1.] 
expected returns: [[77.59345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 29. 22.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.78659057617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[72.6007  ]
 [88.31143 ]
 [84.88831 ]
 [42.350517]
 [88.94759 ]
 [89.565155]
 [77.01406 ]
 [96.399055]
 [57.985622]
 [84.7432  ]
 [82.3477  ]
 [77.874214]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  4. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 29. 22.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.59345245361328



buy possibilites: [-1] 
expected returns: [[87.631226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 1. 25. 29. 29. 11.  0.  0.  0.  3. 25.  3.  0.  0. 25. 11. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 29. 22.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 343 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 96.39909362792969






Player: 1 
cards in hand: [ 6.  6. 10. 29. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10. 29. 22.] 
cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 25. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29] -> size -> 25 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10. 29.  0.  0.  6.] 
cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 25. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29] -> size -> 25 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10. 29.  0.  0.  6.] 
cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  7.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 25. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29] -> size -> 25 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10. 29.  0.  0.  6.] 
cards in discard: [ 6.  8.  0.  3.  0.  3.  0.  6.  3.  8. 11.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 25. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29] -> size -> 25 
adversary victory points: 5
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[ 2.3448215]
 [18.506233 ]
 [ 8.090807 ]
 [ 4.3841996]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  8.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3  8] -> size -> 24 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.6312255859375



action possibilites: [-1] 
expected returns: [[31.745249]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  8.  6.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.499500274658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 24.516562]
 [ 41.996082]
 [ 34.728096]
 [-36.87984 ]
 [ 37.478973]
 [ 28.402391]
 [ 31.99586 ]
 [ 26.268732]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  8.  6.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.745248794555664



buy possibilites: [-1] 
expected returns: [[21.79119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.  3.  0.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  8.  6.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 41.99606704711914






Player: 1 
cards in hand: [11.  8.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6.  8.  3.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  0 11 22  6  8  6 29  6 10  6  8  6  3  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[17.359335]
 [30.149973]
 [30.149973]
 [30.149973]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0. 29.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  8.  6.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6] -> size -> 22 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.791189193725586



action possibilites: [-1. 29. 29. 11.] 
expected returns: [[25.776985]
 [40.13536 ]
 [40.13536 ]
 [29.60261 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 29. 11.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  8.  6.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6] -> size -> 22 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.994985580444336



action possibilites: [-1. 29. 11. 25.] 
expected returns: [[27.36733 ]
 [42.654045]
 [32.605858]
 [46.068207]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 11. 25.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8.  4. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  8.  6.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6] -> size -> 22 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.13536071777344



action possibilites: [-1] 
expected returns: [[57.915684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 11.  3.  3.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  8.  6.] 
adversary cards in discard: [6. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6] -> size -> 23 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.068206787109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[56.014908 ]
 [68.416336 ]
 [65.4003   ]
 [-3.4566276]
 [70.08009  ]
 [59.424866 ]
 [65.773865 ]
 [58.65827  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 11.  3.  3.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  7.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  8.  6.] 
adversary cards in discard: [6. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6] -> size -> 23 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.91568374633789



buy possibilites: [-1] 
expected returns: [[29.657785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 11.  3.  3.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  8.  6.] 
adversary cards in discard: [6. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6] -> size -> 23 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 349 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 70.08009338378906






Player: 1 
cards in hand: [29.  0.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  8.  6.] 
cards in discard: [6. 8. 6. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [25. 29.  3. 29.  0.] 
adversary cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0. 11. 29. 29. 25.  3.  0. 29. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  8.  6.] 
cards in discard: [6. 8. 6. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [25. 29.  3. 29.  0.] 
adversary cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0. 11. 29. 29. 25.  3.  0. 29. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
adversary victory points: 5
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25. 29.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[ 99.24537]
 [114.42713]
 [113.63781]
 [113.63781]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3. 29.  0.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0. 11. 29. 29. 25.  3.  0. 29. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 6. 22.  0. 10.  6.] 
adversary cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.657785415649414



action possibilites: [-1] 
expected returns: [[40.731953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0. 29.  0.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0. 11. 29. 29. 25.  3.  0. 29. 11.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 6. 22.  0. 10.  6.] 
adversary cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 114.42713928222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 25.672548]
 [ 30.327559]
 [-56.988354]
 [ 42.068626]
 [ 42.780888]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29.  0. 29.  0.] 
cards in discard: [ 1. 25.  0. 11.  0. 10.  3.  0. 11. 29. 29. 25.  3.  0. 29. 11.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 6. 22.  0. 10.  6.] 
adversary cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.73195266723633






Player: 1 
cards in hand: [ 6. 22.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  0. 10.  6.] 
cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  3.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  0. 10.  6.] 
cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  3.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
adversary victory points: 5
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  0. 10.  6.] 
cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  3.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
adversary victory points: 5
player victory points: -5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 8.076023]
 [13.54204 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  1.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  8.  9. 10.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.  0.  6. 22.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.780887603759766



action possibilites: [-1] 
expected returns: [[-8.044182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.  0.  6. 22.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 342 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 16.420076370239258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-12.946001 ]
 [ -0.2504115]
 [ -6.7959495]
 [-53.73605  ]
 [ -0.801445 ]
 [ -7.3460507]
 [ -4.2619295]
 [ -6.61012  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.  0.  6. 22.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.044181823730469



buy possibilites: [-1] 
expected returns: [[-10.23559]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [10.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.  0.  6. 22.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.25041627883911133






Player: 1 
cards in hand: [1. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.  0.  6. 22.  0. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11. 29. 10.  3.] 
adversary cards in discard: [10.  1. 11.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1] -> size -> 29 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [ 6.  8.  6.  6. 29.  0.  0.  8.  6.  6.  0.  6. 22.  0. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11. 29. 10.  3.] 
adversary cards in discard: [10.  1. 11.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1] -> size -> 29 
adversary victory points: 5
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[ 5.817079]
 [14.251364]
 [25.302399]
 [12.398245]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 10.  3.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.235589981079102



action possibilites: [-1. 11. 10. 25.] 
expected returns: [[ 3.4007802]
 [10.610125 ]
 [ 6.566713 ]
 [19.399168 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3. 25.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.302425384521484



action possibilites: [-1] 
expected returns: [[28.47338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  0.  3.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  1. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6] -> size -> 26 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.399179458618164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 20.53797 ]
 [ 34.57613 ]
 [ 26.784643]
 [-16.3071  ]
 [ 32.514996]
 [ 26.257107]
 [ 28.753916]
 [ 27.68727 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  3.  0.  3.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 27. 30.  8.  1. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6] -> size -> 26 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.473379135131836



buy possibilites: [-1] 
expected returns: [[25.232233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  3.  0.  3.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  1. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6] -> size -> 26 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 389 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 34.57613754272461






Player: 1 
cards in hand: [6. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  1. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 1. 25. 25. 29. 29.] 
adversary cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1] -> size -> 30 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 27. 30.  8.  1. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 1. 25. 25. 29. 29.] 
adversary cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1] -> size -> 30 
adversary victory points: 5
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 1. 25. 25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 29.] 
expected returns: [[-56.708027]
 [-39.126152]
 [-39.126152]
 [-35.278774]
 [-35.278774]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 29. 29.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  1. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  8. 22.  1.  6.] 
adversary cards in discard: [6. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6] -> size -> 26 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.23223304748535



action possibilites: [-1. 25. 25. 29. 29.] 
expected returns: [[-6.435239]
 [27.018373]
 [27.018373]
 [22.910557]
 [22.910557]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 29. 29.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 27. 30.  8.  1. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  8. 22.  1.  6.] 
adversary cards in discard: [6. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6] -> size -> 26 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -35.27874755859375



action possibilites: [-1] 
expected returns: [[21.881227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 29. 29. 29. 11.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  8. 22.  1.  6.] 
adversary cards in discard: [6. 6. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6] -> size -> 27 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.01841163635254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 8.176775]
 [25.492989]
 [18.133059]
 [33.975044]
 [22.192598]
 [29.686533]
 [25.670197]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 29. 29. 29. 11.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  6.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  8. 22.  1.  6.] 
adversary cards in discard: [6. 6. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6] -> size -> 27 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.881227493286133



buy possibilites: [-1] 
expected returns: [[37.440132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 29. 29. 29. 11.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  8. 22.  1.  6.] 
adversary cards in discard: [6. 6. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6] -> size -> 27 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 419 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 33.97502899169922






Player: 1 
cards in hand: [ 0.  8. 22.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 22.  1.  6.] 
cards in discard: [6. 6. 0. 6. 3. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3. 11. 29.
 25.  1. 25. 29. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11] -> size -> 31 
adversary victory points: 5
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 6. 6. 0. 3.] 
cards in discard: [6. 6. 0. 6. 3. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3. 11. 29.
 25.  1. 25. 29. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11] -> size -> 31 
adversary victory points: 5
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 6. 6. 0. 3.] 
cards in discard: [6. 6. 0. 6. 3. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  3. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3. 11. 29.
 25.  1. 25. 29. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11] -> size -> 31 
adversary victory points: 5
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 6. 6. 0. 3.] 
cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  3. 10. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3. 11. 29.
 25.  1. 25. 29. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11] -> size -> 31 
adversary victory points: 5
player victory points: -7 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[42.89748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3. 11. 29.
 25.  1. 25. 29. 29. 29. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  3. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  6.  8.  6.  0.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.44013214111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.105894]
 [49.28623 ]
 [39.52219 ]
 [54.16337 ]
 [48.86183 ]
 [39.735832]
 [60.602165]
 [ 3.45927 ]
 [43.53782 ]
 [31.583578]
 [40.767586]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3. 11. 29.
 25.  1. 25. 29. 29. 29. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  3. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  6.  8.  6.  0.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.89748001098633



buy possibilites: [-1] 
expected returns: [[3.9759421]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  1. 11.  3.  3.  1.  0.  1. 29. 25.  0. 11. 10.  3.  0.  3. 11. 29.
 25.  1. 25. 29. 29. 29. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  2. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  6.  8.  6.  0.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 483 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 60.602134704589844






Player: 1 
cards in hand: [29.  6.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  8.  6.  0.] 
cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  2. 10. 10.  7.  9.  9.] 
adversary cards in hand: [25. 29.  1. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29] -> size -> 32 
adversary victory points: 5
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  8.  6.  0.] 
cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  2. 10. 10.  7.  9.  9.] 
adversary cards in hand: [25. 29.  1. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29] -> size -> 32 
adversary victory points: 5
player victory points: -7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [25. 29.  1. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11. 29.] 
expected returns: [[-28.583952]
 [-11.092785]
 [-10.068785]
 [-15.749647]
 [-10.068785]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1. 11. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  2. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.9759421348571777



action possibilites: [-1. 25. 11. 29.] 
expected returns: [[-12.579273 ]
 [ -2.6894398]
 [ -9.601554 ]
 [  1.8913136]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29.  0.] 
cards in discard: [1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  2. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.72077178955078



action possibilites: [-1. 25. 11.] 
expected returns: [[48.297516]
 [66.58914 ]
 [55.848255]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.] 
cards in discard: [1. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  2. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.418336868286133



action possibilites: [-1] 
expected returns: [[31.337893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.] 
cards in discard: [1. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  2. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 66.58912658691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.933723]
 [34.65929 ]
 [23.518305]
 [43.549698]
 [39.599213]
 [32.53405 ]
 [47.569836]
 [-9.073084]
 [36.696175]
 [19.430416]
 [33.02203 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  0.] 
cards in discard: [1. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  2. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.337892532348633



buy possibilites: [-1] 
expected returns: [[36.846405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  0.] 
cards in discard: [ 1.  0. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  1. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 543 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.56983184814453






Player: 1 
cards in hand: [ 0.  8. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  6.  6.] 
cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  1. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1. 29.  1.  0. 29.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29] -> size -> 33 
adversary victory points: 5
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  6.  6.] 
cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  1. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1. 29.  1.  0. 29.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29] -> size -> 33 
adversary victory points: 5
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  6.  6.] 
cards in discard: [ 6.  6.  0.  6.  3.  0.  6. 15. 22.  0.  8.  1.  6.  6.  0.  3. 29.  6.
  8.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  1. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1. 29.  1.  0. 29.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29] -> size -> 33 
adversary victory points: 5
player victory points: -7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-8.679434]
 [ 6.403978]
 [ 6.403978]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  1.  0. 29.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  1. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15  0] -> size -> 29 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.846405029296875



action possibilites: [-1. 29.] 
expected returns: [[-9.037127 ]
 [ 4.2674994]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  3.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  1. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15  0] -> size -> 29 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -0.38392210006713867



action possibilites: [-1.] 
expected returns: [[17.923628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  1. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15  0] -> size -> 29 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -0.5840272903442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.243608]
 [28.193666]
 [24.197033]
 [30.756964]
 [30.85855 ]
 [19.306614]
 [36.074135]
 [-4.942708]
 [25.632757]
 [17.756702]
 [18.780252]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  1. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15  0] -> size -> 29 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.923627853393555



buy possibilites: [-1] 
expected returns: [[59.572044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15  0] -> size -> 29 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 523 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.074134826660156






Player: 1 
cards in hand: [8. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6
  0  6  6 15  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29] -> size -> 34 
adversary victory points: 5
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29] -> size -> 34 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29] -> size -> 34 
adversary victory points: 5
player victory points: -8 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[19.838081]
 [23.216503]
 [31.168505]
 [21.764061]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 10.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.572044372558594



action possibilites: [-1. 11.] 
expected returns: [[47.071323]
 [56.594444]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8.  0. 10.  5.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 25.58156394958496



action possibilites: [-1] 
expected returns: [[65.82471]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  5.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 452 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 55.48870849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[61.980827]
 [74.33822 ]
 [70.078674]
 [75.76335 ]
 [66.06353 ]
 [70.92712 ]
 [65.569046]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  5.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.82470703125



buy possibilites: [-1] 
expected returns: [[37.24455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 469 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 75.76335906982422






Player: 1 
cards in hand: [1. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [8. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  3.  1. 25.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1. 11. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [8. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  3.  1. 25.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1. 11. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
adversary victory points: 5
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [ 8.  6. 23.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [10.  3.  3.  1. 25.] 
adversary cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1. 11. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
adversary victory points: 5
player victory points: -8 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  3.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[ 6.130861 ]
 [ 7.7752357]
 [28.67568  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  1. 25.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1. 11. 29. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.24454879760742



action possibilites: [-1] 
expected returns: [[55.3583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  1. 25.  3.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1. 11. 29. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 28.67563819885254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[47.979362]
 [55.294624]
 [50.635357]
 [57.231327]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  1. 25.  3.] 
cards in discard: [ 1.  0. 29. 29. 29. 25. 11.  0. 11.  0.  1.  1. 29. 29. 29.  0.  3.  0.
 10.  3.  1. 11. 29. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.358299255371094






Player: 1 
cards in hand: [ 6. 15.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3.  6.  0.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  3.  6.  0.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
adversary victory points: 5
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[39.136765]
 [46.35679 ]
 [54.2361  ]
 [54.2361  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.23133087158203



action possibilites: [-1. 29.] 
expected returns: [[48.837914]
 [63.740112]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.] 
cards in discard: [ 3. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 50.19755554199219



action possibilites: [-1.] 
expected returns: [[63.877457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 11.  1. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.53213882446289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[57.108047]
 [69.28649 ]
 [62.414   ]
 [68.0664  ]
 [62.408157]
 [65.31532 ]
 [63.423157]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 11.  1. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.87745666503906



buy possibilites: [-1] 
expected returns: [[31.240118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 11.  1. 29.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 459 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 69.28648376464844






Player: 1 
cards in hand: [10.  0.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [1. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1] -> size -> 37 
adversary victory points: 5
player victory points: -8 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 6.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [1. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1] -> size -> 37 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 6.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [1. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1] -> size -> 37 
adversary victory points: 5
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 6.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [1. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1] -> size -> 37 
adversary victory points: 5
player victory points: -8 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.6012778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 3. 0.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 22.  6. 29.  6.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.  0. 10.  0.  0.  3.
  8.  6.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.2401180267334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  0.48339415]
 [ 13.875347  ]
 [ -3.1856751 ]
 [  7.4823537 ]
 [-13.035069  ]
 [ 14.264704  ]
 [ 12.411383  ]
 [  4.5846496 ]
 [ 21.270988  ]
 [-20.016289  ]
 [  9.202995  ]
 [  7.6776643 ]
 [ -8.035982  ]
 [  0.56949663]
 [  4.2927947 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 3. 0.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  6.  7.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 22.  6. 29.  6.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.  0. 10.  0.  0.  3.
  8.  6.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.6012778282165527



buy possibilites: [-1] 
expected returns: [[50.858315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 3. 0.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  6.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 22.  6. 29.  6.] 
adversary cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.  0. 10.  0.  0.  3.
  8.  6.] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  390.    0.    0.    0.    0.    0.    0.    0.  -30.
   0.    0.   62.5   0. ] 
sum of rewards: 417.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 21.2709903717041






Player: 1 
cards in hand: [ 6. 22.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  6. 29.  6.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.  0. 10.  0.  0.  3.
  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  6.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 11.  0.  3.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25] -> size -> 38 
adversary victory points: 5
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29.  6.  6.  6.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.  0. 10.  0.  0.  3.
  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  6.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 11.  0.  3.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25] -> size -> 38 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 29.  6.  6.  6.] 
cards in discard: [ 8.  6. 23.  1.  0.  0.  6.  0.  6. 15.  3.  6.  0.  0. 10.  0.  0.  3.
  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  6.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 11.  0.  3.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25] -> size -> 38 
adversary victory points: 5
player victory points: -8 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 98.55528]
 [109.1048 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  0.  3.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  6.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 15.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.858314514160156



action possibilites: [-1] 
expected returns: [[74.88919]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 15.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -40   0   0   8   0] 
sum of rewards: 373 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 109.36509704589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[70.18533 ]
 [83.75021 ]
 [74.466866]
 [78.242424]
 [74.552864]
 [75.31177 ]
 [75.52533 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 15.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.88919067382812



buy possibilites: [-1] 
expected returns: [[17.765047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 15.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 409 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 83.75016784667969






Player: 1 
cards in hand: [ 6. 15.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  8.  6.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6
 15  0 23  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  1.  0. 11. 29.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1] -> size -> 40 
adversary victory points: 5
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 22. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  1.  0. 11. 29.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1] -> size -> 40 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 22. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  1.  0. 11. 29.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1] -> size -> 40 
adversary victory points: 5
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  1.  0. 11. 29.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1] -> size -> 40 
adversary victory points: 5
player victory points: -8 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11.  1.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[21.361982]
 [18.96913 ]
 [18.96913 ]
 [33.716328]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0. 11. 29.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  6.  6. 29.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.] 
adversary owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0  1] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.765047073364258



action possibilites: [-1. 11. 29.] 
expected returns: [[80.95515 ]
 [91.086075]
 [96.85475 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 21. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  6.  6. 29.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.] 
adversary owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0  1] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 11.880472183227539



action possibilites: [-1. 11.] 
expected returns: [[59.033577]
 [64.350555]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 21. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  6.  6. 29.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.] 
adversary owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0  1] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 89.83064270019531



action possibilites: [-1] 
expected returns: [[77.680405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 20. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  6.  6. 29.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.] 
adversary owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0  1] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  60   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 412 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 62.672454833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[74.2755 ]
 [79.27614]
 [78.04896]
 [78.1564 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 20. 30. 27. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  6.  6. 29.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.] 
adversary owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0  1] -> size -> 28 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.68040466308594



buy possibilites: [-1] 
expected returns: [[71.3747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  6.  6. 29.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.] 
adversary owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0  1] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  60   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 421 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 79.276123046875






Player: 1 
cards in hand: [ 8.  6.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  6. 29.  6.] 
cards in discard: [ 1. 15.  6.  8.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  6  8  6 29  6 10  6  8  6  3  8  6  6  6  0  6  6 15
  0 23  0  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 25. 10. 10.  0.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 1. 15.  6.  8.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 25. 10. 10.  0.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 1. 15.  6.  8.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 25. 10. 10.  0.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 1. 15.  6.  8.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 25. 10. 10.  0.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
expected returns: [[69.144775]
 [83.42485 ]
 [70.07017 ]
 [70.07017 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 10. 10.  0.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 22.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0] -> size -> 26 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.37470245361328



action possibilites: [-1] 
expected returns: [[53.600067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0. 25.  0.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 22.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0] -> size -> 26 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.42485046386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[41.257664]
 [40.6436  ]
 [50.092606]
 [53.600067]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0. 25.  0.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 22.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0] -> size -> 26 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.600067138671875






Player: 1 
cards in hand: [ 6.  0.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 22.] 
cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [29. 29. 25. 11. 29.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11. 25.  3. 10. 10.  0. 25.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  0. 22.] 
cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [29. 29. 25. 11. 29.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11. 25.  3. 10. 10.  0. 25.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  0. 22.] 
cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [29. 29. 25. 11. 29.] 
adversary cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11. 25.  3. 10. 10.  0. 25.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29. 29. 25. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 11. 29.] 
expected returns: [[ 1.5255046]
 [12.869429 ]
 [12.869429 ]
 [14.825094 ]
 [ 6.799499 ]
 [12.869429 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 11. 29.] 
cards in discard: [ 3. 11.  1. 29.  1. 29. 29.  0. 25.  1.  1.  0.  3.  0.  8.  1. 11.  1.
  3.  0.  3.  0. 11.  1. 29.  1.  3. 29. 29. 11. 25.  3. 10. 10.  0. 25.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  6.  8.  6.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 53.600067138671875



action possibilites: [-1] 
expected returns: [[14.908554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  6.  8.  6.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.825082778930664





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.690002]
 [15.474422]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 11. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  6.  8.  6.  6.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.908554077148438






Player: 1 
cards in hand: [23.  6.  8.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  8.  6.  6.] 
cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0. 29. 11. 11.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  8.  6.  6.] 
cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0. 29. 11. 11.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
adversary victory points: 6
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[ 4.7036166]
 [18.508917 ]
 [14.033667 ]
 [14.033667 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 11. 11.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22. 23.  6.  8.  6.
  6.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.474416732788086



action possibilites: [-1. 11. 11.] 
expected returns: [[-1.1771812]
 [ 9.662735 ]
 [ 9.662735 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 20. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22. 23.  6.  8.  6.
  6.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.11737823486328



action possibilites: [-1] 
expected returns: [[30.737913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 19. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22. 23.  6.  8.  6.
  6.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 312 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 9.216327667236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[28.761778]
 [40.537754]
 [36.805843]
 [41.789726]
 [32.310238]
 [37.250126]
 [30.103937]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 19. 30. 26. 30.  8.  0. 10.  4.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22. 23.  6.  8.  6.
  6.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.737913131713867



buy possibilites: [-1] 
expected returns: [[31.065184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22. 23.  6.  8.  6.
  6.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 329 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.78974151611328






Player: 1 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22. 23.  6.  8.  6.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 29.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11] -> size -> 44 
adversary victory points: 6
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [ 1. 15.  6.  8.  6.  0.  8. 29.  0.  6.  0.  3.  0. 22. 23.  6.  8.  6.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 19. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 29.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11] -> size -> 44 
adversary victory points: 6
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-16.851374 ]
 [ -1.4125133]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 29.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.065183639526367



action possibilites: [-1.] 
expected returns: [[31.870913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 19. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -7.214539527893066





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[27.351606 ]
 [41.708992 ]
 [37.049797 ]
 [40.636208 ]
 [40.98683  ]
 [30.768484 ]
 [ 7.3235164]
 [36.09558  ]
 [30.935835 ]
 [30.391203 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 19. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.870912551879883



buy possibilites: [-1] 
expected returns: [[37.306038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[  -5.     0.     0.   330.     0.     0.    20.     0.     0.     0.
    0.  -100.     0.     0.    13.5    0. ] 
sum of rewards: 258.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 41.709014892578125






Player: 1 
cards in hand: [ 0.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  1.  3.  1. 10.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1] -> size -> 45 
adversary victory points: 6
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 18. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  1.  3.  1. 10.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1] -> size -> 45 
adversary victory points: 6
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 18. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  1.  3.  1. 10.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1] -> size -> 45 
adversary victory points: 6
player victory points: -5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8.  1.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-1.7693853 ]
 [-5.5670867 ]
 [ 0.50784636]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  3.  1. 10.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  6.  3.  0.  1.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.30603790283203



action possibilites: [-1.  8.] 
expected returns: [[0.49788332]
 [0.21651077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3. 1. 1.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  6.  3.  0.  1.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 0.507835865020752





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -6.8963747 ]
 [  6.9058967 ]
 [-14.102064  ]
 [ -2.3330207 ]
 [-30.868473  ]
 [  9.438618  ]
 [  7.2893815 ]
 [  0.2165103 ]
 [ 16.454924  ]
 [-34.57751   ]
 [  2.8324943 ]
 [  3.113254  ]
 [-22.138586  ]
 [ -5.7862043 ]
 [  0.49788332]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 1. 1.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 18. 30. 26. 30.  8.  0. 10.  3.  5.  6.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  6.  3.  0.  1.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.4978775978088379



buy possibilites: [-1] 
expected returns: [[30.767847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 1. 1.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 18. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  6.  3.  0.  1.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[  -5.     0.     0.   330.     0.     0.    20.     0.     0.     0.
    0.  -110.     0.     0.    62.5    0. ] 
sum of rewards: 297.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 16.454912185668945






Player: 1 
cards in hand: [23.  6.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  3.  0.  1.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  3.  0.  1.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 18. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  3.  0.  1.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.992344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6.  6. 22.  6.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1] -> size -> 29 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.767847061157227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-34.077137]
 [-31.574831]
 [-22.590693]
 [-14.992304]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6.  6. 22.  6.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1] -> size -> 29 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.99234390258789



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  6. 22.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 22.  6.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 10.  1.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 22.  6.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 10.  1.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 22.  6.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 10.  1.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[-76.09772 ]
 [-76.55864 ]
 [-71.859055]
 [-70.40584 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 10.  1.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  6. 29.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -14.99234390258789



action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-77.0367  ]
 [-82.63495 ]
 [-79.584595]
 [-79.584595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  1. 29.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  6. 29.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -70.40582275390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-86.28544 ]
 [-84.58173 ]
 [-80.01518 ]
 [-79.18212 ]
 [-80.24973 ]
 [-79.143265]
 [-77.0367  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 29.  1. 29.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  6. 29.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -77.03671264648438






Player: 1 
cards in hand: [ 8.  0.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 29.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  6  8  6  3  8  6  6  6  0  6  6 15  0 23  0
  1  0  0  0  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11. 25.  1. 25.  1.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3. 10.  0.
 25. 29.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1
  0  0  0  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11. 25.  1. 25.  1.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3. 10.  0.
 25. 29.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1
  0  0  0  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 17. 30. 26. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11. 25.  1. 25.  1.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3. 10.  0.
 25. 29.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1
  0  0  0  1  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11. 25.  1. 25.  1.] 
adversary cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3. 10.  0.
 25. 29.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 25.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
expected returns: [[ 3.04664 ]
 [11.518389]
 [23.476473]
 [23.476473]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  1. 25.  1.] 
cards in discard: [25. 29. 29. 11. 29. 29.  0.  0.  3.  1. 11. 29. 11.  1. 11.  0. 29.  1.
 29.  1.  3.  0. 25. 10.  8.  1.  3.  1.  1.  0.  3.  3.  0.  3. 10.  0.
 25. 29.  1. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [15.  6.  1.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1
  0  0  0  1  0  3] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -77.03671264648438



action possibilites: [-1] 
expected returns: [[0.01383972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 25.  1.  0. 11.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [15.  6.  1.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1
  0  0  0  1  0  3] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.476469039916992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -0.04087162]
 [ 11.612116  ]
 [  6.0153403 ]
 [-11.353746  ]
 [ 10.831213  ]
 [  9.120972  ]
 [  2.5500207 ]
 [ 15.725355  ]
 [-18.073599  ]
 [  7.1800904 ]
 [  5.3059926 ]
 [ -7.664069  ]
 [  0.05841494]
 [  1.5521593 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 25.  1.  0. 11.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  5.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [15.  6.  1.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1
  0  0  0  1  0  3] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.0138397216796875



buy possibilites: [-1] 
expected returns: [[46.805145]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 25.  1.  0. 11.] 
cards in discard: [25.] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [15.  6.  1.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1
  0  0  0  1  0  3] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -120    0    0
  250    0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 15.725379943847656






Player: 1 
cards in hand: [15.  6.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  1.  3.  0.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.  8.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1
  0  0  0  1  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25] -> size -> 47 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.  8.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0
  0  0  1  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25] -> size -> 47 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.  8.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0
  0  0  1  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25] -> size -> 47 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3.] 
cards in discard: [ 0.  0.  0.  0.  6. 10.  1. 23.  6.  3.  0.  1.  0.  6.  6. 22.  6.  0.
  3.  8.  0. 29.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0
  0  0  1  0  3 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25] -> size -> 47 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 3.9459567]
 [16.820837 ]
 [16.820837 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 29.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [29.  6.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0
  0  0  1  0  3 14] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.805145263671875



action possibilites: [-1.] 
expected returns: [[-6.429987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [29.  6.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0
  0  0  1  0  3 14] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.324052810668945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-8.438985 ]
 [ 3.58606  ]
 [-2.566915 ]
 [ 2.337339 ]
 [-4.151285 ]
 [-1.0911746]
 [-6.2653627]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 17. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [29.  6.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0
  0  0  1  0  3 14] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -6.429986953735352



buy possibilites: [-1] 
expected returns: [[12.107607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [29.  6.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0
  0  0  1  0  3 14] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -130    0    0
   54    0] 
sum of rewards: 209 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 3.586047649383545






Player: 1 
cards in hand: [29.  6.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  8.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  0 22  8 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0
  0  0  1  0  3 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 29.  1. 29.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0  0
  0  1  0  3 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 29.  1. 29.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0  0
  0  1  0  3 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 29.  1. 29.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0  0
  0  1  0  3 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 29.  1. 29.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 29.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[33.92019 ]
 [44.511215]
 [44.511215]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  1. 29.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [1. 8. 1. 6. 6.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.] 
adversary owned cards: [ 0  3  1  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0  0
  0  1  0  3 14  0] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.107606887817383



action possibilites: [-1. 29.] 
expected returns: [[ 0.78172207]
 [16.002558  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [1. 8. 1. 6. 6.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.] 
adversary owned cards: [ 0  3  1  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0  0
  0  1  0  3 14  0] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 41.6851806640625



action possibilites: [-1.] 
expected returns: [[72.014694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [1. 8. 1. 6. 6.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.] 
adversary owned cards: [ 0  3  1  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0  0
  0  1  0  3 14  0] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 1.5061655044555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[64.8646  ]
 [72.076515]
 [69.170746]
 [72.36789 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
action values: 1 
buys: 1 
player value: 2 
card supply: [21. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [1. 8. 1. 6. 6.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.] 
adversary owned cards: [ 0  3  1  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0  0
  0  1  0  3 14  0] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.01469421386719






Player: 1 
cards in hand: [1. 8. 1. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 1. 6. 6.] 
cards in discard: [ 0.  8. 29.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  1  0  0
  0  1  0  3 14  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  1.  8.  1.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 0.  8. 29.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  1.  8.  1.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 0.  8. 29.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  1.  8.  1.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  1.  8.  1.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [25. 10.  1.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8.] 
expected returns: [[16.300783]
 [31.397707]
 [18.486591]
 [16.61731 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  1.  8.  1.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  6.  3.  1. 14.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6.] 
adversary owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 72.36787414550781



action possibilites: [-1] 
expected returns: [[48.555576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  8.  1.  1.  3.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  6.  3.  1. 14.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6.] 
adversary owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.397729873657227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.002937]
 [56.200394]
 [38.937595]
 [48.70794 ]
 [30.290663]
 [56.7356  ]
 [53.17854 ]
 [47.48492 ]
 [62.961777]
 [23.346151]
 [51.360676]
 [49.546165]
 [34.89004 ]
 [43.271755]
 [48.555576]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  8.  1.  1.  3.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  4.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  6.  3.  1. 14.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6.] 
adversary owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.55557632446289



buy possibilites: [-1] 
expected returns: [[12.993057]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  8.  1.  1.  3.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  3.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  6.  3.  1. 14.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6.] 
adversary owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5.     0.     0.   270.     0.     0.    20.     0.     0.     0.
    0.  -140.     0.     0.    62.5    0. ] 
sum of rewards: 207.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 62.961761474609375






Player: 1 
cards in hand: [ 0.  6.  3.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  1. 14.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  3.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [25.  3.  1.  3.  0.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25] -> size -> 49 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  1. 14.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  3.  0.  9.  9.  7.  9.  9.] 
adversary cards in hand: [25.  3.  1.  3.  0.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25] -> size -> 49 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  1. 14.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25.  3.  1.  3.  0.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25] -> size -> 49 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [25.  3.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-50.215515]
 [-36.799103]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  1.  3.  0.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 15. 22. 10.  0.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.] 
adversary owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0 10] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.993057250976562



action possibilites: [-1] 
expected returns: [[-10.465437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3.  0.  0. 25.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 15. 22. 10.  0.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.] 
adversary owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0 10] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -36.799095153808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-2.1061546e+01]
 [-9.1167374e+00]
 [-1.0881224e+01]
 [-2.2048469e+00]
 [-2.5957108e-02]
 [-1.5434584e+01]
 [-3.6223560e+01]
 [-6.5773935e+00]
 [-1.5912830e+01]
 [-1.0465414e+01]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  0.  0. 25.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  3.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 15. 22. 10.  0.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.] 
adversary owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0 10] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.465436935424805



buy possibilites: [-1] 
expected returns: [[-30.325968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  0.  0. 25.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 15. 22. 10.  0.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.] 
adversary owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0 10] -> size -> 30 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5.     0.     0.   270.     0.     0.    20.     0.     0.     0.
    0.  -150.     0.     0.    13.5    0. ] 
sum of rewards: 148.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -0.02596902847290039






Player: 1 
cards in hand: [ 0. 15. 22. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 22. 10.  0.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1
  0  3 14  0  0 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 11.  0. 29. 10.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 10.  0.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 11.  0. 29. 10.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 10.  0.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 16. 30. 25. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 11.  0. 29. 10.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 10.  0.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 16. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 11.  0. 29. 10.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [11. 11.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 10.] 
expected returns: [[-28.850275]
 [-35.93422 ]
 [-35.93422 ]
 [-20.55733 ]
 [-39.3021  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 29. 10.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 23.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -30.32596778869629



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[-127.13447]
 [-132.06955]
 [-132.06955]
 [-132.50452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 16. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 23.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -37.28871154785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-151.36853]
 [-127.13447]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 16. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 23.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -127.13440704345703






Player: 1 
cards in hand: [ 0.  6.  0.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  3. 23.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3. 11. 29. 29. 11.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.  0.  1. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  3. 23.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 16. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3. 11. 29. 29. 11.] 
adversary cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.  0.  1. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
adversary victory points: 6
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 11.] 
expected returns: [[ 5.6496406]
 [ 6.5494447]
 [14.345205 ]
 [14.345205 ]
 [ 6.5494447]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 29. 11.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.  0.  1. 29. 11. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.  0.  6.  0.  3. 23.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -127.13440704345703



action possibilites: [-1. 11. 11.] 
expected returns: [[-18.896471]
 [-10.644701]
 [-10.644701]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.  0.  1. 29. 11. 11. 10. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 16. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.  0.  6.  0.  3. 23.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.769712448120117



action possibilites: [-1] 
expected returns: [[-12.869888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.  0.  1. 29. 11. 11. 10. 29. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 15. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.  0.  6.  0.  3. 23.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: 142 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -12.629738807678223





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-17.851744]
 [-12.869888]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [25. 25. 11.  1. 25.  1.  0. 11. 29.  1.  1. 29.  0.  0.  3.  1.  1.  0.
 29. 29. 29.  3. 25. 25. 10.  1.  8.  1.  1.  3. 11. 25.  3.  1.  3.  0.
  0. 25.  0.  1. 29. 11. 11. 10. 29. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 15. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.  0.  6.  0.  3. 23.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.869888305664062






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.  0.  6.  0.  3. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 25. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1] -> size -> 51 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 0.  8. 29.  6.  3.  0.  8.  6.  6. 10.  0.  6.  3.  1. 14.  3. 15. 22.
 10.  0.  0.  6.  0.  3. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 15. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 25. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1] -> size -> 51 
adversary victory points: 6
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [11. 25. 29.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29. 29.] 
expected returns: [[64.41676 ]
 [68.92862 ]
 [79.15911 ]
 [74.122986]
 [74.122986]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29.  1. 29.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 10. 10.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -12.869888305664062



action possibilites: [-1] 
expected returns: [[15.311466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  1. 29. 29. 10.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 10. 10.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 79.15912628173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[13.560377]
 [19.329947]
 [18.298391]
 [16.15389 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  1. 29. 29. 10.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 15. 30. 24. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 10. 10.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.311466217041016



buy possibilites: [-1] 
expected returns: [[43.636513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  1. 29. 29. 10.] 
cards in discard: [3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 10. 10.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -170    0    0
   16    0] 
sum of rewards: 131 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 19.3299503326416






Player: 1 
cards in hand: [ 0. 10. 10.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3. 23.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 29.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3] -> size -> 52 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3. 23.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 15. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 29.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3] -> size -> 52 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3. 23.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 15. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 29.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3] -> size -> 52 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[-0.26998997]
 [ 4.92703   ]
 [13.368877  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 29.  0.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 14.  0. 29.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.636512756347656



action possibilites: [-1.] 
expected returns: [[-3.7094738]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 15. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 14.  0. 29.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.283653736114502





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-6.3227997]
 [ 6.038034 ]
 [-1.4636292]
 [ 3.1659684]
 [-1.9154236]
 [-0.8898587]
 [-2.9341245]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 15. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 14.  0. 29.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -3.7094738483428955



buy possibilites: [-1] 
expected returns: [[17.279182]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 14. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 14.  0. 29.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -180    0    0
   54    0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 6.0380330085754395






Player: 1 
cards in hand: [ 0.  6. 14.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14.  0. 29.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 14. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [29.  3.  1. 29.  1.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1] -> size -> 53 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  0. 29.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 14. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [29.  3.  1. 29.  1.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1] -> size -> 53 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  0. 29.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [29.  3.  1. 29.  1.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1] -> size -> 53 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [29.  3.  1. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[31.852365]
 [45.244392]
 [45.244392]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1. 29.  1.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.27918243408203



action possibilites: [-1. 29.] 
expected returns: [[25.34497 ]
 [40.258133]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 34.102237701416016



action possibilites: [-1.] 
expected returns: [[47.189564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.36564064025879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[36.917698]
 [48.685894]
 [44.50241 ]
 [51.705196]
 [42.257618]
 [47.79454 ]
 [47.18957 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  2.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 47.1895637512207



buy possibilites: [-1] 
expected returns: [[88.81373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.] 
adversary owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -190    0    0
   54    0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 51.70521545410156






Player: 1 
cards in hand: [1. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 6.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  1  0
  3 14  0  0 10  3  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 25. 29.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 25. 29.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 25. 29.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[25.455675]
 [39.73032 ]
 [36.65207 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 25. 29.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.81372833251953



action possibilites: [-1] 
expected returns: [[40.270523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 29.  0. 25.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 39.730323791503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.164833]
 [40.27054 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 29.  0. 25.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.27052307128906






Player: 1 
cards in hand: [0. 3. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 8.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 25.  1.  1.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 8.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 25.  1.  1.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
adversary victory points: 7
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  1.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[45.15986 ]
 [57.968307]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1.  1.  0.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 22.  0.  6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.  0.  3.  6.
  6.  8.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.27052307128906



action possibilites: [-1] 
expected returns: [[26.206903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0. 8. 1.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 22.  0.  6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.  0.  3.  6.
  6.  8.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 57.96829605102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.79186   ]
 [30.60837   ]
 [17.067966  ]
 [26.976198  ]
 [ 4.446097  ]
 [30.323168  ]
 [34.26887   ]
 [32.870518  ]
 [22.866213  ]
 [41.464935  ]
 [ 0.20074177]
 [31.041002  ]
 [28.85219   ]
 [14.385223  ]
 [20.754225  ]
 [26.206917  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 8. 1.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11] -> size -> 54 
action values: 0 
buys: 1 
player value: 9 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  3.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 22.  0.  6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.  0.  3.  6.
  6.  8.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.2069034576416



buy possibilites: [-1] 
expected returns: [[14.0641]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 8. 1.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 22.  0.  6.] 
adversary cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.  0.  3.  6.
  6.  8.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5.     0.     0.   270.     0.     0.    20.     0.     0.     0.
    0.  -200.     0.     0.    62.5    0. ] 
sum of rewards: 147.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 41.46492004394531






Player: 1 
cards in hand: [ 0.  3. 22.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 22.  0.  6.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.  0.  3.  6.
  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 25. 25.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6.  6.  0. 15.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.  0.  3.  6.
  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 25. 25.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6.  6.  0. 15.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.  0.  3.  6.
  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 25. 25.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6.  6.  0. 15.] 
cards in discard: [ 0.  0. 10. 10.  3. 23.  0.  0.  6. 14.  0. 29.  8.  0.  6.  0.  3.  6.
  6.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [11. 25. 25.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [11. 25. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25. 10.] 
expected returns: [[-24.460682 ]
 [ -1.4037228]
 [  9.353863 ]
 [  9.353863 ]
 [ -8.347085 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25.  0. 10.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.06410026550293



action possibilites: [-1] 
expected returns: [[-100.755615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0. 10. 11. 11.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.353845596313477





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-109.580246]
 [-100.75557 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  0. 10. 11. 11.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -100.755615234375






Player: 1 
cards in hand: [ 0. 22.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  1.  0. 29.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1. 25. 11. 25.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  1.  0. 29.] 
adversary cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1. 25. 11. 25.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
adversary victory points: 7
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[20.804525]
 [32.02025 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1.  0. 29.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1. 25. 11. 25.  0. 10. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -100.755615234375



action possibilites: [-1. 25.] 
expected returns: [[-48.545334]
 [-40.380974]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1. 25. 11. 25.  0. 10. 11. 11.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 26.384164810180664



action possibilites: [-1] 
expected returns: [[-51.808075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 11.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1. 25. 11. 25.  0. 10. 11. 11.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -40.38099670410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -84.97796 ]
 [ -68.332146]
 [ -75.05743 ]
 [-113.41219 ]
 [ -39.34946 ]
 [ -43.975235]
 [ -61.273277]
 [ -14.137045]
 [-107.43113 ]
 [ -60.023903]
 [ -48.304565]
 [ -92.118095]
 [ -77.83551 ]
 [ -51.808052]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 11.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1. 25. 11. 25.  0. 10. 11. 11.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  2.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: -51.808074951171875



buy possibilites: [-1] 
expected returns: [[13.6505375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 11.] 
cards in discard: [ 3. 25. 11. 29.  1. 29. 29. 10.  1. 11.  1. 29.  0.  0.  3.  3.  1.  1.
 11. 11. 29. 29.  0. 25.  3.  3.  3. 29.  0. 25. 25. 25.  1.  1.  1.  0.
  8.  1. 25. 11. 25.  0. 10. 11. 11.  1.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -210    0    0
  250    0] 
sum of rewards: 345 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -14.137046813964844






Player: 1 
cards in hand: [3. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [ 0. 22.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 29. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25] -> size -> 56 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [ 0. 22.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 14. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 29. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25] -> size -> 56 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [ 0. 22.  0.  0.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 14. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 29. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25] -> size -> 56 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 11.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[20.072323]
 [30.73165 ]
 [25.634192]
 [30.73165 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 11.  1. 29.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 14. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [14.  6.  0. 29.  0.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.650537490844727



action possibilites: [-1. 29.] 
expected returns: [[39.112778]
 [52.375294]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.] 
cards in discard: [ 1. 11.] 
cards in deck: 50 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 14. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [14.  6.  0. 29.  0.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.936418533325195



action possibilites: [-1. 11.] 
expected returns: [[47.179455]
 [52.851234]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 1. 11.  1.  3.] 
cards in deck: 49 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 14. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [14.  6.  0. 29.  0.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 46.80411911010742



action possibilites: [-1] 
expected returns: [[29.207994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1. 11.  1.  3.  1.] 
cards in deck: 49 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 13. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [14.  6.  0. 29.  0.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   60    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 53.726776123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 9.822268]
 [11.347876]
 [23.616762]
 [29.389383]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 11.  1.  3.  1.] 
cards in deck: 49 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 13. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [14.  6.  0. 29.  0.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.20799446105957






Player: 1 
cards in hand: [14.  6.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0. 29.  0.] 
cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 13. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 11.  0.  1.] 
adversary cards in discard: [ 1. 11.  1.  3.  1. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25  1] -> size -> 57 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0. 29.  0.] 
cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 13. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 11.  0.  1.] 
adversary cards in discard: [ 1. 11.  1.  3.  1. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25  1] -> size -> 57 
adversary victory points: 7
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [25. 25. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11.] 
expected returns: [[42.889263]
 [56.232666]
 [56.232666]
 [46.61132 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 11.  0.  1.] 
cards in discard: [ 1. 11.  1.  3.  1. 29. 29. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 13. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6. 14.  6.  0. 29.  0.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.389371871948242



action possibilites: [-1] 
expected returns: [[50.866234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.  1.  3.  1.] 
cards in discard: [ 1. 11.  1.  3.  1. 29. 29. 11.] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 13. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6. 14.  6.  0. 29.  0.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.232666015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[49.79979 ]
 [61.0372  ]
 [55.51219 ]
 [38.41739 ]
 [59.964294]
 [58.930885]
 [52.153503]
 [64.8196  ]
 [31.613405]
 [55.612404]
 [54.57436 ]
 [41.418106]
 [49.050518]
 [50.86622 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.  0.  1.  3.  1.] 
cards in discard: [ 1. 11.  1.  3.  1. 29. 29. 11.] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 13. 30. 23. 30.  8.  0. 10.  1.  5.  1.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6. 14.  6.  0. 29.  0.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.866233825683594



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 9 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25. 11.  0.  1.  3.  1.] 
cards in discard: [ 1. 11.  1.  3.  1. 29. 29. 11. 25.] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 11 25 25 29  3 25 10 29  1  3
 29  1 11 10  1  1 11 29 29 29  1 11  1 25  8  1  1  3  1 11  1 25 25  1
 25 11  1  3  1 11 25 25  1 25] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 13. 30. 23. 30.  8.  0. 10.  1.  5.  0.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 22.  0.  0.  3.  0.  3.  6.  6.  0.  6. 14.  6.  0. 29.  0.] 
adversary owned cards: [ 3 22 29 10  8  6  3  8  6  6  6  0  6  6 15  0 23  0  0  0  0  0  3 14
  0  0 10  3  0  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[     -5 3000000       0     270       0       0      20       0       0
       0       0    -230       0       0     125       0] 
sum of rewards: 3000180 

action type: buy - action 25.0
Learning step: 120004.609375
desired expected reward: 120069.4296875



