 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[303.02582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -2  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -847 

action type: buy - action 6.0
Learning step: -42.09280014038086
desired expected reward: -47.236759185791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[280.82285]
 [288.98087]
 [286.4295 ]
 [266.31696]
 [296.9198 ]
 [288.3408 ]
 [285.86813]
 [303.00064]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.780633926391602
desired expected reward: 294.970458984375



buy possibilites: [-1] 
expected returns: [[295.06863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.132432460784912
desired expected reward: 279.2970886230469






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[307.1196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.3413896560668945
desired expected reward: 287.72723388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[282.01715]
 [293.6954 ]
 [291.22656]
 [265.13205]
 [286.65   ]
 [304.10165]
 [292.5633 ]
 [298.16165]
 [276.0259 ]
 [290.36957]
 [289.24265]
 [312.97983]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.424086570739746
desired expected reward: 301.0000305175781



buy possibilites: [-1] 
expected returns: [[288.17938]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 41 

action type: buy - action 29.0
Learning step: -6.374047756195068
desired expected reward: 291.7876281738281






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[283.87784]
 [269.05502]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.677222728729248
desired expected reward: 280.5021667480469



action possibilites: [-1.] 
expected returns: [[287.18958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action 29.0
Learning step: -5.627938270568848
desired expected reward: 265.1661376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[256.72815]
 [266.1538 ]
 [264.0402 ]
 [245.7639 ]
 [241.11119]
 [260.4442 ]
 [274.41205]
 [265.30432]
 [281.64865]
 [269.7588 ]
 [251.4352 ]
 [257.4867 ]
 [263.4112 ]
 [246.42523]
 [262.50122]
 [281.3608 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -6.96072244644165
desired expected reward: 280.2288513183594



buy possibilites: [-1] 
expected returns: [[257.17505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 37.0 

action type: buy - action 15.0
Learning step: -5.488623142242432
desired expected reward: 257.0126037597656






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [15. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [15. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  3.  0. 11. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [15. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[275.78696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [15. 29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.1483917236328125
desired expected reward: 251.0266571044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[255.985  ]
 [263.49295]
 [239.33684]
 [265.111  ]
 [281.1811 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [15. 29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.52875280380249
desired expected reward: 270.7095031738281



buy possibilites: [-1] 
expected returns: [[221.83058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [15. 29.  0.  0.  0.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -22.075653076171875
desired expected reward: 217.2611541748047






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[274.05765]
 [253.35428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 15. 11.  0.  3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -5.229384899139404
desired expected reward: 216.6011962890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[245.74292]
 [253.67052]
 [228.5955 ]
 [255.11916]
 [273.92838]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 15. 11.  0.  3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.100046157836914
desired expected reward: 266.3802795410156



buy possibilites: [-1] 
expected returns: [[240.81662]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 15. 11.  0.  3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.661401748657227
desired expected reward: 206.93411254882812






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3. 15. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.  0.  3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  3. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 11.  0.  3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  3. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[236.66914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [ 6.  3. 15.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.408665657043457
desired expected reward: 233.407958984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[208.36443]
 [217.64339]
 [215.19478]
 [194.04343]
 [225.15799]
 [216.84781]
 [214.57463]
 [230.80374]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [ 6.  3. 15.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.1905083656311035
desired expected reward: 221.4414825439453



buy possibilites: [-1] 
expected returns: [[231.71294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [ 6.  3. 15.  3.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -6.178849697113037
desired expected reward: 210.66896057128906






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[229.63147]
 [216.61955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.22964334487915
desired expected reward: 224.48329162597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[201.23743]
 [211.43806]
 [209.10086]
 [185.13727]
 [220.4354 ]
 [210.42119]
 [208.30432]
 [228.20326]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.291213512420654
desired expected reward: 220.84063720703125



buy possibilites: [-1] 
expected returns: [[238.86678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 11.0
Learning step: -5.397266864776611
desired expected reward: 215.03811645507812






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 6. 0. 3. 6.] 
adversary cards in discard: [11.  0. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 6. 0. 3. 6.] 
adversary cards in discard: [11.  0. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[192.18045]
 [179.7712 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 3. 6.] 
cards in discard: [11.  0. 29.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 15.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.424031257629395
desired expected reward: 230.4427490234375



action possibilites: [-1] 
expected returns: [[221.84386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6.] 
cards in discard: [11.  0. 29.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 15.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.34095573425293
desired expected reward: 189.30789184570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[202.05959]
 [187.80528]
 [220.17854]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [11.  0. 29.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 15.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -6.116626262664795
desired expected reward: 215.72723388671875






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 15.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [11.  0. 29.  3.  0.  0.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [11.  0. 29.  3.  0.  0.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [11.  0. 29.  3.  0.  0.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 16 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  0.  3.  0.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [11.  0. 29.  3.  0.  0.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 16 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[168.88274]
 [154.28642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [11.  0. 29.  3.  0.  0.  8.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -8.50390911102295
desired expected reward: 211.6746368408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[152.10513]
 [159.99864]
 [157.77872]
 [139.14343]
 [166.37506]
 [159.4016 ]
 [157.33052]
 [171.15332]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [11.  0. 29.  3.  0.  0.  8.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.007062911987305
desired expected reward: 162.98464965820312



buy possibilites: [-1] 
expected returns: [[143.29659]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [11.  0. 29.  3.  0.  0.  8.  6.  3.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 8.0
Learning step: -5.795907497406006
desired expected reward: 153.60569763183594






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8] -> size -> 17 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[195.02745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3. 10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -4.432162761688232
desired expected reward: 138.8644256591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[176.75484]
 [181.9433 ]
 [163.68127]
 [183.95146]
 [195.71837]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3. 10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -7.284340858459473
desired expected reward: 187.50083923339844



buy possibilites: [-1] 
expected returns: [[200.68063]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3. 10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 8.0
Learning step: -5.932258129119873
desired expected reward: 178.01919555664062






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [16.  3. 10. 11.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  8.  8. 29.] 
adversary cards in discard: [8. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8  8] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [16.  3. 10. 11.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  8.  8. 29.] 
adversary cards in discard: [8. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8  8] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [16.  3. 10. 11.  0.  0.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 26. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  8.  8. 29.] 
adversary cards in discard: [8. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8  8] -> size -> 18 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 3. 11.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 29.] 
expected returns: [[183.58084]
 [178.64462]
 [172.02705]
 [172.02705]
 [175.20816]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  8. 29.] 
cards in discard: [8. 0. 0. 6. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8 11  8  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -8.304584503173828
desired expected reward: 192.3760528564453



action possibilites: [-1] 
expected returns: [[228.79211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.] 
cards in discard: [8. 0. 0. 6. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.8318276405334473
desired expected reward: 152.76116943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[213.29626]
 [199.38084]
 [227.78204]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [8. 0. 0. 6. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -7.743488311767578
desired expected reward: 221.0486297607422



buy possibilites: [-1] 
expected returns: [[218.88986]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [8. 0. 0. 6. 3. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -334 

action type: buy - action 6.0
Learning step: -21.744022369384766
desired expected reward: 177.63685607910156






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  0.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  6.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6] -> size -> 17 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  0.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  6.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6] -> size -> 17 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 26. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  0.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  6.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6] -> size -> 17 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  0.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  6.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6] -> size -> 17 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [15.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[173.30592]
 [161.89807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.  0.  3.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  6.  8.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3  0] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -9.920896530151367
desired expected reward: 208.96896362304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[159.14359]
 [162.91606]
 [149.76869]
 [164.28738]
 [173.26923]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  0.  3.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  6.  8.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3  0] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -7.534193515777588
desired expected reward: 162.67445373535156



buy possibilites: [-1] 
expected returns: [[162.37793]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  0.  3.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  6.  8.  3. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3  0] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -35 

action type: buy - action 3.0
Learning step: -6.242300510406494
desired expected reward: 156.6737823486328






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [ 0. 15.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  8 15 10  3 16  3  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 11  8 15 10  3 16  3  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 11  8 15 10  3 16  3  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 11  8 15 10  3 16  3  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[221.33235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 16. 10.  3.] 
adversary cards in discard: [ 0. 15.  3.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 11  8 15 10  3 16  3  3  0  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -4.820558071136475
desired expected reward: 157.557373046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[203.66934]
 [210.41718]
 [187.4727 ]
 [212.52327]
 [226.19772]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 16. 10.  3.] 
adversary cards in discard: [ 0. 15.  3.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 11  8 15 10  3 16  3  3  0  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -7.910892009735107
desired expected reward: 212.0152587890625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 10.  3.] 
cards in discard: [ 0. 15.  3.  3.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 11  8 15 10  3 16  3  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 15.  6.  3.  3.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3.  0.] 
cards in discard: [ 0. 15.  3.  3.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0 11  8 15 10  3 16  3  3  0  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 15.  6.  3.  3.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 15.  3.  3.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  3  3  0 11  8 15 10  3 16  3  3  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 15.  6.  3.  3.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 15.  3.  3.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  3  3  0 11  8 15 10  3 16  3  3  0  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 15.  6.  3.  3.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 15.  3.  3.  0.  0.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  3  3  0 11  8 15 10  3 16  3  3  0  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 15.  6.  3.  3.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 8. 15.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[218.02351]
 [207.7256 ]
 [204.01811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  6.  3.  3.] 
cards in discard: [3. 3. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 16.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 11  8 15 10  3 16  3  3  0  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -8.264871597290039
desired expected reward: 217.9328155517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[197.19324]
 [183.61557]
 [216.0702 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  6.  3.  3.] 
cards in discard: [3. 3. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 16.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 11  8 15 10  3 16  3  3  0  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -7.907574653625488
desired expected reward: 207.7972869873047



buy possibilites: [-1] 
expected returns: [[213.75562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  6.  3.  3.] 
cards in discard: [3. 3. 3. 0. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 16.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 11  8 15 10  3 16  3  3  0  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -40    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -344 

action type: buy - action 6.0
Learning step: -21.571277618408203
desired expected reward: 162.04429626464844






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 11  8 15 10  3 16  3  3  0  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 3.  3.  3.  0.  0.  6.  8. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 3.  3.  3.  0.  0.  6.  8. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 3.  3.  3.  0.  0.  6.  8. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [6. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[200.90686]
 [188.72546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 3.  3.  3.  0.  0.  6.  8. 15.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 16.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -8.532135963439941
desired expected reward: 205.22348022460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[181.35432]
 [187.0757 ]
 [167.3605 ]
 [189.08423]
 [201.41412]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 3.  3.  3.  0.  0.  6.  8. 15.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 16.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -7.946533203125
desired expected reward: 191.31468200683594



buy possibilites: [-1] 
expected returns: [[152.47913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 3.  3.  3.  0.  0.  6.  8. 15.  6.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 16.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -74.0 

action type: buy - action 0.0
Learning step: -9.336935997009277
desired expected reward: 172.0173797607422






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 16.  8.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 16.  8.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 25. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 16.  8.  3.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 6.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[134.40323]
 [124.20318]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -7.466986179351807
desired expected reward: 145.01214599609375



action possibilites: [-1.] 
expected returns: [[204.6392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action 29.0
Learning step: -2.3705861568450928
desired expected reward: 103.12877655029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[187.35953]
 [195.0587 ]
 [192.59291]
 [173.76059]
 [200.83075]
 [194.49341]
 [192.15776]
 [204.7703 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -7.56158447265625
desired expected reward: 197.07762145996094



buy possibilites: [-1] 
expected returns: [[159.82916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -64.0 

action type: buy - action 0.0
Learning step: -8.971821784973145
desired expected reward: 178.3877410888672






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 3 
card supply: [22. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 16.  8.  3.  3.  3.  3.  0.  0.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [3. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[180.97374]
 [168.07591]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 0.] 
cards in discard: [ 0. 29.  6.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [15. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -6.839585781097412
desired expected reward: 152.9895782470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[158.82141]
 [165.67834]
 [143.09479]
 [166.98679]
 [179.9298 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 6. 0.] 
cards in discard: [ 0. 29.  6.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 24. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [15. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -7.829110622406006
desired expected reward: 169.07568359375



buy possibilites: [-1] 
expected returns: [[226.94463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 6. 0.] 
cards in discard: [ 0. 29.  6.  3.  0.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [15. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -35 

action type: buy - action 3.0
Learning step: -4.927665710449219
desired expected reward: 160.750732421875






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [15. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.  3.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3] -> size -> 22 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.  3.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3] -> size -> 22 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.  3.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3] -> size -> 22 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 0. 29.  6.  3.  0.  0.  3.  3.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3] -> size -> 22 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[176.67624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 0. 29.  6.  3.  0.  0.  3.  3.  3.  8.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 16. 15.  0.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -9.071008682250977
desired expected reward: 217.8736114501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[152.8629 ]
 [158.55128]
 [156.6597 ]
 [143.23192]
 [162.59346]
 [158.15067]
 [156.3352 ]
 [165.05437]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 0. 29.  6.  3.  0.  0.  3.  3.  3.  8.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 16. 15.  0.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.824643135070801
desired expected reward: 167.6741485595703



buy possibilites: [-1] 
expected returns: [[151.33583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 0. 29.  6.  3.  0.  0.  3.  3.  3.  8.  0.  6.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 16. 15.  0.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -15 

action type: buy - action 1.0
Learning step: -5.2725067138671875
desired expected reward: 153.27874755859375






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  0. 16. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  3.  6.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  0. 16. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  3.  6.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  0. 16. 15.  0.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  3.  6.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 1.  3.  6.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[157.46599]
 [148.23296]
 [145.10646]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6.  8. 15.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  3.  3.] 
adversary cards in discard: [ 0.  0. 16. 15.  0.  0. 14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -5.87870979309082
desired expected reward: 145.45712280273438



action possibilites: [-1] 
expected returns: [[165.97986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  3.  3.] 
adversary cards in discard: [ 0.  0. 16. 15.  0.  0. 14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 15.0
Learning step: -4.029165744781494
desired expected reward: 138.24508666992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[145.12407]
 [150.99336]
 [131.45741]
 [152.33807]
 [164.32927]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  3.  3.] 
adversary cards in discard: [ 0.  0. 16. 15.  0.  0. 14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -5.553691387176514
desired expected reward: 160.42616271972656






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3.  3.] 
cards in discard: [ 0.  0. 16. 15.  0.  0. 14.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  0.  0.  8. 29.] 
adversary cards in discard: [15.  1.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3.  3.] 
cards in discard: [ 0.  0. 16. 15.  0.  0. 14.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  0.  0.  8. 29.] 
adversary cards in discard: [15.  1.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  0.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[124.67906]
 [115.99263]
 [118.30573]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  8. 29.] 
cards in discard: [15.  1.  3.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -7.195700168609619
desired expected reward: 157.13356018066406



action possibilites: [-1.  8.] 
expected returns: [[198.0424]
 [190.7914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 3.] 
cards in discard: [15.  1.  3.  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 29.0
Learning step: -2.102043628692627
desired expected reward: 114.64287567138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[186.14987]
 [193.59879]
 [190.5545 ]
 [173.17401]
 [198.39342]
 [193.26518]
 [190.30617]
 [200.51619]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 8. 3.] 
cards in discard: [15.  1.  3.  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -6.231194019317627
desired expected reward: 191.81118774414062



buy possibilites: [-1] 
expected returns: [[131.66061]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 8. 3.] 
cards in discard: [15.  1.  3.  6.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -7.135739326477051
desired expected reward: 186.12940979003906






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 14.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14.  3.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 14.  3.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 14.  3.  8.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[70.55412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.668294429779053
desired expected reward: 124.99231719970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.106304]
 [62.528442]
 [51.083195]
 [63.67498 ]
 [69.97774 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -3.7225425243377686
desired expected reward: 65.8212890625



buy possibilites: [-1] 
expected returns: [[85.889114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 8.0
Learning step: -2.501244068145752
desired expected reward: 61.173736572265625






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [15.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.  8.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8] -> size -> 25 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.  8.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8] -> size -> 25 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[64.43923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.  8.  6.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -4.49457311630249
desired expected reward: 81.39453887939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[52.26369 ]
 [56.283264]
 [43.137245]
 [57.41873 ]
 [66.71042 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.  8.  6.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -3.596330404281616
desired expected reward: 60.84290313720703



buy possibilites: [-1] 
expected returns: [[94.228294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [15.  1.  3.  6.  8.  8. 29.  6.  0.  0.  8.  3.  8.  6.  3.  0.  3.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -17.236726760864258
desired expected reward: 25.90053367614746






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6] -> size -> 26 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6] -> size -> 26 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6] -> size -> 26 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6] -> size -> 26 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[101.87979]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -4.735823154449463
desired expected reward: 89.49246978759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 79.12896 ]
 [ 88.41481 ]
 [ 86.1344  ]
 [ 63.933563]
 [ 82.83435 ]
 [ 97.63898 ]
 [ 87.47719 ]
 [ 91.655396]
 [ 73.658226]
 [ 85.37565 ]
 [ 84.26314 ]
 [105.461426]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -5.051351070404053
desired expected reward: 91.64161682128906



buy possibilites: [-1] 
expected returns: [[79.5854]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -12 

action type: buy - action 15.0
Learning step: -3.022486448287964
desired expected reward: 81.24067687988281






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.  0. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 6. 15.  6.  0.  3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6 15] -> size -> 27 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.  0. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [15.  6.  0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6 15] -> size -> 27 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.  0. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  8.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [15.  6.  0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6 15] -> size -> 27 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3. 10. 14.  3.  8. 15.  0.  3.  3.  0.  0.  0. 16.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [15.  6.  0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6 15] -> size -> 27 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[80.95693 ]
 [67.198074]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8
  8  6 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[   -5     0     1   -40     0     0     0     0     0     0     0     0
     0 -1500    57     0] 
sum of rewards: -1487 

action type: discard_down_to_3_cards - action 7
Learning step: -77.03507995605469
desired expected reward: 10.480400085449219



action possibilites: [-1] 
expected returns: [[149.15973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 15.0
Learning step: -1.205155611038208
desired expected reward: 66.01983642578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[123.4316 ]
 [135.08368]
 [132.27391]
 [106.16691]
 [144.6519 ]
 [133.88333]
 [131.30046]
 [152.37901]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -5.619418621063232
desired expected reward: 143.54031372070312






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [6. 8. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[84.246574]
 [75.55244 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 6. 6.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [10. 14.  0. 11.  8.] 
adversary cards in discard: [ 1.  0. 15.  0.  0.  3.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -8.008234977722168
desired expected reward: 144.37075805664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.91989 ]
 [58.388138]
 [82.94831 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 6. 6.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [10. 14.  0. 11.  8.] 
adversary cards in discard: [ 1.  0. 15.  0.  0.  3.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -4.797009468078613
desired expected reward: 79.4495620727539



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [10. 14.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0. 11.  8.] 
cards in discard: [ 1.  0. 15.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  5.  9.  7.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [0. 3. 1. 3. 8.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  8.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  5.  9.  6.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [0. 3. 1. 3. 8.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  8.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 23. 30.  8.  5.  9.  6.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [0. 3. 1. 3. 8.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[68.39428 ]
 [63.856155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 8.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  5.  9.  6.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -4.852824687957764
desired expected reward: 78.09548950195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[55.457073]
 [60.052776]
 [58.797306]
 [48.670372]
 [63.741734]
 [59.65751 ]
 [58.489796]
 [66.40018 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 8.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 23. 30.  8.  5.  9.  6.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -4.112893104553223
desired expected reward: 61.10099792480469



buy possibilites: [-1] 
expected returns: [[88.873024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 8.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -18.183876037597656
desired expected reward: 30.486495971679688






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  8.  0. 29.  8.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.  6.  0.  3.
  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 29.  8.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.  6.  0.  3.
  1.  3.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 29.  8.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.  6.  0.  3.
  1.  3.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11 22] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 29.  8.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.  6.  0.  3.
  1.  3.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[92.61438 ]
 [83.017815]
 [79.39102 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.  6.  0.  3.
  1.  3.  8.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  9.  9.  7.] 
adversary cards in hand: [16.  0.  0.  3.  3.] 
adversary cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8. 22. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11 22] -> size -> 26 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[   -5     0     0   -50     0     0     0     0     0     0     0     0
     0 -1800    48     0] 
sum of rewards: -1807 

action type: discard_down_to_3_cards - action 3
Learning step: -89.93460845947266
desired expected reward: -59.53478240966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.71459]
 [62.14526]
 [92.77036]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.] 
cards in discard: [15.  3.  0.  0.  0.  0.  6.  3. 15.  6.  6.  8.  3.  6.  6.  6.  0.  3.
  1.  3.  8.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  9.  9.  7.] 
adversary cards in hand: [16.  0.  0.  3.  3.] 
adversary cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8. 22. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11 22] -> size -> 26 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -5.623064994812012
desired expected reward: 86.99134063720703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [16.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.  3.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8. 22. 14.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1
 11 22] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  9.  9.  7.] 
adversary cards in hand: [3. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8. 22. 14.  0.  0.  0.  3.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [3. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8. 22. 14.  0.  0.  0.  3.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [3. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1.  0. 15.  0.  0.  3. 11. 11. 10. 14.  0.  8. 22. 14.  0.  0.  0.  3.
 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [3. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[50.17903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -5.814143180847168
desired expected reward: 86.95626068115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.3887  ]
 [38.185474]
 [48.957737]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.6552655696868896
desired expected reward: 44.09482955932617



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [3. 3. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 23. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [3. 3. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 22. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [3. 3. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [8. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[95.770096]
 [88.13436 ]
 [88.13436 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 8. 0.] 
cards in discard: [3. 3. 6. 3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29 15  6  6  8  8  6  3  6  0  0  3  1  8  8
  6 15  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -3.142399787902832
desired expected reward: 45.815330505371094



action possibilites: [-1] 
expected returns: [[49.58479]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [3. 3. 6. 3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 29 15  6  6  8  6  3  6  0  0  3  1  8  8  6 15
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 5
Learning step: -4.540622234344482
desired expected reward: 73.5849838256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.945972]
 [26.490698]
 [52.819576]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [3. 3. 6. 3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 29 15  6  6  8  6  3  6  0  0  3  1  8  8  6 15
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 22. 30.  8.  4.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -3.3088200092315674
desired expected reward: 46.275970458984375



buy possibilites: [-1] 
expected returns: [[28.685919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [3. 3. 6. 3. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 29 15  6  6  8  6  3  6  0  0  3  1  8  8  6 15
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 22. 30.  8.  3.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3] -> size -> 28 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -17.979101181030273
desired expected reward: 8.511598587036133






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  3.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 29 15  6  6  8  6  3  6  0  0  3  1  8  8  6 15
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 22. 30.  8.  3.  9.  6.  4. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 29 15  6  6  8  6  3  6  0  0  3  1  8  8  6 15
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 22. 30.  8.  3.  9.  6.  3. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 29 15  6  6  8  6  3  6  0  0  3  1  8  8  6 15
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [8. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.080902]
 [ 9.971934]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 29 15  6  6  8  6  3  6  0  0  3  1  8  8  6 15
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  3.  9.  6.  3. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8] -> size -> 29 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -4.457568645477295
desired expected reward: 24.228349685668945



action possibilites: [-1] 
expected returns: [[65.6311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  3.  9.  6.  3. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.05830369144678116
desired expected reward: 4.426226615905762





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.636417]
 [57.036022]
 [70.501305]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 22. 30.  8.  3.  9.  6.  3. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -3.0405330657958984
desired expected reward: 62.59056854248047



buy possibilites: [-1] 
expected returns: [[28.27592]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  3. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -4.819030284881592
desired expected reward: 50.285743713378906






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  3. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  8.  6.  0. 29.] 
adversary cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  3. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  8.  6.  0. 29.] 
adversary cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  8.  6.  0. 29.] 
adversary cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 6.  8.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[60.744667]
 [55.85856 ]
 [57.25197 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  0. 29.] 
cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [11. 22.  8. 10. 16.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.  8.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -2.3015449047088623
desired expected reward: 25.974376678466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.87608 ]
 [47.288914]
 [60.26413 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  6.  0. 29.] 
cards in discard: [3. 3. 6. 3. 3. 6. 8. 6. 0. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [11. 22.  8. 10. 16.] 
adversary cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.  8.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -4.02025842666626
desired expected reward: 56.72441482543945



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [11. 22.  8. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.  8. 10. 16.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 22.  8. 10. 16.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.  8.  0.  3.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [15.  0. 15.  1.  3.] 
adversary cards in discard: [ 3.  3.  6.  3.  3.  6.  8.  6.  0.  0.  8.  0.  6.  8.  6.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10. 16. 14.  1.  0.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.  8.  0.  3.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [15.  0. 15.  1.  3.] 
adversary cards in discard: [ 3.  3.  6.  3.  3.  6.  8.  6.  0.  0.  8.  0.  6.  8.  6.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 10. 16. 14.  1.  0.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.  8.  0.  3.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [15.  0. 15.  1.  3.] 
adversary cards in discard: [ 3.  3.  6.  3.  3.  6.  8.  6.  0.  0.  8.  0.  6.  8.  6.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 10. 16. 14.  1.  0.] 
cards in discard: [ 3. 11.  0.  0.  0.  3.  8. 10.  0.  0.  0.  3.  8.  0.  3.  0.  0. 15.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [15.  0. 15.  1.  3.] 
adversary cards in discard: [ 3.  3.  6.  3.  3.  6.  8.  6.  0.  0.  8.  0.  6.  8.  6.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [15.  0. 15.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[48.48581 ]
 [41.843346]
 [41.843346]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  1.  3.] 
cards in discard: [ 3.  3.  6.  3.  3.  6.  8.  6.  0.  0.  8.  0.  6.  8.  6.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -4.2086944580078125
desired expected reward: 56.055450439453125



action possibilites: [-1] 
expected returns: [[47.67985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  3.] 
cards in discard: [ 3.  3.  6.  3.  3.  6.  8.  6.  0.  0.  8.  0.  6.  8.  6.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 15.0
Learning step: -2.2193710803985596
desired expected reward: 39.62398147583008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[38.220222]
 [41.563805]
 [40.540897]
 [34.293354]
 [32.582203]
 [39.498596]
 [44.443985]
 [41.30668 ]
 [47.573597]
 [42.575893]
 [36.085793]
 [38.020187]
 [40.343666]
 [34.232765]
 [39.87559 ]
 [46.64926 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3.] 
cards in discard: [ 3.  3.  6.  3.  3.  6.  8.  6.  0.  0.  8.  0.  6.  8.  6.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -2.664060354232788
desired expected reward: 45.01579284667969



buy possibilites: [-1] 
expected returns: [[59.947124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3.] 
cards in discard: [ 3.  3.  6.  3.  3.  6.  8.  6.  0.  0.  8.  0.  6.  8.  6.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 5 
card supply: [13. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -3.2622017860412598
desired expected reward: 34.958038330078125






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [1. 6. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [1. 8. 3.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  9.  8. 10.  8.  9.  7.] 
adversary cards in hand: [1. 8. 3.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  8.  8. 10.  8.  9.  7.] 
adversary cards in hand: [1. 8. 3.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[37.422703]
 [35.78733 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3.] 
cards in discard: [6. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  8.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29] -> size -> 32 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: discard_down_to_3_cards - action 5
Learning step: -1.5320289134979248
desired expected reward: 1.2819442749023438



action possibilites: [-1] 
expected returns: [[127.38804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [6. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  8.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.6834203600883484
desired expected reward: 35.30960464477539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[112.75351]
 [115.80516]
 [105.90716]
 [116.48468]
 [124.21485]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 22. 30.  8.  3.  9.  6.  2. 10.  8.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -5.503749370574951
desired expected reward: 121.88429260253906



buy possibilites: [-1] 
expected returns: [[78.46945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6. 0. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 22. 30.  8.  2.  9.  6.  2. 10.  8.  8. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29] -> size -> 32 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -20.829795837402344
desired expected reward: 85.07736206054688






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [29. 14.  3.  0.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  2.  9.  6.  2. 10.  8.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [6. 0. 6. 8. 1.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [29. 14.  3.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  2.  9.  6.  2. 10.  8.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [6. 0. 6. 8. 1.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [29. 14.  3.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 22. 30.  8.  2.  9.  6.  2. 10.  8.  8. 10.  8.  9.  7.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [6. 0. 6. 8. 1.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [6. 0. 6. 8. 1.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [8. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[7.8789816]
 [4.030015 ]
 [4.030015 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [6. 0. 6. 8. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [16.  0. 15.  8.  8.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29 14] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -7.09627103805542
desired expected reward: 71.37318420410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[3.0419462 ]
 [4.4258738 ]
 [0.84558606]
 [4.821908  ]
 [8.529563  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [6. 0. 6. 8. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [16.  0. 15.  8.  8.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29 14] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.583930730819702
desired expected reward: 4.2950639724731445



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [16.  0. 15.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.  8.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 15.  8.  8.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 15 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11
 22 10  0  3  8  8  0 29 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 29.  0.  0.  6.] 
adversary cards in discard: [6. 0. 6. 8. 1. 8. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 29.  0.  0.  6.] 
adversary cards in discard: [6. 0. 6. 8. 1. 8. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 29.  0.  0.  6.] 
adversary cards in discard: [6. 0. 6. 8. 1. 8. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [ 3. 29.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.970823]
 [11.913178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  6.] 
cards in discard: [6. 0. 6. 8. 1. 8. 8. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: -3.3812427520751953
desired expected reward: 5.148333549499512





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 3.4596753 ]
 [ 6.071634  ]
 [ 0.31776166]
 [ 6.4894996 ]
 [13.89642   ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  6.] 
cards in discard: [6. 0. 6. 8. 1. 8. 8. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.6370561122894287
desired expected reward: 6.29383659362793



buy possibilites: [-1] 
expected returns: [[64.63831]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  6.] 
cards in discard: [6. 0. 6. 8. 1. 8. 8. 0. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -3.518620729446411
desired expected reward: -0.058962106704711914






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.  0.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 15.  3.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  8.  1.  8.  8.  0.  0.  3.  0.  3. 29.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  0.  0.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 15.  3.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  8.  1.  8.  8.  0.  0.  3.  0.  3. 29.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 15.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[52.979427]
 [45.445732]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  6.  3.] 
cards in discard: [ 6.  0.  6.  8.  1.  8.  8.  0.  0.  3.  0.  3. 29.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  3.  1. 22.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -5.413388252258301
desired expected reward: 59.22492599487305



action possibilites: [-1] 
expected returns: [[39.341694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 3.] 
cards in discard: [ 6.  0.  6.  8.  1.  8.  8.  0.  0.  3.  0.  3. 29.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  3.  1. 22.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action 15.0
Learning step: -3.687098741531372
desired expected reward: 41.75864028930664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.948616]
 [23.113344]
 [39.64988 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3.] 
cards in discard: [ 6.  0.  6.  8.  1.  8.  8.  0.  0.  3.  0.  3. 29.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  2.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  3.  1. 22.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -3.5456387996673584
desired expected reward: 35.79605484008789



buy possibilites: [-1] 
expected returns: [[35.74186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3.] 
cards in discard: [ 6.  0.  6.  8.  1.  8.  8.  0.  0.  3.  0.  3. 29.  0.  0.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  1.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  3.  1. 22.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -357 

action type: buy - action 6.0
Learning step: -18.201475143432617
desired expected reward: 4.911867141723633






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  1. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 22.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  1.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  6.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0  6] -> size -> 26 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1. 22.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 28. 29. 22. 30.  8.  1.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  6.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0  6] -> size -> 26 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1. 22.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  6.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0  6] -> size -> 26 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[5.658462 ]
 [3.4883256]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  6. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.  3.  0.  0.  3.  1. 22.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2  3] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.030952453613281
desired expected reward: 29.710906982421875



action possibilites: [-1] 
expected returns: [[46.299484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.  3.  0.  0.  3.  1. 22.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2  3] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 15.0
Learning step: -2.482677698135376
desired expected reward: 1.0056450366973877





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.522102]
 [39.139244]
 [37.765587]
 [29.452011]
 [36.324875]
 [42.61105 ]
 [38.7193  ]
 [40.404747]
 [32.254833]
 [37.42269 ]
 [36.72514 ]
 [44.960426]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  2. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.  3.  0.  0.  3.  1. 22.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2  3] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -4.798463344573975
desired expected reward: 41.50102233886719



buy possibilites: [-1] 
expected returns: [[21.63134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0
  6  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.  3.  0.  0.  3.  1. 22.] 
adversary owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2  3] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -65.0 

action type: buy - action 8.0
Learning step: -4.699260234832764
desired expected reward: 34.02003860473633






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 11.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.  3.  0.  0.  3.  1. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 10  3 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22
 10  0  3  8  8  0 29 14  2  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.] 
adversary owned cards: [ 0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0
  6  8] -> size -> 26 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.  3.  0.  0.  3.  1. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.] 
adversary owned cards: [ 0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0
  6  8] -> size -> 26 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [29. 14.  3.  0.  3.  0. 14. 10.  0.  0.  0.  0. 14.  2. 16.  0.  8.  8.
  3. 11. 10.  0.  0.  3.  0.  0.  3.  1. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.] 
adversary owned cards: [ 0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0
  6  8] -> size -> 26 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 0. 15.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-6.871767 ]
 [-6.4817877]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  6.] 
cards in discard: [ 8. 15.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0
  6  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 10.  1.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3] -> size -> 32 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -5.081212520599365
desired expected reward: 16.550127029418945



action possibilites: [-1] 
expected returns: [[-6.9248557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8. 15.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 10.  1.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3] -> size -> 32 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action 15.0
Learning step: -2.6817197799682617
desired expected reward: -9.163507461547852





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-5.99438  ]
 [-7.3037353]
 [-6.457817 ]
 [-4.070237 ]
 [-6.457201 ]
 [-7.5981393]
 [-7.2291026]
 [-7.2369466]
 [-4.815791 ]
 [-6.372503 ]
 [-5.999815 ]
 [-7.0129223]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8. 15.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 28. 29. 21. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 10.  1.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3] -> size -> 32 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -2.6403939723968506
desired expected reward: -9.5652494430542



buy possibilites: [-1] 
expected returns: [[-0.22709799]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8. 15.  6.  0.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0  6
  8  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 28. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 10.  1.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3] -> size -> 32 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -44.0 

action type: buy - action 3.0
Learning step: -1.8822189569473267
desired expected reward: -8.340034484863281






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  1.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  8.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [8. 6. 0. 8. 3.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.] 
adversary owned cards: [ 3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0  6
  8  3] -> size -> 26 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  8.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [8. 6. 0. 8. 3.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.] 
adversary owned cards: [ 3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0  6
  8  3] -> size -> 26 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  8.  8.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [8. 6. 0. 8. 3.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.] 
adversary owned cards: [ 3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0  6
  8  3] -> size -> 26 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [8. 6. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[ 1.0545704]
 [-5.561392 ]
 [-5.561392 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 8. 3.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  8  6  3  6  0  0  3  1  8  8  6 15  6  6  0  0  6  0  6
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 22. 16.  0. 14.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3  1] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -3.3509907722473145
desired expected reward: -3.5780887603759766



action possibilites: [-1] 
expected returns: [[-9.098047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 22. 16.  0. 14.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3  1] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.1254351139068604
desired expected reward: -9.71085262298584





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-9.070608]
 [-7.649819]
 [-7.601624]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 22. 16.  0. 14.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3  1] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -2.026003360748291
desired expected reward: -11.12405014038086



buy possibilites: [-1] 
expected returns: [[10.259504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 22. 16.  0. 14.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3  1] -> size -> 33 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action 0.0
Learning step: -3.115630626678467
desired expected reward: -12.18624496459961






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0. 22. 16.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 16.  0. 14.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0
  3  8  8  0 29 14  2  3  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [29.  8.  3.  6.  3.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0] -> size -> 25 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0. 14.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [29.  8.  3.  6.  3.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0] -> size -> 25 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0. 14.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [29.  8.  3.  6.  3.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0] -> size -> 25 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0. 14.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [29.  8.  3.  6.  3.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0] -> size -> 25 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [29.  8.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[-6.9770474]
 [-7.5363894]
 [-7.727108 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.  6.  3.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 29.  8.  3.  2.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -3.9784762859344482
desired expected reward: 6.281027793884277





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-6.7420187]
 [-4.506495 ]
 [-6.97428  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3.  6.  3.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 29.  8.  3.  2.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.083138942718506
desired expected reward: -10.060187339782715



buy possibilites: [-1] 
expected returns: [[-6.544206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3.  6.  3.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 29.  8.  3.  2.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action 0.0
Learning step: -4.610143661499023
desired expected reward: -11.352163314819336






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  8.  3.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  3.  2.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.  0. 29.  8.  3.
  6.  3.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  3.  2.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 27. 29. 20. 30.  8.  1.  9.  6.  1. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.  0. 29.  8.  3.
  6.  3.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  3.  2.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 27. 29. 20. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.  0. 29.  8.  3.
  6.  3.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-6.895143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.  0. 29.  8.  3.
  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 29. 20. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8] -> size -> 35 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -3.1279304027557373
desired expected reward: -9.672136306762695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-7.461474]
 [-7.402057]
 [-5.689991]
 [-6.898268]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.  0. 29.  8.  3.
  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 29. 20. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8] -> size -> 35 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.1061577796936035
desired expected reward: -10.001300811767578



buy possibilites: [-1] 
expected returns: [[-7.66223]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [ 8. 15.  6.  0.  6.  3. 15.  3.  0.  6.  0.  8.  6.  3.  0. 29.  8.  3.
  6.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 29. 19. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -47 

action type: buy - action 3.0
Learning step: -2.152297258377075
desired expected reward: -9.554354667663574






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11.  0.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 29. 19. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3] -> size -> 27 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 29. 19. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3] -> size -> 27 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 29. 19. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3] -> size -> 27 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 26. 29. 19. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3] -> size -> 27 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [0. 8. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[31.02709 ]
 [28.666315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 29. 19. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -1.6918140649795532
desired expected reward: -9.354043960571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.030243]
 [29.650976]
 [29.102634]
 [26.293674]
 [25.529549]
 [28.579779]
 [31.018309]
 [32.45574 ]
 [30.187517]
 [27.060722]
 [27.883585]
 [29.000349]
 [26.227526]
 [28.750092]
 [31.95299 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 26. 29. 19. 30.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -3.64280104637146
desired expected reward: 27.384281158447266



buy possibilites: [-1] 
expected returns: [[-8.006737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [4.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3  4] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 29. 19. 29.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 28 

action type: buy - action 4.0
Learning step: -0.09483537822961807
desired expected reward: 26.198841094970703






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 29. 19. 29.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  8.  3. 29.] 
adversary cards in discard: [4. 0. 8. 0. 0. 1.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3  4] -> size -> 28 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 29. 19. 29.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  8.  3. 29.] 
adversary cards in discard: [4. 0. 8. 0. 0. 1.] 
adversary owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3  4] -> size -> 28 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[4.9782043]
 [3.0627809]
 [3.616539 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  3. 29.] 
cards in discard: [4. 0. 8. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3
  0  0  3  4] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 29. 19. 29.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0. 14. 10.  3.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -0.6089709401130676
desired expected reward: -8.615707397460938



action possibilites: [-1] 
expected returns: [[-8.096773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [4. 0. 8. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 29. 19. 29.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0. 14. 10.  3.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 7
Learning step: -1.3690788745880127
desired expected reward: -1.631049633026123





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-6.95503 ]
 [-5.400734]
 [-6.831093]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [4. 0. 8. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 29. 19. 29.  8.  1.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0. 14. 10.  3.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -0.9360929727554321
desired expected reward: -9.032866477966309



buy possibilites: [-1] 
expected returns: [[-7.449728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [4. 0. 8. 0. 0. 1. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0. 14. 10.  3.] 
adversary cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -335.0 

action type: buy - action 6.0
Learning step: -16.591800689697266
desired expected reward: -23.108196258544922






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 10.  3.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [8. 6. 3. 3. 6.] 
adversary cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6] -> size -> 27 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14. 10.  3.] 
cards in discard: [ 1.  0. 10.  1.  8.  8.  0.  0. 16. 22.  0. 14.  8.  0. 29.  8.  3.  2.
  1.  0. 11.  3.  0. 11.  0.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [8. 6. 3. 3. 6.] 
adversary cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6] -> size -> 27 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 6. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-6.258128]
 [-7.532784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 3. 6.] 
cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.53075909614563
desired expected reward: -9.980486869812012





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.20179 ]
 [-6.007526]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 3. 6.] 
cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.5741586685180664
desired expected reward: -8.832283020019531



buy possibilites: [-1] 
expected returns: [[20.556187]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 3. 6.] 
cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action 0.0
Learning step: -3.4773964881896973
desired expected reward: -9.679183959960938






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [6. 6. 3. 0. 6.] 
adversary cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [6. 3. 6.] 
adversary cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [6. 3. 6.] 
adversary cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 5. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [6. 3. 6.] 
adversary cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.420404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6.] 
cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_down_to_3_cards - action 0
Learning step: -2.2466509342193604
desired expected reward: -0.42444872856140137





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.042168]
 [25.998589]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -3.5832011699676514
desired expected reward: 22.837203979492188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  6.  3.] 
adversary cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.
  6.  3.  6.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  6.  3.] 
adversary cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.
  6.  3.  6.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 15.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[3.5720816]
 [2.2644777]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.
  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [22.  3. 10.  0.  1.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -3.982316732406616
desired expected reward: 22.016271591186523





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[3.3269467]
 [5.4637346]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.
  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [22.  3. 10.  0.  1.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.826519727706909
desired expected reward: 0.7455642223358154



buy possibilites: [-1] 
expected returns: [[44.5756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  6.  3.] 
cards in discard: [ 4.  0.  8.  0.  0.  1.  6.  8.  0. 29.  0.  8.  6.  3.  3.  6.  6.  0.
  6.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [22.  3. 10.  0.  1.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: -3.4133965969085693
desired expected reward: -0.08645033836364746






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [22.  3. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3. 10.  0.  1.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 29.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  1.  0.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 29.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0.  1. 10. 14.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 22. 11. 16.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 29.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0.  1. 14.  0.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 22. 11. 16. 10.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 29.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  0.  1. 14.  0.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 22. 11. 16. 10.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 4. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 29.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 6. 29.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[-10.15815 ]
 [-10.846814]
 [ -9.935484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3.  3. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 3. 0. 8. 2.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.209704875946045
desired expected reward: 39.36589431762695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -9.68263]
 [-10.04584]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  3.  3. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 3. 0. 8. 2.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.4634954929351807
desired expected reward: -12.621648788452148



buy possibilites: [-1] 
expected returns: [[-7.1006174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  3.  3. 15.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [0. 3. 0. 8. 2.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action 0.0
Learning step: -3.9256322383880615
desired expected reward: -13.60826301574707






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 2.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [8. 3. 6. 6. 0.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 2.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  9.  7.] 
adversary cards in hand: [8. 3. 6. 6. 0.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 2.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [8. 3. 6. 6. 0.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [8. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-6.2029834]
 [-7.414455 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 6. 0.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 11.  1.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22] -> size -> 39 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.5463571548461914
desired expected reward: -9.646974563598633





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.778166]
 [-7.019169]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 6. 0.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 11.  1.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22] -> size -> 39 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.6051883697509766
desired expected reward: -8.808164596557617



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.  1.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 0. 6. 8.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.  1.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 0. 6. 8.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.  1.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 2. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 0. 6. 8.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.] 
adversary owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [0. 1. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[7.554367 ]
 [6.2493286]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6. 8.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  0  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0
  3  4  6  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 14.  0.  8. 29.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.  0.  8.  0. 11.  1.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -2.241802453994751
desired expected reward: -9.260967254638672



action possibilites: [-1] 
expected returns: [[6.89904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 14.  0.  8. 29.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.  0.  8.  0. 11.  1.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 0
Learning step: -1.8590755462646484
desired expected reward: 3.4270052909851074





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.1459074 ]
 [-2.4474566 ]
 [-2.0034392 ]
 [ 0.42106795]
 [-2.2361462 ]
 [ 3.441557  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 14.  0.  8. 29.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.  0.  8.  0. 11.  1.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -2.1073496341705322
desired expected reward: 4.791690826416016



buy possibilites: [-1] 
expected returns: [[21.382675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 14.  0.  8. 29.] 
adversary cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.  0.  8.  0. 11.  1.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -2.561594009399414
desired expected reward: -6.707508087158203






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  8. 29.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.  0.  8.  0. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.] 
adversary owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 29.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.  0.  8.  0. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.  8.  3.] 
adversary owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 29.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.  0.  8.  0. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.  8.  3.] 
adversary owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 29.] 
cards in discard: [ 0. 14.  0.  0.  8.  0.  3.  3.  3.  0.  0. 10. 22. 11. 16. 10.  3.  0.
  1.  0.  1. 14.  0. 22.  0.  3.  0.  8.  2.  0.  0.  8.  0. 11.  1. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  7.  8.  7.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.  8.  3.] 
adversary owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[1.7916923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  7.  8.  7.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0 10] -> size -> 41 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_down_to_3_cards - action 4
Learning step: -4.179250240325928
desired expected reward: 25.212018966674805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[1.0411947 ]
 [0.78175545]
 [0.65082216]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  7.  8.  7.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0 10] -> size -> 41 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.8203847408294678
desired expected reward: -1.0286924839019775



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  7.  8.  7.] 
adversary cards in hand: [15.  6.  4.  6.  0.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.  8.  3.
  6.  0.  0.] 
adversary owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  7.  8.  7.] 
adversary cards in hand: [15.  6.  4.  6.  0.] 
adversary cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.  8.  3.
  6.  0.  0.] 
adversary owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 


Player 1 won the game! 



Player 0 bought cards:
Copper: 11 
Silver: 1 
Gold: 0 
Estate: 5 
Duchy: 1 
Province: 0 
Curse: 10 

Remodel: 0 
Workshop: 1 
Chapel: 6 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  6.  4.  6.  0.] 
cards in discard: [ 0.  6. 29.  3.  3. 15.  8.  3.  6.  6.  0.  0.  8.  1.  0.  6.  8.  3.
  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 15  6  3  6  3  1  8  8  6 15  6  6  0  0  6  0  6  8  3  0  0  3
  4  6  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 19. 29.  8.  0.  9.  6.  0. 10.  8.  7. 10.  7.  8.  7.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0.] 
adversary owned cards: [ 8 10 16  3  3  0  0  0  0  3 14  0  0 14  0  0  0 11  1 11 22 10  0  3
  8  8  0 29 14  2  3  1  0  0  8  1  0  0 22  0 10  0] -> size -> 42 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -50    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -555 

action type: buy - action -1.0
Learning step: -27.782541275024414
desired expected reward: -27.13172721862793



