 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.6004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000035 

action type: buy - action -1
Learning step: -299999.09375
desired expected reward: -300043.21875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.58502 ]
 [85.272285]
 [79.8975  ]
 [72.471016]
 [84.8715  ]
 [81.498375]
 [76.19309 ]
 [72.471016]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.84090423583984



buy possibilites: [-1] 
expected returns: [[73.517204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 85.27227020263672






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.584175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.51720428466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 87.00206 ]
 [ 96.1213  ]
 [ 90.416336]
 [ 82.53138 ]
 [ 87.04194 ]
 [ 95.69806 ]
 [ 92.14358 ]
 [101.008415]
 [ 86.047554]
 [ 86.60906 ]
 [ 95.09457 ]
 [ 82.53138 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.828857421875



buy possibilites: [-1] 
expected returns: [[34.11581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 101.00841522216797






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[53.56934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.11581039428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[57.64246 ]
 [64.7428  ]
 [60.353115]
 [54.341484]
 [57.604836]
 [64.41126 ]
 [61.64867 ]
 [68.32445 ]
 [56.87315 ]
 [57.318935]
 [63.919674]
 [54.341484]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 51.825077056884766



buy possibilites: [-1] 
expected returns: [[29.712496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 68.3244400024414






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3.  1.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3.  1.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [1. 3. 0. 0. 0. 3. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3.  1.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[59.192753]
 [73.19495 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  1.  3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.712495803833008



action possibilites: [-1.] 
expected returns: [[78.86411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.98400115966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[86.32348 ]
 [94.24541 ]
 [89.36179 ]
 [85.817276]
 [82.40722 ]
 [86.35554 ]
 [93.8918  ]
 [90.85349 ]
 [98.80746 ]
 [98.30125 ]
 [85.46369 ]
 [88.887634]
 [85.9699  ]
 [83.201836]
 [93.3856  ]
 [82.40722 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.8641128540039



buy possibilites: [-1] 
expected returns: [[21.109434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 98.80745697021484






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.154764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.109434127807617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[32.473682]
 [38.97167 ]
 [34.97754 ]
 [32.02095 ]
 [29.184546]
 [32.4236  ]
 [38.66996 ]
 [36.166092]
 [42.61399 ]
 [42.161255]
 [31.719229]
 [34.474724]
 [32.171967]
 [29.839685]
 [38.21722 ]
 [29.184546]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.689062118530273



buy possibilites: [-1] 
expected returns: [[28.775267]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 42.613990783691406






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [10.  0.  1.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 29.  0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 29.  0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 29.  0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 29.  0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[40.40604 ]
 [54.768375]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 29.  0.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  1.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.775266647338867



action possibilites: [-1.] 
expected returns: [[63.50404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  1.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.09327697753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[68.25849 ]
 [75.44459 ]
 [71.00102 ]
 [64.69992 ]
 [68.24216 ]
 [75.11238 ]
 [72.32338 ]
 [79.112076]
 [67.45524 ]
 [67.93323 ]
 [74.625046]
 [64.69992 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  1.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.5040397644043



buy possibilites: [-1] 
expected returns: [[32.982594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [25.  0.  0.  0.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  1.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 79.11207580566406






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [10. 10.  1.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  1.  3.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  1.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
action values: 3 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 27. 30. 28. 30.  8. 10. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 1.  0. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 3.5602517]
 [12.823923 ]
 [13.154808 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8. 10. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 10. 10.  1.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.98259353637695



action possibilites: [-1] 
expected returns: [[24.800945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 10. 10.  1.  3.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 11.040006637573242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.541216]
 [34.073936]
 [30.062784]
 [27.093212]
 [24.383396]
 [27.507837]
 [33.775578]
 [31.268827]
 [37.756054]
 [37.3132  ]
 [26.803915]
 [29.581396]
 [27.239672]
 [25.011372]
 [33.334167]
 [24.383396]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 10. 10.  1.  3.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.800945281982422



buy possibilites: [-1] 
expected returns: [[49.465893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  0.  0.  3.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 10. 10.  1.  3.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 205 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 37.75605392456055






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 10. 10.  1.  3.  1.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 25.] 
adversary cards in discard: [25. 25.  1.  0. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 10. 10.  1.  3.  1.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 25.] 
adversary cards in discard: [25. 25.  1.  0. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 10. 10.  1.  3.  1.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 27. 30. 28. 30.  8.  9. 10. 10. 10.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 25.] 
adversary cards in discard: [25. 25.  1.  0. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[14.681761]
 [23.980305]
 [24.33544 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 25.] 
cards in discard: [25. 25.  1.  0. 29.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  9. 10. 10. 10.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.46589279174805



action possibilites: [-1] 
expected returns: [[11.445044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 29.  3.] 
cards in discard: [25. 25.  1.  0. 29.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10. 10. 10.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 18.93107032775879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.246912]
 [16.074072]
 [11.870956]
 [16.89199 ]
 [11.870956]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0. 29.  3.] 
cards in discard: [25. 25.  1.  0. 29.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  8. 10. 10. 10.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.445043563842773



buy possibilites: [-1] 
expected returns: [[21.245855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0. 29.  3.] 
cards in discard: [25. 25.  1.  0. 29.  0.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 16.891992568969727






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [6. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 25. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 25. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [ 6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 25. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 8. 25. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 25.] 
expected returns: [[-2.298949 ]
 [ 1.7791209]
 [ 5.5906386]
 [ 5.5906386]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [ 6. 11.  6.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.2458553314209



action possibilites: [-1] 
expected returns: [[23.966814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 3.761716365814209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[29.907236]
 [36.09076 ]
 [32.28915 ]
 [29.468454]
 [26.782835]
 [29.842184]
 [35.799793]
 [33.411083]
 [39.54555 ]
 [39.104126]
 [29.179087]
 [31.785318]
 [29.617868]
 [27.400663]
 [35.359375]
 [26.782835]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 28. 30.  8.  7. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.966814041137695



buy possibilites: [-1] 
expected returns: [[40.276085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0.  0.  0.  1.] 
cards in discard: [25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 39.54555892944336






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [10. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [25. 25.  8. 25.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  7. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [25. 25.  8. 25.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25] -> size -> 19 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-2.7315154]
 [ 5.638472 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  0.] 
cards in discard: [25. 25.  8. 25.  0.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6. 10. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.276084899902344



action possibilites: [-1] 
expected returns: [[-9.922161]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29. 29.] 
cards in discard: [25. 25.  8. 25.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  6. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6. 10. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.49926328659057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-7.45155  ]
 [-2.7728748]
 [-5.631893 ]
 [-9.785031 ]
 [-3.0074906]
 [-4.8275347]
 [-7.6858644]
 [-9.785031 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29. 29.] 
cards in discard: [25. 25.  8. 25.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 28. 30.  8.  6. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6. 10. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.922161102294922



buy possibilites: [-1] 
expected returns: [[-8.938599]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29. 29.] 
cards in discard: [25. 25.  8. 25.  0.  0.  0.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6. 10. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -2.7728757858276367






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6. 10. 10.  3.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6. 10. 10.  3.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6. 11.  6.  1.  0.  3.  3.  6. 10. 10.  3.  0.  0.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  8.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 1. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-5.3113236]
 [ 5.218949 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  8.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.9385986328125



action possibilites: [-1.] 
expected returns: [[-5.997884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  8.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 2.405860424041748





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-1.4457009 ]
 [ 2.5195398 ]
 [ 0.04332399]
 [-1.7602448 ]
 [-3.4135218 ]
 [-1.559499  ]
 [ 2.3183074 ]
 [ 0.7422929 ]
 [ 4.713489  ]
 [ 4.3919864 ]
 [-1.9526908 ]
 [-0.36944437]
 [-1.6411886 ]
 [-3.0390174 ]
 [ 1.9968033 ]
 [-3.4135218 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  8.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.9978837966918945



buy possibilites: [-1] 
expected returns: [[16.526125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  8.  9.  5.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 4.713490962982178






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  8.  9.  5.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 25.] 
adversary cards in discard: [25. 29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  8.  9.  5.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 25.] 
adversary cards in discard: [25. 29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  1.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  7.  9.  5.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 25.] 
adversary cards in discard: [25. 29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-10.762833 ]
 [ -2.2639403]
 [ -2.0368705]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 25.] 
cards in discard: [25. 29.  1.  3.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6. 10.  7.  9.  5.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0. 10.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.526124954223633



action possibilites: [-1] 
expected returns: [[-37.284603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.  3.] 
cards in discard: [25. 29.  1.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  7.  9.  5.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0. 10.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -2.9678750038146973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-30.877464]
 [-19.561125]
 [-26.420038]
 [-36.56725 ]
 [-31.599998]
 [-20.17298 ]
 [-24.639833]
 [-15.886158]
 [-32.60056 ]
 [-31.500069]
 [-21.275755]
 [-36.56725 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.  3.] 
cards in discard: [25. 29.  1.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  7.  9.  5.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0. 10.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.284603118896484



buy possibilites: [-1] 
expected returns: [[-37.433018]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.  3.] 
cards in discard: [25. 29.  1.  3.  3.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  7.  9.  5.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0. 10.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -15.886137008666992






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [11.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0. 10.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  7.  9.  5.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25.  1.] 
adversary cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  7.  9.  5.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25.  1.] 
adversary cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  7.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25.  1.] 
adversary cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  7.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25.  1.] 
adversary cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  6.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25.  1.] 
adversary cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25. 29. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-6.301544]
 [ 8.649866]
 [ 8.059038]
 [ 8.649866]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 25.  1.] 
cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  5. 10.  6.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  6.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -37.43301773071289



action possibilites: [-1] 
expected returns: [[13.91678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  1.  8. 25.] 
cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  4. 10.  6.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  6.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 8.64987564086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.44558 ]
 [19.908329]
 [17.166908]
 [13.642357]
 [19.673265]
 [17.912426]
 [15.252474]
 [13.642357]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  1.  8. 25.] 
cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 28. 30.  8.  4. 10.  6.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  6.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.916780471801758



buy possibilites: [-1] 
expected returns: [[22.80226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  1.  8. 25.] 
cards in discard: [25. 29.  1.  3.  3.  0.  0. 29. 25. 29.  0.  0.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  6.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  6.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 19.9083309173584






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10.  6.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  6.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  6.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  6.  9.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  6.  8.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  1.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-25.321726]
 [-15.766806]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  6.  8.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.  8. 10.
  0.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.80225944519043



action possibilites: [-1] 
expected returns: [[-19.001698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  3. 10.  6.  8.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.  8. 10.
  0.  0.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -16.974016189575195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-15.352722]
 [ -9.900452]
 [-13.18782 ]
 [-18.143475]
 [-15.685495]
 [-10.195688]
 [-12.325985]
 [ -7.747525]
 [-16.183458]
 [-15.654093]
 [-10.713667]
 [-18.143475]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 25. 30. 28. 30.  8.  3. 10.  6.  8.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.  8. 10.
  0.  0.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.001697540283203



buy possibilites: [-1] 
expected returns: [[-95.41222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  3. 29. 29.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  3. 10.  6.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 3. 1. 3.] 
adversary cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.  8. 10.
  0.  0.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -7.7475266456604






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.  8. 10.
  0.  0.  6.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  3. 10.  6.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 25.  1.] 
adversary cards in discard: [29. 25.  0.  1.  0.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.  8. 10.
  0.  0.  6.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 30. 28. 30.  8.  3. 10.  6.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 25.  1.] 
adversary cards in discard: [29. 25.  0.  1.  0.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 3.] 
cards in discard: [11. 11.  0.  0.  3.  1.  6. 14. 11. 10. 11.  6.  0.  0.  0.  6.  8. 10.
  0.  0.  6.  6.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 28. 30.  8.  3. 10.  6.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 25.  1.] 
adversary cards in discard: [29. 25.  0.  1.  0.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 0.  0.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-31.275263]
 [-19.022293]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 25.  1.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  3. 10.  6.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -95.41221618652344



action possibilites: [-1] 
expected returns: [[-37.83823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  1. 25. 25.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  6.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 6. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -19.02230453491211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-35.82756 ]
 [-27.898956]
 [-40.966076]
 [-32.994465]
 [-36.55369 ]
 [-40.966076]
 [-36.405476]
 [-28.371784]
 [-31.666203]
 [-23.42473 ]
 [-24.242268]
 [-36.94379 ]
 [-34.460316]
 [-36.22035 ]
 [-39.923916]
 [-29.17451 ]
 [-40.966076]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  1. 25. 25.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  6.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 6. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.83823013305664



buy possibilites: [-1] 
expected returns: [[-74.94607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  1. 25. 25.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 6. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 227.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -23.424734115600586






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [8. 3. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 6. 3.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  3.] 
adversary cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25. 25.  0.  0.  1.  1. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29
 25] -> size -> 25 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 6. 3.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  3.] 
adversary cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25. 25.  0.  0.  1.  1. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29
 25] -> size -> 25 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 6. 3.] 
cards in discard: [6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  3.] 
adversary cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25. 25.  0.  0.  1.  1. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29
 25] -> size -> 25 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 8.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-36.671154]
 [-26.180826]
 [-19.690556]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0.  3.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25. 25.  0.  0.  1.  1. 25. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 11.  6. 11.] 
adversary cards in discard: [6. 0. 8. 3. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -74.9460678100586



action possibilites: [-1.  8.] 
expected returns: [[-70.108925]
 [-51.02554 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25. 25.  0.  0.  1.  1. 25. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 11.  6. 11.] 
adversary cards in discard: [6. 0. 8. 3. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -19.690567016601562



action possibilites: [-1] 
expected returns: [[-1.9622755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25. 25.  0.  0.  1.  1. 25. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 11.  6. 11.] 
adversary cards in discard: [6. 0. 8. 3. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0] -> size -> 33 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -38.12376403808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 4.096311 ]
 [14.074537 ]
 [ 8.856304 ]
 [-2.482552 ]
 [13.77582  ]
 [10.773905 ]
 [ 3.4073167]
 [-2.482552 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25. 25.  0.  0.  1.  1. 25. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 11.  6. 11.] 
adversary cards in discard: [6. 0. 8. 3. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0] -> size -> 33 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.962275505065918



buy possibilites: [-1] 
expected returns: [[22.598839]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 25.  0.  1.  0.  3. 29. 29. 25. 25.  0.  0.  1.  1. 25. 25.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 11.  6. 11.] 
adversary cards in discard: [6. 0. 8. 3. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0] -> size -> 33 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 239 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 14.074522018432617






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [10.  0. 11.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  6. 11.] 
cards in discard: [6. 0. 8. 3. 6. 6. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  2. 10.  6.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6. 11.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  2. 10.  5.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6. 11.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 24. 30. 28. 30.  8.  2. 10.  5.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6. 11.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 30.  8.  2. 10.  5.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [25.  0. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[-67.54407 ]
 [-48.264286]
 [-48.264286]
 [-49.274242]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  2. 10.  5.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  0.  6.  3.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0] -> size -> 35 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.598838806152344



action possibilites: [-1] 
expected returns: [[-51.834446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  1. 10.  5.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  0.  6.  3.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -48.2642707824707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-46.144997]
 [-44.327473]
 [-49.90786 ]
 [-43.684765]
 [-49.90786 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 29.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 30. 28. 30.  8.  1. 10.  5.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  0.  6.  3.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -51.83444595336914



buy possibilites: [-1] 
expected returns: [[-102.48052]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 29.  0. 25. 25.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  1. 10.  5.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  0.  6.  3.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -43.684757232666016






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [11. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  6.  3.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  1. 10.  5.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1. 29. 29.  0.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8] -> size -> 26 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  6.  3.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 28. 30.  8.  1. 10.  5.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1. 29. 29.  0.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8] -> size -> 26 
adversary victory points: 2
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  1. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-51.287212]
 [-33.113438]
 [-34.03842 ]
 [-34.03842 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29. 29.  0.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  1. 10.  5.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -102.48052215576172



action possibilites: [-1] 
expected returns: [[-74.54023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  0.  1.  0.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  5.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6] -> size -> 37 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -33.113468170166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-67.05326 ]
 [-53.09717 ]
 [-74.045616]
 [-61.492107]
 [-68.615364]
 [-68.36131 ]
 [-53.928818]
 [-59.489964]
 [-46.821342]
 [-48.374825]
 [-69.447   ]
 [-64.36226 ]
 [-67.884895]
 [-72.96229 ]
 [-55.490887]
 [-74.045616]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29.  0.  1.  0.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  5.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6] -> size -> 37 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -74.54022979736328



buy possibilites: [-1] 
expected returns: [[-67.12216]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29.  0.  1.  0.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  5.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6] -> size -> 37 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -46.82138442993164






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [10.  1.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  3.  0.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  5.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  8.  3.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8 25] -> size -> 27 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  5.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  8.  3.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8 25] -> size -> 27 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  5.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  8.  3.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8 25] -> size -> 27 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  8.  3.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8 25] -> size -> 27 
adversary victory points: 2
player victory points: -5 





Player: 0 
cards in hand: [29.  0.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[-120.970795]
 [ -97.92515 ]
 [-107.85348 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  8.  3.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 1. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11] -> size -> 38 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -67.12216186523438



action possibilites: [-1.  8.] 
expected returns: [[-40.84404 ]
 [-26.522362]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25
  1  8 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 1. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11] -> size -> 38 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -102.37494659423828



action possibilites: [-1] 
expected returns: [[-176.06935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 1. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11] -> size -> 38 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -21.70206069946289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-175.4631 ]
 [-160.11984]
 [-169.35374]
 [-161.02957]
 [-167.1389 ]
 [-176.37283]
 [-183.1416 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 28. 30.  8.  0. 10.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 1. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11] -> size -> 38 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: -176.06935119628906



buy possibilites: [-1] 
expected returns: [[-181.17743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0. 29.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0. 10.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 1. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11] -> size -> 38 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -160.11984252929688






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [3. 6. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 0. 0.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0. 10.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1.  1. 25.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0. 29.  1.
 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1] -> size -> 27 
adversary victory points: 1
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 0. 0.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 23. 30. 28. 30.  8.  0. 10.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1.  1. 25.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0. 29.  1.
 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1] -> size -> 27 
adversary victory points: 1
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 0. 0.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1.  1. 25.] 
adversary cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0. 29.  1.
 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1] -> size -> 27 
adversary victory points: 1
player victory points: -5 





Player: 0 
cards in hand: [ 3.  0.  1.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-91.90127]
 [-59.61513]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  1. 25.] 
cards in discard: [ 8. 25.  0. 25. 29.  0. 25. 25. 25. 25.  1. 29. 29.  0.  1.  0. 29.  1.
 29.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.  3.  6.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16] -> size -> 39 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -181.17742919921875



action possibilites: [-1] 
expected returns: [[-78.87133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.  3.  6.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16] -> size -> 39 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -59.61518096923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-67.24859 ]
 [-52.352478]
 [-75.86172 ]
 [-60.69546 ]
 [-68.79406 ]
 [-68.17214 ]
 [-52.877747]
 [-57.952347]
 [-47.265   ]
 [-48.226326]
 [-69.68519 ]
 [-63.196045]
 [-68.13973 ]
 [-74.19309 ]
 [-53.780956]
 [-75.86172 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  3.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.  3.  6.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16] -> size -> 39 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -78.87133026123047



buy possibilites: [-1] 
expected returns: [[-56.175755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1. 0. 8.] 
cards in discard: [25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.  3.  6.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16] -> size -> 39 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -47.2650146484375






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 14.  0.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.  3.  6.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0. 29.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25] -> size -> 28 
adversary victory points: 1
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.  3.  6.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25] -> size -> 28 
adversary victory points: 1
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.  3.  6.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25] -> size -> 28 
adversary victory points: 1
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 6.  0.  8.  3.  6.  6.  3. 11.  0. 11. 10.  0.  6. 11.  6. 11. 11.  0.
  6.  3.  6. 11. 10.  1.  0.  3.  0.  6. 16.  3.  6.  1.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25] -> size -> 28 
adversary victory points: 1
player victory points: -5 





Player: 0 
cards in hand: [ 0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-37.47582]
 [-18.4704 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [14. 16.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14] -> size -> 40 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -21.307109832763672



action possibilites: [-1.] 
expected returns: [[-62.174644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [14. 16.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14] -> size -> 40 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -20.732532501220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-54.177395]
 [-40.517166]
 [-48.7398  ]
 [-41.325436]
 [-46.76302 ]
 [-54.985683]
 [-61.02374 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [14. 16.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14] -> size -> 40 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -62.174644470214844



buy possibilites: [-1] 
expected returns: [[-55.850193]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [14. 16.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14] -> size -> 40 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -40.517215728759766






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [14. 16.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  8. 25. 25.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1] -> size -> 29 
adversary victory points: 1
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  6.  0.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  8. 25. 25.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1] -> size -> 29 
adversary victory points: 1
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16.  6.  0.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 21. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  8. 25. 25.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1] -> size -> 29 
adversary victory points: 1
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16.  6.  0.] 
cards in discard: [1. 0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  8. 25. 25.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1] -> size -> 29 
adversary victory points: 1
player victory points: -5 





Player: 0 
cards in hand: [ 0.  1.  8. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 25.] 
expected returns: [[-39.840015]
 [-23.69213 ]
 [-14.167101]
 [-14.167101]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 25. 25.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 1.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0] -> size -> 42 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -55.85019302368164



action possibilites: [-1] 
expected returns: [[9.004568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 25.  1.  0.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 1.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0] -> size -> 42 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -14.167108535766602





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[13.019896]
 [17.989939]
 [ 8.851152]
 [15.218426]
 [12.351648]
 [12.64024 ]
 [17.755686]
 [15.980654]
 [20.340853]
 [19.949757]
 [11.962694]
 [14.640995]
 [12.630945]
 [ 9.643394]
 [17.36459 ]
 [ 8.851152]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 25.  1.  0.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  4.  7.  2.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 1.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0] -> size -> 42 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.004568099975586



buy possibilites: [-1] 
expected returns: [[-32.22704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 25.  1.  0.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 1.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0] -> size -> 42 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 20.34084129333496






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 1.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0. 25.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0. 25. 25.  0.
  1.  8. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25] -> size -> 30 
adversary victory points: 1
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 1.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0. 25.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0. 25. 25.  0.
  1.  8. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25] -> size -> 30 
adversary victory points: 1
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 1.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0. 25.] 
adversary cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0. 25. 25.  0.
  1.  8. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25] -> size -> 30 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [29. 29. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 25.] 
expected returns: [[-28.3794  ]
 [-14.493275]
 [-14.493275]
 [-14.493275]
 [-13.881788]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0. 25.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0. 25. 25.  0.
  1.  8. 25.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -32.2270393371582



action possibilites: [-1] 
expected returns: [[12.69495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  1. 25.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0. 25. 25.  0.
  1.  8. 25.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -13.881792068481445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[15.433971]
 [22.418556]
 [18.595617]
 [22.224302]
 [19.78816 ]
 [14.961479]
 [11.089851]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  0.  1. 25.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0. 25. 25.  0.
  1.  8. 25.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 21. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.694950103759766



buy possibilites: [-1] 
expected returns: [[-13.178583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  0.  1. 25.] 
cards in discard: [25. 25.  3.  0.  1.  1.  0.  8. 25. 29. 25.  1. 29.  0.  0. 25. 25.  0.
  1.  8. 25.  1.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6. 10.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 22.41855812072754






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [11.  6.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  6. 10.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  1. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1] -> size -> 31 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  6. 11.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  1. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1] -> size -> 31 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  1. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1] -> size -> 31 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 11.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  1. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1] -> size -> 31 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [ 1.  0.  1. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-87.09561 ]
 [-67.475746]
 [-67.475746]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 25. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  6.  3. 11.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.178583145141602



action possibilites: [-1] 
expected returns: [[-30.150265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 25.  0. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  6.  3. 11.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -67.47574615478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-24.299772]
 [-18.806698]
 [-27.05406 ]
 [-22.131819]
 [-24.847404]
 [-24.677822]
 [-19.113102]
 [-21.28105 ]
 [-16.166033]
 [-16.713669]
 [-25.153555]
 [-23.057518]
 [-24.606174]
 [-26.592222]
 [-19.660738]
 [-27.05406 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1. 25.  0. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  4.  7.  1.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  6.  3. 11.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -30.150264739990234



buy possibilites: [-1] 
expected returns: [[-47.387676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1. 25.  0. 29.] 
cards in discard: [25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  4.  7.  0.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  6.  3. 11.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 227.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -16.16603660583496






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  3. 11.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  4.  7.  0.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25. 29. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25] -> size -> 32 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  3.  7.  0.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25. 29. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25] -> size -> 32 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  3.  7.  0.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25. 29. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25] -> size -> 32 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [ 0.  1. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-55.598103]
 [-23.497587]
 [-25.123024]
 [-23.497587]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 29. 25.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  3.  7.  0.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11] -> size -> 45 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -47.38767623901367



action possibilites: [-1] 
expected returns: [[-45.434345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 25.  1. 29.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  3.  7.  0.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11] -> size -> 45 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -23.497629165649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-38.955444]
 [-26.127527]
 [-33.00064 ]
 [-40.498833]
 [-40.081837]
 [-26.554031]
 [-30.713097]
 [-23.450783]
 [-41.35029 ]
 [-35.677425]
 [-39.80818 ]
 [-45.254425]
 [-27.328756]
 [-46.495926]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 25.  1. 29.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  3.  7.  0.  5.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11] -> size -> 45 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -45.43434524536133



buy possibilites: [-1] 
expected returns: [[-15.440708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 25.  1. 29.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  3.  7.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11] -> size -> 45 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. 150.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 197.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -23.45079231262207






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [11.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  3.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  0.  9.  3.  7.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 29. 25.  0.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29] -> size -> 33 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  3.  7.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 29. 25.  0.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29] -> size -> 33 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  3.  7.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 29. 25.  0.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29] -> size -> 33 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  7.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 29. 25.  0.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29] -> size -> 33 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [ 3.  8. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25.] 
expected returns: [[23.251085]
 [27.633425]
 [31.28512 ]
 [31.654238]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29. 25.  0.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  7.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -15.44070816040039



action possibilites: [-1] 
expected returns: [[16.068424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  0.  0. 25.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  7.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.654233932495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[19.256952]
 [21.512705]
 [22.449003]
 [16.415617]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29.  0.  0. 25.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  7.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.068424224853516



buy possibilites: [-1] 
expected returns: [[-39.44924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29.  0.  0. 25.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 22.448997497558594






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 1. 1. 1.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29  8] -> size -> 34 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 1. 1. 1.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29  8] -> size -> 34 
adversary victory points: 1
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 0. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[5.387587]
 [9.852743]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 1. 1.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1
  8 25  1 25  1 25  1 25 29  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 10.  6.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.  0.  0.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -39.449241638183594



action possibilites: [-1] 
expected returns: [[44.896374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 10.  6.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.  0.  0.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 11.662635803222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[44.39394 ]
 [48.127953]
 [45.840084]
 [44.11026 ]
 [44.31727 ]
 [47.94725 ]
 [46.50111 ]
 [49.874786]
 [43.929558]
 [45.479744]
 [44.213238]
 [42.87029 ]
 [47.66357 ]
 [42.50673 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  4.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 10.  6.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.  0.  0.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.8963737487793



buy possibilites: [-1] 
expected returns: [[22.554983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  3.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 10.  6.] 
adversary cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.  0.  0.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. 150.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 197.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 49.874778747558594






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  6.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.  0.  0.  3.
  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  3.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25. 29.  8.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29] -> size -> 34 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 1.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.  0.  0.  3.
  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  3.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25. 29.  8.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29] -> size -> 34 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 1.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.  0.  0.  3.
  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  3.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25. 29.  8.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29] -> size -> 34 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 1.] 
cards in discard: [ 1.  0. 11. 14. 16.  6.  0.  3.  6.  6.  0.  3.  1.  1. 10. 11.  6.  0.
  6. 11. 11. 11.  0.  8.  6.  3.  1.  0. 11.  6.  0.  0.  3.  0.  0.  3.
  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  3.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 29. 25. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25. 29.  8.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29] -> size -> 34 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [ 0. 25. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 25.] 
expected returns: [[-33.382572]
 [-29.484703]
 [-29.701342]
 [-29.484703]
 [-29.484703]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 25. 25.] 
cards in discard: [25. 25.  1.  0.  1. 25.  0. 29. 29. 25.  0.  1. 29. 25.  1. 29.  8. 25.
  3.  8. 29.  0.  0. 25. 29.  8.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  3.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 11. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15] -> size -> 48 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.554983139038086



action possibilites: [-1] 
expected returns: [[-29.557213]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  3.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 11. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15] -> size -> 48 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -29.484704971313477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-23.0238  ]
 [-18.176908]
 [-20.643772]
 [-23.573885]
 [-18.380398]
 [-19.785883]
 [-16.923664]
 [-24.04242 ]
 [-23.378407]
 [-18.75417 ]
 [-26.04933 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  3.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 11. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15] -> size -> 48 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -29.557212829589844



buy possibilites: [-1] 
expected returns: [[-20.15964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25. 25.  0.  1.] 
cards in discard: [29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 11. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15] -> size -> 48 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -16.923667907714844






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 11. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11. 14.  6.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 27. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  8. 25. 25.  1.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29] -> size -> 35 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14.  6.] 
cards in discard: [3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  8. 25. 25.  1.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29] -> size -> 35 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  6.] 
cards in discard: [3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 18. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  8. 25. 25.  1.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29] -> size -> 35 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  6.] 
cards in discard: [3. 0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 18. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  8. 25. 25.  1.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29] -> size -> 35 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [25.  8. 25. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 25. 25.] 
expected returns: [[-36.945923]
 [-20.442583]
 [-28.044617]
 [-20.442583]
 [-20.442583]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 25. 25.  1.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0] -> size -> 50 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.159639358520508



action possibilites: [-1] 
expected returns: [[-37.13157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 25.  1. 29.  0.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0] -> size -> 50 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -20.44260597229004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-28.883692]
 [-12.726133]
 [-22.547459]
 [-13.586725]
 [-19.922989]
 [-29.744303]
 [-37.019085]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25. 25.  1. 29.  0.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 18. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0] -> size -> 50 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.131568908691406



buy possibilites: [-1] 
expected returns: [[-18.88654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25. 25.  1. 29.  0.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0] -> size -> 50 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 179 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -12.726188659667969






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  0. 11.  0.  6. 14.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0. 29.  1. 25.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1] -> size -> 36 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  0. 11.  0.  6. 14.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0. 29.  1. 25.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1] -> size -> 36 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0. 29.  1. 25.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1] -> size -> 36 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [29.  0. 29.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-39.16708]
 [-20.42687]
 [-20.42687]
 [-19.75741]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  1. 25.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  3.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0] -> size -> 51 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -18.886539459228516



action possibilites: [-1] 
expected returns: [[-41.008633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  1.  0.  0.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  3.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0] -> size -> 51 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -19.757362365722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-35.43556 ]
 [-28.78993 ]
 [-32.805286]
 [-36.122017]
 [-35.941635]
 [-29.1681  ]
 [-31.798357]
 [-26.34275 ]
 [-36.500183]
 [-33.997852]
 [-35.813705]
 [-38.224815]
 [-29.854548]
 [-38.772167]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  1.  0.  0.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  2.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  3.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0] -> size -> 51 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -41.00863265991211



buy possibilites: [-1] 
expected returns: [[-4.5188465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  1.  0.  0.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  3.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0] -> size -> 51 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. 120.   0.   0.  20.   0.   0.   0.   0. -20.   0.   0.
  32.   0.] 
sum of rewards: 147.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -26.342737197875977






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  3.  0.] 
cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  3.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29. 25.
 29.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29] -> size -> 37 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3. 0.] 
cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3. 14.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0 14] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  1.  7. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  3.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29. 25.
 29.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29] -> size -> 37 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 0.] 
cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3. 14.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0 14] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  1.  7. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  3.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29. 25.
 29.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29] -> size -> 37 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 0.] 
cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3. 14.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0 14  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  1.  7. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  3.] 
adversary cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29. 25.
 29.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29] -> size -> 37 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [25. 29. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 25.] 
expected returns: [[-29.041613]
 [-23.543118]
 [-23.815578]
 [-23.815578]
 [-23.543118]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29. 25.  3.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29. 25.
 29.  0. 29.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  1.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  1.  6.  3. 11.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3. 14.  0. 11.  6.  1.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0 14  0] -> size -> 53 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.51884651184082



action possibilites: [-1] 
expected returns: [[-41.591812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  3.  1.  1.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29. 25.
 29.  0. 29.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  1.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  1.  6.  3. 11.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3. 14.  0. 11.  6.  1.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0 14  0] -> size -> 53 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -23.54313087463379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-41.23737 ]
 [-39.104946]
 [-40.384552]
 [-41.44586 ]
 [-39.232876]
 [-40.080616]
 [-38.40659 ]
 [-41.608685]
 [-41.365765]
 [-39.474968]
 [-42.305267]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 25.  3.  1.  1.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29. 25.
 29.  0. 29.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  1.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  1.  6.  3. 11.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3. 14.  0. 11.  6.  1.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0 14  0] -> size -> 53 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -41.59181213378906



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 8 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 3 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29. 29. 25.  3.  1.  1.] 
cards in discard: [29. 25.  0. 29. 25. 25.  0.  1.  1. 25.  8. 25. 25.  1. 29.  0. 29. 25.
 29.  0. 29.  1.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 29 25 25 29 25  8 25  1 25 29  1 29 25  1  8
 25  1 25  1 25  1 25 29  8 29 29  1 29 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 17. 30. 26. 30.  8.  0.  9.  3.  6.  0.  0.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  1.  6.  3. 11.] 
adversary cards in discard: [ 3.  0. 11.  0.  6. 14.  6.  0.  0.  0.  0.  0.  3. 14.  0. 11.  6.  1.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 10  3  3  6  0  6 11  6  6 11 11
  6 14 11  6  8  6  0  6  0 11  0  6  6 11 16 14  1  0  3  1 11  1  0 15
  3  0  0 14  0] -> size -> 53 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[     -5 3000000       0     120       0       0      20       0       0
       0       0     -30       0       0      64       0] 
sum of rewards: 3000169 

action type: buy - action 29.0
Learning step: 300020.75
desired expected reward: 299982.34375



