 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0    -400       0       0       8       0] 
sum of rewards: 2999783 

action type: buy - action 8.0
Learning step: 299979.46875
desired expected reward: 299968.03125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [11.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16. 11.  0.  0. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16. 11.  0.  0. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16. 11.  0.  0. 29.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [29.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  3.] 
adversary cards in discard: [ 1. 11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  3.] 
adversary cards in discard: [ 1. 11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 5 
card supply: [22. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  3.] 
adversary cards in discard: [ 1. 11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0. 16.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  3.] 
cards in discard: [ 1. 11. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 1. 11. 29. 11.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 1. 11. 29. 11.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 5 
card supply: [21. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [16. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  3.  3.  0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11. 29.  0.] 
adversary cards in discard: [ 0. 16. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11. 29.  0.] 
adversary cards in discard: [ 0. 16. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11. 29.  0.] 
adversary cards in discard: [ 0. 16. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [11.  3. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11. 29.  0.] 
cards in discard: [ 0. 16. 11.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  3.] 
cards in discard: [ 0. 16. 11.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.  0.  3.] 
cards in discard: [ 0. 16. 11.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 0. 16. 11.  3.  3.  0. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 0. 16. 11.  3.  3.  0. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 5 
card supply: [18. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 0. 16. 11.  3.  3.  0. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 0. 16. 11.  3.  3.  0. 29. 11.  3. 11.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 0. 16. 11.  3.  3.  0. 29. 11.  3. 11.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 0. 16. 11.  3.  3.  0. 29. 11.  3. 11.  0.  3. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 1. 23. 29.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 1. 23. 29.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 1. 23. 29.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 1. 23. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 29.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23. 29.  0.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
action values: 0 
buys: 2 
player value: 4 
card supply: [17. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [23.  1. 29.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [23.  1. 29.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 0 
buys: 0 
player value: 5 
card supply: [16. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [23.  1. 29.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  3. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  3.  0.] 
cards in discard: [23.  1. 29.  0.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.  0.] 
cards in discard: [23.  1. 29.  0.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 29. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.  0.] 
cards in discard: [23.  1. 29.  0.  6. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [23.  1. 29.  0.  6. 11.  3.  0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [23.  1. 29.  0.  6. 11.  3.  0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [15. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [23.  1. 29.  0.  6. 11.  3.  0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [23.  1. 29.  0.  6. 11.  3.  0.  3. 16.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [23.  1. 29.  0.  6. 11.  3.  0.  3. 16.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [23.  1. 29.  0.  6. 11.  3.  0.  3. 16.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [14. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [0. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [ 0.  3.  3.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [ 0.  3.  3.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 29. 30. 28. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [ 0.  3.  3.  0. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0. 23.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0. 23.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 0 
buys: 0 
player value: 5 
card supply: [12. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0. 23.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 8. 11.  3.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0. 23.] 
cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 16  3  1 11  6  0 23  3  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.] 
cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 23.] 
cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 16. 29.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.  8.  3.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 16. 29.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.  8.  3.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 0 
buys: 0 
player value: 5 
card supply: [11. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 16. 29.] 
adversary cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.  8.  3.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0. 11.  0. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 16. 29.] 
cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.  8.  3.  0. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 16.  6.] 
cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.  8.  3.  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 16.  6.] 
cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.  8.  3.  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 16.  6.] 
cards in discard: [ 0.  3.  3.  0. 11.  3.  0.  3.  1.  3.  0.  8.  3.  0. 23.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 9. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  0. 16.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 29. 30. 26. 30.  8.  9.  9.  7.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.] 
cards in discard: [ 3. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8.  9.  9.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8.  9.  9.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  6.  0.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 29. 30. 26. 30.  8.  9.  9.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  6.  0.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 8. 29. 30. 26. 30.  8.  9.  9.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  6.  0.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  8. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  6.  0.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8.  9.  9.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 29. 30. 26. 30.  8.  9.  9.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 29. 30. 26. 30.  8.  9.  9.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.
 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [3. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3. 0.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 0.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3. 11.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.  3.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3. 11.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.  3.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 6. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3. 11.] 
adversary cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.  3.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [23.  0.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  1.  3. 11.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.  3.  3.  3.  3.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  1.  3.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.  3.  3.  3.  3.
  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  1.  3.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.  3.  3.  3.  3.
  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  1.  3.] 
cards in discard: [ 3. 11. 11.  0.  0. 16.  0. 16. 29.  0.  8.  6.  0.  0.  3.  3.  3.  3.
  0.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16  1 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16  1 10] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16  1 10] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 5. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16  1 10] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  0. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16  1 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11
 16  1 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  1. 11. 11. 16.] 
adversary cards in discard: [29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  1. 11. 11. 16.] 
adversary cards in discard: [29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 4. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  1. 11. 11. 16.] 
adversary cards in discard: [29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  1. 11. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11. 11. 16.] 
cards in discard: [29.  8.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11. 16.] 
cards in discard: [29.  8.  3.  3. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11. 16.] 
cards in discard: [29.  8.  3.  3. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 23.  3. 11.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14] -> size -> 26 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 23.  3. 11.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14] -> size -> 26 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 23.  3. 11.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14] -> size -> 26 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 1.  3. 23.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 23.  3. 11.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 23.  3. 11.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 23.  3. 11.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 2. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.
 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 36 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 1. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [10.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  6.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.
 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 36 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.
 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 36 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.
 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 36 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.
 0. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11. 10.  3.
  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.
 0. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11. 10.  3.
  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 3. 0.
 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 37 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11. 10.  3.
  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0. -20.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11. 10.  3.
  0.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1
 10 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 26. 30.  8.  9.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 37 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11. 10.  3.
  0.  0.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1 10
 14  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 37 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11. 10.  3.
  0.  0.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1 10
 14  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 28. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 37 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  8.  3.  3. 14. 11.  3.  1. 11. 16.  0.  1.  3. 23.  3. 11. 10.  3.
  0.  0.  6.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1 10
 14  0  6  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 37 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1 10
 14  0  6  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 27. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1 10
 14  0  6  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1 10
 14  0  6  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.  -30.
   0.    0.   13.5   0. ] 
sum of rewards: -51.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 1.  8.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 16  3  1 11  6  0 23  3  8  3  0  3 11 16  1 10
 14  0  6  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1] -> size -> 38 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [22.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29 11 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14
  0  6  1 22] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1] -> size -> 38 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [22.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29 11 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14
  0  6  1 22] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1] -> size -> 38 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [11. 16.  0. 14.  0.] 
adversary cards in discard: [22. 16.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14
  0  6  1 22] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 26. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [11. 16.  0. 14.  0.] 
adversary cards in discard: [22. 16.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14
  0  6  1 22] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 25. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [11. 16.  0. 14.  0.] 
adversary cards in discard: [22. 16.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14
  0  6  1 22] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.  -40.
   0.    0.   13.5   0. ] 
sum of rewards: -61.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [11. 16.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0. 14.  0.] 
cards in discard: [22. 16.  8.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14
  0  6  1 22] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8.  8.  8.  6.  9. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.] 
cards in discard: [22. 16.  8.  0.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8.  7.  8.  6.  9. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [22. 16.  8.  0.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 25. 30. 26. 30.  8.  7.  8.  6.  9. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [22. 16.  8.  0.  3.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 24. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -50.
   0.    0.   13.5   0. ] 
sum of rewards: -41.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [1. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 3. 0. 0.] 
cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 0. 0.] 
cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 0. 0.] 
cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [11.  3.  6.  3.  3.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 23. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [11.  3.  6.  3.  3.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [11.  3.  6.  3.  3.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -60.
   0.    0.   13.5   0. ] 
sum of rewards: -51.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [11.  3.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  3.  3.] 
cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  3.  3.] 
cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 3.  0. 10.  1.  0.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0. 11.
  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 22. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 3.  0. 10.  1.  0.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0. 11.
  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 3.  0. 10.  1.  0.] 
adversary cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0. 11.
  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -70.
   0.    0.   13.5   0. ] 
sum of rewards: -61.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  0. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  1.  0.] 
cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0. 11.
  3.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  1.  0.] 
cards in discard: [22. 16.  8.  0.  3.  6.  8. 16.  0. 14.  0.  1.  1.  6.  3.  0.  0. 11.
  3.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 21. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  3. 11. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  3. 11. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  3. 11. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -80   0   0  54   0] 
sum of rewards: -31 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  3. 11. 23. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 23. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 26. 30.  8.  7.  8.  6.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 23. 29.] 
cards in discard: [11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 23. 29.] 
cards in discard: [11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 20. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3. 1. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [22. 16. 16.  0.  3.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3. 1. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 20. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [22. 16. 16.  0.  3.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 3. 1. 3. 0. 3. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 19. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [22. 16. 16.  0.  3.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -90.
   0.    0.   13.5   0. ] 
sum of rewards: -81.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [22. 16. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 16. 16.  0.  3.] 
cards in discard: [11. 11.  0.  3. 23. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 16. 16.  0.  3.] 
cards in discard: [11. 11.  0.  3. 23. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 19. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 1.  3.  6.  6. 11.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1] -> size -> 44 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 19. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 1.  3.  6.  6. 11.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 18. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 1.  3.  6.  6. 11.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -100.     0.     0.    13.5    0. ] 
sum of rewards: -91.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 1.  3.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6.  6. 11.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 6.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 6.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 17. 30. 26. 30.  8.  7.  8.  5.  8. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 6.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11  1  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 6. 14.  3.  1.  8.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11  1  8] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 17. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 6. 14.  3.  1.  8.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11  1  8] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 16. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 6. 14.  3.  1.  8.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11  1  8] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -110.     0.     0.    13.5    0. ] 
sum of rewards: -101.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 6. 14.  3.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.  1.  8.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 16  3 11  6  0 23  3  8  3  0  3 11 16  1 10 14  0
  6  1 22  6  8  1 11  1  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 16. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 16. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 15. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -120.     0.     0.    13.5    0. ] 
sum of rewards: -111.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 15. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 15. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 15. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  1.  8. 10.  0.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0. 15. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  1.  8. 10.  0.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0. 14. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  1.  8. 10.  0.] 
adversary cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -130.     0.     0.    13.5    0. ] 
sum of rewards: -121.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  1.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 10.  0.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 10.  0.] 
cards in discard: [11. 11.  0.  3. 23. 29. 22. 16. 16.  0.  3.  1.  8. 11.  1.  3.  6.  6.
  8. 14.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 14. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [16.  3.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 14. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [16.  3.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 13. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [16.  3.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -140.     0.     0.    13.5    0. ] 
sum of rewards: -131.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [16.  3.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  8. 14.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 16  3 11  0 23  3  8  3  0  3 11 16 10 14  0  6  1 22
  6  8  1 11  1  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 13. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 8. 16.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 13. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 8. 16.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 12. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 8. 16.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -150.     0.     0.    13.5    0. ] 
sum of rewards: -111.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [0. 8. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0. 3.] 
cards in discard: [ 8. 16.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0. 3.] 
cards in discard: [ 8. 16.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 12. 30. 26. 30.  8.  7.  8.  5.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0. 3.] 
cards in discard: [ 8. 16.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 12. 30. 26. 30.  8.  7.  8.  4.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 26. 30.  8.  7.  8.  4.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 1. 22. 23. 16.  6.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 12. 30. 26. 30.  8.  7.  8.  4.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 1. 22. 23. 16.  6.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 11. 30. 26. 30.  8.  7.  8.  4.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 1. 22. 23. 16.  6.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -160.     0.     0.    13.5    0. ] 
sum of rewards: -121.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 1. 22. 23. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 23. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22. 23. 16.  6.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 26. 30.  8.  7.  8.  4.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22. 23. 16.  6.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 11. 30. 26. 30.  8.  7.  8.  4.  7. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22. 23. 16.  6.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 11.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 11. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 11.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 1. 1. 0. 0. 3. 0. 0. 1. 1. 0. 1. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 10. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 11.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -170.     0.     0.    13.5    0. ] 
sum of rewards: -131.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  0.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 11.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 11.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 10. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  9.  9.  9.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 11.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 10. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [ 6.  3. 11.  3.  8.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8 14] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 10. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [ 6.  3. 11.  3.  8.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8 14] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  9. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [ 6.  3. 11.  3.  8.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8 14] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -180.     0.     0.    13.5    0. ] 
sum of rewards: -141.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 6.  3. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  3.  8.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  3 11  0 23  3  8  3  0  3 11 16 10  0  6  1 22  6  8
  1 11  1  8 11  8 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  9. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [10. 29.  0.  0. 11.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  9. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [10. 29.  0.  0. 11.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [10. 29.  0.  0. 11.] 
adversary cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0 -190    0    0
   54    0] 
sum of rewards: -111 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [10. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0. 11.] 
cards in discard: [ 8. 16.  3. 11.  0.  8.  1.  0.  3.  8.  1. 22. 23. 16.  6. 14.  0.  0.
  1.  0. 11.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [1. 1. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [1. 1. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  9.  9. 10.] 
adversary cards in hand: [1. 1. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 29. 11.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 29. 11.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  6. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 29. 11.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3. 16.  1. 22.  0.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  8. 30. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3. 16.  1. 22.  0.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 0.  7. 30. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3. 16.  1. 22.  0.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -200.     0.     0.    13.5    0. ] 
sum of rewards: -161.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3. 16.  1. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  1. 22.  0.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  1.  0.  0. 23.  1.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.  8. 14.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  1.  0.  0. 23.  1.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.  8. 14.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  7. 30. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  1.  0.  0. 23.  1.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.  8. 14.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  7. 29. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  7. 29. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 8.  1.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  7. 29. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 8.  1.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  6. 29. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 8.  1.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -210.     0.     0.    13.5    0. ] 
sum of rewards: -171.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 8.  1.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  3. 11.  0.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  6. 29. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  3. 11.  0.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  6. 29. 26. 30.  8.  7.  8.  4.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  3. 11.  0.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  6. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  6. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 6. 16.  0.  3.  8.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1. 11.  8.  1.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  6. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 6. 16.  0.  3.  8.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1. 11.  8.  1.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  5. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 6. 16.  0.  3.  8.] 
adversary cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1. 11.  8.  1.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -220.     0.     0.    13.5    0. ] 
sum of rewards: -181.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 6. 16.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  3.  8.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1. 11.  8.  1.  3. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  5. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  3.  8.] 
cards in discard: [ 8. 10.  8. 10. 29. 11.  0.  0.  0.  2. 22.  8. 14.  3. 16.  1.  0.  0.
 23.  1. 11.  8.  1.  3. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  5. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  5. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 6. 16.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  5. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 6. 16.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  4. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 6. 16.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -230.     0.     0.    13.5    0. ] 
sum of rewards: -191.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 6. 16.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  4. 29. 26. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0. 11.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  4. 29. 25. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 29. 25. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  8. 23.  2.  8.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  4. 29. 25. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  8. 23.  2.  8.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  3. 29. 25. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  8. 23.  2.  8.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -240.     0.     0.    13.5    0. ] 
sum of rewards: -231.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  8. 23.  2.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 23.  2.  8.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  3. 29. 25. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  2.  8. 10.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3] -> size -> 33 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0.  3. 29. 25. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  2.  8. 10.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3] -> size -> 33 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 0.  3. 29. 25. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
adversary victory points: 3
player victory points: 3 


buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  2.  8. 10.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  3. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  3. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 14. 16.  0.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  3. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 14. 16.  0.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  2. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 14. 16.  0.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -250.     0.     0.    13.5    0. ] 
sum of rewards: -271.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0. 11. 14. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14. 16.  0.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  2. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 1. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 14. 16.  0.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  2. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 1. 1. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  2. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  1. 22.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  2. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  1. 22.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  1. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  1. 22.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -260.     0.     0.    13.5    0. ] 
sum of rewards: -281.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  0. 11.  1. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  1. 22.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  1. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 0. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  1.  0.  0. 10.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  1. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 0. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1.  0.  0. 10.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  1. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [1. 0. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1.  0.  0. 10.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  1. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [1. 0. 0. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 1. 1. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  1. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8.  3.  8.  1. 11.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.
 10. 22.  3.  0. 11.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 1. 1. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  1. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8.  3.  8.  1. 11.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.
 10. 22.  3.  0. 11.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 1. 3. 0. 0. 0. 3. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 1. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 1. 1. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  0. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8.  3.  8.  1. 11.] 
adversary cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.
 10. 22.  3.  0. 11.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -270.     0.     0.    13.5    0. ] 
sum of rewards: -291.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 8.  3.  8.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  1. 11.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.
 10. 22.  3.  0. 11.  1.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  1. 11.] 
cards in discard: [ 3.  6. 16.  0.  0. 11.  3. 23.  3.  8.  2.  8. 10.  0. 11. 14. 16.  0.
 10. 22.  3.  0. 11.  1.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 57 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [16.  3.  8.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 57 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 29. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [16.  3.  8.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [2.] 
cards in deck: 57 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 63 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 28. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [16.  3.  8.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0. 1500.    0. -280.
    0.    0.  108.    0.] 
sum of rewards: 1293.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [16.  3.  8.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  8.  1. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  3  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1
  8 11  8 14 10  8  2 11  3  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 24. 30.  8.  7.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 63 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 29.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 24. 30.  8.  6.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 63 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 29.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 28. 24. 30.  8.  6.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 63 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 29.] 
cards in discard: [6. 3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 23. 30.  8.  6.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 63 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0.] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 23. 30.  8.  6.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 3.  2. 10. 11.  3.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0.] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 63 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 28. 23. 30.  8.  6.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 3.  2. 10. 11.  3.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3.] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 64 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 28. 22. 30.  8.  6.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 3.  2. 10. 11.  3.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3] -> size -> 36 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.   30.    0.    0.    0.    0.    0.    0.    0. -290.
    0.    0.    4.    0.] 
sum of rewards: -261.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  2. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  2. 10. 11.  3.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 22. 30.  8.  6.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 64 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  2. 10. 11.  3.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  0. 28. 22. 30.  8.  6.  8.  3.  5. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 64 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  2. 10. 11.  3.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 28. 22. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 64 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 22. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8.  6. 23.  8.  1.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3  8] -> size -> 37 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 64 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 28. 22. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8.  6. 23.  8.  1.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3  8] -> size -> 37 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3] -> size -> 65 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 28. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8.  6. 23.  8.  1.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3  8] -> size -> 37 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.   60.    0.    0.    0.    0.    0.    0.    0. -300.
    0.    0.    4.    0.] 
sum of rewards: -241.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 8.  6. 23.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 23.  8.  1.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 23  8  3  0  3 11 16 10  0  1 22  6  8  1 11  1  8
 11  8 14 10  8  2 11  3  3 10  6  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3] -> size -> 65 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0  8  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8
 14 10  8  2 11  3  3 10  6  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3] -> size -> 65 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0  8  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8
 14 10  8  2 11  3  3 10  6  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 28. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3] -> size -> 65 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8. 10.  1. 22.  8.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8
 14 10  8  2 11  3  3 10  6  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3] -> size -> 65 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 28. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8. 10.  1. 22.  8.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8
 14 10  8  2 11  3  3 10  6  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 8. 10.  1. 22.  8.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8
 14 10  8  2 11  3  3 10  6  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0 1500    0 -310    0    0
  432    0] 
sum of rewards: 1677 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 8. 10.  1. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1. 22.  8.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  8  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8
 14 10  8  2 11  3  3 10  6  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2] -> size -> 66 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 22.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2] -> size -> 66 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 22.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 27. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2] -> size -> 66 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8] -> size -> 34 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2] -> size -> 66 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 27. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8] -> size -> 34 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2] -> size -> 67 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 26. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8] -> size -> 34 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.   60.    0.    0.    0.    0.    0. 1500.    0. -320.
    0.    0.  108.    0.] 
sum of rewards: 1343.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 1. 1. 0. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2] -> size -> 67 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 21. 30.  8.  6.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 1. 1. 0. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2] -> size -> 67 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 1. 1. 0. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2] -> size -> 67 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 26. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [0. 1. 1. 0. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2] -> size -> 67 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 1. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 16.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.  6. 10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2] -> size -> 67 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 26. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 16.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.  6. 10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2] -> size -> 68 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 25. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 16.] 
adversary cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.  6. 10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -330.
    0.    0.  108.    0.] 
sum of rewards: 1363.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0. 11.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 16.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.  6. 10. 11.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9. 10.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2] -> size -> 68 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.  6. 10. 11.  0.  3.  3.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2] -> size -> 68 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 6.  3. 16.  8.  1. 29.  8.  3.  2. 10. 11.  3.  8.  6.  8.  8. 10.  1.
 22.  6. 10. 11.  0.  3.  3.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  0. 25. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2] -> size -> 68 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2] -> size -> 68 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 8. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2] -> size -> 68 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 25. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 8. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2] -> size -> 69 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 24. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 8. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -340.
    0.    0.  108.    0.] 
sum of rewards: 1353.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 8. 11. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2] -> size -> 69 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 24. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2] -> size -> 69 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0. 24. 21. 30.  8.  5.  8.  3.  4. 10.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2] -> size -> 69 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 21. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2] -> size -> 69 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 21. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0 6000    0 -340    0    0
 1485    0] 
sum of rewards: 7230 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2] -> size -> 69 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  0. 24. 21. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3] -> size -> 70 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 24. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0.    0.    0. -350.
    0.    0.    4.    0.] 
sum of rewards: -231.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  6.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 11.  0.] 
cards in discard: [29. 14.  8. 11.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3] -> size -> 70 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 11.  0.] 
cards in discard: [29. 14.  8. 11.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 24. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3] -> size -> 70 
adversary victory points: 6
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16.  1.  8.  8.  0.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3] -> size -> 70 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 24. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16.  1.  8.  8.  0.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2] -> size -> 71 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 23. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16.  1.  8.  8.  0.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0. 1500.    0. -360.
    0.    0.  108.    0.] 
sum of rewards: 1363.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [16.  1.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  8.  8.  0.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  3  0  3 11 16 10  0 22  6  8  1 11  1  8 11  8 14
 10  8  2 11  3  3 10  6  3  8  6 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2] -> size -> 71 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2] -> size -> 71 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  0. 23. 20. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2] -> size -> 71 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 23. 19. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2] -> size -> 71 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2] -> size -> 71 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 19. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 10. 15. 10.  1.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2] -> size -> 71 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 23. 19. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 10. 15. 10.  1.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2] -> size -> 72 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 22. 19. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 10. 15. 10.  1.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3] -> size -> 36 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -370.
    0.    0.  108.    0.] 
sum of rewards: 1323.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 6. 10. 15. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 15. 10.  1.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 19. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2] -> size -> 72 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.  1.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 19. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2] -> size -> 72 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 10.  1.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 22. 19. 30.  8.  5.  8.  3.  4. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2] -> size -> 72 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 10.  1.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 19. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2] -> size -> 72 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 19. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  0.  8. 16.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8] -> size -> 37 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2] -> size -> 72 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 22. 19. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  0.  8. 16.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8] -> size -> 37 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3] -> size -> 73 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 22. 18. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  0.  8. 16.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8] -> size -> 37 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0.    0.    0. -380.
    0.    0.    4.    0.] 
sum of rewards: -261.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0. 11.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8. 16.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 18. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0. 3. 0. 0. 1. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3] -> size -> 73 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8. 16.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 22. 18. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0. 3. 0. 0. 1. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3] -> size -> 73 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8. 16.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 17. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0. 3. 0. 0. 1. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3] -> size -> 73 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0. 3. 0. 0. 1. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3] -> size -> 73 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 17. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10. 29.  3. 11.  2.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0. 3. 0. 0. 1. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3] -> size -> 73 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 22. 17. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10. 29.  3. 11.  2.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [2. 0. 1. 0. 1. 0. 3. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 1. 3. 1.
 2. 1. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 1. 0. 1. 0. 1. 1. 0. 3. 0. 0. 0.
 2. 0. 0. 0. 1. 1. 2. 1. 0. 1. 1. 0. 3. 0. 0. 1. 0. 3. 2.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2] -> size -> 74 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 21. 17. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10. 29.  3. 11.  2.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -390.
    0.    0.  108.    0.] 
sum of rewards: 1303.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [10. 29.  3. 11.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3. 11.  2.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 17. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 1. 1. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2] -> size -> 74 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3. 11.  2.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  0. 21. 17. 30.  8.  5.  8.  3.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 1. 1. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2] -> size -> 74 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3. 11.  2.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 1. 1. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2] -> size -> 74 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [2. 1. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 1. 1. 1. 1.] 
cards in discard: [] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2] -> size -> 74 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [22.  3.  0.  3.  3.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16. 11. 10. 29.  3. 11.  2.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 1. 1. 1.] 
cards in discard: [] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2] -> size -> 74 
action values: 0 
buys: 1 
player value: 11 
card supply: [ 0.  0. 21. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [22.  3.  0.  3.  3.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16. 11. 10. 29.  3. 11.  2.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 1. 1. 1.] 
cards in discard: [2.] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2] -> size -> 75 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  0. 20. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [22.  3.  0.  3.  3.] 
adversary cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16. 11. 10. 29.  3. 11.  2.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -400.
    0.    0.  108.    0.] 
sum of rewards: 1293.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [22.  3.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  3.  3.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16. 11. 10. 29.  3. 11.  2.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2] -> size -> 75 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 8.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16. 11. 10. 29.  3. 11.  2.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2] -> size -> 75 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 8.] 
cards in discard: [29. 14.  8. 11.  0.  0.  3.  6.  6. 11.  0.  3.  8.  1.  0.  8. 15.  6.
 10. 10.  1.  3.  0. 11.  0.  8. 16. 11. 10. 29.  3. 11.  2.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 20. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2] -> size -> 75 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2] -> size -> 75 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 11. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2] -> size -> 75 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 20. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 11. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2] -> size -> 76 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 11. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0 1500    0 -410    0    0
  432    0] 
sum of rewards: 1607 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 6. 11. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 11 16 10  0 22  6  1 11  1  8 11  8 14 10  8
  2 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2] -> size -> 76 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2] -> size -> 76 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2] -> size -> 76 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 10.  8. 15.  6.] 
adversary cards in discard: [ 8.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2] -> size -> 76 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 19. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 10.  8. 15.  6.] 
adversary cards in discard: [ 8.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2] -> size -> 77 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 18. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 10.  8. 15.  6.] 
adversary cards in discard: [ 8.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -420.
    0.    0.  108.    0.] 
sum of rewards: 1273.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0. 10.  8. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 15.  6.] 
cards in discard: [ 8.  6. 11.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2] -> size -> 77 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 15.  6.] 
cards in discard: [ 8.  6. 11.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 18. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2] -> size -> 77 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [2. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2] -> size -> 77 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 11. 16.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2] -> size -> 77 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 18. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 11. 16.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2] -> size -> 78 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 17. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 11. 16.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -430.
    0.    0.  108.    0.] 
sum of rewards: 1263.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  0. 11. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 16.  0.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 3. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2] -> size -> 78 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 16.  0.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 17. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 3. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2] -> size -> 78 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2] -> size -> 78 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 29.  1.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2] -> size -> 78 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 17. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 29.  1.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2] -> size -> 79 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 29.  1.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0 1500    0 -440    0    0
  432    0] 
sum of rewards: 1577 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  0.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.  1.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2] -> size -> 79 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 29.  1.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  0. 16. 17. 30.  8.  5.  8.  2.  3. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2] -> size -> 79 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 29.  1.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 16. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2] -> size -> 79 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2] -> size -> 79 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 10.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2] -> size -> 79 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 16. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 10.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2] -> size -> 80 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 10.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0 1500    0 -450    0    0
  432    0] 
sum of rewards: 1567 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0.  3. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3. 10.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2] -> size -> 80 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  8.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2] -> size -> 80 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  8.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 15. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2] -> size -> 80 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2] -> size -> 80 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8.  6.  0. 11.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2] -> size -> 80 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 15. 17. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8.  6.  0. 11.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3] -> size -> 81 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 15. 16. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8.  6.  0. 11.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0.    0.    0. -460.
    0.    0.    4.    0.] 
sum of rewards: -341.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 1.  8.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  6.  0. 11.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 16. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 2. 0. 3.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3] -> size -> 81 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  6.  0. 11.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  0. 15. 16. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 2. 0. 3.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3] -> size -> 81 
adversary victory points: 8
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  6.  0. 11.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 15. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 2. 0. 3.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3] -> size -> 81 
adversary victory points: 8
player victory points: 5 





         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [0. 1. 2. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 2. 0. 3.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3] -> size -> 81 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 22.  3.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.  3.  1.  8.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 2. 0. 3.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3] -> size -> 81 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 15. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 22.  3.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.  3.  1.  8.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 2. 0. 3.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2] -> size -> 82 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 14. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 22.  3.] 
adversary cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.  3.  1.  8.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -470.
    0.    0.  108.    0.] 
sum of rewards: 1223.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 0. 11.  8. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 22.  3.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.  3.  1.  8.  6.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2] -> size -> 82 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 22.  3.] 
cards in discard: [ 8.  6. 11.  3.  0. 10.  8. 15.  6.  3.  0. 11. 16.  0.  8.  3.  0.  3.
 29.  1. 10.  0.  3. 29.  3.  8.  3.  1.  8.  6.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 14. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2] -> size -> 82 
adversary victory points: 8
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2] -> size -> 82 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0. 10.  2. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2] -> size -> 82 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 14. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0. 10.  2. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2] -> size -> 83 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 13. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0. 10.  2. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -480.
    0.    0.  108.    0.] 
sum of rewards: 1213.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [11.  0. 10.  2. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  2. 14.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 13. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 2. 0. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2] -> size -> 83 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  2. 14.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0. 13. 15. 30.  8.  5.  8.  2.  2. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 2. 0. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2] -> size -> 83 
adversary victory points: 8
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  2. 14.] 
cards in discard: [8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 13. 15. 30.  8.  5.  8.  2.  1. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 2. 0. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2] -> size -> 83 
adversary victory points: 8
player victory points: 5 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [0. 0. 2. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 2. 0. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2] -> size -> 83 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 13. 15. 30.  8.  5.  8.  2.  1. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  3. 11. 11.  6.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8] -> size -> 41 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 2. 0. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2] -> size -> 83 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 13. 15. 30.  8.  5.  8.  2.  1. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  3. 11. 11.  6.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8] -> size -> 41 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 2. 0. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2] -> size -> 84 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 12. 15. 30.  8.  5.  8.  2.  1. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  3. 11. 11.  6.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8] -> size -> 41 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -490.
    0.    0.  108.    0.] 
sum of rewards: 1203.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  3. 11. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 11.  6.] 
cards in discard: [ 8. 11.  0. 10.  2. 14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 12. 15. 30.  8.  5.  8.  2.  1. 10.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2] -> size -> 84 
adversary victory points: 8
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  6.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 12. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2] -> size -> 84 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  6.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 12. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2] -> size -> 84 
adversary victory points: 8
player victory points: 5 





         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2] -> size -> 84 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 12. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  3. 29.  0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 42 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2] -> size -> 84 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 12. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  3. 29.  0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 42 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2] -> size -> 85 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 11. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  3. 29.  0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 42 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -500.
    0.    0.  108.    0.] 
sum of rewards: 1193.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3.  8.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 29.  0.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  3  0  3 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2
 11  3  3 10  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 2. 2.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2] -> size -> 85 
adversary victory points: 8
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2 11  3  3 10
  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 2. 2.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2] -> size -> 85 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2 11  3  3 10
  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 11. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 0. 2. 2.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2] -> size -> 85 
adversary victory points: 8
player victory points: 3 





         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 2. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 2. 2.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2] -> size -> 85 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [8. 8. 6. 0. 0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2 11  3  3 10
  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 38 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 2. 2.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2] -> size -> 85 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0. 11. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [8. 8. 6. 0. 0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2 11  3  3 10
  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 38 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 2. 2.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 86 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0. 10. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [8. 8. 6. 0. 0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2 11  3  3 10
  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 38 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -510.
    0.    0.  108.    0.] 
sum of rewards: 1243.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [8. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 0. 0.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 10  0 22  6  1 11  1  8 11  8 14 10  8  2 11  3  3 10
  6  3  8  6 15 29  3  8  3 11  8  3  8 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 86 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 86 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 10. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 86 
adversary victory points: 8
player victory points: 4 





         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 86 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 16.  8.  0.  0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29] -> size -> 35 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 86 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0. 10. 15. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 16.  8.  0.  0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29] -> size -> 35 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.
 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3] -> size -> 87 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 10. 14. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 16.  8.  0.  0.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29] -> size -> 35 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0.    0.    0. -520.
    0.    0.    4.    0.] 
sum of rewards: -371.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3. 16.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8.  0.  0.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 14. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 2. 0. 0. 3.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.
 3. 0. 3. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3] -> size -> 87 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  8.  0.  0.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 10. 14. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 2. 0. 0. 3.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.
 3. 0. 3. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3] -> size -> 87 
adversary victory points: 9
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  8.  0.  0.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 2. 0. 0. 3.] 
adversary cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.
 3. 0. 3. 0. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3] -> size -> 87 
adversary victory points: 9
player victory points: 5 





         -------------------- Turn: 78 -------------------- 
Player: 0 
cards in hand: [1. 2. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 2. 0. 0. 3.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.
 3. 0. 3. 0. 3. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3] -> size -> 87 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  6.  3.  0.  3.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 0. 0. 3.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.
 3. 0. 3. 0. 3. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3] -> size -> 87 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 10. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  6.  3.  0.  3.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 0. 0. 3.] 
cards in discard: [2. 2. 1. 1. 1. 1. 2. 0. 0. 3. 1. 1. 2. 0. 0. 0. 1. 1. 2. 2. 0. 0. 1. 0.
 2. 1. 0. 0. 3. 1. 2. 0. 0. 0. 0. 1. 3. 0. 3. 1. 0. 0. 2. 0. 1. 2. 0. 3.
 2. 1. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 2. 0. 1. 0. 1. 1. 2. 1. 0. 0. 2. 2.
 3. 0. 3. 0. 3. 1. 2.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2] -> size -> 88 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0.  9. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  6.  3.  0.  3.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0. 1500.    0. -530.
    0.    0.  108.    0.] 
sum of rewards: 1193.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [10.  6.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  0.  3.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 2. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2] -> size -> 88 
adversary victory points: 9
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 8.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  6  3  8
  6 15 29  3  8  3 11  8  3  8 29  3] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 2. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2] -> size -> 88 
adversary victory points: 9
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 2. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2] -> size -> 88 
adversary victory points: 9
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0.  9. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 2. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2] -> size -> 88 
adversary victory points: 9
player victory points: 6 





         -------------------- Turn: 79 -------------------- 
Player: 0 
cards in hand: [2. 2. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 2. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 83 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2] -> size -> 88 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 22. 11.  1.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0. 10.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3] -> size -> 35 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 2. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 83 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2] -> size -> 88 
action values: 0 
buys: 1 
player value: 11 
card supply: [ 0.  0.  9. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 22. 11.  1.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0. 10.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3] -> size -> 35 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 2. 1. 1. 0.] 
cards in discard: [2.] 
cards in deck: 83 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2] -> size -> 89 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  0.  8. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3. 22. 11.  1.] 
adversary cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0. 10.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3] -> size -> 35 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -540.
    0.    0.  108.    0.] 
sum of rewards: 1153.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 1.  3. 22. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 22. 11.  1.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0. 10.  8.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  7.  9.  9.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2] -> size -> 89 
adversary victory points: 9
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 22.  1.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0. 10.  8.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2] -> size -> 89 
adversary victory points: 9
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 22.  1.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0. 10.  8.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0.  8. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2] -> size -> 89 
adversary victory points: 9
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 22.  1.] 
cards in discard: [ 8. 11.  0. 10.  2. 14. 29. 11.  3.  3. 11.  6.  8.  8.  8.  3.  3. 16.
  8.  0.  0. 10.  8.  3.  0.  3. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2] -> size -> 89 
adversary victory points: 9
player victory points: 6 





         -------------------- Turn: 80 -------------------- 
Player: 0 
cards in hand: [2. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [2. 2. 2. 1. 1. 0.] 
cards in deck: 78 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2] -> size -> 89 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 15. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [2. 2. 2. 1. 1. 0.] 
cards in deck: 78 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2] -> size -> 89 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0.  8. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 15. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [2. 2. 2. 1. 1. 0. 2.] 
cards in deck: 78 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2] -> size -> 90 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0.  7. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 15. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -550.
    0.    0.  108.    0.] 
sum of rewards: 1143.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 3. 15. 10. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 29.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [3. 2. 0. 0. 0.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2] -> size -> 90 
adversary victory points: 9
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [3. 2. 0. 0. 0.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2] -> size -> 90 
adversary victory points: 9
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  7. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [3. 2. 0. 0. 0.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2] -> size -> 90 
adversary victory points: 9
player victory points: 6 





         -------------------- Turn: 81 -------------------- 
Player: 0 
cards in hand: [3. 2. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.533694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 2. 0. 0. 0.] 
cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0.] 
cards in deck: 73 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2] -> size -> 90 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  8.  3.  8. 11.] 
adversary cards in discard: [15.  3. 10. 29.  8.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.53369426727295





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]
 [-10.533694]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 2. 0. 0. 0.] 
cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0.] 
cards in deck: 73 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2] -> size -> 90 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0.  7. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  8.  3.  8. 11.] 
adversary cards in discard: [15.  3. 10. 29.  8.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.53369426727295



buy possibilites: [-1] 
expected returns: [[-10.533694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 2. 0. 0. 0.] 
cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0. 2.] 
cards in deck: 73 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 2] -> size -> 91 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  8.  3.  8. 11.] 
adversary cards in discard: [15.  3. 10. 29.  8.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0 1500    0 -560    0    0
  432    0] 
sum of rewards: 1457 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -10.53369426727295






Player: 1 
cards in hand: [ 1.  8.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3.  8. 11.] 
cards in discard: [15.  3. 10. 29.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [1. 3. 2. 3. 1.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0. 2. 3. 2. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 2] -> size -> 91 
adversary victory points: 9
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3.  8. 11.] 
cards in discard: [15.  3. 10. 29.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0.  6. 13. 30.  8.  5.  8.  2.  1. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [1. 3. 2. 3. 1.] 
adversary cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0. 2. 3. 2. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 2] -> size -> 91 
adversary victory points: 9
player victory points: 6 


Player 0 won the game! 



Player 0 bought cards:
Copper: 27 
Silver: 25 
Gold: 23 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1. 3. 2. 3. 1.] 
cards in discard: [2. 2. 2. 1. 1. 0. 2. 2. 0. 0. 1. 0. 2. 3. 2. 0. 0. 0.] 
cards in deck: 68 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 2 2 2 3 2 2 3 2
 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 2] -> size -> 91 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 13. 30.  8.  5.  8.  2.  0. 10.  7.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  8.  3.  8. 11.] 
adversary cards in discard: [15.  3. 10. 29.  8.  8.] 
adversary owned cards: [ 0  0  0 16 10  0 22  1 11  1  8 11  8 14 10  8  2 11  3  3 10  3  8  6
 15 29  3  8  3 11  8  3  8 29  3 10 15  8] -> size -> 38 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[     -5 3000000       0      90       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000085 

action type: buy - action -1
Learning step: 300009.5625
desired expected reward: 299999.03125



