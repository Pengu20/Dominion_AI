 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[103.99827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0.00024555204436182976
desired expected reward: -5.005893230438232





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 98.18486 ]
 [107.74853 ]
 [101.66567 ]
 [ 81.8103  ]
 [106.364365]
 [109.757576]
 [106.27675 ]
 [113.72443 ]
 [ 89.898415]
 [100.1939  ]
 [ 99.46208 ]
 [102.21669 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.79618072509766



buy possibilites: [-1] 
expected returns: [[97.14524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 113.72443389892578






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[95.18367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.1452407836914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 92.45017 ]
 [100.73428 ]
 [ 95.49286 ]
 [ 78.326515]
 [102.47978 ]
 [ 99.43708 ]
 [ 94.19565 ]
 [ 96.17071 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 96.5713119506836



buy possibilites: [-1] 
expected returns: [[110.85093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 102.4797592163086






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [16.  0.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[90.22735 ]
 [98.888214]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.8509292602539



action possibilites: [-1.] 
expected returns: [[93.49185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 99.78192901611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 86.15201 ]
 [ 95.660645]
 [ 89.68725 ]
 [ 77.30416 ]
 [ 72.354774]
 [ 94.23044 ]
 [ 97.76632 ]
 [ 94.092354]
 [111.97236 ]
 [101.691185]
 [ 79.09798 ]
 [ 87.725334]
 [ 88.16779 ]
 [ 79.21781 ]
 [ 87.586716]
 [ 91.65592 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 93.49185180664062



buy possibilites: [-1] 
expected returns: [[117.49693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 111.97235107421875






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[108.71862]
 [115.02647]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3.] 
cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.49693298339844



action possibilites: [-1] 
expected returns: [[135.68314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25. 29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 127.38248443603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[131.46063]
 [135.11636]
 [115.06297]
 [139.60687]
 [136.72787]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25. 29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.68313598632812



buy possibilites: [-1] 
expected returns: [[119.17651]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25. 29.  0.  3.  0.  0.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 139.60687255859375






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[109.10548]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.176513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[104.05842 ]
 [113.35598 ]
 [107.58944 ]
 [ 89.09671 ]
 [111.97502 ]
 [115.3709  ]
 [111.83987 ]
 [119.16178 ]
 [ 96.508644]
 [106.073326]
 [105.478645]
 [109.44644 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 109.80329132080078



buy possibilites: [-1] 
expected returns: [[119.92183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 119.16178131103516






Player: 1 
cards in hand: [ 3.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 25. 11.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 25. 11.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 25. 11.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 25. 11.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[105.94128 ]
 [113.95872 ]
 [123.120674]
 [110.63842 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 25. 11.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.92182922363281



action possibilites: [-1] 
expected returns: [[114.827705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  3. 10.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 16.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.77892303466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[111.46479]
 [115.06671]
 [ 96.31879]
 [119.25681]
 [117.33019]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 11.  3. 10.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  9.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 16.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.82770538330078



buy possibilites: [-1] 
expected returns: [[111.420334]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 11.  3. 10.] 
cards in discard: [29.  3.  0.  0.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9.  9.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 16.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 119.25682830810547






Player: 1 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 8.  0. 16.  3.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9.  9.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 8.  0. 16.  3.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 30. 30.  8.  9.  9.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 8.  0. 16.  3.  3.  0.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  3.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[81.40347]
 [88.367  ]
 [80.69709]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.42033386230469



action possibilites: [-1.  8.] 
expected returns: [[96.66716]
 [98.38132]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 89.2828140258789



action possibilites: [-1] 
expected returns: [[86.048615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 10  8 29  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 99.7884750366211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[78.30764 ]
 [86.53378 ]
 [81.400696]
 [64.43735 ]
 [88.31735 ]
 [85.224304]
 [80.09122 ]
 [82.82139 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 10  8 29  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.04861450195312



buy possibilites: [-1] 
expected returns: [[130.12787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 10  8 29  8 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  8.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 88.31736755371094






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  8.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [11. 29.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 10  8 29  8 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  8.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [11. 29.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 10  8 29  8 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [11. 29.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 10  8 29  8 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[106.01262]
 [104.95455]
 [109.16587]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  8.] 
cards in discard: [11. 29.  8.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 10  8 29  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  1.  0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.12786865234375



action possibilites: [-1] 
expected returns: [[111.92115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11. 29.  8.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  1.  0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 113.12572479248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.62224]
 [ 89.8922 ]
 [111.25005]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 29.  8.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  1.  0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.92115020751953






Player: 1 
cards in hand: [ 0. 16.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  1.  0.] 
cards in discard: [11.  8.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  1  8  0  6  1 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  0. 29.] 
adversary cards in discard: [11. 29.  8.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [11.  8.  0.  0.  0.  3. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  0. 29.] 
adversary cards in discard: [11. 29.  8.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [11.  8.  0.  0.  0.  3. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  0. 29.] 
adversary cards in discard: [11. 29.  8.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [11.  8.  0.  0.  0.  3. 14. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  0. 29.] 
adversary cards in discard: [11. 29.  8.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[ 89.00323]
 [100.27262]
 [ 91.12757]
 [ 93.59375]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  0. 29.] 
cards in discard: [11. 29.  8.  3.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9.  9.  7.  7.  9.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3. 14. 29. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 111.25005340576172



action possibilites: [-1] 
expected returns: [[134.61542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  7.  7.  9.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3. 14. 29. 16.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.4033432006836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[126.94227 ]
 [136.24255 ]
 [130.68628 ]
 [111.410484]
 [138.39822 ]
 [134.6542  ]
 [129.0979  ]
 [134.4314  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  7.  7.  9.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3. 14. 29. 16.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.61541748046875



buy possibilites: [-1] 
expected returns: [[135.58463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.  8.  0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  6.  7.  9.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3. 14. 29. 16.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 138.39822387695312






Player: 1 
cards in hand: [0. 0. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 1.] 
cards in discard: [11.  8.  0.  0.  0.  3. 14. 29. 16.  0.  1.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  6.  7.  9.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 29.] 
adversary cards in discard: [11. 25.  0. 11.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 1.] 
cards in discard: [11.  8.  0.  0.  0.  3. 14. 29. 16.  0.  1.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  6.  7.  9.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 29.] 
adversary cards in discard: [11. 25.  0. 11.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 1.] 
cards in discard: [11.  8.  0.  0.  0.  3. 14. 29. 16.  0.  1.  0.  6. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  6.  7.  9.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 29.] 
adversary cards in discard: [11. 25.  0. 11.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[125.45025]
 [130.33267]
 [133.62491]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 29.] 
cards in discard: [11. 25.  0. 11.  0. 29.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  6.  7.  9.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.58462524414062



action possibilites: [-1. 11.  8.] 
expected returns: [[107.912926]
 [112.70663 ]
 [108.56153 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  8.] 
cards in discard: [11. 25.  0. 11.  0. 29.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  6.  7.  9.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 133.94345092773438



action possibilites: [-1] 
expected returns: [[103.978645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [11. 25.  0. 11.  0. 29.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  6.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 119.65216064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.20667 ]
 [105.731895]
 [101.314964]
 [ 85.93212 ]
 [107.66421 ]
 [104.39547 ]
 [ 99.97852 ]
 [105.13402 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [11. 25.  0. 11.  0. 29.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  6.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.97864532470703



buy possibilites: [-1] 
expected returns: [[97.2895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [11. 25.  0. 11.  0. 29.  8.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  5.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 107.66419219970703






Player: 1 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  5.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11] -> size -> 17 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  8.  9.  5.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11] -> size -> 17 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8.  9.  5.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11] -> size -> 17 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11. 11. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[118.73575]
 [123.58225]
 [123.58225]
 [136.09064]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8.  9.  5.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 0. 1. 6.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.28949737548828



action possibilites: [-1] 
expected returns: [[122.67359]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7.  9.  5.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 0. 1. 6.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.26705932617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[120.06378 ]
 [123.305855]
 [105.70295 ]
 [127.205086]
 [125.09478 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  7.  9.  5.  7.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 0. 1. 6.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.67359161376953



buy possibilites: [-1] 
expected returns: [[120.65821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0. 10.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 0. 1. 6.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 127.2050552368164






Player: 1 
cards in hand: [0. 1. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 6.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [ 8. 25. 11. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8] -> size -> 18 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 6.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [ 8. 25. 11. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8] -> size -> 18 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 6.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 6 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [ 8. 25. 11. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8] -> size -> 18 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
expected returns: [[102.48747]
 [101.66306]
 [101.66306]
 [109.0084 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 29.] 
cards in discard: [ 8. 25. 11. 11.  3.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16. 29.  0.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.65821075439453



action possibilites: [-1.  8.  8.] 
expected returns: [[80.81225]
 [78.95702]
 [78.95702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 8. 25. 11. 11.  3.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16. 29.  0.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 109.3896713256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[70.218   ]
 [82.00781 ]
 [74.916466]
 [52.978596]
 [80.03925 ]
 [84.928894]
 [79.82803 ]
 [89.78998 ]
 [61.035545]
 [72.9082  ]
 [72.31698 ]
 [81.26719 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 8. 25. 11. 11.  3.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16. 29.  0.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.812255859375



buy possibilites: [-1] 
expected returns: [[91.93892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 8. 25. 11. 11.  3.  0. 10.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16. 29.  0.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 89.78997039794922






Player: 1 
cards in hand: [11. 16. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16. 29.  0.  0.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  5.  6.  9.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29] -> size -> 19 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0.  0.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  6.  9.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29] -> size -> 19 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  0.  0.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  6.  9.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29] -> size -> 19 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  0.  0.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29] -> size -> 19 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[102.184456]
 [110.528694]
 [107.27311 ]
 [107.27311 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  3. 14.  8.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.93891906738281



action possibilites: [-1. 11. 11.] 
expected returns: [[102.68232]
 [103.60236]
 [103.60236]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  3. 14.  8.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.01387023925781



action possibilites: [-1] 
expected returns: [[95.44332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  3. 14.  8.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 108.3099594116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 90.48463 ]
 [ 98.29958 ]
 [ 93.74849 ]
 [ 77.64678 ]
 [ 97.06809 ]
 [100.14899 ]
 [ 96.885124]
 [103.15762 ]
 [ 84.20807 ]
 [ 92.334015]
 [ 92.02303 ]
 [ 98.03875 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  3. 14.  8.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.44332122802734



buy possibilites: [-1] 
expected returns: [[151.90686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  3. 14.  8.] 
adversary cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.15763092041016






Player: 1 
cards in hand: [ 6.  0.  3. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 14.  8.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  8.  0. 10.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8.] 
cards in discard: [ 3.  0.  0. 29.  0.  3.  6.  0.  0.  1.  0.  1.  6.  1.  8. 11. 16. 29.
  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[91.43932]
 [87.69778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.] 
cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0. 16. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8 10] -> size -> 26 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 141.75677490234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[86.05743 ]
 [77.86976 ]
 [91.058815]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0. 16. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8 10] -> size -> 26 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.32161712646484



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 16. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16. 10.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 25.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16.  6.  1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  6  1 11 14 29  6 29  3  6  0  1
  8 10] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 25.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 25.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 25.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [ 0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 25.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.  8.] 
expected returns: [[82.895   ]
 [87.49066 ]
 [90.16739 ]
 [97.850914]
 [85.06709 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 25.  8.] 
cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  5.  5.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 14.  1.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29] -> size -> 27 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 91.0588150024414



action possibilites: [-1] 
expected returns: [[67.59501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  8.  0.  8.] 
cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  5.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 14.  1.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 97.8509292602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.091965]
 [66.11775 ]
 [50.04471 ]
 [69.65502 ]
 [67.987816]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  8.  0.  8.] 
cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  5.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 14.  1.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.59500885009766



buy possibilites: [-1] 
expected returns: [[119.03058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  8.  0.  8.] 
cards in discard: [10. 29. 29. 11.  0. 11.  0.  0. 11.  8.  0. 10.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 14.  1.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 69.65502166748047






Player: 1 
cards in hand: [ 8. 29.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 14.  1.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 25.  8. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8] -> size -> 22 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  1.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  8. 11.] 
adversary cards in discard: [25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8] -> size -> 22 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3.  1.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  8. 11.] 
adversary cards in discard: [25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8] -> size -> 22 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
expected returns: [[82.8662  ]
 [84.042496]
 [84.042496]
 [87.17611 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.] 
cards in discard: [25. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 170.90365600585938



action possibilites: [-1] 
expected returns: [[84.49447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [25. 29. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 91.46599578857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[81.09904 ]
 [68.260086]
 [86.3174  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [25. 29. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.49446868896484






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29.  0.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10] -> size -> 23 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  4.  9.  3.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29.  0.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10] -> size -> 23 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  3.  9.  3.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29.  0.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10] -> size -> 23 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
expected returns: [[75.29958]
 [75.77782]
 [78.46461]
 [81.30314]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 29.  0.] 
cards in discard: [25. 29. 10. 11.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  3.  9.  3.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0. 29.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8] -> size -> 29 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.31739807128906



action possibilites: [-1.  8. 11.] 
expected returns: [[84.128105]
 [85.72899 ]
 [88.34943 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  3.] 
cards in discard: [25. 29. 10. 11.  8.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  3.  9.  3.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0. 29.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8] -> size -> 29 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.23826599121094



action possibilites: [-1] 
expected returns: [[97.82226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  3.  9.  3.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0. 29.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8] -> size -> 29 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.56464385986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 92.971085]
 [101.19227 ]
 [ 96.11297 ]
 [ 79.23032 ]
 [103.00698 ]
 [ 99.837746]
 [ 94.76475 ]
 [ 98.6495  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  5.  3.  9.  3.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0. 29.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8] -> size -> 29 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.82225799560547



buy possibilites: [-1] 
expected returns: [[78.12037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  3.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0. 29.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8] -> size -> 29 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 103.00700378417969






Player: 1 
cards in hand: [ 8. 11.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0. 29.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  3.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0. 10. 29.  0.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11] -> size -> 25 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 29.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  2.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0. 10. 29.  0.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11] -> size -> 25 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 29.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  2.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0. 10. 29.  0.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11] -> size -> 25 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11.  0. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[167.73251]
 [170.85797]
 [164.31204]
 [173.51529]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 29.  0.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  2.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29. 11.  8.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.12036895751953



action possibilites: [-1. 11. 10.] 
expected returns: [[152.65573]
 [155.17523]
 [150.4448 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  2.  9. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29. 11.  8.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 173.51528930664062



action possibilites: [-1] 
expected returns: [[167.37137]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  2.  9. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29. 11.  8.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 158.36984252929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[159.99918]
 [166.08649]
 [162.54541]
 [150.34766]
 [165.14664]
 [167.54654]
 [164.96417]
 [169.95657]
 [155.24814]
 [161.43744]
 [161.25452]
 [166.04251]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  2.  9. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29. 11.  8.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.37136840820312



buy possibilites: [-1] 
expected returns: [[183.97992]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  1.  9. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29. 11.  8.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 169.95657348632812






Player: 1 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29. 11.  8.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  1.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11.  0.  8. 29.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3. 10. 29. 29. 11.
  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29] -> size -> 27 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29. 11.  8.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  4.  3.  9.  1.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11.  0.  8. 29.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3. 10. 29. 29. 11.
  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29] -> size -> 27 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 0. 29. 10. 16.  1.  0.  1.  6. 14.  8. 29.  3.  1.  8.  0.  0.  3.  0.
  0. 29. 11.  8.  3.  0. 29. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  3.  9.  1.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11.  0.  8. 29.] 
adversary cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3. 10. 29. 29. 11.
  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29] -> size -> 27 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10. 11.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 29.] 
expected returns: [[148.5636 ]
 [144.09647]
 [151.53445]
 [148.63596]
 [154.5279 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  8. 29.] 
cards in discard: [25. 29. 10. 11.  8.  8. 10. 11. 29. 11.  8.  0.  0.  3. 10. 29. 29. 11.
  0. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  3.  9.  1.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 183.97991943359375



action possibilites: [-1. 10. 11.  8.  8.] 
expected returns: [[122.016914]
 [120.45973 ]
 [127.45211 ]
 [124.89335 ]
 [124.89335 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  3.  9.  1.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 154.52789306640625



action possibilites: [-1] 
expected returns: [[116.53009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  8.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  3.  9.  1.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.88571166992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[111.84942]
 [114.42832]
 [100.89976]
 [118.10847]
 [116.53884]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  8.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  3.  9.  1.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.53009033203125



buy possibilites: [-1] 
expected returns: [[172.76059]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  8.] 
cards in discard: [10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 81 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 118.10845184326172






Player: 1 
cards in hand: [ 6. 29.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  6.  1.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 29. 10.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10  8] -> size -> 29 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 29. 10.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10  8] -> size -> 29 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 29. 10.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10  8] -> size -> 29 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 0. 8.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 29. 10.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10  8] -> size -> 29 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[144.25214]
 [138.6687 ]
 [150.3071 ]
 [138.6687 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29. 10.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 172.76058959960938



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[120.300255]
 [114.943886]
 [114.943886]
 [120.39634 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 10.  8.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 29  8 11 11 10 11  8 29 10 29  8 10 10
 11 10 29 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 150.30712890625



action possibilites: [-1] 
expected returns: [[93.80718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 128.4237060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[89.100006]
 [91.68826 ]
 [78.82423 ]
 [93.74412 ]
 [96.17852 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15] -> size -> 32 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.80718231201172






Player: 1 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8] -> size -> 26 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  3.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8] -> size -> 26 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8] -> size -> 26 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[122.82752]
 [117.60186]
 [128.02283]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 29.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.17852020263672



action possibilites: [-1. 10. 11.] 
expected returns: [[141.03714]
 [137.85513]
 [143.45282]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.0228271484375



action possibilites: [-1] 
expected returns: [[138.76767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 146.34481811523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[133.51816 ]
 [141.99994 ]
 [136.48932 ]
 [124.336006]
 [140.54333 ]
 [144.20761 ]
 [140.36209 ]
 [147.91458 ]
 [128.8866  ]
 [135.00552 ]
 [134.73996 ]
 [140.66092 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.76766967773438



buy possibilites: [-1] 
expected returns: [[157.04614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 147.91461181640625






Player: 1 
cards in hand: [ 0.  3.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 11.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 11.  8. 11. 29.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10. 29. 29. 11.  0. 10.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 11.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 11.  8. 11. 29.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10. 29. 29. 11.  0. 10.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 11.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 11.  8. 11. 29.] 
adversary cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10. 29. 29. 11.  0. 10.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 11.  8. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 11. 29.] 
expected returns: [[123.917854]
 [126.26888 ]
 [126.26888 ]
 [123.64321 ]
 [126.26888 ]
 [129.16772 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8. 11. 29.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10. 29. 29. 11.  0. 10.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11.  1.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 157.046142578125



action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[148.69196]
 [148.52155]
 [148.52155]
 [148.52155]
 [141.28842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 10.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10. 29. 29. 11.  0. 10.  0.
  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11.  1.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 124.7561264038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[139.63684]
 [129.42618]
 [149.13992]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11. 10.] 
cards in discard: [10.  8. 29. 11. 10.  0.  8.  8. 29.  8.  0. 10. 29. 29. 11.  0. 10.  0.
  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11.  1.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 148.69195556640625






Player: 1 
cards in hand: [ 0.  3.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.  1.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 10. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.  1.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 10. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.  1.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[115.22675]
 [107.09443]
 [120.03903]
 [129.96841]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  6.  9.  2.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8. 16.  0.  0.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.13992309570312



action possibilites: [-1] 
expected returns: [[133.38965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  5.  9.  2.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8. 16.  0.  0.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6] -> size -> 36 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.96841430664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.62628]
 [133.73746]
 [113.65178]
 [137.20932]
 [136.31174]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  5.  9.  2.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8. 16.  0.  0.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6] -> size -> 36 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.3896484375



buy possibilites: [-1] 
expected returns: [[146.62228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  0. 29.  8.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8. 16.  0.  0.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6] -> size -> 36 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 137.20932006835938






Player: 1 
cards in hand: [10.  8. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 16.  0.  0.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 10. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8] -> size -> 29 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 16.  0.  0.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 10. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8] -> size -> 29 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 16.  0.  0.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 10. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8] -> size -> 29 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[114.85579 ]
 [110.71363 ]
 [110.71363 ]
 [118.833466]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.  0.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0.  8. 29. 14.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.  0. 10.  8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.62228393554688



action possibilites: [-1] 
expected returns: [[88.69953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0.  8. 29. 14.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.  0. 10.  8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 116.9930191040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[83.966515]
 [86.5839  ]
 [73.94428 ]
 [88.90886 ]
 [90.13261 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0.  8. 29. 14.] 
adversary cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.  0. 10.  8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.69953155517578






Player: 1 
cards in hand: [29.  0.  8. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 29. 14.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.  0. 10.  8. 16.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11 14 29  6 29  3  6  0  1  8
 10  0 29  6  8 29 11 15 11  0 10  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.  0. 10.  8. 16.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.  0. 10.  8. 16.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 29.  6.  6.  1.  0.  8. 11.  3.  0.  0.  0. 29.  0.  0.  3.  0.  6.
 11. 10.  0.  3.  1. 11.  1.  6.  0. 10.  8. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 29. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.  8. 10.] 
expected returns: [[155.0275 ]
 [150.20544]
 [160.13174]
 [157.3422 ]
 [154.41666]
 [150.20544]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.  8. 10.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  6.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.13260650634766



action possibilites: [-1.  8. 10.  8.] 
expected returns: [[178.16785]
 [177.27322]
 [173.12518]
 [177.27322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  6.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 155.67764282226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[171.13199]
 [158.41653]
 [178.08853]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  6.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 178.1678466796875






Player: 1 
cards in hand: [29.  6.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11. 29.  8.
 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11. 29.  8.
 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3. 15.  0.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11. 29.  8.
 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
expected returns: [[129.78061]
 [128.0167 ]
 [131.65103]
 [128.0167 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  8.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11. 29.  8.
 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 8. 8. 0.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0  0] -> size -> 36 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 178.08856201171875



action possibilites: [-1] 
expected returns: [[112.61882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11. 29.  8.
 10.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 8. 8. 0.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0  0] -> size -> 36 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 129.57601928710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[105.42365 ]
 [108.943085]
 [ 91.38485 ]
 [112.739876]
 [112.569275]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11. 29.  8.
 10.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 29. 30.  8.  5.  9.  2.  1.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 8. 8. 0.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0  0] -> size -> 36 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.61882019042969



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 7 
Witch: 1 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 8. 25.  0. 10. 29.  0. 29.  8.  1. 11.  0. 10. 10.  0. 10. 11. 29.  8.
 10.  8.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 29 11 25  8 29  8 11 11 11  8 29 29  8 10 10 11 10 29
 10  8 10 29  8  1  1  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 29. 30.  8.  5.  9.  2.  0.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 8. 8. 0.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  1  8  0  1 11  6  3  6  0  1  8 10  0 29
  6  8 29 11 15 11  0 10  6  0  0  0] -> size -> 36 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      20       0       0
       0       0       0       0       0       8       0] 
sum of rewards: 3000053 

action type: buy - action 8.0
Learning step: 119997.609375
desired expected reward: 120110.3515625



