 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.27812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -300        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000305 

action type: buy - action -1.0
Learning step: -120009.5
desired expected reward: -120076.9296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.286774]
 [35.08673 ]
 [31.749832]
 [11.938234]
 [32.964195]
 [39.716343]
 [33.25328 ]
 [40.359848]
 [19.605604]
 [29.916386]
 [29.345535]
 [29.363724]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.999710083007812



buy possibilites: [-1] 
expected returns: [[30.431648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 40.35984802246094






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.51898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.43164825439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.377626]
 [25.837118]
 [22.98731 ]
 [ 6.423877]
 [29.899689]
 [24.062727]
 [21.212925]
 [21.476538]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.647491455078125



buy possibilites: [-1] 
expected returns: [[13.585647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 29.899688720703125






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.775005]
 [28.182755]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.585646629333496



action possibilites: [-1] 
expected returns: [[20.174519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.412708282470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.390645 ]
 [20.773605 ]
 [ 2.6441476]
 [21.979017 ]
 [20.948141 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.174518585205078



buy possibilites: [-1] 
expected returns: [[15.8407755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 21.97901725769043






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [1. 3. 0. 0. 3. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.485214]
 [33.85161 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.840775489807129



action possibilites: [-1.] 
expected returns: [[32.84881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.361385345458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[26.959263]
 [35.98248 ]
 [33.00975 ]
 [17.61456 ]
 [14.642259]
 [33.9768  ]
 [40.20655 ]
 [34.156067]
 [50.196815]
 [40.85212 ]
 [21.838627]
 [30.682583]
 [31.183334]
 [21.659365]
 [30.86185 ]
 [31.336788]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.84880828857422



buy possibilites: [-1] 
expected returns: [[29.624256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 50.19682693481445






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [29.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  1  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[19.757812]
 [35.888763]
 [26.877615]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.624256134033203



action possibilites: [-1] 
expected returns: [[6.214445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.77726745605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 4.2287893 ]
 [12.612569  ]
 [ 9.866786  ]
 [-7.1587696 ]
 [10.730155  ]
 [16.611979  ]
 [10.899083  ]
 [17.356441  ]
 [-0.48847246]
 [ 8.153296  ]
 [ 7.8953047 ]
 [ 8.595154  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.214445114135742



buy possibilites: [-1] 
expected returns: [[34.882923]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 17.356441497802734






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 29.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [29. 25.  3. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 29.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [29. 25.  3. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 29.  3.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [29. 25.  3. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[36.62494 ]
 [43.193794]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [29. 25.  3. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.8829231262207



action possibilites: [-1. 10.] 
expected returns: [[48.287926]
 [45.658318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [29. 25.  3. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.52906036376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.020264]
 [50.772266]
 [47.325684]
 [29.957249]
 [56.016933]
 [48.830334]
 [45.403084]
 [48.20314 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [29. 25.  3. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.28791809082031



buy possibilites: [-1] 
expected returns: [[54.09263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [29. 25.  3. 11.  0.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 56.01693344116211






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [8. 1. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  1  8  0  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  6.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[18.169735]
 [16.299591]
 [19.603834]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 25 29 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  6.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [8. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.092628479003906



action possibilites: [-1] 
expected returns: [[16.737791]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  6.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [8. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 20.005916595458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[13.6430025]
 [21.848747 ]
 [19.187828 ]
 [ 3.322899 ]
 [25.815031 ]
 [20.176462 ]
 [17.530067 ]
 [18.82184  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  8.  6.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [8. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.737791061401367



buy possibilites: [-1] 
expected returns: [[9.469642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  6.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [8. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 25.815038681030273






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  0.] 
cards in discard: [8. 8. 1. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  6.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 11.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  0.  0.] 
cards in discard: [8. 8. 1. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  6.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 11.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  0.  0.] 
cards in discard: [8. 8. 1. 3. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  5.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 11.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[19.966125]
 [29.279285]
 [28.433754]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11.  3.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  5.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 8.  8.  1.  3.  8.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.46964168548584



action possibilites: [-1. 11.] 
expected returns: [[21.914902]
 [29.533577]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  5.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 8.  8.  1.  3.  8.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.828380584716797



action possibilites: [-1] 
expected returns: [[32.044926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.  8.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 8.  8.  1.  3.  8.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.62710189819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.325014]
 [34.427406]
 [31.342941]
 [14.021554]
 [39.153065]
 [32.539577]
 [29.541649]
 [32.255684]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.  8.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  7.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 8.  8.  1.  3.  8.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.044925689697266



buy possibilites: [-1] 
expected returns: [[25.383484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.  8.  0.  0.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 8.  8.  1.  3.  8.  0. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 39.153076171875






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 8.  8.  1.  3.  8.  0. 29.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 11.  0. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0. 10. 11. 29. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 8.  8.  1.  3.  8.  0. 29.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 11.  0. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0. 10. 11. 29. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[78.942535]
 [95.61072 ]
 [85.28348 ]
 [86.21507 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11.  0. 29.] 
cards in discard: [11.  8.  0.  0.  0. 10. 11. 29. 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.38348388671875



action possibilites: [-1] 
expected returns: [[8.146766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 95.11619567871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 3.410998 ]
 [ 8.86168  ]
 [-6.8070135]
 [ 9.814409 ]
 [10.289485 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.14676570892334






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 8. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  8  0  6  1  8  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[25.994518]
 [25.261223]
 [30.301437]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 29.] 
cards in discard: [25.  3. 11.  0. 29. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 29.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.289490699768066



action possibilites: [-1.  8.] 
expected returns: [[15.208861]
 [16.407263]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [25.  3. 11.  0. 29. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 25 29 11 11 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 29.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.569988250732422



action possibilites: [-1] 
expected returns: [[21.173763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  3. 11.  0. 29. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 29.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 18.166893005371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.500379 ]
 [21.710093 ]
 [19.24126  ]
 [ 5.5831966]
 [19.887653 ]
 [25.568678 ]
 [20.169222 ]
 [26.354544 ]
 [10.908423 ]
 [17.700388 ]
 [17.839867 ]
 [20.478485 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  3. 11.  0. 29. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 29.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.173763275146484



buy possibilites: [-1] 
expected returns: [[77.87415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  3. 11.  0. 29. 11.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 29.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.354549407958984






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 29.] 
cards in discard: [6. 8. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11.  0. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29] -> size -> 19 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [6. 8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11.  0. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29] -> size -> 19 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [6. 8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11.  0. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29] -> size -> 19 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [6. 8. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11.  0. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29] -> size -> 19 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [11. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[50.56743 ]
 [55.70379 ]
 [46.838783]
 [55.70379 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.  0.] 
cards in discard: [25.  3. 11.  0. 29. 11.  0. 29. 29.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  3. 29.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.87415313720703



action possibilites: [-1] 
expected returns: [[135.99713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [25.  3. 11.  0. 29. 11.  0. 29. 29.  8.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  3. 29.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 60.01278305053711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[123.03077 ]
 [130.49434 ]
 [109.012375]
 [132.20248 ]
 [135.00095 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [25.  3. 11.  0. 29. 11.  0. 29. 29.  8.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  3. 29.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.99713134765625






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [1. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 0. 0.] 
cards in discard: [ 6.  8.  6.  3. 29.  0.  0.  3.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  1  0  6  1  8  8  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [ 6.  8.  6.  3. 29.  0.  0.  3.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  1  0  6  1  8  8  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 6.  8.  6.  3. 29.  0.  0.  3.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  1  0  6  1  8  8  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 6.  8.  6.  3. 29.  0.  0.  3.  1.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  1  0  6  1  8  8  6  3 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[49.633224]
 [46.55835 ]
 [55.21906 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  1  0  6  1  8  8  6  3 10] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 135.0009765625



action possibilites: [-1. 10.] 
expected returns: [[34.745544]
 [32.392456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  1  0  6  1  8  8  6  3 10] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 55.01342010498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.412937 ]
 [36.59902  ]
 [33.636288 ]
 [15.2047415]
 [41.10599  ]
 [34.881203 ]
 [31.919632 ]
 [34.27272  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  1  0  6  1  8  8  6  3 10] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.74554443359375



buy possibilites: [-1] 
expected returns: [[55.96698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  1  0  6  1  8  8  6  3 10] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.105995178222656






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 29.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  6.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  1  0  6  1  8  8  6  3 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11. 11.  0.] 
adversary cards in discard: [11. 29. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11. 11.  0.] 
adversary cards in discard: [11. 29. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11. 11.  0.] 
adversary cards in discard: [11. 29. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11. 11.  0.] 
adversary cards in discard: [11. 29. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[44.376427]
 [52.88407 ]
 [52.272346]
 [52.272346]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 11.  0.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.96697998046875



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[91.267815]
 [98.751236]
 [98.751236]
 [99.45085 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 29.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 52.05315399169922



action possibilites: [-1. 11. 11.] 
expected returns: [[57.987495]
 [65.704895]
 [65.704895]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 99.45085144042969



action possibilites: [-1] 
expected returns: [[18.338905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 68.1166763305664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.499114]
 [19.865625]
 [18.193872]
 [ 9.308811]
 [ 7.681699]
 [18.59013 ]
 [22.669264]
 [18.679136]
 [30.78437 ]
 [23.377197]
 [11.790439]
 [16.98527 ]
 [17.007378]
 [11.692349]
 [17.074284]
 [18.41049 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.338905334472656



buy possibilites: [-1] 
expected returns: [[4.991538]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0. 10. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 30.78437042236328






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [0. 8. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0. 25.] 
adversary cards in discard: [11. 29. 10.  3.  0.  3.  0. 10. 25. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25] -> size -> 23 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [0. 8. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0. 25.] 
adversary cards in discard: [11. 29. 10.  3.  0.  3.  0. 10. 25. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25] -> size -> 23 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [ 0.  8.  6.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0. 25.] 
adversary cards in discard: [11. 29. 10.  3.  0.  3.  0. 10. 25. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25] -> size -> 23 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11.  8. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 25.] 
expected returns: [[53.27605 ]
 [55.5866  ]
 [52.524673]
 [55.5866  ]
 [61.277924]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  0. 25.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0. 10. 25. 29. 29. 11.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 29.  0.  0.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29] -> size -> 15 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.991538047790527



action possibilites: [-1] 
expected returns: [[-6.3238125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  0. 10.  0.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0. 10. 25. 29. 29. 11.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 29.  0.  0.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6] -> size -> 16 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 61.49552917480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-10.600219]
 [ -8.015921]
 [-15.105818]
 [ -7.835931]
 [ -9.371052]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 11.  0. 10.  0.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0. 10. 25. 29. 29. 11.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 29.  0.  0.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6] -> size -> 16 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.323812484741211



buy possibilites: [-1] 
expected returns: [[11.389535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 11.  0. 10.  0.] 
cards in discard: [11. 29. 10.  3.  0.  3.  0. 10. 25. 29. 29. 11.  0. 11.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  4.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 29.  0.  0.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6] -> size -> 16 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -7.835942268371582






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  1.] 
cards in discard: [ 0.  8.  6.  3. 29.  0.  0.  6.  3.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  4.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8] -> size -> 24 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  1.] 
cards in discard: [ 0.  8.  6.  3. 29.  0.  0.  6.  3.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  4.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8] -> size -> 24 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  1.] 
cards in discard: [ 0.  8.  6.  3. 29.  0.  0.  6.  3.  1.  6. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  4.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8] -> size -> 24 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [11.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[71.70192]
 [75.89389]
 [69.77647]
 [75.89389]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  4.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15] -> size -> 17 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.389534950256348



action possibilites: [-1] 
expected returns: [[27.44998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  4.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15] -> size -> 17 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.99687194824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.373215]
 [27.73471 ]
 [ 9.397437]
 [28.961723]
 [28.219322]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  4.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15] -> size -> 17 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.449979782104492



buy possibilites: [-1] 
expected returns: [[46.368683]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  3.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15] -> size -> 17 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 28.961727142333984






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  3.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 25. 10. 25.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  3.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 25. 10. 25.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  3.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 25. 10. 25.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 6.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  2.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 25. 10. 25.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [29.  3. 25. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10. 25.] 
expected returns: [[40.44841 ]
 [43.914173]
 [50.540756]
 [36.14754 ]
 [50.540756]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25. 10. 25.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  5.  2.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6.  0.] 
adversary cards in discard: [ 8. 10.  1.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8] -> size -> 18 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.368682861328125



action possibilites: [-1] 
expected returns: [[11.97069]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10. 25.  3. 10.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  5.  2.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6.  0.] 
adversary cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.052650451660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -0.0182929]
 [-10.078471 ]
 [  7.7810087]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 10. 25.  3. 10.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  5.  2.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6.  0.] 
adversary cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.97068977355957






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6.  0.] 
cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  5.  2.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  0. 29.  0.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  6.  0.] 
cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  5.  2.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  0. 29.  0.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[40.255684]
 [38.797935]
 [46.394085]
 [47.065033]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 29.  0.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  5.  2.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  1.  8.  6.  8.] 
adversary cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 7.781012535095215



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[38.69176 ]
 [37.28201 ]
 [44.420784]
 [44.420784]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0. 11.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  5.  2.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  1.  8.  6.  8.] 
adversary cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.06502151489258



action possibilites: [-1] 
expected returns: [[99.593155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  5.  2.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  1.  8.  6.  8.] 
adversary cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.7274169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 92.412994]
 [ 99.83238 ]
 [ 97.515045]
 [ 82.81971 ]
 [103.8114  ]
 [ 98.39633 ]
 [ 96.07898 ]
 [ 99.30317 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  5.  2.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  1.  8.  6.  8.] 
adversary cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.59315490722656



buy possibilites: [-1] 
expected returns: [[44.275295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  1.  8.  6.  8.] 
adversary cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 103.81137084960938






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [29.  1.  8.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  8.  6.  8.] 
cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 6. 8. 3.] 
cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  1  0  6  1  8  8  6  3 10  0 29  6 15  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 8. 10.  1.  3.  0.  0.  6.  6.  0. 15.  0.  6.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 8.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[10.790122]
 [11.844787]
 [16.20119 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0.  0.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10] -> size -> 18 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.27529525756836



action possibilites: [-1.  8. 11.] 
expected returns: [[27.66632 ]
 [30.176899]
 [34.1861  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 11.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10] -> size -> 18 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.201183319091797



action possibilites: [-1] 
expected returns: [[49.07818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10] -> size -> 18 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.585968017578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.210323]
 [49.893047]
 [48.194317]
 [37.427284]
 [48.576775]
 [52.62989 ]
 [48.64589 ]
 [53.242374]
 [41.494457]
 [46.947155]
 [47.177185]
 [49.57149 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  5. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10] -> size -> 18 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.07817840576172



buy possibilites: [-1] 
expected returns: [[38.527725]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 25. 29.  3. 10. 25.  3. 10. 10. 11. 29. 11.
 10.  0.  0. 11. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10] -> size -> 18 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.24235534667969






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 11.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29] -> size -> 30 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 11.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29] -> size -> 30 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 11.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29] -> size -> 30 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [10. 11.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 11.] 
expected returns: [[36.688984]
 [33.738335]
 [41.875   ]
 [36.407925]
 [41.875   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 1.  0.  8. 10.  6.] 
adversary cards in discard: [0. 6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.52772521972656



action possibilites: [-1] 
expected returns: [[46.932404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 11.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  8. 10.  6.] 
adversary cards in discard: [0. 6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.62603759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.328354]
 [28.489418]
 [47.642212]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 11.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  8. 10.  6.] 
adversary cards in discard: [0. 6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.932403564453125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  8. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 10.  6.] 
cards in discard: [0. 6. 0. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 29. 10. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10] -> size -> 31 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 10.  6.] 
cards in discard: [0. 6. 0. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 29. 10. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10] -> size -> 31 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 10.  6.] 
cards in discard: [0. 6. 0. 0. 3. 6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 29. 10. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10] -> size -> 31 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [29. 10. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 10. 11.] 
expected returns: [[28.902534]
 [32.984924]
 [25.426746]
 [32.984924]
 [25.426746]
 [32.1956  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29. 10. 11.] 
cards in discard: [10. 11. 10.  8.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  0.  3.  6.  8.  1.  0.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8] -> size -> 20 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.64221954345703



action possibilites: [-1. 10. 10. 11. 10.] 
expected returns: [[40.879665]
 [39.373756]
 [39.373756]
 [47.13434 ]
 [39.373756]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 10.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  0.  3.  6.  8.  1.  0.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8] -> size -> 20 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.13379669189453



action possibilites: [-1] 
expected returns: [[39.90872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  0.  3.  6.  8.  1.  0.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8] -> size -> 20 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.66006851196289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.080704]
 [24.15187 ]
 [39.4441  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  0.  3.  6.  8.  1.  0.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8] -> size -> 20 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.90871810913086






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 3. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  6.  8.  1.  0.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  8.  8. 29. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15] -> size -> 32 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  6.  8.  1.  0.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  8.  8. 29. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15] -> size -> 32 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  6.  8.  1.  0.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  8.  8. 29. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15] -> size -> 32 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  6.  8.  1.  0.  8. 10.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  8.  8. 29. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15] -> size -> 32 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [11.  8.  8. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 29. 11.] 
expected returns: [[71.912636]
 [74.974335]
 [70.9157  ]
 [70.9157  ]
 [75.63589 ]
 [74.974335]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8. 29. 11.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  0. 10. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 39.444087982177734



action possibilites: [-1. 11.  8. 11.] 
expected returns: [[32.78929 ]
 [36.77959 ]
 [33.293762]
 [36.77959 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  0.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  0. 10. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.99726104736328



action possibilites: [-1] 
expected returns: [[36.725964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0. 10. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.445133209228516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.06608 ]
 [35.89852 ]
 [27.547077]
 [36.235294]
 [37.095013]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0. 10. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3] -> size -> 19 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.7259635925293






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 10. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 15. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15] -> size -> 33 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10. 15. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15] -> size -> 33 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10. 15. 29.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15] -> size -> 33 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 0. 25.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[10.71894 ]
 [23.485285]
 [ 9.973106]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 10.  3.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  6. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 1. 8. 0.] 
adversary cards in discard: [ 0.  1.  0. 10. 15. 29.] 
adversary owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3  0] -> size -> 20 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.09501266479492



action possibilites: [-1] 
expected returns: [[30.471085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0. 10.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 1. 8. 0.] 
adversary cards in discard: [ 0.  1.  0. 10. 15. 29.  6.] 
adversary owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.48529052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[24.879374]
 [30.43275 ]
 [28.830143]
 [18.18608 ]
 [33.238583]
 [29.199276]
 [31.282303]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0. 10.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 1. 8. 0.] 
adversary cards in discard: [ 0.  1.  0. 10. 15. 29.  6.] 
adversary owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.471084594726562



buy possibilites: [-1] 
expected returns: [[27.615349]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0. 10.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 1. 8. 0.] 
adversary cards in discard: [ 0.  1.  0. 10. 15. 29.  6.] 
adversary owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 33.23857498168945






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 6. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 8. 0.] 
cards in discard: [ 0.  1.  0. 10. 15. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  1  8  6  3 10  0 29  6 15  8  6 10  0  8  3  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 25.  3.  0.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0. 11. 25.  0.  0. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 0.  1.  0. 10. 15. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 25.  3.  0.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0. 11. 25.  0.  0. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 0.  1.  0. 10. 15. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8.  5. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 25.  3.  0.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0. 11. 25.  0.  0. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 0.  1.  0. 10. 15. 29.  6. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5. 10.  3.  1.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11. 25.  3.  0.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0. 11. 25.  0.  0. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 0. 11. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[27.64442 ]
 [29.383476]
 [35.9664  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  3.  0.] 
cards in discard: [10. 11. 10.  8.  0. 11. 29. 15. 29. 11. 10. 10. 10.  8. 15. 29. 11.  8.
 11.  0. 11. 25.  0.  0. 10.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  5. 10.  3.  1.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  8.  3.  3.  8.] 
adversary cards in discard: [ 0.  1.  0. 10. 15. 29.  6. 15.  8.  0.  1.  0.] 
adversary owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.61534881591797



action possibilites: [-1] 
expected returns: [[-0.23763466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 15. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  8.  3.  3.  8.] 
adversary cards in discard: [ 0.  1.  0. 10. 15. 29.  6. 15.  8.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.96638870239258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -3.9784377 ]
 [  0.08838677]
 [-11.923865  ]
 [  0.84240174]
 [  0.12554145]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0. 15. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  8.  3.  3.  8.] 
adversary cards in discard: [ 0.  1.  0. 10. 15. 29.  6. 15.  8.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.23763465881347656



buy possibilites: [-1] 
expected returns: [[6.951435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0. 15. 29.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  8.  3.  3.  8.] 
adversary cards in discard: [ 0.  1.  0. 10. 15. 29.  6. 15.  8.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 0.8424017429351807






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10.  8.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  3.  8.] 
cards in discard: [ 0.  1.  0. 10. 15. 29.  6. 15.  8.  0.  1.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 15. 11. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  3.  8.] 
cards in discard: [ 0.  1.  0. 10. 15. 29.  6. 15.  8.  0.  1.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 15. 11. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  3.  8.] 
cards in discard: [ 0.  1.  0. 10. 15. 29.  6. 15.  8.  0.  1.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 15. 11. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [ 8. 15. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11. 11.] 
expected returns: [[13.721465]
 [14.349267]
 [12.466924]
 [18.605175]
 [18.605175]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 11. 11.  0.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.951435089111328



action possibilites: [-1] 
expected returns: [[-2.8063383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 11.  0.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 15.676436424255371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -4.9924097]
 [-11.471251 ]
 [ -2.4275584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 11.  0.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.806338310241699






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [8. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  1  8  3 10  0 29  6 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1] -> size -> 36 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1] -> size -> 36 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1] -> size -> 36 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 0. 11.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[31.1722  ]
 [36.737576]
 [36.737576]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.  0.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  1.  3. 15.  0.] 
adversary cards in discard: [8. 6. 0.] 
adversary owned cards: [ 0  1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.4275600910186768



action possibilites: [-1] 
expected returns: [[31.119484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  1.  3. 15.  0.] 
adversary cards in discard: [8. 6. 0.] 
adversary owned cards: [ 0  1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 33.1240119934082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[27.63234 ]
 [31.520866]
 [20.459915]
 [31.86464 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  1.  3. 15.  0.] 
adversary cards in discard: [8. 6. 0.] 
adversary owned cards: [ 0  1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.119483947753906






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 15.  0.] 
cards in discard: [8. 6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 10. 10.  8.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [8. 6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 10. 10.  8.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [8. 6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 10. 10.  8.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 8.  6.  0. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 10. 10.  8.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [29. 10. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10.  8.] 
expected returns: [[14.843717]
 [16.548927]
 [11.426913]
 [11.426913]
 [11.426913]
 [12.600036]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 10.  8.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 15.  0.  1.] 
adversary cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.864643096923828



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[49.98226 ]
 [48.609737]
 [48.609737]
 [48.609737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 15.  0.  1.] 
adversary cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.652647972106934





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.275116]
 [42.814987]
 [50.279087]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 15.  0.  1.] 
adversary cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16] -> size -> 21 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.98225402832031






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [29. 10. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 15.  0.  1.] 
cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10. 11. 29.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 15.  0.  1.] 
cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10. 11. 29.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 15.  0.  1.] 
cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10. 11. 29.  0.] 
adversary cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 0. 10. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[24.307613]
 [21.359673]
 [26.10801 ]
 [26.671127]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29.  0.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10. 29. 10. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1. 29. 10. 15.  0.  1.] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.279075622558594



action possibilites: [-1. 11. 25.] 
expected returns: [[51.68356 ]
 [54.081978]
 [58.524647]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10. 29. 10. 10. 10.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 28. 30.  8.  4.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1. 29. 10. 15.  0.  1.] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.785316467285156



action possibilites: [-1] 
expected returns: [[0.19923806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 10.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10. 29. 10. 10. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 28. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1. 29. 10. 15.  0.  1.  6.] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.52465057373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-1.0267613]
 [ 1.943682 ]
 [-7.04044  ]
 [ 0.4747727]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29. 10.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10. 29. 10. 10. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1. 29. 10. 15.  0.  1.  6.] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.19923806190490723



buy possibilites: [-1] 
expected returns: [[12.7251005]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29. 10.] 
cards in discard: [ 8. 25.  0. 11.  3.  0. 15. 29.  1. 11.  8. 15. 11.  0.  1. 11.  0.  3.
 11.  0.  8. 10. 29. 10. 10. 10.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1. 29. 10. 15.  0.  1.  6.] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 141 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 1.9436876773834229






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1. 29. 10. 15.  0.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3] -> size -> 38 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1. 29. 10. 15.  0.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3] -> size -> 38 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 8.  6.  0. 16. 15.  1.  3.  0.  1. 29. 10. 15.  0.  1.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3] -> size -> 38 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 0. 11.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 10.] 
expected returns: [[-13.615235 ]
 [ -6.9807196]
 [-12.251227 ]
 [ -6.9807196]
 [-14.586135 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 11. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.72510051727295



action possibilites: [-1] 
expected returns: [[1.2558696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 10.] 
cards in discard: [1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -10.801681518554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -3.6782866]
 [-10.665677 ]
 [  1.501497 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11. 10.] 
cards in discard: [1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.2558696269989014






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [1. 0. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  8  3 10  0 29 15  8  6 10  0  8  3  0  6 15  6  0 16  1  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  3. 29.  0. 25.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  3. 29.  0. 25.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  3. 29.  0. 25.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 24. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  3. 29.  0. 25.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3.  3. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[23.669008]
 [29.41391 ]
 [36.292816]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0. 25.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 30.  8.  3.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 15.  8.  0.  6.] 
adversary cards in discard: [0. 8. 1. 0.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.5014994144439697



action possibilites: [-1] 
expected returns: [[-7.006526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0. 15.  0.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 15.  8.  0.  6.] 
adversary cards in discard: [0. 8. 1. 0. 6.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.292789459228516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ -9.260644]
 [ -5.88113 ]
 [-15.551578]
 [ -6.701398]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0. 15.  0.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 27. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 15.  8.  0.  6.] 
adversary cards in discard: [0. 8. 1. 0. 6.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.006525993347168



buy possibilites: [-1] 
expected returns: [[9.595092]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0. 15.  0.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 15.  8.  0.  6.] 
adversary cards in discard: [0. 8. 1. 0. 6.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -5.881134986877441






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [10. 15.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  8.  0.  6.] 
cards in discard: [0. 8. 1. 0. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10.  0.  8. 15.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  8.  0.  6.] 
cards in discard: [0. 8. 1. 0. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10.  0.  8. 15.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 10.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8. 15.] 
expected returns: [[19.62143 ]
 [23.025318]
 [17.337147]
 [18.90636 ]
 [17.531092]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  8. 15.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  0.  3.  3.  1.] 
adversary cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.595091819763184



action possibilites: [-1. 10.] 
expected returns: [[2.5514462]
 [1.3710992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  0.  3.  3.  1.] 
adversary cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 24.05093765258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-1.0232146]
 [ 2.1747353]
 [-6.924192 ]
 [ 2.2935002]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  0.  3.  3.  1.] 
adversary cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.5514438152313232






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [29.  0.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.  1.] 
cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 11. 11.  8. 10.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  3.  1.] 
cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 11. 11.  8. 10.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  3.  1.] 
cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 11. 11.  8. 10.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [10. 11. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8. 10.] 
expected returns: [[27.961689]
 [26.282782]
 [30.050694]
 [30.050694]
 [27.359282]
 [26.282782]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  8. 10.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15. 10.  0.  6.  6.] 
adversary cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.  0. 29.  0.  3.  3.  1.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.293492555618286



action possibilites: [-1] 
expected returns: [[11.183928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8. 10.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15. 10.  0.  6.  6.] 
adversary cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.  0. 29.  0.  3.  3.  1.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 28.31418228149414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 7.558012 ]
 [ 1.6200602]
 [11.0714655]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8. 10.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15. 10.  0.  6.  6.] 
adversary cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.  0. 29.  0.  3.  3.  1.] 
adversary owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.183927536010742






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [15. 10.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  6.  6.] 
cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.  0. 29.  0.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  1.  1.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.] 
cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.  0. 29.  0.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  1.  1.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.] 
cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.  0. 29.  0.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  1.  1.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.] 
cards in discard: [ 0.  8.  1.  0.  6. 10. 15.  8.  0.  6.  0. 29.  0.  3.  3.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  1.  1.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [ 0. 29. 10.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[41.53987 ]
 [44.73704 ]
 [40.299355]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  1.  1.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.071457862854004



action possibilites: [-1.  8.] 
expected returns: [[ 0.99075675]
 [-0.49518347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 8.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.32738494873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-4.099619  ]
 [ 0.60514855]
 [-0.74315286]
 [-8.345668  ]
 [-9.583108  ]
 [-0.5631192 ]
 [ 2.8857815 ]
 [ 7.8498583 ]
 [ 3.4454305 ]
 [-6.1665487 ]
 [-1.5341964 ]
 [-6.2337074 ]
 [-1.4669502 ]
 [ 0.99075675]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 8.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.990760087966919



buy possibilites: [-1] 
expected returns: [[24.642921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 8.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -70   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 7.849855422973633






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  1. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [25. 11.  0. 10. 11.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10. 25. 29.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25] -> size -> 42 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  1. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [25. 11.  0. 10. 11.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10. 25. 29.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25] -> size -> 42 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  1. 16.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [25. 11.  0. 10. 11.] 
adversary cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10. 25. 29.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25] -> size -> 42 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [25. 11.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10. 11.] 
expected returns: [[-10.056275  ]
 [  0.29395843]
 [ -5.721918  ]
 [-11.258145  ]
 [ -5.721918  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 10. 11.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10. 25. 29.  1.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  2.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  6. 10.  0.  8.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29] -> size -> 26 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.642921447753906



action possibilites: [-1] 
expected returns: [[-5.1913695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 11.  0. 11.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10. 25. 29.  1.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  6. 10.  0.  8.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.29395556449890137





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ -8.123689 ]
 [ -4.463879 ]
 [-15.189073 ]
 [ -5.1913733]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 11.  0. 11.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10. 25. 29.  1.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 26. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  6. 10.  0.  8.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.191369533538818



buy possibilites: [-1] 
expected returns: [[1.2937553]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 11.  0. 11.] 
cards in discard: [ 1. 11.  0.  8. 11. 10.  3. 25.  3.  3. 29.  0. 15.  0.  8. 15. 29. 10.
  0.  3.  1. 11. 10. 11.  8. 10.  0. 10. 25. 29.  1.  1.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  6. 10.  0.  8.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 161 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -4.463882923126221






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [29.  6. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 10.  0.  8.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  8. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 43 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 10.  0.  8.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  8. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 43 
adversary victory points: 5
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  8. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 10. 29.] 
expected returns: [[ -8.057753]
 [ -9.854763]
 [ -9.854763]
 [ -5.656893]
 [-11.6328  ]
 [ -4.946831]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11. 10. 29.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 15.  1.  0.  3.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.293755292892456



action possibilites: [-1.  8.  8.] 
expected returns: [[13.088143]
 [13.840301]
 [13.840301]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [11. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11  8 25 29 11 11 10 11 29 10 11 10 25  8
 10  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 15.  1.  0.  3.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.638701438903809



action possibilites: [-1] 
expected returns: [[29.205795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 15.  1.  0.  3.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 14.905913352966309





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[24.783405]
 [27.816751]
 [19.382511]
 [28.501144]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 15.  1.  0.  3.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.205795288085938






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  0.  3.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15.  8. 11.  1. 10.] 
adversary cards in discard: [11. 10. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 42 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  0.  3.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 25. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15.  8. 11.  1. 10.] 
adversary cards in discard: [11. 10. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 42 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  0.  3.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 24. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15.  8. 11.  1. 10.] 
adversary cards in discard: [11. 10. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 42 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [15.  8. 11.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11. 10.] 
expected returns: [[-18.532791]
 [-17.91309 ]
 [-15.975826]
 [-12.799878]
 [-17.594149]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 11.  1. 10.] 
cards in discard: [11. 10. 29.  8.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3] -> size -> 28 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.501163482666016



action possibilites: [-1] 
expected returns: [[-5.1320667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  1. 10.] 
cards in discard: [11. 10. 29.  8.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 24. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3] -> size -> 28 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 172 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -14.891571044921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ -7.878984 ]
 [ -4.285751 ]
 [-14.907593 ]
 [ -5.3336625]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  1. 10.] 
cards in discard: [11. 10. 29.  8.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 24. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3] -> size -> 28 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.13206672668457



buy possibilites: [-1] 
expected returns: [[5.337968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  1. 10.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3] -> size -> 28 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -4.285737991333008






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.  0.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  8. 29. 10.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.  0.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 22. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  8. 29. 10.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.  0.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  8. 29. 10.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [10.  8. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29. 10.] 
expected returns: [[-6.749034 ]
 [-7.944128 ]
 [-6.5324726]
 [-2.9179583]
 [-7.944128 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 10.  0.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  6.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.
  1. 10.  0.  0.  1.  0.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1] -> size -> 29 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.337967872619629



action possibilites: [-1. 10. 10.] 
expected returns: [[7.6459265]
 [5.8397045]
 [5.8397045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  6.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.
  1. 10.  0.  0.  1.  0.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1] -> size -> 29 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.470713138580322





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 4.3730927]
 [ 8.214821 ]
 [-2.9180765]
 [ 8.907969 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  6.] 
adversary cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.
  1. 10.  0.  0.  1.  0.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1] -> size -> 29 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.645923614501953






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  8.  6.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.
  1. 10.  0.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 1. 11. 29. 10.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  8.  6.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.
  1. 10.  0.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 1. 11. 29. 10.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  8.  6.] 
cards in discard: [29.  6.  0.  0.  1. 16.  6. 29.  6. 10.  0.  8.  3.  3. 15.  1.  0.  3.
  1. 10.  0.  0.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 1. 11. 29. 10.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [ 1. 11. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[ 0.63458085]
 [ 3.523268  ]
 [ 4.0884323 ]
 [-2.1511497 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29. 10.  0.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15.  1.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 8.907960891723633



action possibilites: [-1. 11.] 
expected returns: [[-1.0011365]
 [ 3.5154755]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15.  1.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 0.8433754444122314



action possibilites: [-1] 
expected returns: [[-0.7311256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15.  1.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: 202 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 0.9847147464752197





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
expected returns: [[-3.323568  ]
 [ 0.9464214 ]
 [-0.41527486]
 [-9.035549  ]
 [-0.01860523]
 [ 2.8834379 ]
 [ 3.1998265 ]
 [-5.736826  ]
 [-1.4668329 ]
 [-1.1851537 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 30. 23. 30.  8.  1.  9.  3.  0.  7.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15.  1.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.7311255931854248



buy possibilites: [-1] 
expected returns: [[25.218613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 23. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [15.  1.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0] -> size -> 30 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -110    0    0
  128    0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 3.199836492538452






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [15.  1.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  6.  6.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 23. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 15.  3.  0.  3.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  6.  6.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 20. 30. 23. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 15.  3.  0.  3.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  6.  6.  3.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 15.  3.  0.  3.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 3. 15.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[12.159209]
 [10.481509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  0.  3.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  6. 29. 15.  0.] 
adversary cards in discard: [ 3. 15.  1.  6.  6.  3.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0  3] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.218612670898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.1449175]
 [ 2.6403716]
 [12.159209 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  0.  3.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 20. 30. 22. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  6. 29. 15.  0.] 
adversary cards in discard: [ 3. 15.  1.  6.  6.  3.] 
adversary owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0  3] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.159205436706543



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29. 15.  0.] 
cards in discard: [ 3. 15.  1.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3 10  0 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0
  0 29  6  3  1  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 25. 11.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.  3. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29.] 
cards in discard: [ 3. 15.  1.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  3 10 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0  0
 29  6  3  1  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 20. 30. 22. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 25. 11.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.  3. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.] 
cards in discard: [ 3. 15.  1.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  3 10 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0  0
 29  6  3  1  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 30. 22. 30.  8.  1.  9.  3.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 25. 11.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.  3. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.] 
cards in discard: [ 3. 15.  1.  6.  6.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  3 10 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0  0
 29  6  3  1  0  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 30.  8.  1.  9.  2.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 25. 11.  0.] 
adversary cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.  3. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 3.  0. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[23.491894]
 [34.67635 ]
 [27.665695]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 11.  0.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.  3. 15.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 30.  8.  1.  9.  2.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 16.  0.  8.  8.] 
adversary cards in discard: [ 3. 15.  1.  6.  6.  3. 11. 15.  3.  6. 29.] 
adversary owned cards: [ 1  1  3 10 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0  0
 29  6  3  1  0  3 11] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.159205436706543



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 4 
Witch: 3 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  0. 11.  0. 25.  0.] 
cards in discard: [11. 10. 29.  8.  0.  1.  3. 11. 15.  8.  1. 10. 10.  8. 29. 10.  0. 10.
 11. 10.  1. 29. 29. 11.  1.  0.  3. 15.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 29 11 11 10 11 29 10 11 10 25  8 10
  8 10 11 10 29 10 15 15 11  8  1  1  3  1  3  1 25  3  1  3  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 30.  8.  0.  9.  2.  0.  7.  2. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 16.  0.  8.  8.] 
adversary cards in discard: [ 3. 15.  1.  6.  6.  3. 11. 15.  3.  6. 29.  6.] 
adversary owned cards: [ 1  1  3 10 29 15  8 10  0  8  3  0  6 15  6  0 16  1  6  0  0  6  0  0
 29  6  3  1  0  3 11  6] -> size -> 32 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0     210       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000225 

action type: take_action - action 25.0
Learning step: 120007.609375
desired expected reward: 120042.2890625



