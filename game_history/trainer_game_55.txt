 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.14062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    4  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -511 

action type: buy - action -1.0
Learning step: -30.991195678710938
desired expected reward: 77.83273315429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[282.9744 ]
 [293.42975]
 [290.5905 ]
 [264.3946 ]
 [302.44843]
 [291.71265]
 [288.90704]
 [309.12997]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.955060958862305
desired expected reward: 299.06005859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[330.55566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.042278289794922
desired expected reward: 301.0876770019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[300.8419 ]
 [312.3297 ]
 [309.8924 ]
 [281.19855]
 [305.81732]
 [321.47928]
 [310.2071 ]
 [314.4146 ]
 [292.54614]
 [308.13663]
 [305.8681 ]
 [328.31345]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.865789413452148
desired expected reward: 324.0995178222656



buy possibilites: [-1] 
expected returns: [[304.49896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -6.942178249359131
desired expected reward: 298.9259338378906






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 3. 0. 0. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[266.46304]
 [251.83511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.490674018859863
desired expected reward: 295.00830078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[255.99014]
 [264.83347]
 [261.77817]
 [240.15045]
 [270.45966]
 [263.46808]
 [260.61157]
 [273.4948 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.540380954742432
desired expected reward: 259.0118713378906



buy possibilites: [-1] 
expected returns: [[270.43512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -7.088613986968994
desired expected reward: 256.37945556640625






Player: 1 
cards in hand: [3. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.5667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  0. 15.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.597935676574707
desired expected reward: 263.8371887207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[293.04227]
 [303.06787]
 [300.69263]
 [275.59628]
 [297.35632]
 [310.6987 ]
 [301.2377 ]
 [304.74902]
 [285.59848]
 [299.16147]
 [297.1357 ]
 [316.0934 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  0. 15.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.977810859680176
desired expected reward: 303.1919860839844



buy possibilites: [-1] 
expected returns: [[294.21756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  0. 15.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 10.0
Learning step: -8.213179588317871
desired expected reward: 290.9483337402344






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.  3.  8.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.  3.  8.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.  3.  8.  1.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[280.0771 ]
 [260.76666]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.6799955368042
desired expected reward: 285.5375671386719



action possibilites: [-1] 
expected returns: [[247.14253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 15.0
Learning step: -6.6689133644104
desired expected reward: 255.92349243164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[222.178  ]
 [232.72237]
 [230.61234]
 [209.85524]
 [204.42389]
 [226.78888]
 [241.23775]
 [230.72351]
 [249.0201 ]
 [234.67227]
 [214.74467]
 [222.33798]
 [228.95691]
 [210.33133]
 [226.8899 ]
 [247.74564]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -6.33542537689209
desired expected reward: 240.80711364746094



buy possibilites: [-1] 
expected returns: [[279.2989]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [16.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 68 

action type: buy - action 22.0
Learning step: -0.8323417901992798
desired expected reward: 209.49899291992188






Player: 1 
cards in hand: [16.  0.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [22. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [22. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1.  3.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [22. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.6087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [22. 15.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 16.] 
adversary cards in discard: [ 0. 16.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.483155250549316
desired expected reward: 271.81573486328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.12354]
 [285.15192]
 [281.54025]
 [252.4455 ]
 [292.94324]
 [283.03464]
 [279.69714]
 [296.90106]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [22. 15.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 16.] 
adversary cards in discard: [ 0. 16.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.403343200683594
desired expected reward: 284.1206359863281



buy possibilites: [-1] 
expected returns: [[249.45123]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [22. 15.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 16.] 
adversary cards in discard: [ 0. 16.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.884017944335938
desired expected reward: 249.0493927001953






Player: 1 
cards in hand: [ 3.  0.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 16.] 
cards in discard: [ 0. 16.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1 16 16  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [ 0. 16.  0.  1.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [ 0. 16.  0.  1.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [ 0. 16.  0.  1.  3.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[265.95184]
 [249.31638]
 [251.27707]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 22  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -6.308629989624023
desired expected reward: 243.14260864257812



action possibilites: [-1] 
expected returns: [[244.5354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 2
Learning step: -5.679678440093994
desired expected reward: 245.95481872558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[219.20383]
 [227.05273]
 [201.88367]
 [227.31998]
 [243.1228 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  9.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -5.782130718231201
desired expected reward: 238.75326538085938



buy possibilites: [-1] 
expected returns: [[270.27307]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  8.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -283.0 

action type: buy - action 6.0
Learning step: -18.163040161132812
desired expected reward: 183.7206268310547






Player: 1 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  8.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  8.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6] -> size -> 14 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  8.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6] -> size -> 14 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[288.9327 ]
 [255.91437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 22.  0.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 16. 16.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0  0] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -7.560128688812256
desired expected reward: 262.71295166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[266.22876]
 [272.68182]
 [248.82962]
 [274.36038]
 [286.06064]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 22.  0.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  8.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 16. 16.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0  0] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -8.4351806640625
desired expected reward: 278.7894592285156



buy possibilites: [-1] 
expected returns: [[244.86945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 22.  0.] 
cards in discard: [6. 8. 3. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  7.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 16. 16.] 
adversary cards in discard: [0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0  0] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -22.63191795349121
desired expected reward: 226.1977081298828






Player: 1 
cards in hand: [ 3.  0.  0. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16. 16.] 
cards in discard: [0. 6. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  1 16 16  0  6  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  7.  8. 10.  8. 10. 10. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6] -> size -> 15 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 0.  6.  0.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  7.  8. 10.  8. 10. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 0.  6.  0.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  7.  8. 10.  8. 10. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6] -> size -> 15 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 0.  6.  0.  0.  3.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  7.  8. 10.  7. 10. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6] -> size -> 15 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[262.62274]
 [242.91812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  7.  8. 10.  7. 10. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 0.] 
adversary cards in discard: [ 0.  6.  0.  0.  3.  0. 10.  8. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -6.770398139953613
desired expected reward: 238.0990447998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[237.51154]
 [248.11896]
 [244.92413]
 [220.20941]
 [255.65683]
 [246.14548]
 [243.22787]
 [260.51862]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  7.  8. 10.  7. 10. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 0.] 
adversary cards in discard: [ 0.  6.  0.  0.  3.  0. 10.  8. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -7.7759599685668945
desired expected reward: 253.96726989746094



buy possibilites: [-1] 
expected returns: [[260.63367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8.  7.  8. 10.  7. 10. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 0.] 
adversary cards in discard: [ 0.  6.  0.  0.  3.  0. 10.  8. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -7.7113189697265625
desired expected reward: 229.8002166748047






Player: 1 
cards in hand: [0. 0. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  0. 10.  8. 16.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  7.  8. 10.  7. 10. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  0. 10.  8. 16.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 30. 30.  8.  7.  8. 10.  7. 10. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 0.] 
cards in discard: [ 0.  6.  0.  0.  3.  0. 10.  8. 16.  0.  0. 16. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  7.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[266.616  ]
 [251.87314]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 22  0  6  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  7.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -7.432460784912109
desired expected reward: 253.20120239257812



action possibilites: [-1] 
expected returns: [[211.72159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  7.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 9
Learning step: -7.45352029800415
desired expected reward: 252.8916015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[190.88943]
 [173.14053]
 [218.14417]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8.  7.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -5.406100273132324
desired expected reward: 206.31549072265625



buy possibilites: [-1] 
expected returns: [[191.05693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8.  6.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 6.0
Learning step: -18.48322868347168
desired expected reward: 142.15696716308594






Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  6.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 22.  3.  6.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  6.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 22.  3.  6.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 30. 30.  8.  6.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 22.  3.  6.  0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 22.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[290.46277]
 [250.255  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  3.  6.  0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  6.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [16.  0. 25.  1.  3.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -4.286587238311768
desired expected reward: 186.7703399658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[262.23517]
 [271.25992]
 [242.75754]
 [271.31384]
 [289.4326 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3.  6.  0.] 
cards in discard: [ 0.  3.  0. 15.  0.  0.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 30. 30.  8.  6.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [16.  0. 25.  1.  3.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -9.070223808288574
desired expected reward: 277.9143371582031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 25.  1.  3.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  6.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [22.  0.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  3.  0.  8.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [22.  0.  6.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1.  3.  0.  8.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [22.  0.  6.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [22.  0.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[190.54898]
 [151.5008 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  6.  0.  6.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [10. 16.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -326 

action type: buy - action -1.0
Learning step: -26.8929500579834
desired expected reward: 262.53961181640625



action possibilites: [-1] 
expected returns: [[234.52972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [10. 16.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -4 

action type: take_action - action 22.0
Learning step: -2.5415382385253906
desired expected reward: 149.82760620117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[213.05055]
 [222.37868]
 [220.26349]
 [196.73183]
 [217.05515]
 [229.99962]
 [220.69434]
 [224.17982]
 [206.19606]
 [218.8929 ]
 [217.10262]
 [236.25452]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  7.  9. 10. 10. 10.  8.  9.  9.] 
adversary cards in hand: [10. 16.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -7.098695278167725
desired expected reward: 227.4310302734375



buy possibilites: [-1] 
expected returns: [[261.75507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  7.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10. 16.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 26 

action type: buy - action 15.0
Learning step: -3.6656410694122314
desired expected reward: 213.4369659423828






Player: 1 
cards in hand: [10. 16.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  6.  0.  0.] 
cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  7.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 16 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  7.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 16 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  6.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 16 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  6.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 16 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 25. 16.  0.  1.  3.  0.  8.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 16 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[174.29514]
 [155.70842]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 8. 10. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25  8  8] -> size -> 19 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -10.750805854797363
desired expected reward: 251.00425720214844



action possibilites: [-1] 
expected returns: [[127.1368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 8. 10. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25  8  8] -> size -> 19 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action 15.0
Learning step: -5.04445743560791
desired expected reward: 147.05624389648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[111.01692 ]
 [118.69323 ]
 [117.14417 ]
 [101.696266]
 [ 97.58541 ]
 [114.41775 ]
 [124.75423 ]
 [117.24541 ]
 [130.35889 ]
 [120.00835 ]
 [105.34943 ]
 [111.06287 ]
 [115.94259 ]
 [102.01098 ]
 [114.39921 ]
 [129.23526 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  8 22  0  6  0  6  6 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 8. 10. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25  8  8] -> size -> 19 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -4.073066711425781
desired expected reward: 123.06373596191406



buy possibilites: [-1] 
expected returns: [[114.38877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 15. 22.  0.  6.  0.  6.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  8 22  0  6  0  6  6 15 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 10. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25  8  8] -> size -> 19 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -1.5 

action type: buy - action 10.0
Learning step: -3.298382520675659
desired expected reward: 112.64421081542969






Player: 1 
cards in hand: [ 8. 10. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16 16  0  6  0  0 10  8 25  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 22  0  6  0  6  6 15 10] -> size -> 16 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 22  0  6  0  6  6 15 10] -> size -> 16 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 22  0  6  0  6  6 15 10] -> size -> 16 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[198.90634]
 [186.8899 ]
 [188.44987]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 22  0  6  0  6  6 15 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -2.6742279529571533
desired expected reward: 111.71454620361328



action possibilites: [-1.  8.] 
expected returns: [[196.82288]
 [182.35184]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 15  8 22  0  6  0  6  6 15 10] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -5 

action type: take_action - action 10.0
Learning step: -5.402930736541748
desired expected reward: 183.05215454101562



action possibilites: [-1.] 
expected returns: [[122.69953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: trash_cards_n_from_hand - action 8
Learning step: -6.596210479736328
desired expected reward: 172.54278564453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.69053]
 [ 95.88755]
 [124.23882]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8.  5.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: take_action - action -1.0
Learning step: -4.060543060302734
desired expected reward: 118.63899230957031



buy possibilites: [-1] 
expected returns: [[121.87636]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8.  4.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -50.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -319.0 

action type: buy - action 6.0
Learning step: -17.686845779418945
desired expected reward: 71.89442443847656






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  4.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 6. 22.  6.  0.  6.] 
adversary cards in discard: [ 6. 10.  8.  0.] 
adversary owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 30. 30.  8.  4.  8. 10.  5.  9. 10. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 6. 22.  6.  0.  6.] 
adversary cards in discard: [ 6. 10.  8.  0.] 
adversary owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 6. 22.  6.  0.  6.] 
adversary cards in discard: [ 6. 10.  8.  0.] 
adversary owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 6. 22.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[130.63094]
 [103.01918]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  6.  0.  6.] 
cards in discard: [ 6. 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [16.  0.  3.  1.  6.] 
adversary cards in discard: [ 8.  0.  0. 14.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8 14] -> size -> 18 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -6.476692199707031
desired expected reward: 115.39966583251953



action possibilites: [-1] 
expected returns: [[139.50514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  6.  0.  0. 15.] 
cards in discard: [ 6. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [16.  0.  3.  1.  6.] 
adversary cards in discard: [ 8.  0.  0. 14.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8 14] -> size -> 18 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: LIBRARY: skip_action_card - action 1
Learning step: -4.415557384490967
desired expected reward: 107.67289733886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[122.56934]
 [130.36234]
 [126.94121]
 [109.37857]
 [134.7132 ]
 [129.12814]
 [125.84784]
 [136.33812]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  6.  0.  0. 15.] 
cards in discard: [ 6. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [16.  0.  3.  1.  6.] 
adversary cards in discard: [ 8.  0.  0. 14.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8 14] -> size -> 18 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1
Learning step: -6.064433574676514
desired expected reward: 133.44070434570312






Player: 1 
cards in hand: [16.  0.  3.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  1.  6.] 
cards in discard: [ 8.  0.  0. 14.  8.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  6  0  0  8 25  8  8 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1.] 
cards in discard: [ 8.  0.  0. 14.  8.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [ 8.  0.  0. 14.  8.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [ 8.  0.  0. 14.  8.  0.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  6.  6. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[127.21373 ]
 [119.396255]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 15.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -8.465533256530762
desired expected reward: 127.87260437011719



action possibilites: [-1] 
expected returns: [[125.561935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action 15.0
Learning step: -6.653738498687744
desired expected reward: 113.92390441894531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[110.947365]
 [119.78052 ]
 [117.05951 ]
 [ 96.04964 ]
 [114.72    ]
 [125.268425]
 [118.23228 ]
 [120.784355]
 [104.06829 ]
 [115.84695 ]
 [113.80988 ]
 [128.04184 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  8 22  0  6  0  6  6 15 10  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 28. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -7.124769687652588
desired expected reward: 118.43716430664062



buy possibilites: [-1] 
expected returns: [[89.88368]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  8 22  0  6  0  6  6 15 10  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.    0.   -4.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -64.5 

action type: buy - action 1.0
Learning step: -7.191642761230469
desired expected reward: 112.5888671875






Player: 1 
cards in hand: [ 0.  3.  8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  8. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [15.  6.  8. 10.  6.] 
adversary cards in discard: [ 1. 15.  6.  6.  0.] 
adversary owned cards: [ 0  0 15  8 22  0  6  0  6  6 15 10  6  1] -> size -> 14 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [15.  6.  8. 10.  6.] 
adversary cards in discard: [ 1. 15.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0 15  8 22  0  6  0  6  6 15 10  6  1  6] -> size -> 15 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  3.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [15.  6.  8. 10.  6.] 
adversary cards in discard: [ 1. 15.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0 15  8 22  0  6  0  6  6 15 10  6  1  6] -> size -> 15 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [15.  6.  8. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
expected returns: [[25.74583 ]
 [17.161768]
 [20.98163 ]
 [18.535091]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  8. 10.  6.] 
cards in discard: [ 1. 15.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8 22  0  6  0  6  6 15 10  6  1  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [25.  0.  3.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5  -90    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -400 

action type: buy - action -1
Learning step: -24.027807235717773
desired expected reward: 65.85587310791016



action possibilites: [-1] 
expected returns: [[119.31482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1. 15.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [25.  0.  3.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: trash_cards_n_from_hand - action 12
Learning step: -1.0465834140777588
desired expected reward: 15.576749801635742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.62172]
 [ 89.42175]
 [123.51031]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 15.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  3.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [25.  0.  3.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: -6.4813737869262695
desired expected reward: 112.83344268798828



buy possibilites: [-1] 
expected returns: [[103.75204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 15.  6.  6.  0.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [25.  0.  3.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -80    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -369 

action type: buy - action 6.0
Learning step: -20.586666107177734
desired expected reward: 68.83505249023438






Player: 1 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [25.  0.  3.  8.  8.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6] -> size -> 12 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [25.  0.  3.  8.  8.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 28. 30.  8.  2.  8. 10.  5.  9. 10.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6] -> size -> 12 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [25.  0.  3.  8.  8.  8.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  2.  8. 10.  5.  9. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6] -> size -> 12 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[141.67342]
 [115.82348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  8. 10.  5.  9. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [16.  8.  0. 14.  0.] 
adversary cards in discard: [25.  0.  3.  8.  8.  8.  0. 10.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3 10] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -6.72761869430542
desired expected reward: 97.02442169189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[120.75949 ]
 [128.41705 ]
 [125.96269 ]
 [107.18883 ]
 [123.966515]
 [133.38705 ]
 [127.127914]
 [129.27121 ]
 [114.542076]
 [124.848404]
 [123.07763 ]
 [136.40376 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 28. 30.  8.  2.  8. 10.  5.  9. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [16.  8.  0. 14.  0.] 
adversary cards in discard: [25.  0.  3.  8.  8.  8.  0. 10.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3 10] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -8.735370635986328
desired expected reward: 133.16702270507812



buy possibilites: [-1] 
expected returns: [[80.19052]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 28. 30. 28. 30.  8.  1.  8. 10.  5.  9. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [16.  8.  0. 14.  0.] 
adversary cards in discard: [25.  0.  3.  8.  8.  8.  0. 10.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3 10] -> size -> 20 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -400.0 

action type: buy - action 6.0
Learning step: -23.028833389282227
desired expected reward: 73.633544921875






Player: 1 
cards in hand: [16.  8.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0. 14.  0.] 
cards in discard: [25.  0.  3.  8.  8.  8.  0. 10.  0.  3.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 16  0  0  0  8 25  8  8 14  3  3 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  1.  8. 10.  5.  9. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  6.  6. 15.] 
adversary cards in discard: [ 6.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.] 
cards in discard: [25.  0.  3.  8.  8.  8.  0. 10.  0.  3.  0.  3.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  6.  6. 15.] 
adversary cards in discard: [ 6.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [25.  0.  3.  8.  8.  8.  0. 10.  0.  3.  0.  3.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  6.  6. 15.] 
adversary cards in discard: [ 6.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [25.  0.  3.  8.  8.  8.  0. 10.  0.  3.  0.  3.  1. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  6.  6. 15.] 
adversary cards in discard: [ 6.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[85.142365]
 [72.87547 ]
 [70.56128 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  6. 15.] 
cards in discard: [ 6.  0.  0.  0. 22.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3] -> size -> 21 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -7.79829740524292
desired expected reward: 72.39222717285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.25125 ]
 [56.570744]
 [86.330444]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  6.  6. 15.] 
cards in discard: [ 6.  0.  0.  0. 22.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3] -> size -> 21 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -8.146368980407715
desired expected reward: 76.63492584228516



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [22.  6.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [22.  6.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [22.  6.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [22.  6.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[121.24489]
 [ 97.28862]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [16.  3. 10.  0. 14.] 
adversary cards in discard: [0. 8. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -7.3244829177856445
desired expected reward: 79.00594329833984



action possibilites: [-1] 
expected returns: [[74.63185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 1. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [16.  3. 10.  0. 14.] 
adversary cards in discard: [0. 8. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: LIBRARY: skip_action_card - action 1
Learning step: -8.476819038391113
desired expected reward: 104.64388275146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[72.691055]
 [79.41775 ]
 [77.53525 ]
 [64.557846]
 [60.859516]
 [75.55726 ]
 [84.20058 ]
 [78.22938 ]
 [89.67865 ]
 [80.253555]
 [67.38403 ]
 [71.99704 ]
 [76.52019 ]
 [64.39903 ]
 [74.97908 ]
 [87.157936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [16.  3. 10.  0. 14.] 
adversary cards in discard: [0. 8. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -6.528332710266113
desired expected reward: 68.103515625






Player: 1 
cards in hand: [16.  3. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 10.  0. 14.] 
cards in discard: [0. 8. 3. 0. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 15.  0.  6.  6.] 
adversary cards in discard: [22.  6.  0.  6.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1. 16. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0. 14. 25.] 
cards in discard: [0. 8. 3. 0. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 15.  0.  6.  6.] 
adversary cards in discard: [22.  6.  0.  6.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0. 14. 25.] 
cards in discard: [0. 8. 3. 0. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 6. 15.  0.  6.  6.] 
adversary cards in discard: [22.  6.  0.  6.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[122.63826]
 [106.12142]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  6.  6.] 
cards in discard: [22.  6.  0.  6.  1.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 29.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -7.352604866027832
desired expected reward: 79.80532836914062



action possibilites: [-1] 
expected returns: [[148.99068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [22.  6.  0.  6.  1.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 29.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action 15.0
Learning step: -6.291687965393066
desired expected reward: 96.5878677368164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[129.26698 ]
 [137.6682  ]
 [135.76837 ]
 [115.436455]
 [145.32254 ]
 [135.76512 ]
 [134.2083  ]
 [150.4506  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [22.  6.  0.  6.  1.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 29.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -8.892607688903809
desired expected reward: 140.0980682373047



buy possibilites: [-1] 
expected returns: [[78.01236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [22.  6.  0.  6.  1.  0.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 29.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -72 

action type: buy - action 10.0
Learning step: -8.555136680603027
desired expected reward: 125.65316009521484






Player: 1 
cards in hand: [ 3.  0.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 29.] 
cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [6. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  0. 29.] 
cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  5.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [6. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  0. 29.] 
cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [6. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [6. 6. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[132.08852]
 [123.20366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [3. 0. 0. 1. 8.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.  8.  3.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8] -> size -> 23 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -6.5679168701171875
desired expected reward: 71.44444274902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.438  ]
 [ 99.79538]
 [124.45153]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [3. 0. 0. 1. 8.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.  8.  3.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8] -> size -> 23 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -9.49036979675293
desired expected reward: 120.81231689453125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 8.] 
cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.  8.  3.  0.  8.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10. 22. 15.  6.  0.] 
adversary cards in discard: [6. 6. 8. 0. 6.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.  8.  3.  0.  8.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10. 22. 15.  6.  0.] 
adversary cards in discard: [6. 6. 8. 0. 6.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.  8.  3.  0.  8.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 27. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10. 22. 15.  6.  0.] 
adversary cards in discard: [6. 6. 8. 0. 6.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
adversary victory points: -5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 0.  8.  3.  0.  3.  0. 10. 16.  3.  0. 14. 25.  8.  3.  0.  8.  0. 29.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10. 22. 15.  6.  0.] 
adversary cards in discard: [6. 6. 8. 0. 6.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10. 22. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22. 15.] 
expected returns: [[36.877617]
 [28.25791 ]
 [16.88164 ]
 [26.821318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 22. 15.  6.  0.] 
cards in discard: [6. 6. 8. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8  3] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -11.123052597045898
desired expected reward: 113.32845306396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.565012]
 [15.304045]
 [37.59806 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 22. 15.  6.  0.] 
cards in discard: [6. 6. 8. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8  3] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -6.681652069091797
desired expected reward: 28.99758529663086



buy possibilites: [-1] 
expected returns: [[63.23351]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 22. 15.  6.  0.] 
cards in discard: [6. 6. 8. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8  3] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -140.0 

action type: buy - action 0.0
Learning step: -6.638031005859375
desired expected reward: 19.926984786987305






Player: 1 
cards in hand: [0. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 16  0  0  0  8 25  8  8 14  3  3 10 29  3  0  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0] -> size -> 14 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0] -> size -> 14 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0] -> size -> 14 
adversary victory points: -5
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[94.92665]
 [82.78586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3] -> size -> 18 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -90 

action type: buy - action -1
Learning step: -5.673752784729004
desired expected reward: 57.559757232666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[80.066345]
 [87.19216 ]
 [85.56497 ]
 [68.03512 ]
 [92.73589 ]
 [85.87106 ]
 [84.470795]
 [96.6116  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  4.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3] -> size -> 18 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -90 

action type: take_action - action -1.0
Learning step: -7.292874813079834
desired expected reward: 86.97650146484375



buy possibilites: [-1] 
expected returns: [[62.82681]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  6.  1.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3] -> size -> 18 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5.   0.  -5. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -88.0 

action type: buy - action 8.0
Learning step: -7.279950141906738
desired expected reward: 78.59110260009766






Player: 1 
cards in hand: [ 1.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 10.  0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  0.  8.  6.] 
adversary cards in discard: [ 8.  6. 10.  0.  6.  1.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8] -> size -> 15 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10.  0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 26. 30.  8.  1.  8. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  0.  8.  6.] 
adversary cards in discard: [ 8.  6. 10.  0.  6.  1.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8] -> size -> 15 
adversary victory points: -5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10.  0.] 
cards in discard: [ 8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  0.  8.  6.] 
adversary cards in discard: [ 8.  6. 10.  0.  6.  1.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8] -> size -> 15 
adversary victory points: -5
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[82.27722]
 [72.31064]
 [75.37517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  8.  6.] 
cards in discard: [ 8.  6. 10.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 0. 16.  3. 14. 29.] 
adversary cards in discard: [ 8. 16.  1.  3.  0. 10.  0.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -90 

action type: buy - action -1
Learning step: -5.939181804656982
desired expected reward: 56.88762664794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[66.41281 ]
 [70.2661  ]
 [57.161846]
 [71.10362 ]
 [78.81002 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  8.  6.] 
cards in discard: [ 8.  6. 10.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 0. 16.  3. 14. 29.] 
adversary cards in discard: [ 8. 16.  1.  3.  0. 10.  0.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -90 

action type: take_action - action -1.0
Learning step: -6.998422145843506
desired expected reward: 74.02212524414062



buy possibilites: [-1] 
expected returns: [[106.86627]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  8.  6.] 
cards in discard: [ 8.  6. 10.  0.  6.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 0. 16.  3. 14. 29.] 
adversary cards in discard: [ 8. 16.  1.  3.  0. 10.  0.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -71 

action type: buy - action 3.0
Learning step: -4.658812999725342
desired expected reward: 65.60726928710938






Player: 1 
cards in hand: [ 0. 16.  3. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3. 14. 29.] 
cards in discard: [ 8. 16.  1.  3.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10.  0.  6.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3] -> size -> 16 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3. 14. 29.] 
cards in discard: [ 8. 16.  1.  3.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 25. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10.  0.  6.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3] -> size -> 16 
adversary victory points: -4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  0.  6.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
expected returns: [[41.703014]
 [33.52313 ]
 [25.944557]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  6. 22.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [25.  8.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  1.  3.  0. 10.  0.  0. 16.  3. 14. 29.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -8.52616024017334
desired expected reward: 98.3401107788086



action possibilites: [-1] 
expected returns: [[46.212437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  6.  1.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [25.  8.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  1.  3.  0. 10.  0.  0. 16.  3. 14. 29.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: LIBRARY: skip_action_card - action 1
Learning step: -3.5437958240509033
desired expected reward: 29.127716064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.51598 ]
 [49.94302 ]
 [47.741646]
 [35.597286]
 [46.728855]
 [52.752384]
 [49.08066 ]
 [50.11772 ]
 [39.74832 ]
 [46.953377]
 [45.4845  ]
 [53.70988 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  6.  1.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 25. 30.  8.  1.  7. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [25.  8.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  1.  3.  0. 10.  0.  0. 16.  3. 14. 29.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -4.202285289764404
desired expected reward: 42.01015090942383



buy possibilites: [-1] 
expected returns: [[68.82435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  6.  1.  0.  8.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  1.  6. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [25.  8.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  1.  3.  0. 10.  0.  0. 16.  3. 14. 29.] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -27 

action type: buy - action 16.0
Learning step: -2.137894868850708
desired expected reward: 44.59096145629883






Player: 1 
cards in hand: [25.  8.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.  8.  0.] 
cards in discard: [ 8. 16.  1.  3.  0. 10.  0.  0. 16.  3. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  1.  6. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  0.] 
adversary cards in discard: [16. 22. 10.  0.  6.  6.  1.  0.  8.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16] -> size -> 17 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  0.  8.  0.] 
cards in discard: [ 8. 16.  1.  3.  0. 10.  0.  0. 16.  3. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 25. 30.  8.  1.  6. 10.  3.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  0.] 
adversary cards in discard: [16. 22. 10.  0.  6.  6.  1.  0.  8.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16] -> size -> 17 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  0.  8.  0.] 
cards in discard: [ 8. 16.  1.  3.  0. 10.  0.  0. 16.  3. 14. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  0.] 
adversary cards in discard: [16. 22. 10.  0.  6.  6.  1.  0.  8.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16] -> size -> 17 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[26.320496]
 [17.064394]
 [18.676872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.  8.  0.] 
cards in discard: [16. 22. 10.  0.  6.  6.  1.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [29.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16  8] -> size -> 20 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -6.976298809051514
desired expected reward: 61.84804916381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.686387]
 [20.14888 ]
 [ 5.240387]
 [19.617596]
 [27.821161]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.  8.  0.] 
cards in discard: [16. 22. 10.  0.  6.  6.  1.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 25. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [29.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16  8] -> size -> 20 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1.0
Learning step: -4.818215847015381
desired expected reward: 20.451824188232422



buy possibilites: [-1] 
expected returns: [[6.108529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.  8.  0.] 
cards in discard: [16. 22. 10.  0.  6.  6.  1.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [29.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16  8] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -60 

action type: buy - action 3.0
Learning step: -3.870002508163452
desired expected reward: 16.278881072998047






Player: 1 
cards in hand: [29.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  0  0  0  8 25  8  8 14  3 10 29  3  0  8  3 16  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 3. 10.  3.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3] -> size -> 18 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 3. 10.  3.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3] -> size -> 18 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 3. 10.  3.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3] -> size -> 18 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[41.048275]
 [34.55157 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  6.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [0. 1. 8. 3. 8.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8] -> size -> 18 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -2.8627588748931885
desired expected reward: 3.245770215988159





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.55489 ]
 [24.222668]
 [40.45268 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  6.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [0. 1. 8. 3. 8.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8] -> size -> 18 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -4.7048492431640625
desired expected reward: 35.9217643737793



buy possibilites: [-1] 
expected returns: [[100.36068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  6.  6.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [0. 1. 8. 3. 8.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8] -> size -> 18 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action 0.0
Learning step: -3.874680757522583
desired expected reward: 20.78123664855957






Player: 1 
cards in hand: [0. 1. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 3. 8.] 
cards in discard: [8. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 8. 15.  0.  6.  6.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 19 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 8.] 
cards in discard: [8. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  2.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 8. 15.  0.  6.  6.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 19 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 8.] 
cards in discard: [8. 3. 3. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 8. 15.  0.  6.  6.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6.] 
adversary owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 19 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8. 15.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[50.582733]
 [40.90274 ]
 [38.781532]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  6.  6.] 
cards in discard: [ 0.  3. 10.  3.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 22  0  0  6 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10. 16.  8.  0.  0.] 
adversary cards in discard: [8. 3. 3. 8. 0. 1. 8. 3. 8.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8  8] -> size -> 19 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -7.479044437408447
desired expected reward: 92.88163757324219



action possibilites: [-1] 
expected returns: [[47.944466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.] 
cards in discard: [ 0.  3. 10.  3.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 22  0  0 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10. 16.  8.  0.  0.] 
adversary cards in discard: [8. 3. 3. 8. 0. 1. 8. 3. 8.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8  8] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: trash_cards_n_from_hand - action 6
Learning step: -2.2639784812927246
desired expected reward: 27.59059715270996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.373863]
 [35.739468]
 [47.828705]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.] 
cards in discard: [ 0.  3. 10.  3.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 22  0  0 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10. 16.  8.  0.  0.] 
adversary cards in discard: [8. 3. 3. 8. 0. 1. 8. 3. 8.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8  8] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -3.3066489696502686
desired expected reward: 44.6378173828125






Player: 1 
cards in hand: [10. 16.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  8.  0.  0.] 
cards in discard: [8. 3. 3. 8. 0. 1. 8. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3 10  3  0  8  3 16  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 8.  6. 16. 22.  0.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6.  8. 15.  6.] 
adversary owned cards: [ 8 22  0  0 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 17 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  6. 16. 22.  0.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6.  8. 15.  6.] 
adversary owned cards: [ 8 22  0  0 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 17 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  6. 16. 22.  0.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6.  8. 15.  6.] 
adversary owned cards: [ 8 22  0  0 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 17 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  6. 16. 22.  0.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6.  8. 15.  6.] 
adversary owned cards: [ 8 22  0  0 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 17 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 16. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 22.] 
expected returns: [[32.96867 ]
 [26.420965]
 [24.927666]
 [18.630352]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 16. 22.  0.] 
cards in discard: [ 0.  3. 10.  3.  6.  6.  8. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 22  0  0 15  6  1  6  6  6 10  0  8  3 16  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16. 25.  8. 14.] 
adversary cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.  0. 16.  8.  0.  0.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -4.729119300842285
desired expected reward: 43.09959411621094



action possibilites: [-1] 
expected returns: [[21.63578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  3. 10.  3.  6.  6.  8. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16. 25.  8. 14.] 
adversary cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.  0. 16.  8.  0.  0.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: trash_cards_n_from_hand - action 10
Learning step: -2.28607439994812
desired expected reward: 16.171510696411133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.398006 ]
 [ 1.8318405]
 [19.198814 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  3. 10.  3.  6.  6.  8. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16. 25.  8. 14.] 
adversary cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.  0. 16.  8.  0.  0.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -2.6765007972717285
desired expected reward: 18.959280014038086






Player: 1 
cards in hand: [ 0. 16. 25.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 25.  8. 14.] 
cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.  0. 16.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 25.  8. 14.] 
cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.  0. 16.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 25.  8. 14.] 
cards in discard: [ 8.  3.  3.  8.  0.  1.  8.  3.  8. 22.  0. 16.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[95.93503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -1.6695778369903564
desired expected reward: 17.52924346923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[84.01916 ]
 [90.221535]
 [88.44938 ]
 [73.18223 ]
 [86.611046]
 [94.97051 ]
 [89.06577 ]
 [91.021484]
 [79.11516 ]
 [87.5289  ]
 [86.1096  ]
 [97.87402 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 24. 30.  8.  1.  6. 10.  1.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -5.63507080078125
desired expected reward: 89.4921875



buy possibilites: [-1] 
expected returns: [[38.040398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 1.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -55.0 

action type: buy - action 8.0
Learning step: -6.347379684448242
desired expected reward: 82.71839141845703






Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [8. 6. 3. 0. 0. 1.] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [8. 6. 3. 0. 0. 1.] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [8. 6. 3. 0. 0. 1.] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[36.887226]
 [36.262558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 8.] 
cards in discard: [8. 6. 3. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 3. 8. 1. 0.] 
adversary cards in discard: [0. 0. 0. 3. 8. 0.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0  0] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -3.918991804122925
desired expected reward: 34.12140655517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.98786 ]
 [26.494461]
 [37.14809 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 8.] 
cards in discard: [8. 6. 3. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 3. 8. 1. 0.] 
adversary cards in discard: [0. 0. 0. 3. 8. 0.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0  0] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -3.9876115322113037
desired expected reward: 33.31524658203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 1. 0.] 
cards in discard: [0. 0. 0. 3. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  3  0  8  3 16  8  8 22  0  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 10.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0.] 
cards in discard: [0. 0. 0. 3. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 10.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [0. 0. 0. 3. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 10.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [0. 0. 0. 3. 8. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 10.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 10.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 15.] 
expected returns: [[78.92069]
 [72.27166]
 [72.27166]
 [70.09929]
 [68.43901]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  6. 15.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  6  1  6  6  6 10  0  8  3  3  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 3. 25. 16. 14. 22.] 
adversary cards in discard: [0. 0. 0. 3. 8. 0. 1. 8. 8. 1. 0.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1] -> size -> 22 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -2.5724854469299316
desired expected reward: 34.57561111450195



action possibilites: [-1] 
expected returns: [[31.157032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 3. 25. 16. 14. 22.] 
adversary cards in discard: [0. 0. 0. 3. 8. 0. 1. 8. 8. 1. 0.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: trash_cards_n_from_hand - action 5
Learning step: -3.0956711769104004
desired expected reward: 56.83841323852539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.525734 ]
 [ 7.6996536]
 [29.537899 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 3. 25. 16. 14. 22.] 
adversary cards in discard: [0. 0. 0. 3. 8. 0. 1. 8. 8. 1. 0.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -1.948032259941101
desired expected reward: 29.208999633789062






Player: 1 
cards in hand: [ 3. 25. 16. 14. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16. 14. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 16. 14. 22.] 
cards in discard: [0. 0. 0. 3. 8. 0. 1. 8. 8. 1. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 10.] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 16. 14. 22.] 
cards in discard: [0. 0. 0. 3. 8. 0. 1. 8. 8. 1. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 10.] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 16. 14. 22.] 
cards in discard: [0. 0. 0. 3. 8. 0. 1. 8. 8. 1. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 10.] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8] -> size -> 13 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.658245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16.  0.  8.  8.] 
adversary cards in discard: [ 0.  0.  0.  3.  8.  0.  1.  8.  8.  1.  0.  0.  3. 25. 16. 14. 22.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -2.731543779373169
desired expected reward: 26.806365966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[16.217165 ]
 [20.98253  ]
 [19.459276 ]
 [ 6.8033237]
 [24.035618 ]
 [18.731657 ]
 [25.413662 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16.  0.  8.  8.] 
adversary cards in discard: [ 0.  0.  0.  3.  8.  0.  1.  8.  8.  1.  0.  0.  3. 25. 16. 14. 22.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -2.585002899169922
desired expected reward: 21.652856826782227



buy possibilites: [-1] 
expected returns: [[58.374443]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16.  0.  8.  8.] 
adversary cards in discard: [ 0.  0.  0.  3.  8.  0.  1.  8.  8.  1.  0.  0.  3. 25. 16. 14. 22.] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -2.7974331378936768
desired expected reward: 13.419732093811035






Player: 1 
cards in hand: [ 0. 16.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  8.  8.] 
cards in discard: [ 0.  0.  0.  3.  8.  0.  1.  8.  8.  1.  0.  0.  3. 25. 16. 14. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 6. 8. 3. 1.] 
adversary cards in discard: [ 8.  8. 10.  0.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  8.  8.] 
cards in discard: [ 0.  0.  0.  3.  8.  0.  1.  8.  8.  1.  0.  0.  3. 25. 16. 14. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 6. 8. 3. 1.] 
adversary cards in discard: [ 8.  8. 10.  0.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  8.  8.] 
cards in discard: [ 0.  0.  0.  3.  8.  0.  1.  8.  8.  1.  0.  0.  3. 25. 16. 14. 22.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [6. 6. 8. 3. 1.] 
adversary cards in discard: [ 8.  8. 10.  0.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [6. 6. 8. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[94.08477]
 [79.15533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 3. 1.] 
cards in discard: [ 8.  8. 10.  0.  6.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -2.8352901935577393
desired expected reward: 55.539154052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[71.541595]
 [77.45546 ]
 [61.617004]
 [93.006096]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3. 1.] 
cards in discard: [ 8.  8. 10.  0.  6.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 24. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.605006694793701
desired expected reward: 85.84654998779297



buy possibilites: [-1] 
expected returns: [[88.4499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3. 1.] 
cards in discard: [ 8.  8. 10.  0.  6.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -17 

action type: buy - action 3.0
Learning step: -2.7326507568359375
desired expected reward: 74.72281646728516






Player: 1 
cards in hand: [8. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0  0  0  8 25  8  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 1. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 1. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 1. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 1. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [3. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[78.03312]
 [70.205  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  1  6  6  6 10  0  8  3  3  0  8  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 1. 25.  0.  0.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -4.049402713775635
desired expected reward: 84.40049743652344



action possibilites: [-1] 
expected returns: [[72.12902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6  6  6 10  0  8  3  3  0  8  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 1. 25.  0.  0.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.970890998840332
desired expected reward: 64.90498352050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[52.872925]
 [57.188213]
 [42.229202]
 [65.531204]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6  6  6 10  0  8  3  3  0  8  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 23. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 1. 25.  0.  0.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -2.6249172687530518
desired expected reward: 69.50410461425781



buy possibilites: [-1] 
expected returns: [[44.73643]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6  6  6 10  0  8  3  3  0  8  0  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 1. 25.  0.  0.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 14 

action type: buy - action 3.0
Learning step: -1.152841567993164
desired expected reward: 56.03538513183594






Player: 1 
cards in hand: [ 1. 25.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  0.  8.] 
cards in discard: [0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 30.  8.  1.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [10.  6.  8.  6.  0.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 8  0  6  6  6 10  0  8  3  3  0  8  0  3  3] -> size -> 15 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  8.  8. 16.] 
cards in discard: [0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [10.  6.  8.  6.  0.] 
adversary cards in discard: [3. 8. 3. 0. 0. 6.] 
adversary owned cards: [ 8  0  6  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  8.  8. 16.] 
cards in discard: [0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 27. 30. 22. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [10.  6.  8.  6.  0.] 
adversary cards in discard: [3. 8. 3. 0. 0. 6.] 
adversary owned cards: [ 8  0  6  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  8.  8. 16.] 
cards in discard: [0. 8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [10.  6.  8.  6.  0.] 
adversary cards in discard: [3. 8. 3. 0. 0. 6.] 
adversary owned cards: [ 8  0  6  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  6.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[42.860954]
 [34.501953]
 [36.80826 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.  6.  0.] 
cards in discard: [3. 8. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  6  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 14. 16.  0.  3.] 
adversary cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: -18.182180404663086
desired expected reward: 26.554250717163086



action possibilites: [-1] 
expected returns: [[53.517334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.] 
cards in discard: [3. 8. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 14. 16.  0.  3.] 
adversary cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.25309810042381287
desired expected reward: 27.01759910583496





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[38.446156]
 [50.077347]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [3. 8. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 14. 16.  0.  3.] 
adversary cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -1.8766758441925049
desired expected reward: 51.64065933227539






Player: 1 
cards in hand: [ 0. 14. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 16.  0.  3.] 
cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0.  6.  8. 10.  6.  0.] 
adversary owned cards: [ 8  0  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 16.  0.  3.] 
cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0.  6.  8. 10.  6.  0.] 
adversary owned cards: [ 8  0  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 16.  0.  3.] 
cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0.  6.  8. 10.  6.  0.] 
adversary owned cards: [ 8  0  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[50.270416]
 [41.437706]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 8. 0.] 
cards in discard: [ 3.  8.  3.  0.  0.  6.  8. 10.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  6  6 10  0  8  3  3  0  8  0  3  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 0. 1. 0. 8.] 
adversary cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.  0.  0. 14. 16.  0.  3.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -2.756206512451172
desired expected reward: 47.321136474609375



action possibilites: [-1] 
expected returns: [[46.976715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  8.  3.  0.  0.  6.  8. 10.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6 10  0  8  0  8  0  3  3  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 0. 1. 0. 8.] 
adversary cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.  0.  0. 14. 16.  0.  3.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 11
Learning step: -1.934411644935608
desired expected reward: 42.893341064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.929136]
 [45.179905]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  8.  3.  0.  0.  6.  8. 10.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6 10  0  8  0  8  0  3  3  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 0. 1. 0. 8.] 
adversary cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.  0.  0. 14. 16.  0.  3.] 
adversary owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -2.2385640144348145
desired expected reward: 44.73815155029297






Player: 1 
cards in hand: [3. 0. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 8.] 
cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.  0.  0. 14. 16.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  0 25  8 14  3  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  6 10  0  8  0  8  0  3  3  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.  0.  0. 14. 16.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  6 10  0  8  0  8  0  3  3  6] -> size -> 12 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.  0.  0. 14. 16.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 21. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  6 10  0  8  0  8  0  3  3  6] -> size -> 12 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  3. 25.  1.  0.  0.  8.  8. 16.  0.  0. 14. 16.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  6 10  0  8  0  8  0  3  3  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[49.511017]
 [42.035828]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  6 10  0  8  0  8  0  3  3  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [16.  1.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -2.994619131088257
desired expected reward: 42.18529510498047



action possibilites: [-1.  8.] 
expected returns: [[43.34304 ]
 [37.771423]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0  6 10  0  8  0  8  0  3  3  6] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [16.  1.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: -1.8984405994415283
desired expected reward: 39.352752685546875



action possibilites: [-1.] 
expected returns: [[14.060625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  0  6 10  0  8  0  8  0  3  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [16.  1.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0  3] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: trash_cards_n_from_hand - action 1
Learning step: -2.0629961490631104
desired expected reward: 39.524208068847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 3.0357761]
 [ 8.099527 ]
 [ 6.9722714]
 [10.69961  ]
 [ 6.449516 ]
 [12.235189 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  0  6 10  0  8  0  8  0  3  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 20. 30.  8.  0.  6. 10.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [16.  1.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0  3] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: -0.8224843144416809
desired expected reward: 13.238141059875488



buy possibilites: [-1] 
expected returns: [[41.1273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  0  6 10  0  8  0  8  0  3  6 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [16.  1.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0  3] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  40   0   0   0   0   0   0   0  18   0] 
sum of rewards: 12 

action type: buy - action 11.0
Learning step: 0.990384042263031
desired expected reward: 11.689988136291504






Player: 1 
cards in hand: [16.  1.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  1  0  0  0  3  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  9.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 6. 8. 8. 0.] 
adversary cards in discard: [11. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 8  0  6 10  0  8  0  8  0  3  6 11] -> size -> 12 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.] 
cards in discard: [29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 6. 8. 8. 0.] 
adversary cards in discard: [11. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 8  0  6 10  0  8  0  8  0  3  6 11] -> size -> 12 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.] 
cards in discard: [29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 6. 8. 8. 0.] 
adversary cards in discard: [11. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 8  0  6 10  0  8  0  8  0  3  6 11] -> size -> 12 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.] 
cards in discard: [29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [3. 6. 8. 8. 0.] 
adversary cards in discard: [11. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 8  0  6 10  0  8  0  8  0  3  6 11] -> size -> 12 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [3. 6. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[13.977823]
 [ 8.00971 ]
 [ 8.00971 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 8. 0.] 
cards in discard: [11. 10.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  6 10  0  8  0  8  0  3  6 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 25.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -4.142669200897217
desired expected reward: 36.9846305847168



action possibilites: [-1] 
expected returns: [[27.083075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8.] 
cards in discard: [11. 10.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  0  8  0  8  0  3  6 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 25.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: trash_cards_n_from_hand - action 3
Learning step: -0.924250066280365
desired expected reward: 3.748134136199951





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.13191 ]
 [29.368025]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8.] 
cards in discard: [11. 10.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  0  8  0  8  0  3  6 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 25.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -2.0946578979492188
desired expected reward: 24.98841667175293



buy possibilites: [-1] 
expected returns: [[-9.841973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8.] 
cards in discard: [11. 10.  8.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 25.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action 0.0
Learning step: -4.020477294921875
desired expected reward: 16.11144256591797






Player: 1 
cards in hand: [ 0.  0.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [29.  0. 16.  0.  0. 22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0] -> size -> 12 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3.  3. 16.] 
cards in discard: [29.  0. 16.  0.  0. 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0] -> size -> 12 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  3. 16.] 
cards in discard: [29.  0. 16.  0.  0. 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0] -> size -> 12 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  3. 16.] 
cards in discard: [29.  0. 16.  0.  0. 22.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0] -> size -> 12 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[23.057512]
 [18.088179]
 [18.088179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -1.3559887409210205
desired expected reward: -11.197961807250977





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.453233]
 [20.708813]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -3.0907442569732666
desired expected reward: 20.232467651367188



buy possibilites: [-1] 
expected returns: [[36.338184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 8. 6.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -76.0 

action type: buy - action 0.0
Learning step: -3.6050527095794678
desired expected reward: 8.84817886352539






Player: 1 
cards in hand: [ 0.  0. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [0. 8. 0. 6. 8. 6.] 
adversary owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  6.  8.  6.  0. 11.] 
adversary owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 27. 30. 20. 30.  8.  0.  6.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  6.  8.  6.  0. 11.] 
adversary owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  6.  8.  6.  0. 11.] 
adversary owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.044891]
 [22.244345]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 0.  8.  0.  6.  8.  6.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  0  8  0  8  0  3  6 11  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16. 16. 14.  0.  0.
  8.  0.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0
 16] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: discard_down_to_3_cards - action 7
Learning step: -3.5021347999572754
desired expected reward: 31.71282386779785



action possibilites: [-1] 
expected returns: [[9.2208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  8.  0.  6.  8.  6.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  8  0  8  0  6 11  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16. 16. 14.  0.  0.
  8.  0.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0
 16] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: trash_cards_n_from_hand - action 2
Learning step: -2.2511134147644043
desired expected reward: 9.920513153076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.5427055]
 [8.56169  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  0.  6.  8.  6.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  8  0  8  0  6 11  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16. 16. 14.  0.  0.
  8.  0.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0
 16] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -2.1515088081359863
desired expected reward: 7.069291591644287



buy possibilites: [-1] 
expected returns: [[52.24054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  0.  6.  8.  6.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  8  0  8  0  6 11  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16. 16. 14.  0.  0.
  8.  0.] 
adversary owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0
 16] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action 0.0
Learning step: -2.451723575592041
desired expected reward: 3.09098482131958






Player: 1 
cards in hand: [0. 8. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8. 3.] 
cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16. 16. 14.  0.  0.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25  8 14  0  8  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  8  0  6 11  0  0  0] -> size -> 12 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16. 16. 14.  0.  0.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  8  0  6 11  0  0  0] -> size -> 12 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29.  0. 16.  0.  0. 22.  0. 25.  0.  0.  0.  3.  3. 16. 16. 14.  0.  0.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  0  8  0  6 11  0  0  0] -> size -> 12 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[24.968685]
 [20.923557]
 [20.923557]
 [19.47004 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  0  8  0  6 11  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -4.979110240936279
desired expected reward: 47.26142883300781



action possibilites: [-1.  8.  8.] 
expected returns: [[94.12754]
 [92.40861]
 [92.40861]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 10  8  0  8  0  6 11  0  0  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -36 

action type: take_action - action 10.0
Learning step: -0.6740129590034485
desired expected reward: 18.66097068786621



action possibilites: [-1.  8.] 
expected returns: [[39.25799 ]
 [34.585648]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  6 10  8  8  6 11  0  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: trash_cards_n_from_hand - action 4
Learning step: -4.220900535583496
desired expected reward: 79.83844757080078



action possibilites: [-1] 
expected returns: [[46.55041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  60   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -27 

action type: trash_cards_n_from_hand - action 0
Learning step: -1.835387110710144
desired expected reward: 28.820039749145508





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.11493 ]
 [45.649418]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  60   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -2.7659316062927246
desired expected reward: 43.784481048583984



buy possibilites: [-1] 
expected returns: [[72.20231]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 8  6 10  8  8  6 11  0  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  60 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action 0.0
Learning step: -1.2287360429763794
desired expected reward: 28.837018966674805






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  0.  6.] 
adversary cards in discard: [ 0. 10.  8.  8.] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0  0] -> size -> 10 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  0.  6.] 
adversary cards in discard: [ 0. 10.  8.  8.] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0  0] -> size -> 10 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  0.  6.] 
adversary cards in discard: [ 0. 10.  8.  8.] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0  0] -> size -> 10 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[ 0.9245815 ]
 [-1.8088071 ]
 [ 0.07207823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 11.  0.  6.] 
cards in discard: [ 0. 10.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  8  6 11  0  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [14.  8.  3. 16.  0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -6.462085723876953
desired expected reward: 65.74021911621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.3192508]
 [ 1.960949 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 11.  0.  6.] 
cards in discard: [ 0. 10.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  8  6 11  0  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [14.  8.  3. 16.  0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -2.903792381286621
desired expected reward: -1.8842642307281494



buy possibilites: [-1] 
expected returns: [[6.3112717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 11.  0.  6.] 
cards in discard: [ 0. 10.  8.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  8  6 11  0  0  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [14.  8.  3. 16.  0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -87.0 

action type: buy - action 0.0
Learning step: -4.092033386230469
desired expected reward: -6.411289215087891






Player: 1 
cards in hand: [14.  8.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3. 16.  0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0  0  0] -> size -> 11 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3. 16.  0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0  0  0] -> size -> 11 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3. 16.  0.] 
cards in discard: [0. 0. 0. 0. 3. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0  0  0] -> size -> 11 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
expected returns: [[40.852837]
 [33.7026  ]
 [33.7026  ]
 [38.121483]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  8  6 11  0  0  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -2.3578484058380127
desired expected reward: 3.953423261642456



action possibilites: [-1] 
expected returns: [[28.83034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -67 

action type: trash_cards_n_from_hand - action 3
Learning step: -4.088856220245361
desired expected reward: 23.661916732788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.573793]
 [26.63923 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0] -> size -> 25 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -4.280580997467041
desired expected reward: 24.549758911132812






Player: 1 
cards in hand: [ 0.  0. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0. 29.] 
cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  8.] 
adversary cards in discard: [ 8.  8. 11.] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  0. 29.] 
cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  8.] 
adversary cards in discard: [ 8.  8. 11.] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  0. 29.] 
cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 6. 10.  0.  6.  8.] 
adversary cards in discard: [ 8.  8. 11.] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[ 3.5396738]
 [-0.798789 ]
 [-1.032775 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  6.  8.] 
cards in discard: [ 8.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16. 16.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.  0.  0.  0. 25.  0. 29.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -5.660402297973633
desired expected reward: 20.978832244873047



action possibilites: [-1.  8.] 
expected returns: [[51.385857]
 [46.327187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 0.] 
cards in discard: [ 8.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16. 16.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.  0.  0.  0. 25.  0. 29.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0 -30   0   0   0   0   1] 
sum of rewards: -66 

action type: take_action - action 10.0
Learning step: -2.1647391319274902
desired expected reward: -2.855807304382324





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[30.874529]
 [33.690422]
 [39.584366]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 0.] 
cards in discard: [ 8.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 10  8  8  6 11  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 20. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16. 16.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.  0.  0.  0. 25.  0. 29.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -5.135409832000732
desired expected reward: 46.25044631958008



buy possibilites: [-1] 
expected returns: [[5.8827333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 0.] 
cards in discard: [ 8.  8. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 10  8  8  6 11  0  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 16. 16.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.  0.  0.  0. 25.  0. 29.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0 -30   0   0   0   8   0] 
sum of rewards: -48 

action type: buy - action 3.0
Learning step: -3.952159881591797
desired expected reward: 29.738262176513672






Player: 1 
cards in hand: [ 0. 16. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16.  0.  8.] 
cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.  0.  0.  0. 25.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [10.  6. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0  3] -> size -> 10 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 16.  0.  8.] 
cards in discard: [ 0.  0.  0.  0.  3.  0.  0. 14.  8.  3. 16.  0.  0.  0.  0. 25.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [10.  6. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 10  8  8  6 11  0  0  3] -> size -> 10 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10.  6. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[3.1668797 ]
 [0.1393156 ]
 [2.129797  ]
 [0.40218496]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 10  8  8  6 11  0  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -4.065867900848389
desired expected reward: 1.8168654441833496



action possibilites: [-1] 
expected returns: [[38.90458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  8  6 11  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -67 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.4714248180389404
desired expected reward: -2.53587007522583





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.974258]
 [36.010254]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  8  6 11  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -4.584088325500488
desired expected reward: 34.320491790771484






Player: 1 
cards in hand: [ 0.  0.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 22.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [ 8.  6. 11.] 
adversary owned cards: [ 8  6  8  8  6 11  0  0] -> size -> 8 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [ 8.  6. 11.] 
adversary owned cards: [ 8  6  8  8  6 11  0  0] -> size -> 8 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [ 8.  6. 11.] 
adversary owned cards: [ 8  6  8  8  6 11  0  0] -> size -> 8 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  0.  3. 16.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [ 8.  6. 11.] 
adversary owned cards: [ 8  6  8  8  6 11  0  0] -> size -> 8 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[32.391308]
 [26.167376]
 [26.167376]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 8.] 
cards in discard: [ 8.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  8  6 11  0  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -5.227015972137451
desired expected reward: 24.419408798217773



action possibilites: [-1] 
expected returns: [[10.15325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  8  8  6 11] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -77 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.8865065574646
desired expected reward: 20.412580490112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 4.519706]
 [10.035971]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  8  8  6 11] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -4.19234561920166
desired expected reward: 5.960904121398926






Player: 1 
cards in hand: [16.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29.  0.  0.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [11.  8.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  8  6 11] -> size -> 5 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  0.  0.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  9.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [11.  8.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  8  6 11] -> size -> 5 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  0.  0.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [11.  8.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  8  6 11] -> size -> 5 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [11.  8.  8.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[ 1.6152291 ]
 [ 0.79814124]
 [-1.0054264 ]
 [-1.0054264 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  6.  6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  8  6 11] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [25.  0. 14.  8.  0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11] -> size -> 28 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -5.4005126953125
desired expected reward: 4.635456085205078



action possibilites: [-1] 
expected returns: [[19.81039]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [25.  0. 14.  8.  0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11] -> size -> 28 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -127 

action type: trash_cards_n_from_hand - action 8
Learning step: -5.815419673919678
desired expected reward: -7.592362403869629





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.798285]
 [18.720858]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [25.  0. 14.  8.  0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11] -> size -> 28 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -127 

action type: take_action - action -1
Learning step: -6.995213985443115
desired expected reward: 12.815176010131836






Player: 1 
cards in hand: [25.  0. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 14.  8.  0.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11] -> size -> 2 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0.  0. 16.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11] -> size -> 2 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  0. 16.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11] -> size -> 2 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  0. 16.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [ 8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11] -> size -> 2 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[7.976628 ]
 [4.992067 ]
 [6.5882554]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.  3. 25.
  0. 14.  8.  0.  0. 16.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -135 

action type: buy - action -1.0
Learning step: -7.511802673339844
desired expected reward: 11.209051132202148



action possibilites: [-1] 
expected returns: [[28.500116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.  3. 25.
  0. 14.  8.  0.  0. 16.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: trash_cards_n_from_hand - action 0
Learning step: -5.4131178855896
desired expected reward: 0.674285888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.19721 ]
 [27.119616]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.  3. 25.
  0. 14.  8.  0.  0. 16.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: -6.651692867279053
desired expected reward: 21.84842300415039






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.  3. 25.
  0. 14.  8.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.  3. 25.
  0. 14.  8.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  5.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 22.  8.  0.  0.  0.  3.  0.  3. 16. 11. 16.  0. 29.  0.  0.  3. 25.
  0. 14.  8.  0.  0. 16. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.705002]
 [14.149141]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -135 

action type: buy - action -1.0
Learning step: -7.809114933013916
desired expected reward: 19.310501098632812



action possibilites: [-1] 
expected returns: [[21.143023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action 8.0
Learning step: -5.925638198852539
desired expected reward: 7.101482391357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.955832]
 [20.305563]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: -6.376043319702148
desired expected reward: 14.766979217529297



buy possibilites: [-1] 
expected returns: [[-7.2179804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20 -30   0   0 -60   0 -50   0   0   0] 
sum of rewards: -165 

action type: buy - action 0.0
Learning step: -9.312105178833008
desired expected reward: 8.643722534179688






Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  5.  8.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[4.3573256 ]
 [0.29064512]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: -7.335501194000244
desired expected reward: -14.553482055664062



action possibilites: [-1] 
expected returns: [[5.360487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: trash_cards_n_from_hand - action 0
Learning step: -5.6310858726501465
desired expected reward: -5.59715461730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.87521815]
 [1.5669508 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: -5.990354061126709
desired expected reward: -0.6298670768737793



buy possibilites: [-1] 
expected returns: [[-6.102966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20 -30   0   0 -60   0 -50   0   0   0] 
sum of rewards: -165 

action type: buy - action 0.0
Learning step: -8.43107795715332
desired expected reward: -7.555863380432129






Player: 1 
cards in hand: [ 0.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [11.  0. 11.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [11.  0. 11.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [11.  0. 11.  0.  3.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.051812]
 [ 9.395112]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [25.  0. 14. 16. 29.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: -7.183536052703857
desired expected reward: -13.28650188446045



action possibilites: [-1] 
expected returns: [[6.1054907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [25.  0. 14. 16. 29.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: trash_cards_n_from_hand - action 0
Learning step: -6.057553291320801
desired expected reward: 2.840974807739258





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[2.6164207]
 [5.065547 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [25.  0. 14. 16. 29.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: -5.9681572914123535
desired expected reward: 0.13733339309692383






Player: 1 
cards in hand: [25.  0. 14. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 16. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 14. 16. 29.] 
cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 16. 29.  0.  3.] 
cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 16. 29.  0.  3.] 
cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 18. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 16. 29.  0.  3.] 
cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 17. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[4.5654263]
 [4.198778 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 17. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 22. 16.  0.  3.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.  3. 25.  0. 14. 16. 29.
  0.  3.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -145 

action type: buy - action -1.0
Learning step: -7.382061004638672
desired expected reward: -2.316512107849121





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[3.5136857]
 [6.929761 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 26. 30. 17. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 22. 16.  0.  3.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.  3. 25.  0. 14. 16. 29.
  0.  3.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -145 

action type: take_action - action -1.0
Learning step: -7.4228339195251465
desired expected reward: -1.5969862937927246



Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 1 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 1 
Workshop: 1 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 3 
Library: 1 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 17. 30.  8.  0.  5.  7.  0.  9.  8.  9. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 22. 16.  0.  3.] 
adversary cards in discard: [11.  0. 11.  0.  3.  0.  1.  0.  0.  0.  3. 10.  3. 25.  0. 14. 16. 29.
  0.  3.] 
adversary owned cards: [16  0 25 14  0  3 16  8  8 22  0  0  0  0  0  0  3  0  3 29  0  0 16  0
  0  0  0 11  3 10 11  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -50    0    0    0  -30    0    0  -60    0  -50    0
    0    0] 
sum of rewards: -695 

action type: buy - action 0.0
Learning step: -34.92568588256836
desired expected reward: -31.41199493408203



