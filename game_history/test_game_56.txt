 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[11.893383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000125 

action type: buy - action 0.0
Learning step: -120004.734375
desired expected reward: -120011.15625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 10.519392]
 [ 25.45345 ]
 [ 16.10942 ]
 [-53.648857]
 [ 21.233753]
 [ 13.621795]
 [ 17.800549]
 [ 10.8274  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.637131690979004



buy possibilites: [-1] 
expected returns: [[12.575323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 25.453453063964844






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.928787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.575323104858398





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 17.225945]
 [ 31.689594]
 [ 22.761425]
 [-43.537514]
 [ 24.83413 ]
 [ 27.562626]
 [ 19.834019]
 [ 37.15925 ]
 [ 24.326237]
 [ 24.337547]
 [ 30.694637]
 [ 17.676846]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.123882293701172



buy possibilites: [-1] 
expected returns: [[-4.0433645]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.15924072265625






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.230015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.043364524841309





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 26.31425  ]
 [ 40.894722 ]
 [ 32.134842 ]
 [ -1.0212822]
 [-38.09433  ]
 [ 34.422832 ]
 [ 37.118668 ]
 [ 29.083797 ]
 [ 42.45282  ]
 [ 46.18227  ]
 [ 33.959682 ]
 [ 39.687157 ]
 [ 33.970757 ]
 [ 19.289936 ]
 [ 40.028698 ]
 [ 27.45308  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.948699951171875



buy possibilites: [-1] 
expected returns: [[34.81706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 46.1822624206543






Player: 1 
cards in hand: [ 0.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-9.973213]
 [ 9.056191]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  3.  0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.81705856323242



action possibilites: [-1.] 
expected returns: [[7.548215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.518148422241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  8.598511 ]
 [ 23.540577 ]
 [ 14.491101 ]
 [-18.144474 ]
 [-54.725174 ]
 [ 16.839558 ]
 [ 19.550362 ]
 [ 11.371489 ]
 [ 25.059937 ]
 [ 28.9007   ]
 [ 16.347012 ]
 [ 22.262451 ]
 [ 16.358242 ]
 [  1.4482927]
 [ 22.593853 ]
 [  9.753684 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.548214912414551



buy possibilites: [-1] 
expected returns: [[15.230348]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.90070343017578






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  0. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 2.8453016]
 [20.558636 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.230347633361816



action possibilites: [-1.] 
expected returns: [[11.872146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 15.066411018371582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  7.7927446 ]
 [ 22.905926  ]
 [ 13.916804  ]
 [-22.849865  ]
 [-63.221066  ]
 [ 16.556973  ]
 [ 19.267632  ]
 [ 11.00753   ]
 [ 24.479046  ]
 [ 28.061405  ]
 [ 16.113293  ]
 [ 21.744114  ]
 [ 16.12434   ]
 [ -0.10002279]
 [ 22.097404  ]
 [  9.670098  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.872145652770996



buy possibilites: [-1] 
expected returns: [[8.626554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.061389923095703






Player: 1 
cards in hand: [29.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  3.  8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.7803965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 10. 29.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.626553535461426





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  2.9938912]
 [ 16.761349 ]
 [  8.312468 ]
 [-56.947796 ]
 [ 10.579915 ]
 [ 12.8088045]
 [  5.201688 ]
 [ 21.597958 ]
 [ 10.081662 ]
 [ 10.091221 ]
 [ 15.719106 ]
 [  4.464537 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 10. 29.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 5.352461814880371



buy possibilites: [-1] 
expected returns: [[8.853001]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [29. 29.  0.  0.  0.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 10. 29.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 21.597957611083984






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0. 10. 29.  3.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0. 10. 29.  3.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0. 10. 29.  3.  0.  3.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[23.99878]
 [42.48328]
 [42.48328]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.85300064086914



action possibilites: [-1. 29.] 
expected returns: [[-2.7401109]
 [13.990619 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.532100677490234



action possibilites: [-1. 29.] 
expected returns: [[13.000421]
 [31.159142]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.990607261657715



action possibilites: [-1. 29.] 
expected returns: [[19.334492]
 [37.98767 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.159122467041016



action possibilites: [-1.] 
expected returns: [[45.741783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.98766326904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 46.83191 ]
 [ 61.793747]
 [ 13.180518]
 [ 53.097218]
 [ 17.155567]
 [ 60.407192]
 [-23.276588]
 [ 55.711704]
 [ 58.26331 ]
 [ 49.517204]
 [ 63.20433 ]
 [ 66.62697 ]
 [ 55.231106]
 [ 60.66416 ]
 [ 55.24195 ]
 [ 39.40799 ]
 [ 60.975433]
 [ 48.86931 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 8 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.741783142089844



buy possibilites: [-1] 
expected returns: [[58.14138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 80.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 107.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 66.62698364257812






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[41.182243]
 [56.505516]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 29.  0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.141380310058594



action possibilites: [-1.] 
expected returns: [[6.6018763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 52.49597930908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 10.369269 ]
 [ 24.269993 ]
 [ 15.89994  ]
 [-18.807343 ]
 [-57.147923 ]
 [ 18.551712 ]
 [ 20.726929 ]
 [ 13.127028 ]
 [ 25.436932 ]
 [ 28.780159 ]
 [ 18.109108 ]
 [ 23.13163  ]
 [ 18.118275 ]
 [  2.958292 ]
 [ 23.3763   ]
 [ 12.7171545]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.601876258850098



buy possibilites: [-1] 
expected returns: [[58.658466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.7801513671875






Player: 1 
cards in hand: [ 0.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  8.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-1.1750336]
 [13.920865 ]
 [13.920865 ]
 [13.920865 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.65846633911133



action possibilites: [-1. 29. 29.] 
expected returns: [[-13.30336  ]
 [  4.2547183]
 [  4.2547183]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.134451866149902



action possibilites: [-1. 29.] 
expected returns: [[25.664555]
 [42.69397 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.254709720611572



action possibilites: [-1.] 
expected returns: [[42.741383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.69395446777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 42.71176 ]
 [ 57.33494 ]
 [ 10.33209 ]
 [ 48.683426]
 [ 14.118318]
 [-24.675346]
 [ 51.082226]
 [ 53.760784]
 [ 45.560123]
 [ 58.89266 ]
 [ 62.40789 ]
 [ 50.646732]
 [ 56.193863]
 [ 50.657642]
 [ 35.509075]
 [ 56.544262]
 [ 44.232674]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  2.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.74138259887695



buy possibilites: [-1] 
expected returns: [[34.06409]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  1.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 87.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.407875061035156






Player: 1 
cards in hand: [10.  0. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.  0.  3.] 
cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  1.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14.  0.  3.] 
cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  1.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14.  0.  3.] 
cards in discard: [ 0.  8.  0.  0.  0.  0. 10. 29.  0.  0.  3.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  1.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[41.077194]
 [56.758396]
 [56.758396]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 29.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  1.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.064090728759766



action possibilites: [-1. 29.] 
expected returns: [[59.953815]
 [77.649216]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  1.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  1.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 52.681419372558594



action possibilites: [-1.] 
expected returns: [[63.62741]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  1.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 77.64921569824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[67.06034  ]
 [81.44641  ]
 [34.979424 ]
 [72.67429  ]
 [38.873596 ]
 [ 0.6278286]
 [75.10272  ]
 [77.6505   ]
 [69.984535 ]
 [82.86741  ]
 [86.512146 ]
 [74.633804 ]
 [80.23006  ]
 [74.644295 ]
 [59.72491  ]
 [80.5387   ]
 [68.45659  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  1.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.627410888671875



buy possibilites: [-1] 
expected returns: [[69.03726]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 67.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 86.51215362548828






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 5.142144]
 [21.71146 ]
 [21.71146 ]
 [21.71146 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.03726196289062



action possibilites: [-1. 29.] 
expected returns: [[19.140877]
 [37.212276]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.167387962341309



action possibilites: [-1.] 
expected returns: [[24.91055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 31.212398529052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 23.387142]
 [ 37.68957 ]
 [ 29.22057 ]
 [-41.25091 ]
 [ 31.731014]
 [ 34.043926]
 [ 25.78535 ]
 [ 31.277336]
 [ 31.28704 ]
 [ 36.78761 ]
 [ 25.778053]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.91054916381836



buy possibilites: [-1] 
expected returns: [[50.231613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 48.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 37.68956756591797






Player: 1 
cards in hand: [10.  3.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[25.337917]
 [41.733574]
 [41.733574]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 29.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 10.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 10.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.23161315917969



action possibilites: [-1.] 
expected returns: [[38.80436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 10.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 10.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 35.36719512939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 39.816902]
 [ 53.1842  ]
 [ 45.11379 ]
 [ 13.453208]
 [-23.378197]
 [ 47.504253]
 [ 49.629574]
 [ 42.204567]
 [ 54.322037]
 [ 47.062225]
 [ 52.041462]
 [ 47.071213]
 [ 33.118176]
 [ 52.277966]
 [ 41.77422 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 10.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 10.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.804359436035156



buy possibilites: [-1] 
expected returns: [[75.79189]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 10.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 10.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 54.322059631347656






Player: 1 
cards in hand: [ 0. 14.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 10.  0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 10.  3.  8.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0. 29.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 10.  3.  8.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 10.  3.  8.  0.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 10.  3.  8.  0.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[50.027008]
 [66.196335]
 [66.196335]
 [66.196335]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.7918930053711



action possibilites: [-1. 29.] 
expected returns: [[78.63388]
 [92.66904]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.17034912109375



action possibilites: [-1.] 
expected returns: [[182.72765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 88.79625701904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[177.0948 ]
 [190.5665 ]
 [183.02725]
 [146.37408]
 [107.5025 ]
 [185.83261]
 [187.84166]
 [179.59929]
 [191.72812]
 [185.49985]
 [189.69608]
 [185.50806]
 [169.90372]
 [189.95618]
 [180.67639]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  9.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 182.72764587402344



buy possibilites: [-1] 
expected returns: [[109.1651]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  0. 29. 25. 29.  3.  0.  0.  1. 29. 29. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 191.72816467285156






Player: 1 
cards in hand: [10.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 30.  8. 10. 10. 10.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  8.  0.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10.  9.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[16.349495]
 [31.457771]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8. 10. 10.  9.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.16510009765625



action possibilites: [-1. 25.] 
expected returns: [[25.17522 ]
 [37.625557]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8. 10. 10.  9.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.823200225830078



action possibilites: [-1] 
expected returns: [[40.45996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25. 29.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  9. 10.  9.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.625553131103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 41.92738 ]
 [ 56.003006]
 [ 47.48629 ]
 [-22.429306]
 [ 49.834282]
 [ 52.339172]
 [ 44.594685]
 [ 49.382385]
 [ 49.392746]
 [ 55.137344]
 [ 43.680645]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25. 29.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 30. 30.  8.  9. 10.  9.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.4599609375



buy possibilites: [-1] 
expected returns: [[21.68259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25. 29.] 
cards in discard: [3. 1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 48.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 56.00297927856445






Player: 1 
cards in hand: [ 0.  0.  3. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  8.] 
cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 29. 29.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  8.] 
cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  8.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 29. 29.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  8.] 
cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 29. 29.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 3.696309]
 [18.701477]
 [18.701477]
 [18.701477]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29. 29.  0.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.68259048461914



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[56.79019]
 [73.09068]
 [73.09068]
 [73.09068]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 29.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.660405158996582



action possibilites: [-1. 29. 29.] 
expected returns: [[35.456573]
 [50.630936]
 [50.630936]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.53289031982422



action possibilites: [-1.] 
expected returns: [[50.94059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 46.598548889160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 48.51182 ]
 [ 61.57463 ]
 [ 53.753166]
 [-11.411717]
 [ 56.10471 ]
 [ 58.15312 ]
 [ 50.748253]
 [ 55.67611 ]
 [ 55.684788]
 [ 60.699654]
 [ 50.57418 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.940589904785156



buy possibilites: [-1] 
expected returns: [[21.912209]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 98.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 61.57464599609375






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0. 29.  3.] 
adversary cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0. 29.  3.] 
adversary cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 10.  0.  0. 29.  8.  0.  6.  8.  0.  0.  3. 14.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0. 29.  3.] 
adversary cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  1.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 90.49785]
 [105.11549]
 [105.11549]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 29.  3.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1. 29. 29. 29.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.912208557128906



action possibilites: [-1. 29.] 
expected returns: [[112.15457]
 [127.65886]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1. 29. 29. 29.  0.  3.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 101.00055694580078



action possibilites: [-1.] 
expected returns: [[11.266679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1. 29. 29. 29.  0.  3.
  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 123.30667114257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  8.937768 ]
 [ 22.255718 ]
 [ 14.52955  ]
 [-16.382858 ]
 [-50.948925 ]
 [ 16.974594 ]
 [ 18.8162   ]
 [ 10.498946 ]
 [ 23.176353 ]
 [ 16.538795 ]
 [ 21.14656  ]
 [ 16.54678  ]
 [  2.9458447]
 [ 21.326324 ]
 [ 11.847993 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1. 29. 29. 29.  0.  3.
  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  8.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.266678810119629



buy possibilites: [-1] 
expected returns: [[9.023831]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  1. 29. 25.  0.  0.  0. 25. 29.  1. 29. 29.  1. 29. 29. 29.  0.  3.
  1.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 23.176349639892578






Player: 1 
cards in hand: [ 8.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25] -> size -> 26 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[33.975586]
 [49.635624]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.023831367492676



action possibilites: [-1.] 
expected returns: [[40.09009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.0682487487793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 39.6357  ]
 [ 53.384502]
 [ 45.290382]
 [-25.39087 ]
 [ 47.74633 ]
 [ 50.06208 ]
 [ 42.23636 ]
 [ 47.338177]
 [ 47.3477  ]
 [ 52.610546]
 [ 41.738113]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 30. 30.  8.  9. 10.  9.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.090091705322266



buy possibilites: [-1] 
expected returns: [[28.896751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 30. 30.  8.  9. 10.  9.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 58.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 53.38450622558594






Player: 1 
cards in hand: [ 8. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  1.] 
cards in discard: [ 8.  0. 10.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 30. 30.  8.  9. 10.  9.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  3. 29.] 
adversary cards in discard: [29.  1. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 30. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  3. 29.] 
adversary cards in discard: [29.  1. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 30. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  3. 29.] 
adversary cards in discard: [29.  1. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 24. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  3. 29.] 
adversary cards in discard: [29.  1. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[-0.34864664]
 [15.92484   ]
 [12.6584215 ]
 [15.92484   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  3. 29.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 14.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.896751403808594



action possibilites: [-1. 29.] 
expected returns: [[43.744576]
 [59.515083]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  1.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 14.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.329842567443848



action possibilites: [-1.] 
expected returns: [[63.46537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 24. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 14.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.071014404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[6.1237228e+01]
 [7.4399124e+01]
 [6.6474442e+01]
 [4.7043562e-02]
 [6.8871918e+01]
 [7.0901199e+01]
 [6.3500618e+01]
 [6.8432259e+01]
 [6.8440918e+01]
 [7.3489738e+01]
 [6.3351974e+01]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 14.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.465370178222656



buy possibilites: [-1] 
expected returns: [[60.316605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 14.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 48.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 74.39912414550781






Player: 1 
cards in hand: [29. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  0.  0.  3.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 29. 25.] 
adversary cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  0.  0.  3.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 23. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 29. 25.] 
adversary cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1] -> size -> 28 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[173.6887 ]
 [188.45358]
 [188.45358]
 [185.55374]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 29. 25.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1. 29. 29.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.31660461425781



action possibilites: [-1. 29. 25. 29.] 
expected returns: [[65.66094]
 [80.9827 ]
 [77.89697]
 [80.9827 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 29.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1. 29. 29.  0.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 184.27938842773438



action possibilites: [-1. 25.] 
expected returns: [[15.195786]
 [27.778332]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1. 29. 29.  0.  3.  0.  1. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 29. 30.  8.  9. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 76.69293975830078



action possibilites: [-1] 
expected returns: [[89.148834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1. 29. 29.  0.  3.  0.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.778362274169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[83.89872 ]
 [97.354485]
 [89.58918 ]
 [15.196782]
 [92.32309 ]
 [94.390526]
 [86.58732 ]
 [91.95844 ]
 [91.96697 ]
 [96.663574]
 [86.949066]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1. 29. 29.  0.  3.  0.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 23. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.14883422851562



buy possibilites: [-1] 
expected returns: [[54.73058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.] 
cards in discard: [29.  1. 29.  0.  0.  3.  0. 25.  1.  1. 29. 29.  0.  3.  0.  1. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 68.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 97.35446166992188






Player: 1 
cards in hand: [ 6. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  8.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 0.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  6  8  1
 11  3  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0. 10.  0.  3. 11.  3. 11.  8.  0.  0.  1. 29. 14.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 22. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  1. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-20.326149 ]
 [ -8.1943865]
 [ -4.8374734]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 25. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.7305793762207



action possibilites: [-1. 25.] 
expected returns: [[ 7.025422]
 [18.19886 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.  0.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 29. 30.  8.  8. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.418551445007324



action possibilites: [-1] 
expected returns: [[21.363625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 29. 30.  8.  7. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 18.198856353759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 20.866287]
 [ 34.451   ]
 [ 26.358925]
 [ -5.650014]
 [-41.581512]
 [ 28.717594]
 [ 30.96458 ]
 [ 23.250263]
 [ 35.683014]
 [ 28.284477]
 [ 33.33243 ]
 [ 28.293873]
 [ 14.210309]
 [ 33.59599 ]
 [ 22.764233]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 22. 30. 29. 30.  8.  7. 10.  8.  7.  7.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.363624572753906



buy possibilites: [-1] 
expected returns: [[41.184826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 29.] 
cards in discard: [ 1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 35.68301010131836






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29.  1.  1.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 22. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29.  1.  1.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [6. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29.  1.  1.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29. 25. 29.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[ 4.5000715]
 [17.821861 ]
 [14.896731 ]
 [17.821861 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  1.  1.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [6. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.1848258972168



action possibilites: [-1. 25. 29. 29.] 
expected returns: [[38.425934]
 [51.071056]
 [54.45333 ]
 [54.45333 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1. 29.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [6. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.187718391418457



action possibilites: [-1. 29. 29.] 
expected returns: [[-27.762218]
 [-12.420218]
 [-12.420218]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [6. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 49.947662353515625



action possibilites: [-1. 29.] 
expected returns: [[ 9.76625]
 [25.57573]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [6. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.751033782958984



action possibilites: [-1.] 
expected returns: [[13.2141695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 4 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [6. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.06686782836914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 10.440839]
 [ 24.103588]
 [ 15.909198]
 [-16.474297]
 [-52.56679 ]
 [ 18.272877]
 [ 20.587322]
 [ 13.002765]
 [ 25.393879]
 [ 17.84048 ]
 [ 22.976357]
 [ 17.850101]
 [  3.611463]
 [ 23.255161]
 [ 12.197803]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  6.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [6. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.2141695022583



buy possibilites: [-1] 
expected returns: [[2.6659527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  5.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [6. 1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 25.393882751464844






Player: 1 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [6. 1. 3. 0. 3. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  7. 10.  8.  7.  5.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 25.  0.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25] -> size -> 31 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  7.  9.  8.  7.  5.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 25.  0.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 21. 30. 29. 30.  8.  7.  9.  8.  7.  5.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 25.  0.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25] -> size -> 31 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[65.97946]
 [76.81941]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 25.  0.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  7.  9.  8.  7.  5.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  8.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1 16] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.665952682495117



action possibilites: [-1] 
expected returns: [[20.733173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 1. 3.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  5.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  8.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1 16  6] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 76.81939697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 19.526302]
 [ 32.36946 ]
 [ -8.217723]
 [ 24.942291]
 [ -5.112833]
 [-38.88338 ]
 [ 27.349941]
 [ 29.068298]
 [ 20.983185]
 [ 33.214546]
 [ 26.930565]
 [ 31.304195]
 [ 26.938065]
 [ 13.735223]
 [ 31.466236]
 [ 22.52998 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 1. 3.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  5.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  8.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1 16  6] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.733173370361328



buy possibilites: [-1] 
expected returns: [[8.675904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 1. 3.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  8.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1 16  6] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 107.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 33.214542388916016






Player: 1 
cards in hand: [10.  8.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  8.] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  8 10  0 14  0 10  8  0 11  8  1 11  3
  6  6  1 16  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 29.  0.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0. 25. 25.  3.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 29.  0.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0. 25. 25.  3.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 29.  0.] 
adversary cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0. 25. 25.  3.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[10.595203]
 [24.186832]
 [24.186832]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 29.  0.] 
cards in discard: [ 1. 25. 29. 25.  3.  1.  0.  0. 29.  1. 25.  1. 29. 25. 29. 29. 29. 29.
  0. 25. 25.  3.  1.  0.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 14.  6.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.675904273986816



action possibilites: [-1. 29.] 
expected returns: [[25.722878]
 [41.139095]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1.] 
cards in discard: [1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 14.  6.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.290374755859375



action possibilites: [-1. 25.] 
expected returns: [[36.83113 ]
 [48.745316]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [1. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 21. 30. 29. 30.  8.  6.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 14.  6.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.81937789916992



action possibilites: [-1] 
expected returns: [[62.453003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 21. 30. 29. 30.  8.  5.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 14.  6.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.74531555175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[61.00145  ]
 [74.48484  ]
 [66.57063  ]
 [33.278816 ]
 [-3.6439846]
 [68.98694  ]
 [71.28451  ]
 [63.61905  ]
 [75.8004   ]
 [68.59469  ]
 [73.46159  ]
 [68.60412  ]
 [54.11918  ]
 [73.75379  ]
 [63.05443  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 21. 30. 29. 30.  8.  5.  9.  8.  7.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 14.  6.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.4530029296875



buy possibilites: [-1] 
expected returns: [[34.903694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1.  1. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  5.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 14.  6.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 75.8004150390625






Player: 1 
cards in hand: [ 0. 29.  3. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 14.  6.] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  5.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0. 25.] 
adversary cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 14.  6.] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 21. 30. 29. 30.  8.  5.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0. 25.] 
adversary cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-33.209385]
 [-20.38295 ]
 [-20.38295 ]
 [-22.637695]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0. 25.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 29. 30.  8.  5.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  8.  0. 11.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.  0. 29.
  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.90369415283203



action possibilites: [-1. 25. 29.] 
expected returns: [[-24.049541]
 [-12.473973]
 [ -9.338895]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 21. 30. 29. 30.  8.  5.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  8.  0. 11.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.  0. 29.
  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -22.278697967529297



action possibilites: [-1. 25.] 
expected returns: [[ 4.6520452]
 [16.359665 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 21. 30. 29. 30.  8.  5.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  8.  0. 11.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.  0. 29.
  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -13.496846199035645



action possibilites: [-1] 
expected returns: [[-5.7780037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 21. 30. 29. 30.  8.  4.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  8.  0. 11.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.  0. 29.
  3. 14.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.359664916992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -8.145799  ]
 [  4.5257907 ]
 [ -2.9297216 ]
 [-66.16219   ]
 [ -0.5487013 ]
 [  1.302556  ]
 [ -6.19394   ]
 [ -0.95392036]
 [ -0.94601107]
 [  3.6820822 ]
 [ -5.6016097 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 21. 30. 29. 30.  8.  4.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  8.  0. 11.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.  0. 29.
  3. 14.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.778003692626953



buy possibilites: [-1] 
expected returns: [[-5.232136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 29. 30.  8.  4.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  8.  0. 11.] 
adversary cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.  0. 29.
  3. 14.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 158.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 4.525798797607422






Player: 1 
cards in hand: [10.  1.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  8.  0. 11.] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.  0. 29.
  3. 14.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 29. 30.  8.  4.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  1.  1. 29.] 
adversary cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  8.  0. 11.] 
cards in discard: [ 6.  1.  3.  0.  3.  0.  0. 16. 11.  0.  3.  0.  0.  6.  8.  6.  0. 29.
  3. 14.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 20. 30. 29. 30.  8.  4.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  1.  1. 29.] 
adversary cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  1.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[19.14774 ]
 [31.934235]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  1. 29.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 29. 30.  8.  4.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.232135772705078



action possibilites: [-1. 25.] 
expected returns: [[-6.112687]
 [ 4.388203]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 25.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 29. 30.  8.  4.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.32874298095703



action possibilites: [-1] 
expected returns: [[-21.02259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 25. 29.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 29. 30.  8.  3.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 4.388210296630859





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-24.230309]
 [-11.928192]
 [-49.575912]
 [-19.153687]
 [-46.295532]
 [-74.72004 ]
 [-17.001839]
 [-15.299388]
 [-22.962849]
 [-11.106444]
 [-17.431316]
 [-13.016857]
 [-17.423843]
 [-29.504719]
 [-12.862604]
 [-21.82248 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 25. 29.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 20. 30. 29. 30.  8.  3.  9.  8.  7.  3.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.02259063720703



buy possibilites: [-1] 
expected returns: [[-2.7553883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 25. 29.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 29. 30.  8.  3.  9.  8.  7.  2.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 217.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -11.106433868408203






Player: 1 
cards in hand: [0. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 29. 30.  8.  3.  9.  8.  7.  2.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3. 25.  1.] 
adversary cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1. 25. 29. 25.  0.  1.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25] -> size -> 35 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 20. 30. 29. 30.  8.  3.  9.  8.  7.  2.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3. 25.  1.] 
adversary cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1. 25. 29. 25.  0.  1.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25] -> size -> 35 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [6. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  3.  9.  8.  7.  2.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3. 25.  1.] 
adversary cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1. 25. 29. 25.  0.  1.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25] -> size -> 35 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-3.01481 ]
 [10.185349]
 [ 7.349473]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 25.  1.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1. 25. 29. 25.  0.  1.  1. 25. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  3.  9.  8.  7.  2.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.7553882598876953



action possibilites: [-1. 25.] 
expected returns: [[-24.627441]
 [-13.432907]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  3.] 
cards in discard: [ 1.  1. 25. 29. 29. 25.  0.  0.  3.  0. 29.  1.  1. 29. 29. 25.  0.  0.
 29. 25.  1. 25. 29. 25.  0.  1.  1. 25. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 28. 30.  8.  3.  9.  8.  7.  2.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.468480110168457



action possibilites: [-1] 
expected returns: [[10.090816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  2.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -13.432910919189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  7.7794943]
 [ 20.745876 ]
 [ 13.031306 ]
 [-17.084837 ]
 [-50.327267 ]
 [ 15.42073  ]
 [ 17.348839 ]
 [  9.821638 ]
 [ 21.740986 ]
 [ 14.992791 ]
 [ 19.652054 ]
 [ 15.001044 ]
 [  1.4448113]
 [ 19.85297  ]
 [ 10.139997 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  2.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.090815544128418



buy possibilites: [-1] 
expected returns: [[20.077301]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 395 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 21.74099349975586






Player: 1 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6. 3. 0. 3. 3. 6. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16
  6  6  6  6  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  1. 25.] 
adversary cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [6. 3. 0. 3. 3. 6. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  1. 25.] 
adversary cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6. 3. 0. 3. 3. 6. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  1. 25.] 
adversary cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 25.] 
expected returns: [[-18.6632   ]
 [ -3.6226645]
 [ -3.6226645]
 [ -3.6226645]
 [ -6.7755785]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  1. 25.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  8. 16.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.077301025390625



action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-7.831167 ]
 [ 6.3660326]
 [ 6.3660326]
 [ 3.3110914]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  1.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  8. 16.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -7.8606061935424805



action possibilites: [-1. 29. 25. 25.] 
expected returns: [[-20.21553  ]
 [ -5.8505583]
 [ -8.944281 ]
 [ -8.944281 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  8. 16.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.3672614097595215



action possibilites: [-1. 25.] 
expected returns: [[-16.49824 ]
 [ -5.645998]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 20. 30. 28. 30.  8.  2.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  8. 16.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.915494918823242



action possibilites: [-1] 
expected returns: [[-14.404145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 20. 30. 28. 30.  8.  1.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  8. 16.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3. 6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6  6] -> size -> 28 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -5.645998954772949





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-15.377753 ]
 [ -2.0265493]
 [-43.37744  ]
 [-10.065786 ]
 [-41.011326 ]
 [-83.7776   ]
 [ -7.845996 ]
 [ -5.7522073]
 [-13.4862   ]
 [ -0.9515424]
 [ -8.315802 ]
 [ -3.2264898]
 [ -8.306817 ]
 [-21.437492 ]
 [ -3.0106056]
 [-13.596073 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 29.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 20. 30. 28. 30.  8.  1.  9.  8.  7.  1.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  8. 16.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3. 6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6  6] -> size -> 28 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.404145240783691



buy possibilites: [-1] 
expected returns: [[-198.73087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 29.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 20. 30. 28. 30.  8.  1.  9.  8.  7.  0.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  8. 16.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3. 6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6  6] -> size -> 28 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   80.    0.    0.    0.    0.  -20.
   0.    0.   62.5   0. ] 
sum of rewards: 267.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -0.951545000076294






Player: 1 
cards in hand: [10.  6.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8. 16.  0.] 
cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  1.  9.  8.  7.  0.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29. 25.] 
adversary cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25. 25. 29. 29. 29. 25.  1.  1.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  8. 16.  0.] 
cards in discard: [6. 3. 0. 3. 3. 6. 0. 6. 8. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 20. 30. 28. 30.  8.  1.  9.  8.  7.  0.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29. 25.] 
adversary cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25. 25. 29. 29. 29. 25.  1.  1.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25. 25. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 29. 25.] 
expected returns: [[45.5629  ]
 [55.818283]
 [55.818283]
 [55.818283]
 [58.790554]
 [55.818283]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25. 29. 25.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25. 25. 29. 29. 29. 25.  1.  1.
 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  1.  9.  8.  7.  0.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  6.  1.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  0.  6.  8.  3.  6. 10.  6.  8. 16.  0.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -198.73086547851562



action possibilites: [-1. 25. 25.] 
expected returns: [[ 1.7567534]
 [12.948411 ]
 [12.948411 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  1.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25. 25. 29. 29. 29. 25.  1.  1.
 29. 25. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 28. 30.  8.  1.  9.  8.  7.  0.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  6.  1.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  0.  6.  8.  3.  6. 10.  6.  8. 16.  0.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.050445556640625



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 8 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25.  1. 29.  1.] 
cards in discard: [25. 29. 25.  0.  3.  3.  0.  1.  1.  1. 25. 25. 29. 29. 29. 25.  1.  1.
 29. 25. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25 25  1
  1 25  1  1  1 25 25 25 25  1 25 25 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 28. 30.  8.  0.  9.  8.  7.  0.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  6.  1.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  0.  6.  8.  3.  6. 10.  6.  8. 16.  0.  6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 14  0 10  8  0 11  8  1 11  3  6  6  1 16  6  6  6
  6  3  6  6  6] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      40       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000215 

action type: take_action - action 25.0
Learning step: 120008.078125
desired expected reward: 120021.0234375



