 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[95.9237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000345 

action type: gain_card_n - action 0
Learning step: -120009.8203125
desired expected reward: -120109.3203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.66371 ]
 [103.265015]
 [ 96.73457 ]
 [ 69.87762 ]
 [109.86963 ]
 [102.50593 ]
 [ 95.93768 ]
 [ 94.973816]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.31108856201172



buy possibilites: [-1] 
expected returns: [[91.56248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 109.86964416503906






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.02093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.5624771118164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 88.69822 ]
 [101.74285 ]
 [ 95.050804]
 [ 72.80349 ]
 [ 99.214615]
 [109.698975]
 [101.00959 ]
 [112.67217 ]
 [ 79.892006]
 [ 94.220726]
 [ 92.91648 ]
 [ 94.11504 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.37651062011719



buy possibilites: [-1] 
expected returns: [[82.83454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.67218017578125






Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 86.99137]
 [101.01888]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.83454132080078



action possibilites: [-1] 
expected returns: [[99.05909]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.59912872314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 92.25825]
 [101.05341]
 [ 67.74149]
 [106.20134]
 [ 98.49044]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.05908966064453



buy possibilites: [-1] 
expected returns: [[83.91906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 106.2013931274414






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 97.871605]
 [115.565506]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10.  8. 11.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.91905975341797



action possibilites: [-1.] 
expected returns: [[94.33157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 115.96745300292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 90.04467 ]
 [105.63816 ]
 [ 98.3968  ]
 [ 72.77289 ]
 [ 66.77033 ]
 [102.21831 ]
 [112.52157 ]
 [104.93108 ]
 [131.43661 ]
 [115.44048 ]
 [ 81.39929 ]
 [ 94.05955 ]
 [ 98.12175 ]
 [ 78.47871 ]
 [ 96.03271 ]
 [ 96.172325]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.33157348632812



buy possibilites: [-1] 
expected returns: [[133.34247]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  0.  3.  0.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 131.4366455078125






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[106.2925  ]
 [123.306755]
 [136.2414  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.34246826171875



action possibilites: [-1] 
expected returns: [[78.38251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.83001708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[70.24601 ]
 [85.42454 ]
 [78.62098 ]
 [51.4315  ]
 [81.41596 ]
 [94.913414]
 [85.44777 ]
 [97.27466 ]
 [62.572773]
 [78.643814]
 [78.720345]
 [80.89229 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.38250732421875



buy possibilites: [-1] 
expected returns: [[89.439644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.  3.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 97.27467346191406






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[113.954475]
 [120.63059 ]
 [128.2281  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  3.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.43964385986328



action possibilites: [-1] 
expected returns: [[141.45218]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 132.61294555664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[155.02084]
 [141.97945]
 [142.70099]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.45217895507812



buy possibilites: [-1] 
expected returns: [[136.866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0.  3. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 155.02085876464844






Player: 1 
cards in hand: [ 0.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [ 6. 11.  0.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [ 6. 11.  0.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[ 89.324745]
 [106.90899 ]
 [ 98.8969  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.86599731445312



action possibilites: [-1.  8.] 
expected returns: [[87.20045 ]
 [95.643715]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.58538055419922



action possibilites: [-1] 
expected returns: [[69.99199]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 93.59198760986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[64.0306  ]
 [75.8939  ]
 [70.13775 ]
 [45.87804 ]
 [73.64347 ]
 [84.423965]
 [75.656944]
 [87.06849 ]
 [56.806484]
 [69.35296 ]
 [69.18534 ]
 [71.659805]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.99198913574219



buy possibilites: [-1] 
expected returns: [[107.8895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 87.0685043334961






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  3. 11.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  3. 11.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 10.  3. 11.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[ 94.67385 ]
 [ 89.666115]
 [ 89.666115]
 [111.10066 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3. 11.] 
cards in discard: [29. 29.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  3.  3. 11.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.8895034790039



action possibilites: [-1] 
expected returns: [[125.772255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [29. 29.  8.  0.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [29.  3.  3.  3. 11.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.14180755615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[125.88282]
 [109.96695]
 [126.72123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [29. 29.  8.  0.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [29.  3.  3.  3. 11.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.77225494384766






Player: 1 
cards in hand: [29.  3.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  3. 11.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 10. 11.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10] -> size -> 19 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  3.] 
cards in discard: [22.  0.  0.  0.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 10. 11.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  3.] 
cards in discard: [22.  0.  0.  0.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 10. 11.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10] -> size -> 19 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[110.46899]
 [141.82219]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  0.] 
cards in discard: [29. 29.  8.  0.  0.  0. 10. 11.  0. 10. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.72124481201172



action possibilites: [-1] 
expected returns: [[117.67046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0.  0. 29.] 
cards in discard: [29. 29.  8.  0.  0.  0. 10. 11.  0. 10. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.55108642578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[121.831215]
 [125.5947  ]
 [120.11256 ]
 [ 97.42926 ]
 [125.28957 ]
 [134.12872 ]
 [124.98283 ]
 [136.96968 ]
 [112.51443 ]
 [118.65359 ]
 [117.92321 ]
 [120.165306]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  0. 29.] 
cards in discard: [29. 29.  8.  0.  0.  0. 10. 11.  0. 10. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.67046356201172



buy possibilites: [-1] 
expected returns: [[123.11338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  0. 29.] 
cards in discard: [29. 29.  8.  0.  0.  0. 10. 11.  0. 10. 10.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 136.9696807861328






Player: 1 
cards in hand: [3. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [29.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [29.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [29.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29] -> size -> 20 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[136.12006]
 [150.55154]
 [139.24753]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.1133804321289



action possibilites: [-1. 10.] 
expected returns: [[116.225075]
 [115.57998 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.9008331298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[106.49709]
 [123.25063]
 [117.98643]
 [ 78.1469 ]
 [118.91633]
 [129.08084]
 [123.52213]
 [131.05724]
 [105.08941]
 [118.47922]
 [118.2798 ]
 [118.97866]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 116.2250747680664



buy possibilites: [-1] 
expected returns: [[81.76624]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  4. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [6. 0. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 131.05722045898438






Player: 1 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [6. 0. 3. 6. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  4. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [29. 29.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29] -> size -> 21 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [6. 0. 3. 6. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  4. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [29. 29.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29] -> size -> 21 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  4. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [29. 29.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29] -> size -> 21 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[130.57489 ]
 [122.447014]
 [143.75987 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  3.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  4. 10. 10.  6.  9. 10.] 
adversary cards in hand: [16. 29.  0. 22.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.76624298095703



action possibilites: [-1] 
expected returns: [[130.79762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [16. 29.  0. 22.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 150.52243041992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[126.53391]
 [133.1052 ]
 [106.93362]
 [138.90959]
 [133.59209]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  9.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [16. 29.  0. 22.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.79762268066406



buy possibilites: [-1] 
expected returns: [[157.17354]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [16. 29.  0. 22.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 138.9095916748047






Player: 1 
cards in hand: [16. 29.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 22.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0. 22.  0.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 29. 29.] 
adversary cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 16. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 22.  0.  3.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 29. 29.] 
adversary cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 22.  0.  3.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 29. 29.] 
adversary cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 22.  0.  3.] 
cards in discard: [ 6.  0.  3.  6.  3.  0.  0. 10. 11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 29. 29.] 
adversary cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[154.3483 ]
 [151.81586]
 [167.78052]
 [167.78052]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29. 29.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 157.1735382080078



action possibilites: [-1. 10. 29. 29.] 
expected returns: [[196.8652]
 [197.8377]
 [210.8691]
 [210.8691]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29. 29.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 167.8650360107422



action possibilites: [-1. 10. 29. 25.] 
expected returns: [[230.01709]
 [225.92947]
 [245.11299]
 [257.259  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29. 25.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 210.86912536621094



action possibilites: [-1] 
expected returns: [[178.63818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29.  8.  0.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 257.2589416503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[178.07812]
 [186.01904]
 [181.7092 ]
 [151.86554]
 [147.06456]
 [185.7254 ]
 [190.5488 ]
 [184.97461]
 [201.34229]
 [192.16385]
 [171.76425]
 [178.85521]
 [180.43095]
 [162.23883]
 [178.99979]
 [180.48193]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 29.  8.  0.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  8.  8.  9.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 178.63818359375



buy possibilites: [-1] 
expected returns: [[169.54556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 29.  8.  0.] 
cards in discard: [29. 29.  3.  0. 10.  0.  0. 10.  8. 11.  0.  0. 10.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  8.  8.  8.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 201.34226989746094






Player: 1 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  8.  8.  8.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11. 29. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  8.  8.  8.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11. 29. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25] -> size -> 24 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  8.  8.  8.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11. 29. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25] -> size -> 24 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.  8.] 
expected returns: [[128.99539]
 [141.07925]
 [143.42917]
 [126.59377]
 [132.87564]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 10.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  8.  8.  8.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0. 22.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 169.54556274414062



action possibilites: [-1. 11. 10.  8.] 
expected returns: [[150.41838]
 [163.23267]
 [148.68839]
 [155.1398 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  8.  8.  8.  4. 10. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0. 22.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 140.74884033203125



action possibilites: [-1] 
expected returns: [[111.64379]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  8.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 22.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 169.50343322753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[102.048134]
 [116.65059 ]
 [113.18981 ]
 [ 82.14221 ]
 [121.61178 ]
 [116.63636 ]
 [113.05232 ]
 [115.065994]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  8.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 22.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.64379119873047



buy possibilites: [-1] 
expected returns: [[104.35333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.] 
cards in discard: [10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 22.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 121.61176300048828






Player: 1 
cards in hand: [11.  0. 22.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 22.  0.  3.] 
cards in discard: [6. 3. 0. 0. 3. 6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [29.  0. 25. 29. 25.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 22.  0.  3.] 
cards in discard: [6. 3. 0. 0. 3. 6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [29.  0. 25. 29. 25.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 22.  0.  3.] 
cards in discard: [6. 3. 0. 0. 3. 6. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [29.  0. 25. 29. 25.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  0. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[ 88.07078]
 [103.58308]
 [120.89738]
 [103.58308]
 [120.89738]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 29. 25.] 
cards in discard: [10. 11. 29. 11.  0. 10.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.35333251953125



action possibilites: [-1] 
expected returns: [[105.751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 25. 10.  3.] 
cards in discard: [10. 11. 29. 11.  0. 10.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 120.72725677490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 96.3357 ]
 [ 81.12699]
 [110.10323]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 25. 10.  3.] 
cards in discard: [10. 11. 29. 11.  0. 10.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.7509994506836






Player: 1 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29.  8. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  8.  0. 25. 29.  0. 29. 25. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29.  8. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  8.  0. 25. 29.  0. 29. 25. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29.  8. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0. 10.  8.  0. 25. 29.  0. 29. 25. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 10.] 
expected returns: [[151.28558]
 [162.71884]
 [155.31372]
 [162.71884]
 [150.3918 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 29. 10.] 
cards in discard: [10. 11. 29. 11.  0. 10.  8.  0. 25. 29.  0. 29. 25. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  6. 29.] 
adversary cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.  3. 10.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 110.10321807861328



action possibilites: [-1.  8. 29. 10. 10.] 
expected returns: [[120.916565]
 [124.7595  ]
 [130.95721 ]
 [121.03247 ]
 [121.03247 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 10. 10.] 
cards in discard: [10. 11. 29. 11.  0. 10.  8.  0. 25. 29.  0. 29. 25. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  6. 29.] 
adversary cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.  3. 10.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 162.71884155273438



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[165.75098]
 [169.34995]
 [162.57314]
 [162.57314]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10.  0.] 
cards in discard: [10. 11. 29. 11.  0. 10.  8.  0. 25. 29.  0. 29. 25. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 10  8 25 29 10  0 29 10 29 29 10  8 25
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  6. 29.] 
adversary cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.  3. 10.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.95724487304688



action possibilites: [-1] 
expected returns: [[102.781815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 11. 29. 11.  0. 10.  8.  0. 25. 29.  0. 29. 25. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  6. 29.] 
adversary cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.  3. 10.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 179.09393310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 85.82334 ]
 [ 94.13592 ]
 [ 71.19657 ]
 [101.75714 ]
 [103.325294]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11. 29. 11.  0. 10.  8.  0. 25. 29.  0. 29. 25. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  6. 29.] 
adversary cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.  3. 10.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.78181457519531






Player: 1 
cards in hand: [ 0. 16.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  6. 29.] 
cards in discard: [ 6.  3.  0.  0.  3.  6.  3.  3. 11.  0. 22.  0.  3.  6.  3. 10.  3.  0.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  6 11 22 16  6  0 10  0  6  3  3  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  6.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  8.  4. 10. 10.  4.  9. 10.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  8.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[59.88078]
 [66.89256]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  8.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.32535552978516



action possibilites: [-1. 29.] 
expected returns: [[ 96.06143]
 [112.64335]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  8.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.91022872924805



action possibilites: [-1. 10.] 
expected returns: [[101.7814 ]
 [ 94.81696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  8.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 112.64334106445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 80.11515 ]
 [102.27744 ]
 [ 95.55222 ]
 [ 47.699635]
 [ 42.349533]
 [ 96.218704]
 [113.93166 ]
 [103.26645 ]
 [126.59957 ]
 [115.794655]
 [ 77.418045]
 [ 91.387955]
 [ 97.11003 ]
 [ 61.261906]
 [ 99.36561 ]
 [103.77764 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  8.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 101.78141784667969



buy possibilites: [-1] 
expected returns: [[132.7144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 126.59957122802734






Player: 1 
cards in hand: [6. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 6.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [25. 25. 29.  8.  0.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 6.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  5.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [25. 25. 29.  8.  0.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 6.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  5.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [25. 25. 29.  8.  0.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25. 25. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.  8.] 
expected returns: [[47.37198 ]
 [68.61705 ]
 [68.61705 ]
 [57.43971 ]
 [52.130997]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  8.  0.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  5.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10. 22.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 132.7144012451172



action possibilites: [-1] 
expected returns: [[85.13732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  8.  0. 10. 11.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10. 22.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 68.69879150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[88.5963  ]
 [77.75907 ]
 [85.568825]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  8.  0. 10. 11.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10. 22.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.13732147216797



buy possibilites: [-1] 
expected returns: [[47.843464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  8.  0. 10. 11.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10. 22.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 88.59629821777344






Player: 1 
cards in hand: [ 0.  0.  3. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 22.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.  0. 25. 25. 29.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 22.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.  0. 25. 25. 29.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0] -> size -> 24 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[84.212524]
 [92.847626]
 [90.91558 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 11.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.  0. 25. 25. 29.  8.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.84346389770508



action possibilites: [-1. 11.  8.] 
expected returns: [[87.57977 ]
 [96.797844]
 [95.214134]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  8.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.  0. 25. 25. 29.  8.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 92.8476333618164



action possibilites: [-1] 
expected returns: [[159.84755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.  0. 25. 25. 29.  8.  0. 10. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 101.94490814208984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[139.8798 ]
 [158.58519]
 [152.17244]
 [118.33472]
 [172.83246]
 [159.66855]
 [153.26949]
 [160.51138]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.  0. 25. 25. 29.  8.  0. 10. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  7.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.84754943847656



buy possibilites: [-1] 
expected returns: [[186.76558]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0. 10.  0. 25. 25. 29.  8.  0. 10. 11. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 172.83242797851562






Player: 1 
cards in hand: [ 0. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  0.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  4.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  8. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  4.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  8. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 26. 30.  8.  4.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  8. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 6. 15. 29. 16.  0.  0.  0.  0.  6.  0.  3.  3.  6.  6.  0.  0.  3. 10.
 22.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  4.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  8. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 29.] 
expected returns: [[ 89.422775]
 [ 86.15778 ]
 [ 75.5733  ]
 [ 75.5733  ]
 [107.77724 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  4.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 186.7655792236328



action possibilites: [-1.  8. 10. 10. 25.] 
expected returns: [[84.54186]
 [73.22468]
 [66.11614]
 [66.11614]
 [93.06169]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 26. 30.  8.  4.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 107.73827362060547



action possibilites: [-1] 
expected returns: [[49.641956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 29. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 26. 30.  8.  3.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.06167602539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  6.1521535]
 [ 31.992313 ]
 [-16.750967 ]
 [ 44.155575 ]
 [ 51.260612 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 10. 29. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  3.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.6419563293457






Player: 1 
cards in hand: [3. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  3.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [29. 25. 10.  0.  0.] 
adversary cards in discard: [29. 25.  0.  8. 10. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 26. 30.  8.  3.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [29. 25. 10.  0.  0.] 
adversary cards in discard: [29. 25.  0.  8. 10. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 25. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[31.440605]
 [39.74455 ]
 [49.210346]
 [26.7159  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 10.  0.  0.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  3.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 22. 29.  0.] 
adversary cards in discard: [6. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.2606315612793



action possibilites: [-1] 
expected returns: [[43.5286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0.  0.  8.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 22. 29.  0.] 
adversary cards in discard: [6. 3. 0. 6. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 49.21037673950195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.776733]
 [45.631123]
 [40.66307 ]
 [25.518898]
 [55.77843 ]
 [45.830063]
 [40.68399 ]
 [45.0369  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  0.  0.  8.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  6.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 22. 29.  0.] 
adversary cards in discard: [6. 3. 0. 6. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.52859878540039



buy possibilites: [-1] 
expected returns: [[102.19479]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  0.  0.  8.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  5.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 22. 29.  0.] 
adversary cards in discard: [6. 3. 0. 6. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 55.778404235839844






Player: 1 
cards in hand: [ 0.  0. 22. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22. 29.  0.] 
cards in discard: [6. 3. 0. 6. 3. 3. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  5.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [29.  0. 29. 11.  3.] 
adversary cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11. 25. 29. 10.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22. 29.  0.] 
cards in discard: [6. 3. 0. 6. 3. 3. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  5.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [29.  0. 29. 11.  3.] 
adversary cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11. 25. 29. 10.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[121.54615]
 [130.72955]
 [130.72955]
 [129.39763]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 11.  3.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11. 25. 29. 10.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  5.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11. 16.  0. 10.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.19479370117188



action possibilites: [-1. 29. 11. 11.] 
expected returns: [[137.99776]
 [148.34065]
 [146.52573]
 [146.52573]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  3. 11.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11. 25. 29. 10.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  5.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11. 16.  0. 10.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.72952270507812



action possibilites: [-1. 11. 11.] 
expected returns: [[133.80988]
 [140.46695]
 [140.46695]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.  3.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11. 25. 29. 10.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  5.  8.  7.  4. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11. 16.  0. 10.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.34063720703125



action possibilites: [-1] 
expected returns: [[101.95102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11. 25. 29. 10.  0.  0.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  5.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 0. 11. 16.  0. 10.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 144.80555725097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 64.99417 ]
 [ 94.02952 ]
 [ 86.954124]
 [ 35.312305]
 [111.38531 ]
 [ 95.89119 ]
 [ 89.347374]
 [103.14399 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11. 25. 29. 10.  0.  0.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  5.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 0. 11. 16.  0. 10.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.95101928710938



buy possibilites: [-1] 
expected returns: [[152.39926]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [29. 25.  0.  8. 10. 10. 29. 11. 11. 25. 29. 10.  0.  0.  0.  8. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  4.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 0. 11. 16.  0. 10.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 111.38531494140625






Player: 1 
cards in hand: [ 0. 11. 16.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16.  0. 10.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3
  6 15  0  6  0  0  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  2.  9.  4.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11] -> size -> 29 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6
 15  0  6  0  0  6  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  2.  9.  4.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11] -> size -> 29 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6
 15  0  6  0  0  6  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 25. 30.  8.  2.  9.  4.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11] -> size -> 29 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6
 15  0  6  0  0  6  6  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 25. 30.  8.  2.  9.  4.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11] -> size -> 29 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
expected returns: [[81.898285]
 [89.97095 ]
 [77.70148 ]
 [99.158714]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  2.  9.  4.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  3.  6. 15.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6
 15  0  6  0  0  6  6  3  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 152.39926147460938



action possibilites: [-1] 
expected returns: [[40.19484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  1.  9.  4.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  3.  6. 15.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6
 15  0  6  0  0  6  6  3  0  6] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.15872192382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.509964]
 [37.42186 ]
 [29.782963]
 [43.181484]
 [42.20989 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 25. 30.  8.  1.  9.  4.  8.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  3.  6. 15.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6
 15  0  6  0  0  6  6  3  0  6] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.19483947753906



buy possibilites: [-1] 
expected returns: [[55.754696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0. 10. 29.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  3.  6. 15.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6
 15  0  6  0  0  6  6  3  0  6] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 43.181488037109375






Player: 1 
cards in hand: [ 3.  0.  3.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  6. 15.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6
 15  0  6  0  0  6  6  3  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [10.  3. 11. 11.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8] -> size -> 30 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [10.  3. 11. 11.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8] -> size -> 30 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [10.  3. 11. 11.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8] -> size -> 30 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [10.  3. 11. 11.  0.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8] -> size -> 30 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10.  3. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[25.479713]
 [20.215809]
 [31.301098]
 [31.301098]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 11.  0.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  2.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.754695892333984



action possibilites: [-1] 
expected returns: [[47.164417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  1.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 35.510589599609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.584095]
 [17.002434]
 [47.647182]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.  0.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  1.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.1644172668457






Player: 1 
cards in hand: [6. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10. 29. 11. 29.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  7.  7.  4. 10. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10. 29. 11. 29.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  6.  7.  4. 10. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10. 29. 11. 29.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 29.] 
expected returns: [[53.651787]
 [50.998695]
 [66.76997 ]
 [63.93276 ]
 [66.76997 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11. 29.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  6.  7.  4. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.64718246459961



action possibilites: [-1. 10. 11. 29.  8.] 
expected returns: [[56.819077]
 [51.482582]
 [61.09284 ]
 [62.044178]
 [55.73662 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29.  8.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  6.  7.  4. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.76998138427734



action possibilites: [-1. 10. 11.  8. 11.] 
expected returns: [[89.47497 ]
 [83.64078 ]
 [98.120964]
 [89.016945]
 [98.120964]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  8. 11.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  6.  7.  4. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.0442008972168



action possibilites: [-1] 
expected returns: [[107.60767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 103.96241760253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 75.42318 ]
 [ 98.2784  ]
 [ 90.20913 ]
 [ 62.217915]
 [120.478676]
 [101.19785 ]
 [109.53306 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  4.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.60767364501953



buy possibilites: [-1] 
expected returns: [[126.76258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  3.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 120.47864532470703






Player: 1 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  3.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 25. 10.  0. 25.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10. 11. 29. 29.
 11.  0. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 25. 30.  8.  1.  9.  3.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 25. 10.  0. 25.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10. 11. 29. 29.
 11.  0. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [ 6.  3.  0.  6.  3.  3.  6.  0.  0. 22. 29.  0.  3.  0. 16. 11.  0. 10.
  6.  0. 15.  3.  3.  6.  8.  6.  0.  3.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 24. 30.  8.  1.  9.  3.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 25. 10.  0. 25.] 
adversary cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10. 11. 29. 29.
 11.  0. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11] -> size -> 33 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
expected returns: [[54.372204]
 [67.703926]
 [47.680706]
 [67.703926]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10.  0. 25.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10. 11. 29. 29.
 11.  0. 10.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  1.  9.  3.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 126.76258087158203



action possibilites: [-1] 
expected returns: [[70.459274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 25. 29.  8.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10. 11. 29. 29.
 11.  0. 10.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  9.  3.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 67.70391845703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[77.94882]
 [79.59958]
 [81.25876]
 [71.75538]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 25. 29.  8.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10. 11. 29. 29.
 11.  0. 10.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 24. 30.  8.  0.  9.  3.  6.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.45927429199219



buy possibilites: [-1] 
expected returns: [[86.7118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 25. 29.  8.] 
cards in discard: [ 8. 25. 11. 10.  0.  0. 10. 29. 10. 11. 10.  3. 11.  0. 10. 11. 29. 29.
 11.  0. 10.  8. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 81.2587890625






Player: 1 
cards in hand: [3. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  8.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 24. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  8.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [6. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  8.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  8.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[51.230717]
 [56.782925]
 [48.65086 ]
 [56.782925]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  0.] 
adversary cards in discard: [6. 3. 3. 0. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.71179962158203



action possibilites: [-1. 29.] 
expected returns: [[78.707726]
 [88.218666]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.] 
cards in discard: [ 8. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  0.] 
adversary cards in discard: [6. 3. 3. 0. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 58.44747543334961



action possibilites: [-1.] 
expected returns: [[50.665024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 25.  0. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  0.] 
adversary cards in discard: [6. 3. 3. 0. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 67.22200775146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[16.532393]
 [31.961243]
 [41.64694 ]
 [51.55765 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 25.  0. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 1 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  0.] 
adversary cards in discard: [6. 3. 3. 0. 6. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.66502380371094






Player: 1 
cards in hand: [ 3.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  3.  0.] 
cards in discard: [6. 3. 3. 0. 6. 6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15
  0  6  0  0  6  6  3  0  6  0  8  3  6  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10. 10. 11. 25.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [6. 3. 3. 0. 6. 6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10. 10. 11. 25.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [6. 3. 3. 0. 6. 6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10. 10. 11. 25.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [6. 3. 3. 0. 6. 6. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10. 10. 11. 25.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 25.] 
expected returns: [[30.156624]
 [28.240662]
 [28.240662]
 [42.178375]
 [60.64871 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11. 25.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.557655334472656



action possibilites: [-1] 
expected returns: [[70.259544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11. 11. 29.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.648746490478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[68.71042]
 [71.25738]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 11. 11. 29.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 11.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.2595443725586






Player: 1 
cards in hand: [ 0. 10.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 29. 11.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25.] 
expected returns: [[74.94925 ]
 [83.90168 ]
 [72.025185]
 [94.036865]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10. 25.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.2574234008789



action possibilites: [-1] 
expected returns: [[95.57336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10. 11.  0.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.03689575195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 78.98282]
 [ 89.72214]
 [ 85.48249]
 [101.73438]
 [ 91.36666]
 [ 97.51452]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10. 11.  0.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 23. 30.  8.  0.  9.  3.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.57335662841797



buy possibilites: [-1] 
expected returns: [[83.89086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10. 11.  0.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.73436737060547






Player: 1 
cards in hand: [0. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 23. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 10.  8. 10.  0.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8 11] -> size -> 35 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 23. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 10.  8. 10.  0.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8 11] -> size -> 35 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 10.  8. 10.  0.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8 11] -> size -> 35 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 10.] 
expected returns: [[51.02662 ]
 [54.495052]
 [52.885475]
 [54.495052]
 [52.885475]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8. 10.  0.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 25 29  0 29 10 29 29 10  8 25 10 11 25  0
 10 11 11 10 11  8 10 10 11  8 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  6.  6. 22.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.89086151123047



action possibilites: [-1] 
expected returns: [[-11.730692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  6.  6. 22.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 55.11300277709961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.053932]
 [ -9.825821]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  6.  6. 22.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.730691909790039






Player: 1 
cards in hand: [ 0.  0.  6.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  6. 22.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 11.  0.  3.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.  8. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  6. 22.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 11.  0.  3.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.  8. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  6. 22.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 11.  0.  3.] 
adversary cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.  8. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[61.080296]
 [61.948277]
 [55.096066]
 [60.68807 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  0.  3.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.  8. 10. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -9.825838088989258



action possibilites: [-1. 10. 11.] 
expected returns: [[14.19939 ]
 [ 9.724844]
 [13.311428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.  8. 10. 10.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 57.03395080566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.8509293]
 [14.610104 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.] 
cards in discard: [ 8. 25.  0. 11. 29. 29.  3. 25.  0. 10. 10. 11. 11. 29. 11. 25. 29.  0.
  0. 10. 11.  0.  8. 10. 10.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.199390411376953






Player: 1 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [25. 11. 29.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [25. 11. 29.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [25. 11. 29.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [25. 11. 29.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.  8. 10.] 
expected returns: [[16.383728]
 [27.89595 ]
 [19.477978]
 [20.552862]
 [12.923311]
 [ 8.67639 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29.  8. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 16.  8.  6.  3.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.  0.  0.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0] -> size -> 42 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.610097885131836



action possibilites: [-1] 
expected returns: [[86.838905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8. 10. 11. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 16.  8.  6.  3.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.  0.  0.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0] -> size -> 42 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.895946502685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[54.605938]
 [87.682045]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  8. 10. 11. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 16.  8.  6.  3.] 
adversary cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.  0.  0.  0.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0] -> size -> 42 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.83890533447266






Player: 1 
cards in hand: [ 0. 16.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  6.  3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.  0.  0.  0.  3.  3.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  6  0 10  0  6  3  3  6  3  6 15  0
  6  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 22. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [10.  3.  0. 29.  0.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.  0.  0.  0.  3.  3.
  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 21. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [10.  3.  0. 29.  0.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.  0.  0.  0.  3.  3.
  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 21. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [10.  3.  0. 29.  0.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3.] 
cards in discard: [ 6.  3.  3.  0.  6.  6.  0.  0. 15.  3.  3.  0. 10. 11.  0. 29.  0.  3.
  3.  3.  0.  6.  0.  6.  3.  0.  0.  0.  6.  6. 22.  0.  0.  0.  3.  3.
  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 30. 30. 21. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [10.  3.  0. 29.  0.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[13.421192]
 [16.099493]
 [30.473942]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 29.  0.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 21. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 6.  6.  6. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.68206024169922



action possibilites: [-1.] 
expected returns: [[60.50832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 30. 30. 21. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 6.  6.  6. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.307493209838867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[56.995007]
 [66.57277 ]
 [63.199017]
 [73.56185 ]
 [65.726234]
 [60.01856 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 30. 30. 21. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 6.  6.  6. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.50831985473633



buy possibilites: [-1] 
expected returns: [[69.38267]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 6.  6.  6. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 73.56185150146484






Player: 1 
cards in hand: [ 6.  6.  6. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 15.  3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 29. 25.  8.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 29. 25.  8.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 29. 25.  8.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 29. 25.  8.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [29. 10. 29. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 25.  8.] 
expected returns: [[55.423855]
 [56.213345]
 [51.615208]
 [56.213345]
 [60.64385 ]
 [53.09571 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29. 25.  8.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.3826675415039



action possibilites: [-1] 
expected returns: [[88.28256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29.  8. 11. 10.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.64387130737305





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[69.7321  ]
 [89.411095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 29.  8. 11. 10.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.28256225585938






Player: 1 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [10.  0. 11.  3. 11.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [10.  0. 11.  3. 11.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[28.229107]
 [26.48936 ]
 [28.067226]
 [28.067226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3. 11.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  3.  0. 16.  0.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.41107940673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.294289]
 [29.14907 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  3. 11.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29.  3.  0. 16.  0.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.229095458984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 16.  0.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6
  0  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4. 10. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10.  8. 25. 11.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10. 10.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6  0
  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10.  8. 25. 11.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10. 10.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6  0
  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10.  8. 25. 11.] 
adversary cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10. 10.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [29. 10.  8. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8. 25. 11.] 
expected returns: [[50.903347]
 [50.182556]
 [46.01601 ]
 [48.741337]
 [54.046078]
 [50.124653]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  8. 25. 11.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10. 10.  0. 11.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6  0
  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.149085998535156



action possibilites: [-1] 
expected returns: [[45.27373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  8. 11.  0.  0.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10. 10.  0. 11.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6  0
  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.046085357666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[50.976818]
 [52.786274]
 [52.566692]
 [47.32957 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  8. 11.  0.  0.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10. 10.  0. 11.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 21. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6  0
  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.27373123168945



buy possibilites: [-1] 
expected returns: [[33.000168]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  8. 11.  0.  0.] 
cards in discard: [25. 11. 29.  8. 10. 11. 10. 10.  0. 11. 29.  3.  0.  0. 25. 29. 10. 29.
  8. 11. 10. 10.  0. 11.  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 20. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6  0
  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 52.7862548828125






Player: 1 
cards in hand: [ 0. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3 11 22 16  0 10  0  6  3  3  6  3  6 15  0  6  0
  0  6  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 20. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3] -> size -> 36 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 20. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3] -> size -> 36 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 20. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3] -> size -> 36 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3] -> size -> 36 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 10. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 11.] 
expected returns: [[-19.212646]
 [ -4.735032]
 [-23.719429]
 [ -4.735032]
 [ -4.735032]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 3. 3. 3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.00016784667969



action possibilites: [-1] 
expected returns: [[-48.1014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 3. 3. 3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -16.204195022583008





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-41.686043]
 [-46.964703]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  0.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 3. 3. 3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -48.10139846801758



buy possibilites: [-1] 
expected returns: [[2.2438064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  0.] 
cards in discard: [1. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 3. 3. 3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -30.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -41.686038970947266






Player: 1 
cards in hand: [0. 6. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 3.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  3. 25.  0.  0.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 3.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  3. 25.  0.  0.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 3.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  3. 25.  0.  0.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  3. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[ 0.32775927]
 [-3.2186036 ]
 [14.110338  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 25.  0.  0.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.2438063621520996



action possibilites: [-1] 
expected returns: [[27.218857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  3. 10.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.110345840454102





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[17.339123]
 [26.791862]
 [32.118805]
 [29.034946]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3. 10.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 19. 30.  8.  0.  9.  1.  5.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.218856811523438



buy possibilites: [-1] 
expected returns: [[27.76138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3. 10.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 19. 30.  8.  0.  9.  1.  4.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: -9 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.118812561035156






Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 19. 30.  8.  0.  9.  1.  4.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11. 29.  8. 11. 29.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 19. 30.  8.  0.  9.  1.  4.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11. 29.  8. 11. 29.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 18. 30.  8.  0.  9.  1.  4.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11. 29.  8. 11. 29.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [11. 29.  8. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 11. 29.] 
expected returns: [[45.647507]
 [51.133816]
 [51.87438 ]
 [44.633186]
 [51.133816]
 [51.87438 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8. 11. 29.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0.  9.  1.  4.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22.  3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.76137924194336



action possibilites: [-1.  8. 11.] 
expected returns: [[-53.743645]
 [-50.064785]
 [-45.882603]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 18. 30.  8.  0.  9.  1.  4.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22.  3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.70670700073242



action possibilites: [-1] 
expected returns: [[-20.484282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 18. 30.  8.  0.  9.  1.  4.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22.  3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -50   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -49.37992858886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-23.691263]
 [-21.87879 ]
 [-18.249477]
 [-20.11588 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 18. 30.  8.  0.  9.  1.  4.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22.  3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.484281539916992



buy possibilites: [-1] 
expected returns: [[57.982136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22.  3.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -60   0   0  16   0] 
sum of rewards: -39 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -18.249492645263672






Player: 1 
cards in hand: [ 0.  0.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 22.  3.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 25.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22.  3.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 25.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22.  3.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  3. 29. 25.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[35.941055]
 [28.385395]
 [41.567493]
 [55.08362 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 29. 25.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  6.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.  0.  0.  0.  0.
 22.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0] -> size -> 46 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.98213577270508



action possibilites: [-1] 
expected returns: [[55.62913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 29. 11.  0.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  6.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.  0.  0.  0.  0.
 22.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0] -> size -> 46 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 55.083587646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[35.094006]
 [48.213573]
 [51.220943]
 [55.60632 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 29. 11.  0.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  6.] 
adversary cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.  0.  0.  0.  0.
 22.  3.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0] -> size -> 46 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.62913131713867






Player: 1 
cards in hand: [ 3. 11.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  6.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.  0.  0.  0.  0.
 22.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 10. 29. 29.  8.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0. 25.  0. 10.  3. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.  0.  0.  0.  0.
 22.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 10. 29. 29.  8.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0. 25.  0. 10.  3. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.  0.  0.  0.  0.
 22.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 10. 29. 29.  8.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0. 25.  0. 10.  3. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [ 0. 15.  6.  6.  6.  3.  0.  0.  3.  6.  3. 14. 16. 29.  0.  0.  3.  8.
  0.  0.  0.  0.  6.  3.  3.  3.  3.  0.  3.  0.  0.  6.  0.  0.  0.  0.
 22.  3. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 10. 29. 29.  8.] 
adversary cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0. 25.  0. 10.  3. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 29. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 29.  8.] 
expected returns: [[-49.69577 ]
 [-59.23425 ]
 [-59.536957]
 [-47.144672]
 [-47.144672]
 [-59.23425 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29. 29.  8.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0. 25.  0. 10.  3. 29. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.6063232421875



action possibilites: [-1. 10. 29. 25.] 
expected returns: [[-50.292744]
 [-47.27286 ]
 [-29.292912]
 [-16.55259 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 25.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0. 25.  0. 10.  3. 29. 11.  0.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -44.49531173706055



action possibilites: [-1] 
expected returns: [[20.426277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 11.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0. 25.  0. 10.  3. 29. 11.  0.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -16.55260467529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-21.475576]
 [ 20.426277]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 10. 11.] 
cards in discard: [ 1.  0. 11. 10. 11. 11.  0.  8. 25. 10.  3.  0.  0.  3. 10. 11. 29.  1.
  8. 29. 11.  8.  0. 25.  0. 10.  3. 29. 11.  0.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.42627716064453






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [11. 10.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  9.] 
adversary cards in hand: [11. 10.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [15.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  8.] 
adversary cards in hand: [11. 10.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[ 9.247734 ]
 [18.119858 ]
 [-0.6546111]
 [18.119858 ]
 [-0.6546111]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15] -> size -> 49 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.42627716064453



action possibilites: [-1] 
expected returns: [[-159.94157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15] -> size -> 49 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: -21 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 4.804026126861572





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-189.27667]
 [-157.94504]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15] -> size -> 49 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -159.9415740966797






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.  0.  0.  0.  0.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11. 29. 10. 10. 29.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15] -> size -> 42 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.  0.  0.  0.  0.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11. 29. 10. 10. 29.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15] -> size -> 42 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  7.] 
adversary cards in hand: [11. 29. 10. 10. 29.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15] -> size -> 42 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11. 29. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10. 29.] 
expected returns: [[ 7.193026]
 [16.441196]
 [19.395344]
 [-6.681098]
 [-6.681098]
 [19.395344]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 10. 29.] 
cards in discard: [15. 11. 10.  0. 11. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  7.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -157.94503784179688



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[1.620933 ]
 [3.4809623]
 [3.4809623]
 [3.4809623]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  7.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.727423667907715



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[30.772076]
 [27.65765 ]
 [27.65765 ]
 [40.55602 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15] -> size -> 42 
action values: 2 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  7.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 3.4809727668762207



action possibilites: [-1. 10. 10.] 
expected returns: [[-20.845379]
 [-20.23827 ]
 [-20.23827 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  6.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 9 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 34.19614791870117



action possibilites: [-1. 10.] 
expected returns: [[-79.20243]
 [-75.6791 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15] -> size -> 43 
action values: 2 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  6.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -20.238277435302734



action possibilites: [-1. 10.] 
expected returns: [[-68.32208]
 [-52.01292]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 10. 11. 10. 10.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15] -> size -> 43 
action values: 3 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  6.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -75.67911529541016



action possibilites: [-1. 10.] 
expected returns: [[-11.5204  ]
 [ -9.466927]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10. 11. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15] -> size -> 43 
action values: 4 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  6.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -52.012908935546875



action possibilites: [-1. 11.] 
expected returns: [[-18.54874]
 [-11.4475 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 10. 11. 10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15] -> size -> 43 
action values: 5 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  6.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -9.46691608428955



action possibilites: [-1.] 
expected returns: [[-4.7353992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 10. 11. 10. 10. 10. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
action values: 4 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 160   0   0   0   0 -90   0   0  64   0] 
sum of rewards: 99 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -14.668397903442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.562688 ]
 [-4.6249967]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 10. 11. 10. 10. 10. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
action values: 4 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -4.73539924621582






Player: 1 
cards in hand: [16.  6.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  6.  6.  0.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  6  3  3  6  3  6 15  0  6  0  0  6
  6  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0
 15 14] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  3.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6
  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0 15
 14  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6
  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0 15
 14  8] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6
  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0 15
 14  8  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[66.20235 ]
 [55.932827]
 [55.932827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  8. 14.  0.  3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6
  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0 15
 14  8  0] -> size -> 51 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -4.624976634979248





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[46.35787 ]
 [51.735416]
 [57.058437]
 [67.386536]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  8. 14.  0.  3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6
  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0 15
 14  8  0] -> size -> 51 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 66.20233917236328



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0.  3.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6
  3  0  6  0  8  3  6  3  0  0  3  0  0  3  0  0 14  3  0  3  0 14  0 15
 14  8  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 1.  8.  0.  8. 25.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.  0.  3.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6  3  0
  6  0  8  3  6  3  0  0  3  0  0  3  0  0  3  0  3  0 14  0 15 14  8  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 1.  8.  0.  8. 25.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.  0.  3.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6  3  0
  6  0  8  3  6  3  0  0  3  0  0  3  0  0  3  0  3  0 14  0 15 14  8  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 1.  8.  0.  8. 25.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.  0.  3.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.
  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6  3  0
  6  0  8  3  6  3  0  0  3  0  0  3  0  0  3  0  3  0 14  0 15 14  8  0
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 1.  8.  0.  8. 25.] 
adversary cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.  0.  3.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 1.  8.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
expected returns: [[69.141335]
 [63.640217]
 [63.640217]
 [77.590225]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  8. 25.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.  0.  3.  0.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.
  0.  8.  3.] 
adversary owned cards: [ 0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6  3  0
  6  0  8  3  6  3  0  0  3  0  0  3  0  0  3  0  3  0 14  0 15 14  8  0
  0] -> size -> 49 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 67.38651275634766



action possibilites: [-1] 
expected returns: [[28.105438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  8.  3. 11.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.  0.  3.  0.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.
  0.  8.  3.] 
adversary owned cards: [ 0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6  3  0
  6  0  8  3  6  3  0  0  3  0  0  3  0  0  3  0  3  0 14  0 15 14  8  0
  0] -> size -> 49 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.5902099609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 7.735439]
 [24.857025]
 [20.81411 ]
 [30.831875]
 [25.038948]
 [28.10542 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  8.  3. 11.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.  0.  3.  0.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 18. 30.  8.  0.  9.  1.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.
  0.  8.  3.] 
adversary owned cards: [ 0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6  3  0
  6  0  8  3  6  3  0  0  3  0  0  3  0  0  3  0  3  0 14  0 15 14  8  0
  0] -> size -> 49 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.105438232421875



Player 1 won the game! 



Player 0 bought cards:
Copper: 3 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 6 
Witch: 3 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  8.  0.  8.  3. 11.] 
cards in discard: [15. 11. 10.  0. 11. 10. 11. 29. 15. 15. 29. 10. 11. 10. 10. 10. 10. 11.
  3.  0.  3.  0.  8.  8. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 29  0 29 10 29 29 10  8 25 10 11 25  0 10
 11 11 10 11  8 10 10 11  8 11 11  3  1  0  8  1  8 15 15 15 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 30.  8.  0.  9.  0.  2.  7.  4.  7. 10.  0.  9.  5.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [15.  0.  0.  0.  0.  6. 14.  0.  3.  0.  0.  0.  8.  0. 16.  6.  6.  0.
  0.  8.  3.] 
adversary owned cards: [ 0  0  3 29  3 11 22 16  0  0  3  3  6  3  6 15  0  6  0  0  6  6  3  0
  6  0  8  3  6  3  0  0  3  0  0  3  0  0  3  0  3  0 14  0 15 14  8  0
  0] -> size -> 49 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0       20        0
        0        0        0     -100        0        0       27        0] 
sum of rewards: -3000118 

action type: buy - action 11.0
Learning step: -120005.9453125
desired expected reward: -119975.1171875



