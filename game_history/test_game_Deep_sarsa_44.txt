 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[63.54346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 9
Learning step: -23.531232833862305
desired expected reward: 206.7810821533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.444256]
 [76.13303 ]
 [70.9567  ]
 [53.530132]
 [82.81612 ]
 [70.70249 ]
 [66.0015  ]
 [60.40762 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.48777389526367



buy possibilites: [-1] 
expected returns: [[51.355553]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 82.81610107421875






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[62.62376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.355552673339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[63.16701 ]
 [81.18733 ]
 [75.59743 ]
 [54.988247]
 [69.1225  ]
 [88.18385 ]
 [75.336716]
 [97.180016]
 [66.76848 ]
 [69.799065]
 [85.04011 ]
 [62.952465]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 61.11709213256836



buy possibilites: [-1] 
expected returns: [[25.495764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 97.18001556396484






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[27.328756]
 [49.3139  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.495763778686523



action possibilites: [-1.] 
expected returns: [[30.673342]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.15071487426758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.264654]
 [43.17105 ]
 [39.32553 ]
 [26.099   ]
 [34.90972 ]
 [48.244907]
 [39.097702]
 [54.65255 ]
 [33.549843]
 [35.42072 ]
 [45.949837]
 [31.323431]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.673341751098633



buy possibilites: [-1] 
expected returns: [[30.597738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 54.652549743652344






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[47.934994]
 [66.45754 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.59773826599121



action possibilites: [-1] 
expected returns: [[20.843863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.64241790771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.80982 ]
 [33.189808]
 [29.803263]
 [17.19618 ]
 [37.929337]
 [29.424871]
 [26.156483]
 [22.393522]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.843862533569336



buy possibilites: [-1] 
expected returns: [[9.176468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 37.92934036254883






Player: 1 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[26.175863]
 [44.723583]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.176467895507812



action possibilites: [-1.] 
expected returns: [[28.254614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.71479034423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.59559 ]
 [41.252934]
 [37.810127]
 [24.428465]
 [45.64585 ]
 [37.584763]
 [34.03622 ]
 [29.72772 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.254613876342773



buy possibilites: [-1] 
expected returns: [[30.169436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.64584732055664






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 16] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  0.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  0.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 16  1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  0.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[20.269958]
 [43.86319 ]
 [24.91793 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0.  0.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16  1] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.169435501098633



action possibilites: [-1. 10. 11.] 
expected returns: [[41.00433 ]
 [45.540016]
 [58.43082 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16  1] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.06645584106445



action possibilites: [-1] 
expected returns: [[4.249308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  8.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16  1] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.70139694213867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 7.6254067]
 [21.202404 ]
 [16.972715 ]
 [ 1.8075233]
 [11.737318 ]
 [27.310015 ]
 [16.600311 ]
 [35.34594  ]
 [10.2036915]
 [12.413412 ]
 [24.322687 ]
 [ 7.7024007]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  8.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16  1] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.249308109283447



buy possibilites: [-1] 
expected returns: [[9.635654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  8.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 16  1] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 35.3459358215332






Player: 1 
cards in hand: [16.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  0.  0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 16  1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[14.062103]
 [28.03914 ]
 [28.03914 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.63565444946289



action possibilites: [-1] 
expected returns: [[8.9562435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.25883674621582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.160055 ]
 [23.370518 ]
 [19.217945 ]
 [ 5.1390967]
 [28.534018 ]
 [18.988455 ]
 [14.955948 ]
 [10.149624 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.956243515014648



buy possibilites: [-1] 
expected returns: [[2.0004158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  6.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 28.534006118774414






Player: 1 
cards in hand: [0. 3. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  6.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  6.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[39.38891 ]
 [44.553684]
 [44.553684]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.000415802001953



action possibilites: [-1. 10. 11.] 
expected returns: [[41.61658 ]
 [46.96841 ]
 [62.734295]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 11.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 41.37173080444336



action possibilites: [-1. 10.] 
expected returns: [[33.30879 ]
 [37.572254]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.41388702392578



action possibilites: [-1. 29.] 
expected returns: [[38.1211  ]
 [61.095333]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 37.5722541809082



action possibilites: [-1. 29.] 
expected returns: [[50.96493]
 [71.78654]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10] -> size -> 21 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.095333099365234



action possibilites: [-1.] 
expected returns: [[57.128597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11. 10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10] -> size -> 21 
action values: 2 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.78652954101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[64.79297 ]
 [76.67634 ]
 [73.18183 ]
 [62.736263]
 [59.211456]
 [68.645676]
 [81.235214]
 [72.84635 ]
 [89.16829 ]
 [86.93307 ]
 [67.29512 ]
 [74.97784 ]
 [69.351845]
 [63.094456]
 [79.1785  ]
 [65.14251 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11. 10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.128597259521484



buy possibilites: [-1] 
expected returns: [[27.866617]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11. 10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0 100   0   0   0   0   0   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 89.16830444335938






Player: 1 
cards in hand: [ 0. 16.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  0.  0.] 
cards in discard: [16.  0.  3.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8.  0.  0.] 
cards in discard: [16.  0.  3.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  6.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8.  0.  0.] 
cards in discard: [16.  0.  3.  0.  1.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1 16  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[22.452396]
 [38.709003]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.86661720275879



action possibilites: [-1.] 
expected returns: [[36.315113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 36.0296745300293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[39.025192]
 [49.455036]
 [46.214886]
 [34.34074 ]
 [42.35949 ]
 [53.791637]
 [45.99586 ]
 [59.13616 ]
 [41.135098]
 [42.864315]
 [51.837776]
 [39.14367 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.31511306762695



buy possibilites: [-1] 
expected returns: [[6.2893243]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 16  1 16  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 59.136165618896484






Player: 1 
cards in hand: [ 0.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 16  1 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[47.63457 ]
 [64.5316  ]
 [71.18238 ]
 [51.691406]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 10.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 16.  8.  1.  0.] 
adversary cards in discard: [ 3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.2893242835998535



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[40.386375]
 [56.133904]
 [44.386246]
 [44.386246]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 10.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 16.  8.  1.  0.] 
adversary cards in discard: [ 3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.6709098815918



action possibilites: [-1] 
expected returns: [[43.166203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  8.  1.  0.] 
adversary cards in discard: [ 3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 60.42948532104492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.365356]
 [60.856174]
 [57.20763 ]
 [42.690403]
 [65.61478 ]
 [56.79835 ]
 [53.14982 ]
 [48.931206]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  8.  1.  0.] 
adversary cards in discard: [ 3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.166202545166016



buy possibilites: [-1] 
expected returns: [[13.152277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  8.  1.  0.] 
adversary cards in discard: [ 3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 65.61478424072266






Player: 1 
cards in hand: [ 3. 16.  8.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8.  1.  0.] 
cards in discard: [ 3. 16.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0. 11. 11.  3.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0. 10. 11. 29. 11.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  8.  1.  0.] 
cards in discard: [ 3. 16.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0. 11. 11.  3.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0. 10. 11. 29. 11.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [25.  0. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[ 5.3247724]
 [14.731401 ]
 [11.905172 ]
 [11.905172 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 11. 11.  3.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 10. 11. 29. 11.  0.  0. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.152276992797852



action possibilites: [-1] 
expected returns: [[28.618654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3.  0. 11.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 10. 11. 29. 11.  0.  0. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16. 16.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.826356887817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.960747]
 [24.648325]
 [17.267965]
 [24.172592]
 [21.063538]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3.  0. 11.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 10. 11. 29. 11.  0.  0. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16. 16.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.618654251098633



buy possibilites: [-1] 
expected returns: [[-5.905051]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3.  0. 11.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 10. 11. 29. 11.  0.  0. 10. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16. 16.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 24.648330688476562






Player: 1 
cards in hand: [ 3. 16. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 16.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 16.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 16.  0.  0.] 
cards in discard: [6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 10.] 
expected returns: [[-9.337135 ]
 [ 6.616444 ]
 [-7.0930276]
 [ 6.616444 ]
 [-7.0930276]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 29. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3. 16. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.905051231384277



action possibilites: [-1. 10. 29. 10. 11.] 
expected returns: [[-2.6704957 ]
 [-0.46008515]
 [12.050402  ]
 [-0.46008515]
 [ 8.823696  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 10. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3. 16. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.0622034072875977



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[34.07097]
 [37.22037]
 [37.22037]
 [47.01633]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3. 16. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 12.050394058227539



action possibilites: [-1] 
expected returns: [[38.681927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3. 16. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.0734748840332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[44.665684]
 [55.546074]
 [52.36473 ]
 [39.803852]
 [59.909195]
 [51.923176]
 [48.804855]
 [45.424763]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  5.  9.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3. 16. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.68192672729492



buy possibilites: [-1] 
expected returns: [[18.197208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3. 16. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 59.90919494628906






Player: 1 
cards in hand: [3. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 3.] 
cards in discard: [ 6.  0.  3. 16. 16.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 10. 11. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 3.] 
cards in discard: [ 6.  0.  3. 16. 16.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 10. 11. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[0.45884657]
 [1.8963923 ]
 [7.1046176 ]
 [1.8963923 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11. 10.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.197208404541016



action possibilites: [-1] 
expected returns: [[-21.339056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 10.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 5.425581455230713





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-22.424112]
 [-25.078337]
 [-20.784601]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 10.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.33905601501465






Player: 1 
cards in hand: [0. 3. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  8 16  1 16  3  3  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 25.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10] -> size -> 29 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8 16  1 16  3  3  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 25.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10] -> size -> 29 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8 16  1 16  3  3  6  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 25.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10] -> size -> 29 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.] 
expected returns: [[1.4376640e-03]
 [1.3312597e+01]
 [1.0138403e+01]
 [1.6657072e+01]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 25.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [16.  3.  0.  6.  0.] 
adversary cards in discard: [8. 1.] 
adversary owned cards: [ 0  3  0  8 16  1 16  3  3  6  0] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -20.784603118896484



action possibilites: [-1] 
expected returns: [[7.7800975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8.  8.  4.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [16.  3.  0.  6.  0.] 
adversary cards in discard: [8. 1. 6.] 
adversary owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.42361068725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.811092]
 [17.209528]
 [15.945831]
 [ 9.472231]
 [19.626598]
 [15.351488]
 [14.161331]
 [13.286711]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  8.  8.  4.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [16.  3.  0.  6.  0.] 
adversary cards in discard: [8. 1. 6.] 
adversary owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.780097484588623



buy possibilites: [-1] 
expected returns: [[42.90998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [16.  3.  0.  6.  0.] 
adversary cards in discard: [8. 1. 6.] 
adversary owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 19.626596450805664






Player: 1 
cards in hand: [16.  3.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  6.  0.] 
cards in discard: [8. 1. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10. 11. 25.  0.
 29. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11] -> size -> 30 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  6.  0.] 
cards in discard: [8. 1. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10. 11. 25.  0.
 29. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11] -> size -> 30 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[45.252914]
 [54.465   ]
 [54.465   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10. 11. 25.  0.
 29. 11.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.90998077392578



action possibilites: [-1] 
expected returns: [[34.245674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10. 11. 25.  0.
 29. 11.  0. 10.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 57.21867752075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.366388]
 [34.58444 ]
 [25.127989]
 [33.79872 ]
 [29.77677 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10. 11. 25.  0.
 29. 11.  0. 10.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.24567413330078



buy possibilites: [-1] 
expected returns: [[24.380096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10. 10.  3. 10. 11.  3.  3. 10. 10. 11. 25.  0.
 29. 11.  0. 10.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 34.584449768066406






Player: 1 
cards in hand: [ 3.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 16.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 16  1 16  3  3  6  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3] -> size -> 32 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3] -> size -> 32 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3] -> size -> 32 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11. 10.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[20.29165 ]
 [31.854479]
 [22.66291 ]
 [35.94066 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [16.  6.  8.  1.  6.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.380096435546875



action possibilites: [-1. 11. 10.] 
expected returns: [[13.726046]
 [28.161047]
 [16.559408]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [16.  6.  8.  1.  6.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.75482940673828



action possibilites: [-1] 
expected returns: [[19.107883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16.  6.  8.  1.  6.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.17074203491211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.442352]
 [32.161938]
 [29.830435]
 [19.682598]
 [35.81617 ]
 [29.222849]
 [26.897007]
 [24.616623]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16.  6.  8.  1.  6.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.10788345336914



buy possibilites: [-1] 
expected returns: [[20.64742]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16.  6.  8.  1.  6.] 
adversary cards in discard: [ 0. 16.  3.  3.  3.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 35.8161735534668






Player: 1 
cards in hand: [16.  6.  8.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  8.  1.  6.] 
cards in discard: [ 0. 16.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25. 11. 29.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  8.  1.  6.] 
cards in discard: [ 0. 16.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  8.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25. 11. 29.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  8.  1.  6.] 
cards in discard: [ 0. 16.  3.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  8.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25. 11. 29.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11] -> size -> 34 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25. 11. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29. 10.] 
expected returns: [[-2.276479 ]
 [ 6.8424525]
 [ 4.4816747]
 [ 5.890408 ]
 [-1.513422 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29.  0. 10.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  8.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.64742088317871



action possibilites: [-1] 
expected returns: [[-0.17675734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 10. 11.  0.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 6.297603130340576





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-1.2420735]
 [ 3.8653436]
 [-3.305445 ]
 [ 3.0082989]
 [ 1.3554606]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0. 10. 11.  0.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  7.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.1767573356628418



buy possibilites: [-1] 
expected returns: [[16.800236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0. 10. 11.  0.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 3.86533260345459






Player: 1 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3] -> size -> 35 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8.  7.  8.  2.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3] -> size -> 35 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7.  8.  1.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3] -> size -> 35 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[12.979494]
 [13.58246 ]
 [18.597338]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 11.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7.  8.  1.  9.  9.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 16.  3. 16.  6.] 
adversary cards in discard: [ 6. 11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.800235748291016



action possibilites: [-1] 
expected returns: [[39.75317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7.  8.  1.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 16.  3. 16.  6.] 
adversary cards in discard: [ 6. 11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 19.687211990356445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[37.68344 ]
 [44.436737]
 [34.714294]
 [42.92097 ]
 [41.744102]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  7.  8.  1.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 16.  3. 16.  6.] 
adversary cards in discard: [ 6. 11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.753170013427734



buy possibilites: [-1] 
expected returns: [[32.481716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  7.  8.  1.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 16.  3. 16.  6.] 
adversary cards in discard: [ 6. 11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 191 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 44.436767578125






Player: 1 
cards in hand: [ 3. 16.  3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3. 16.  6.] 
cards in discard: [ 6. 11.  0.  6.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 16  1 16  3  3  6  0  6  0  3  6 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  7.  8.  1.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  3. 10.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3] -> size -> 37 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.] 
cards in discard: [ 6. 11.  0.  6.  3.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8 16  1 16  3  3  6  0  6  0  3  6 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  7.  8.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  3. 10.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3] -> size -> 37 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.] 
cards in discard: [ 6. 11.  0.  6.  3.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8 16  1 16  3  3  6  0  6  0  3  6 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  7.  8.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  3. 10.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3] -> size -> 37 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.] 
cards in discard: [ 6. 11.  0.  6.  3.  0.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  8 16  1 16  3  3  6  0  6  0  3  6 11 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  7.  8.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  3. 10.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3] -> size -> 37 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10. 11.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[13.950003]
 [14.371237]
 [20.224855]
 [14.371237]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 10.  3.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  7.  8.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [16. 16.  3.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 16  1 16  3  3  6  0  6  0  3  6 11 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.48171615600586



action possibilites: [-1] 
expected returns: [[47.67019]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  3.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8.  7.  8.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [16. 16.  3.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 16  1 16  3  3  6  0  6  0  3  6 11 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 17.25142478942871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.42656]
 [41.26389]
 [45.44692]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  3.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8.  7.  8.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [16. 16.  3.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8 16  1 16  3  3  6  0  6  0  3  6 11 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.670188903808594






Player: 1 
cards in hand: [16. 16.  3.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  3.  1.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 16  1 16  3  3  6  0  6  0  3  6 11 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8.  7.  8.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3. 29. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1. 11. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  1.] 
cards in discard: [16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3. 29. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1. 11. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  1.] 
cards in discard: [16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 23. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3. 29. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1. 11. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  1.] 
cards in discard: [16.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3. 29. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1. 11. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  3. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 10.] 
expected returns: [[36.815514]
 [38.33826 ]
 [47.3436  ]
 [47.3436  ]
 [38.33826 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29. 29. 10.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1. 11. 10.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  6. 11.  6.] 
adversary cards in discard: [16.  3. 16. 16.  3.  1.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3] -> size -> 17 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.44694137573242



action possibilites: [-1. 10. 10.] 
expected returns: [[56.36285 ]
 [55.703014]
 [55.703014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1. 11. 10.  3. 10.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  6. 11.  6.] 
adversary cards in discard: [16.  3. 16. 16.  3.  1.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3] -> size -> 17 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.2945556640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.143642]
 [51.752743]
 [56.36285 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [10. 11. 29. 11. 10.  3.  0.  0.  3. 25. 11. 29.  0. 10. 11.  0. 10.  3.
 11.  3.  0. 10.  0.  1. 11. 10.  3. 10.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  6. 11.  6.] 
adversary cards in discard: [16.  3. 16. 16.  3.  1.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3] -> size -> 17 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.36285400390625






Player: 1 
cards in hand: [11.  0.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 11.  6.] 
cards in discard: [16.  3. 16. 16.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  6.] 
cards in discard: [16.  3. 16. 16.  3.  1. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  6.] 
cards in discard: [16.  3. 16. 16.  3.  1. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  6.] 
cards in discard: [16.  3. 16. 16.  3.  1. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29. 10. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 11. 11.] 
expected returns: [[24.319593]
 [31.183935]
 [24.785545]
 [24.785545]
 [30.00849 ]
 [30.00849 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 11. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [16.  3. 16. 16.  3.  1. 15.  0. 11.  0.  6. 11.  6.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0] -> size -> 19 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 56.36285400390625



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[39.50562 ]
 [40.141216]
 [40.141216]
 [47.35261 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [11.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [16.  3. 16. 16.  3.  1. 15.  0. 11.  0.  6. 11.  6.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0] -> size -> 19 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.03241729736328



action possibilites: [-1] 
expected returns: [[55.50765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [11.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [16.  3. 16. 16.  3.  1. 15.  0. 11.  0.  6. 11.  6.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0] -> size -> 19 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 44.085968017578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.300865]
 [50.623318]
 [55.071865]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [11.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [16.  3. 16. 16.  3.  1. 15.  0. 11.  0.  6. 11.  6.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0] -> size -> 19 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.50764846801758






Player: 1 
cards in hand: [0. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [16.  3. 16. 16.  3.  1. 15.  0. 11.  0.  6. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3. 11.  0. 29.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1] -> size -> 39 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [16.  3. 16. 16.  3.  1. 15.  0. 11.  0.  6. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 22. 30.  8.  7.  7.  0.  9.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3. 11.  0. 29.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1] -> size -> 39 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [16.  3. 16. 16.  3.  1. 15.  0. 11.  0.  6. 11.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  7.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3. 11.  0. 29.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1] -> size -> 39 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  3. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[1.3396535]
 [0.8694968]
 [6.7165723]
 [6.7665877]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0. 29.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  7.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8] -> size -> 20 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.071876525878906



action possibilites: [-1. 10. 11.] 
expected returns: [[16.622568]
 [18.123953]
 [36.51616 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 22. 30.  8.  7.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8] -> size -> 20 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.9821839332580566



action possibilites: [-1] 
expected returns: [[122.71576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 22. 30.  8.  7.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8] -> size -> 20 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 28.392587661743164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[118.96779]
 [113.46727]
 [123.05694]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 22. 30.  8.  7.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8] -> size -> 20 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.71575927734375






Player: 1 
cards in hand: [3. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 22. 30.  8.  7.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  3. 25.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 22. 30.  8.  7.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  3. 25.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
adversary victory points: 7
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25.] 
expected returns: [[49.328747]
 [51.452396]
 [61.360775]
 [67.11997 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3. 25.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 22. 30.  8.  7.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3.  3.] 
adversary cards in discard: [3. 0. 6. 6. 0.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8] -> size -> 20 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 123.05693054199219



action possibilites: [-1] 
expected returns: [[93.862175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3. 10. 29.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3.  3.] 
adversary cards in discard: [3. 0. 6. 6. 0. 6.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 67.1199951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[89.94995]
 [84.40631]
 [95.01313]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  3. 10. 29.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3.  3.] 
adversary cards in discard: [3. 0. 6. 6. 0. 6.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.86217498779297






Player: 1 
cards in hand: [ 8. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  3.  3.] 
cards in discard: [3. 0. 6. 6. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  3.  3.] 
cards in discard: [3. 0. 6. 6. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  3.  3.] 
cards in discard: [3. 0. 6. 6. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[55.463264]
 [57.641605]
 [57.641605]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0. 10.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 16. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.01314544677734



action possibilites: [-1. 10.] 
expected returns: [[48.676533]
 [51.08089 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  3.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 16. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 57.641632080078125



action possibilites: [-1. 10.] 
expected returns: [[42.109966]
 [44.232296]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 10.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 16. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 51.08091735839844



action possibilites: [-1. 29.] 
expected returns: [[33.33762 ]
 [40.351177]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 29.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 4 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 16. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 44.2323112487793



action possibilites: [-1.] 
expected returns: [[40.677147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 4 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 16. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.84675216674805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.218273]
 [44.098682]
 [36.40296 ]
 [43.504524]
 [40.642017]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 22. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 16. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.677146911621094



buy possibilites: [-1] 
expected returns: [[123.72306]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 21. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 16. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  80   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 44.09870147705078






Player: 1 
cards in hand: [11.  3. 16. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 16. 16.  0.] 
cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 21. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1.  3.  3. 11.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3] -> size -> 41 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 16.  0.] 
cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1.  3.  3. 11.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3] -> size -> 41 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 16.  0.] 
cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 21. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1.  3.  3. 11.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3] -> size -> 41 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  1.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 88.230446]
 [ 90.7281  ]
 [106.88629 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  3. 11.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 15. 16.  6.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0. 11.  3. 16. 16.  0.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.72306060791016



action possibilites: [-1] 
expected returns: [[66.95368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  3.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 21. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 15. 16.  6.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0. 11.  3. 16. 16.  0.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 99.66280364990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.550343]
 [74.9919  ]
 [56.878387]
 [73.05438 ]
 [66.953674]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  3.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 21. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 15. 16.  6.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0. 11.  3. 16. 16.  0.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.95368194580078



buy possibilites: [-1] 
expected returns: [[125.6609]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  3.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 20. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 15. 16.  6.] 
adversary cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0. 11.  3. 16. 16.  0.] 
adversary owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 221 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 74.99195861816406






Player: 1 
cards in hand: [ 1.  0. 15. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15. 16.  6.] 
cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0. 11.  3. 16. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 20. 30.  8.  6.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3. 11. 10.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3] -> size -> 43 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  6.] 
cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0. 11.  3. 16. 16.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 20. 30.  8.  5.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3. 11. 10.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  6.] 
cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0. 11.  3. 16. 16.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 20. 30.  8.  5.  7.  0.  8.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3. 11. 10.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  6.] 
cards in discard: [ 3.  0.  6.  6.  0.  6.  0.  8. 11.  0.  3.  3.  0. 11.  3. 16. 16.  0.
  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 20. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3. 11. 10.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[87.82863]
 [97.30778]
 [88.156  ]
 [97.30778]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11.  0.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3. 11. 10.  1.
  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 20. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [16. 15.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0  6  8] -> size -> 24 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.66089630126953



action possibilites: [-1] 
expected returns: [[65.64066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3. 11. 10.  1.
  3.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 20. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [16. 15.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0  6  8] -> size -> 24 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 252 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 93.30572509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.111973]
 [71.026375]
 [57.37652 ]
 [69.63601 ]
 [65.64065 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3. 11. 10.  1.
  3.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 20. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [16. 15.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0  6  8] -> size -> 24 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.64066314697266



buy possibilites: [-1] 
expected returns: [[99.45678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [11.  0.  1. 29. 11. 10. 10. 11.  0.  1. 29. 11. 10.  3. 25.  0. 10. 11.
  3. 10. 29.  0.  3.  3. 10. 10. 10. 29.  3.  3.  0.  1.  3. 11. 10.  1.
  3.  3.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [16. 15.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0  6  8] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 71.02637481689453






Player: 1 
cards in hand: [16. 15.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  8.  0. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  3  3  6  0  6  0  3  6 11 11  0 16  3 15  0  8  6  0  0  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3] -> size -> 45 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  3  3  6  0  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3] -> size -> 45 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  3  3  6  0  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3] -> size -> 45 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[-45.468594]
 [-45.70418 ]
 [-40.670357]
 [-40.670357]
 [-45.70418 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [ 8.  0. 16.] 
adversary owned cards: [ 1 16  3  3  6  0  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.45677947998047



action possibilites: [-1] 
expected returns: [[-4.7568917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10.] 
cards in discard: [1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [ 8.  0. 16.] 
adversary owned cards: [ 1 16  3  3  6  0  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 262 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -43.00264358520508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.921609]
 [-7.203233]
 [-4.135126]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 10.] 
cards in discard: [1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 23. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [ 8.  0. 16.] 
adversary owned cards: [ 1 16  3  3  6  0  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.75689172744751






Player: 1 
cards in hand: [1. 3. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 6.] 
cards in discard: [ 8.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  3  6  0  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6.] 
cards in discard: [ 8.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [ 8.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 19. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [ 8.  0. 16.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[36.976665]
 [38.26175 ]
 [52.836163]
 [52.836163]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11. 11.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3] -> size -> 21 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -4.135121822357178



action possibilites: [-1] 
expected returns: [[63.411892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3] -> size -> 21 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 252 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 46.404239654541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[58.09128 ]
 [52.992805]
 [60.35487 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3] -> size -> 21 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.41189193725586






Player: 1 
cards in hand: [11.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [ 8.  0. 16.  3.  8.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1. 10. 10.  0.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [ 8.  0. 16.  3.  8.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1. 10. 10.  0.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1. 10. 10.  0.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  1. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[57.038525]
 [59.106968]
 [59.106968]
 [59.106968]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 10. 10.  0.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  6. 16.  6.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 60.3548698425293



action possibilites: [-1. 10. 10.] 
expected returns: [[70.51243]
 [72.00121]
 [72.00121]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  0.  0.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  6. 16.  6.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 59.106998443603516



action possibilites: [-1. 10. 11.] 
expected returns: [[ 92.36431]
 [ 96.1665 ]
 [111.31063]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  0. 11.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1] -> size -> 47 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  6. 16.  6.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 72.00125122070312



action possibilites: [-1. 10.] 
expected returns: [[63.6188]
 [64.6765]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  0.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  6. 16.  6.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   60    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 105.43726348876953



action possibilites: [-1.] 
expected returns: [[58.52051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1] -> size -> 48 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  6. 16.  6.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 64.6764907836914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[53.128666]
 [65.70116 ]
 [62.546528]
 [50.849285]
 [47.894356]
 [56.482918]
 [61.497295]
 [77.51043 ]
 [75.0646  ]
 [55.9436  ]
 [63.531513]
 [51.057194]
 [68.542076]
 [55.548008]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 20. 30. 18. 30.  8.  5.  7.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  6. 16.  6.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.520511627197266



buy possibilites: [-1] 
expected returns: [[69.667435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  6. 16.  6.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   80    0    0    0    0 -140    0    0
  250    0] 
sum of rewards: 515 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 77.51043701171875






Player: 1 
cards in hand: [ 6.  6.  6. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 16.  6.] 
cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 29.  1. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25] -> size -> 49 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 16.  6.] 
cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 29.  1. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25] -> size -> 49 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 16.  6.] 
cards in discard: [ 8.  0. 16.  3.  8.  1.  6.  1. 11.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 29.  1. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25] -> size -> 49 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[40.668377]
 [41.688564]
 [50.23422 ]
 [41.688564]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  1. 10.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.66743469238281



action possibilites: [-1. 10.] 
expected returns: [[79.9961]
 [78.1085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.3475456237793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[76.532295]
 [79.841415]
 [79.19107 ]
 [75.962555]
 [76.15655 ]
 [77.945404]
 [82.30717 ]
 [77.34449 ]
 [81.23035 ]
 [79.9961  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.99608612060547



buy possibilites: [-1] 
expected returns: [[96.333855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -150    0    0
  128    0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 82.30713653564453






Player: 1 
cards in hand: [ 1.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  1. 29.  1.  3.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29] -> size -> 50 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  1. 29.  1.  3.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29] -> size -> 50 
adversary victory points: 10
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11.  1. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[100.382225]
 [106.647194]
 [108.59252 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.  1.  3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.33385467529297



action possibilites: [-1.] 
expected returns: [[191.14563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 104.32170867919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[187.20737]
 [202.69844]
 [198.42184]
 [185.08464]
 [183.07948]
 [189.68002]
 [196.7997 ]
 [210.64793]
 [210.42912]
 [189.66388]
 [199.58633]
 [185.11682]
 [206.70598]
 [191.14565]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  8.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 191.1456298828125



buy possibilites: [-1] 
expected returns: [[245.75435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.] 
adversary owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -160    0    0
  250    0] 
sum of rewards: 435 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 210.64793395996094






Player: 1 
cards in hand: [ 3. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0.  0.] 
cards in discard: [ 1.  0.  3.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  0  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  7.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 29.  3.  3.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25] -> size -> 51 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 1.  0.  3.  3. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 29.  3.  3.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25] -> size -> 51 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 1.  0.  3.  3. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 20. 30. 18. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 29.  3.  3.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25] -> size -> 51 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 1.  0.  3.  3. 11.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 20. 30. 18. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 29.  3.  3.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25] -> size -> 51 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[56.918842]
 [63.974026]
 [65.128525]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3.  3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 18. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 11.  6.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 245.7543487548828



action possibilites: [-1.] 
expected returns: [[146.83362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 20. 30. 18. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 11.  6.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.87553787231445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[143.28764]
 [154.06091]
 [138.94682]
 [152.61755]
 [146.83353]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 20. 30. 18. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 11.  6.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 146.8336181640625



buy possibilites: [-1] 
expected returns: [[241.98233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 17. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 11.  6.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -170    0    0
   16    0] 
sum of rewards: 221 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 154.0609893798828






Player: 1 
cards in hand: [ 0.  6.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 11.  6.] 
cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 17. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10.  3.  0.  1.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3] -> size -> 52 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11.  6.] 
cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 20. 30. 17. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10.  3.  0.  1.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3] -> size -> 52 
adversary victory points: 11
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11.  6.] 
cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 30. 17. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10.  3.  0.  1.] 
adversary cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3] -> size -> 52 
adversary victory points: 11
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [25. 10.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[31.26069 ]
 [37.360096]
 [31.778315]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  3.  0.  1.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.  3. 29.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  5.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8.  8.  0. 16.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.  0.  0.  6.  6. 11.  6.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0] -> size -> 25 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 241.98233032226562



action possibilites: [-1] 
expected returns: [[153.62917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1.  3.  3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.  3. 29.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8.  8.  0. 16.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.  0.  0.  6.  6. 11.  6.  6.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.3600959777832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[149.35242]
 [163.92374]
 [160.67545]
 [143.19025]
 [158.97867]
 [153.62921]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1.  3.  3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.  3. 29.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8.  8.  0. 16.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.  0.  0.  6.  6. 11.  6.  6.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 153.62916564941406



buy possibilites: [-1] 
expected returns: [[35.188263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1.  3.  3.] 
cards in discard: [ 1. 11.  3. 10. 11. 10.  1. 11.  0. 10.  3. 11.  1. 25. 10. 10. 11. 10.
  1.  0.  0.  0. 10. 11. 29. 29.  0.  1. 10. 11. 10. 25. 29.  1.  1.  3.
 11.  3.  3. 29.  0.  3.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8.  8.  0. 16.] 
adversary cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.  0.  0.  6.  6. 11.  6.  6.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -180    0    0
   54    0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 163.92367553710938






Player: 1 
cards in hand: [ 6.  8.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  8.  0. 16.] 
cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.  0.  0.  6.  6. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
adversary victory points: 11
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  8.  0. 16.] 
cards in discard: [ 1.  0.  3.  3. 11.  8.  0. 16.  3.  3.  0.  0.  0.  6.  6. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
adversary victory points: 11
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 3.9509225]
 [ 1.2609305]
 [-1.7326849]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.188262939453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.64858675]
 [-0.1827159 ]
 [ 5.3768983 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.950934886932373



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [11.  3.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
adversary victory points: 11
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [11.  3.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
adversary victory points: 11
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 1.] 
cards in discard: [14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [11.  3.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
adversary victory points: 11
player victory points: -2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[95.17046 ]
 [95.378944]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  0.] 
cards in discard: [11.  3.  3.  3. 29.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  0.  6. 11.  0.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 5.376893520355225



action possibilites: [-1. 29.] 
expected returns: [[74.08938]
 [97.15783]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [11.  3.  3.  3. 29.] 
cards in deck: 42 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  0.  6. 11.  0.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 95.37891387939453



action possibilites: [-1.] 
expected returns: [[236.56331]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3.] 
cards in deck: 41 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  0.  6. 11.  0.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 84.34129333496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[227.91743]
 [265.3587 ]
 [256.43246]
 [210.99432]
 [237.88509]
 [252.96513]
 [287.98334]
 [236.65485]
 [272.66202]
 [236.29259]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3.] 
cards in deck: 41 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  0.  6. 11.  0.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 236.5633087158203



buy possibilites: [-1] 
expected returns: [[14.83494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29.] 
cards in deck: 41 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  0.  6. 11.  0.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  390    0    0   40    0    0    0    0 -190    0    0
  128    0] 
sum of rewards: 363 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 287.9833679199219






Player: 1 
cards in hand: [16.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6. 11.  0.] 
cards in discard: [14.  3.  0.  6.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 25.  0. 10. 10.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
adversary victory points: 11
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  0.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 25.  0. 10. 10.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
adversary victory points: 11
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 25.  0. 10. 10.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
adversary victory points: 11
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 25.  0. 10. 10.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
adversary victory points: 11
player victory points: -2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
expected returns: [[ 96.03909]
 [126.6406 ]
 [ 99.31156]
 [ 99.31156]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 10. 10.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 17. 30.  8.  4.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 8. 8. 0. 1.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14 15  0] -> size -> 29 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.834939956665039



action possibilites: [-1] 
expected returns: [[16.864206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10. 11. 11.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 17. 30.  8.  3.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 8. 8. 0. 1.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14 15  0  6] -> size -> 30 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.64058685302734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.964081  ]
 [-0.14242816]
 [16.864204  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 10. 11. 11.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 19. 30. 17. 30.  8.  3.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 8. 8. 0. 1.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.] 
adversary owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14 15  0  6] -> size -> 30 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.864206314086914






Player: 1 
cards in hand: [6. 8. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 0. 1.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  3  6  6  3  6 11 11  0 16  3  0  8  6  0  0  6  8  3  1  0  8  0
  0  6 14 15  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 17. 30.  8.  3.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  3. 11.  0.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
adversary victory points: 11
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 17. 30.  8.  3.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  3. 11.  0.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
adversary victory points: 11
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 19. 30. 17. 30.  8.  3.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  3. 11.  0.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
adversary victory points: 11
player victory points: -2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[69.01394]
 [75.07154]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  0.  1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 17. 30.  8.  3.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 8.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.864206314086914



action possibilites: [-1] 
expected returns: [[132.87775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 8.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -200    0    0
   27    0] 
sum of rewards: 232 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 72.08819580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[129.49722]
 [140.02747]
 [137.95818]
 [126.5964 ]
 [123.1095 ]
 [132.53087]
 [136.7358 ]
 [146.97319]
 [145.3813 ]
 [132.48592]
 [138.14851]
 [126.79771]
 [142.19118]
 [132.8778 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  7.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 8.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.87774658203125



buy possibilites: [-1] 
expected returns: [[64.74336]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 8.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -210    0    0
  250    0] 
sum of rewards: 445 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 146.97315979003906






Player: 1 
cards in hand: [6. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 8.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10. 29. 11. 10.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
adversary victory points: 11
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 8.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10. 29. 11. 10.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
adversary victory points: 11
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10. 10. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 11. 10.] 
expected returns: [[56.44691 ]
 [57.369137]
 [57.369137]
 [65.31523 ]
 [63.676647]
 [57.369137]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 11. 10.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11. 16.  6.  3.  6.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.  6.  3.
  3.  0.  8.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.74336242675781



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[81.85488 ]
 [77.8589  ]
 [77.8589  ]
 [74.774574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11. 16.  6.  3.  6.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.  6.  3.
  3.  0.  8.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.94315719604492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.95334 ]
 [75.564285]
 [81.85488 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 29.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
action values: 1 
buys: 1 
player value: 1 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11. 16.  6.  3.  6.] 
adversary cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.  6.  3.
  3.  0.  8.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.85488891601562






Player: 1 
cards in hand: [11. 16.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  6.  3.  6.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.  6.  3.
  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 17. 30.  8.  3.  7.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11. 11.  3.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
adversary victory points: 11
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  3.  6.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.  6.  3.
  3.  0.  8. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 17. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11. 11.  3.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
adversary victory points: 11
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3.  6.] 
cards in discard: [14.  3.  0.  6.  0.  1. 15.  0. 11. 16.  0.  6.  0.  6.  8.  0.  6.  3.
  3.  0.  8. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 18. 30. 17. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11. 11.  3.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
adversary victory points: 11
player victory points: -2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-11.143686 ]
 [ -3.8363652]
 [ -3.8363652]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  3.  1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 17. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [15.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16] -> size -> 28 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.85488891601562



action possibilites: [-1] 
expected returns: [[-14.509581]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 17. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [15.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16] -> size -> 28 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -6.630214214324951





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-17.972046]
 [ -7.678548]
 [-22.784843]
 [ -9.175814]
 [-14.509571]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 17. 30. 17. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [15.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16] -> size -> 28 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.509580612182617



buy possibilites: [-1] 
expected returns: [[-21.54587]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 16. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [15.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16] -> size -> 28 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -230    0    0
   16    0] 
sum of rewards: 221 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -7.678557395935059






Player: 1 
cards in hand: [15.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 16. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11. 10. 10. 25.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3] -> size -> 58 
adversary victory points: 12
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.  0.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 15. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11. 10. 10. 25.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3] -> size -> 58 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  0.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 17. 30. 15. 30.  8.  3.  6.  0.  6.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11. 10. 10. 25.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3] -> size -> 58 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  0.] 
cards in discard: [3. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 15. 30.  8.  3.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11. 10. 10. 25.  1.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3] -> size -> 58 
adversary victory points: 12
player victory points: -1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11. 10. 10. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 25.] 
expected returns: [[15.478167 ]
 [19.889126 ]
 [15.1323185]
 [15.1323185]
 [21.341974 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 25.  1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 15. 30.  8.  3.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8] -> size -> 30 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: -21.545869827270508



action possibilites: [-1] 
expected returns: [[-6.7250395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  1. 29.  0.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 15. 30.  8.  2.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6] -> size -> 31 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 21.341962814331055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[-10.595392 ]
 [ -3.092034 ]
 [ -4.437427 ]
 [-13.771854 ]
 [ -5.800005 ]
 [ -6.7250443]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.  1. 29.  0.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 17. 30. 15. 30.  8.  2.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6] -> size -> 31 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.725039482116699



buy possibilites: [-1] 
expected returns: [[-38.857983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.  1. 29.  0.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 16. 30. 15. 30.  8.  2.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6] -> size -> 31 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -240    0    0
   54    0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -3.0920441150665283






Player: 1 
cards in hand: [6. 6. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 1. 6.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 16. 30. 15. 30.  8.  2.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  1.  0.  1. 25.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.  1. 25. 11. 10. 10.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1] -> size -> 59 
adversary victory points: 12
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 1. 6.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 16. 30. 15. 30.  8.  2.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  1.  0.  1. 25.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.  1. 25. 11. 10. 10.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1] -> size -> 59 
adversary victory points: 12
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 1. 6.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  2.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  1.  0.  1. 25.] 
adversary cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.  1. 25. 11. 10. 10.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1] -> size -> 59 
adversary victory points: 12
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[20.759066]
 [30.068708]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  1. 25.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.  1. 25. 11. 10. 10.  1. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  2.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  6. 16.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1] -> size -> 32 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: -38.85798263549805



action possibilites: [-1] 
expected returns: [[27.283287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 1. 1. 1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.  1. 25. 11. 10. 10.  1. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  1.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  6. 16.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6] -> size -> 33 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.06871223449707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[17.563828]
 [52.94396 ]
 [11.379589]
 [45.09942 ]
 [12.374264]
 [45.981663]
 [ 7.391748]
 [25.973356]
 [41.090813]
 [79.878586]
 [73.94942 ]
 [25.724339]
 [46.354313]
 [12.691158]
 [60.466183]
 [27.28327 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 1. 1. 1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.  1. 25. 11. 10. 10.  1. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 9 
card supply: [19. 15. 30. 15. 30.  8.  1.  6.  0.  5.  6.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  6. 16.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6] -> size -> 33 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.283287048339844



buy possibilites: [-1] 
expected returns: [[-32.471455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 1. 1. 1.] 
cards in discard: [11.  3.  3.  3. 29.  3.  3. 29. 10. 29.  0.  0.  0. 25.  3.  0. 10. 10.
 11. 11.  1. 25. 11.  1.  3.  0.  1. 11. 10. 29. 10. 10. 29.  1.  3. 11.
  3. 11.  3.  1.  1. 25. 11. 10. 10.  1. 29.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 15. 30. 15. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  6. 16.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6] -> size -> 33 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[  -5.     0.     0.   420.     0.     0.    20.     0.     0.     0.
    0.  -250.     0.     0.    62.5    0. ] 
sum of rewards: 247.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 79.87857818603516






Player: 1 
cards in hand: [ 0.  0.  3.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 16.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  1.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
adversary victory points: 12
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 16.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 15. 30. 15. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  1.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
adversary victory points: 12
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 16.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 14. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  1.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
adversary victory points: 12
player victory points: -2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [29.  1.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[137.51143]
 [160.4472 ]
 [137.56519]
 [137.56519]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 14. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  6. 14.  3.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: -32.47145462036133



action possibilites: [-1. 10. 10.] 
expected returns: [[33.214283]
 [35.08527 ]
 [35.08527 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 1. 11.] 
cards in deck: 54 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 15. 30. 14. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  6. 14.  3.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 147.27357482910156



action possibilites: [-1. 10. 29.] 
expected returns: [[32.78624 ]
 [34.657215]
 [55.568638]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.] 
cards in discard: [ 1. 11.] 
cards in deck: 53 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
action values: 2 
buys: 0 
player value: 1 
card supply: [19. 15. 30. 14. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  6. 14.  3.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 35.08529281616211



action possibilites: [-1.] 
expected returns: [[29.8509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1. 11.  3. 10.] 
cards in deck: 52 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
action values: 2 
buys: 0 
player value: 2 
card supply: [19. 15. 30. 14. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  6. 14.  3.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.768497467041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.529417]
 [35.49474 ]
 [16.235174]
 [33.706364]
 [27.525963]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 11.  3. 10.] 
cards in deck: 52 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25] -> size -> 60 
action values: 2 
buys: 1 
player value: 2 
card supply: [19. 15. 30. 14. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  6. 14.  3.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
adversary victory points: -2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 420   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.850900650024414



buy possibilites: [-1] 
expected returns: [[-14.888844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 11.  3. 10.  3.] 
cards in deck: 52 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3] -> size -> 61 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 13. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  6. 14.  3.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
adversary victory points: -2
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  450    0    0   60    0    0    0    0 -260    0    0
   16    0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 35.49473571777344






Player: 1 
cards in hand: [16.  0.  6. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6. 14.  3.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 13. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  1.  3.  3. 11.] 
adversary cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3] -> size -> 61 
adversary victory points: 13
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6. 14.  3.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 15. 30. 13. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  1.  3.  3. 11.] 
adversary cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3] -> size -> 61 
adversary victory points: 13
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6. 14.  3.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 15. 30. 13. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  1.  3.  3. 11.] 
adversary cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3] -> size -> 61 
adversary victory points: 13
player victory points: -2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-15.822281]
 [ -9.777594]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3.  3. 11.] 
cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 15. 30. 13. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  8. 16.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0. 16.  0.  6. 14.  3.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.888843536376953



action possibilites: [-1] 
expected returns: [[91.040276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 13. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  8. 16.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0. 16.  0.  6. 14.  3.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  450    0    0   20    0    0    0    0 -270    0    0
   27    0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -12.703899383544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[86.21452]
 [93.57984]
 [82.99134]
 [91.87177]
 [91.04028]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1] -> size -> 62 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 14. 30. 13. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  8. 16.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0. 16.  0.  6. 14.  3.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.04027557373047



buy possibilites: [-1] 
expected returns: [[145.53603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.  3.] 
cards in deck: 47 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1  3] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 12. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  8. 16.] 
adversary cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0. 16.  0.  6. 14.  3.] 
adversary owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -280    0    0
   16    0] 
sum of rewards: 231 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 93.57981872558594






Player: 1 
cards in hand: [ 3.  8.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  8. 16.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0. 16.  0.  6. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14
 15  0  6 16  3  8  6  1  6  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 12. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1.  1.  1. 25.] 
adversary cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.  3. 11.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1  3] -> size -> 63 
adversary victory points: 14
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0. 16.  0.  6. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14 15
  0  6 16  3  8  6  1  6  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 12. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1.  1.  1. 25.] 
adversary cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.  3. 11.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1  3] -> size -> 63 
adversary victory points: 14
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0. 16.  0.  6. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14 15
  0  6 16  3  8  6  1  6  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 14. 30. 12. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1.  1.  1. 25.] 
adversary cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.  3. 11.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1  3] -> size -> 63 
adversary victory points: 14
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.] 
cards in discard: [ 3.  8. 11. 15.  6.  0.  0.  6.  1.  6.  6.  0.  1.  6.  6.  3.  0.  0.
  3.  6. 16.  0. 16.  0.  6. 14.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14 15
  0  6 16  3  8  6  1  6  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 14. 30. 12. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1.  1.  1. 25.] 
adversary cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.  3. 11.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1  3] -> size -> 63 
adversary victory points: 14
player victory points: -3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [10.  1.  1.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[195.59373]
 [196.87234]
 [219.06157]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  1.  1. 25.] 
cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.  3. 11.  3.  1.  3.  3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1  3] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 12. 30.  8.  1.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14 15
  0  6 16  3  8  6  1  6  3  0  0] -> size -> 35 
adversary victory points: -3
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 510   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 505 

action type: buy - action -1
Learning step: 0
desired expected reward: 145.53602600097656



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 2 
Gold: 0 
Estate: 11 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 5 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  1.  1.  1.  1.  1.] 
cards in discard: [ 1. 11.  3. 10.  3. 29. 10. 29.  3.  1.  3. 11.  3.  1.  3.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 11 10 29 10 11 10 25 29 10
 11  3 10 11 10 11 10  3 10 11  3 10  3  1  1  1  3  1  3  1  3  1  1  1
 25 29 25  3  1 29  1 25  1  3  1 25  3  1  3] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 12. 30.  8.  0.  6.  0.  5.  5.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [16  6  3  6 11 11  0 16  3  0  6  0  0  6  8  3  1  0  8  0  0  6 14 15
  0  6 16  3  8  6  1  6  3  0  0  6] -> size -> 36 
adversary victory points: -3
player victory points: 14 

Reward from previous game state: 
[     -5 3000000       0     510       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000525 

action type: take_action - action 25.0
Learning step: 300030.59375
desired expected reward: 300249.65625



