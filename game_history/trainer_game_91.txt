 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[286.28226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    4  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -511 

action type: buy - action -1.0
Learning step: -25.127521514892578
desired expected reward: -33.57711410522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[253.13329]
 [273.25528]
 [265.07275]
 [212.25964]
 [261.31055]
 [285.30984]
 [268.34195]
 [267.2687 ]
 [233.21268]
 [263.2378 ]
 [253.33412]
 [287.8677 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.380980491638184
desired expected reward: 279.01129150390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[322.2997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.170657634735107
desired expected reward: 280.69708251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[291.0667 ]
 [309.85687]
 [301.9342 ]
 [252.4629 ]
 [320.22717]
 [304.9941 ]
 [299.68857]
 [322.58728]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.427786827087402
desired expected reward: 316.0268859863281



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[309.80435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.203432083129883
desired expected reward: 313.38385009765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[273.83444]
 [293.51248]
 [285.0407 ]
 [248.16508]
 [234.04155]
 [281.96265]
 [303.47516]
 [289.09702]
 [316.16592]
 [287.98297]
 [254.1515 ]
 [263.62698]
 [283.44928]
 [243.33153]
 [273.55853]
 [305.64505]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.14681339263916
desired expected reward: 303.11688232421875



buy possibilites: [-1] 
expected returns: [[232.2618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 48 

action type: buy - action 25.0
Learning step: -8.182406425476074
desired expected reward: 307.9835205078125






Player: 1 
cards in hand: [ 0.  3. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[248.80234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: discard_down_to_3_cards - action 1
Learning step: -9.324263572692871
desired expected reward: 276.9678955078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[227.4205 ]
 [192.13722]
 [253.04332]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.735875129699707
desired expected reward: 240.723876953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3. 14.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3. 14.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[266.52225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -7.309642314910889
desired expected reward: 245.73373413085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[254.24788]
 [264.81705]
 [258.09933]
 [229.64696]
 [258.66064]
 [270.27048]
 [263.65027]
 [262.79758]
 [241.9162 ]
 [258.72607]
 [252.95168]
 [270.47537]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.9071173667907715
desired expected reward: 256.2052001953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  3.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  3.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[300.98752]
 [313.4414 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  3.  0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -7.137826442718506
desired expected reward: 263.3375549316406



action possibilites: [-1] 
expected returns: [[281.34436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 10 

action type: take_action - action 25.0
Learning step: -8.891345024108887
desired expected reward: 305.5404968261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[253.41591]
 [271.09872]
 [262.07977]
 [216.3986 ]
 [260.45782]
 [279.24078]
 [266.51926]
 [265.2295 ]
 [234.07993]
 [259.28986]
 [250.2251 ]
 [279.40338]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -7.6805009841918945
desired expected reward: 273.6638488769531



buy possibilites: [-1] 
expected returns: [[222.23808]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 40 

action type: buy - action 29.0
Learning step: -6.261118412017822
desired expected reward: 258.9683837890625






Player: 1 
cards in hand: [ 3. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  3.  0.] 
cards in discard: [0. 0. 0. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  3.  0.] 
cards in discard: [0. 0. 0. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  3.  0.] 
cards in discard: [0. 0. 0. 0. 0. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[238.0884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -5.80897855758667
desired expected reward: 216.42910766601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[210.91306]
 [228.45178]
 [218.98473]
 [174.4352 ]
 [235.29501]
 [224.80487]
 [216.71054]
 [233.6496 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -6.964077949523926
desired expected reward: 231.30030822753906



buy possibilites: [-1] 
expected returns: [[237.0676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -5.630731105804443
desired expected reward: 229.66429138183594






Player: 1 
cards in hand: [ 3.  6. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[285.07013]
 [295.12378]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [11.  3.  3.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: discard_down_to_3_cards - action 2
Learning step: -6.625635623931885
desired expected reward: 254.90347290039062



action possibilites: [-1] 
expected returns: [[313.96445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [11.  3.  3.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 25.0
Learning step: -6.70303201675415
desired expected reward: 287.6416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[292.47324]
 [308.05408]
 [300.7351 ]
 [260.65   ]
 [316.0869 ]
 [304.11807]
 [298.70654]
 [316.2233 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [11.  3.  3.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.916965007781982
desired expected reward: 306.0474853515625



buy possibilites: [-1] 
expected returns: [[281.83215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [11.  3.  3.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 11.0
Learning step: -7.6631178855896
desired expected reward: 308.4237060546875






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.  3.  6.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.  3.  6.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.  3.  6.  3.  3.  6. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[222.12935]
 [223.67747]
 [223.67747]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -8.657362937927246
desired expected reward: 273.1748046875



action possibilites: [-1] 
expected returns: [[229.61664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 43 

action type: gain_card_n - action 2
Learning step: -3.2479629516601562
desired expected reward: 208.03878784179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[206.41393]
 [215.0413 ]
 [170.06592]
 [219.66599]
 [228.43681]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -4.679993629455566
desired expected reward: 224.9366455078125






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[314.5501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3. 11.  0.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 14.  3.  0.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -3.3740181922912598
desired expected reward: 225.0627899169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[289.08234]
 [307.1306 ]
 [298.21588]
 [250.62796]
 [317.85632]
 [303.4124 ]
 [296.79382]
 [315.9421 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3. 11.  0.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 14.  3.  0.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -7.959622859954834
desired expected reward: 307.49920654296875



buy possibilites: [-1] 
expected returns: [[294.78918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3. 11.  0.  0. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 14.  3.  0.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 32.0 

action type: buy - action 3.0
Learning step: -6.678037166595459
desired expected reward: 291.537841796875






Player: 1 
cards in hand: [ 6. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.  0.  0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [11. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[221.25139]
 [209.76735]
 [235.11533]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.] 
cards in discard: [11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  6.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 16. 14.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16] -> size -> 18 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: discard_down_to_3_cards - action 1
Learning step: -5.698785305023193
desired expected reward: 239.48399353027344



action possibilites: [-1] 
expected returns: [[221.41843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3.] 
cards in discard: [11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  6.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 16. 14.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action 25.0
Learning step: -3.691807508468628
desired expected reward: 219.7826385498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[199.21112]
 [162.41315]
 [221.54547]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  3.] 
cards in discard: [11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  7.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  6.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 16. 14.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1
Learning step: -3.9687371253967285
desired expected reward: 217.44969177246094



buy possibilites: [-1] 
expected returns: [[141.07285]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  3.] 
cards in discard: [11.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  7.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  6.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 16. 14.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 20.0 

action type: buy - action 0.0
Learning step: -5.7864155769348145
desired expected reward: 193.42466735839844






Player: 1 
cards in hand: [14.  3.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  6.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 16. 14.  6.  3.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [11.  0.  0. 25. 29.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  6.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 16. 14.  6.  3.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  7.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [11.  0.  0. 25. 29.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  6.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 16. 14.  6.  3.  0.  0.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  7.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [11.  0.  0. 25. 29.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[156.97083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [11.  0.  0. 25. 29.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  7.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -2.083897829055786
desired expected reward: 138.98895263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[136.52913]
 [143.41791]
 [113.3801 ]
 [144.61531]
 [155.34315]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [11.  0.  0. 25. 29.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  7.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: -2.950408697128296
desired expected reward: 151.26046752929688



buy possibilites: [-1] 
expected returns: [[148.50014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [11.  0.  0. 25. 29.  0. 11.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  6.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.   20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -281.0 

action type: buy - action 6.0
Learning step: -16.37775230407715
desired expected reward: 97.0023422241211






Player: 1 
cards in hand: [ 0. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  6  0  6 14  1 16  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  6.  9.  8. 10.  9.  9.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  6.  9.  8. 10.  9.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  6.  9.  8. 10.  9.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  6.  9.  8. 10.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[183.84538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  6.  9.  8. 10.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 14.  0.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -1.8887615203857422
desired expected reward: 146.6113739013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[163.78496]
 [178.42038]
 [171.22984]
 [132.54858]
 [186.15117]
 [174.96916]
 [169.609  ]
 [187.10207]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  6.  9.  8. 10.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 14.  0.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -3.6549766063690186
desired expected reward: 177.95591735839844



buy possibilites: [-1] 
expected returns: [[160.12837]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  5.  9.  8. 10.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 14.  0.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -282.0 

action type: buy - action 6.0
Learning step: -17.124540328979492
desired expected reward: 115.42401123046875






Player: 1 
cards in hand: [ 0.  6.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 14.  0.] 
cards in discard: [15. 10. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5.  9.  8. 10.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6] -> size -> 19 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  5.  9.  8. 10.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 26. 30.  8.  5.  9.  8. 10.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [6. 3. 0. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6] -> size -> 19 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[219.9082 ]
 [219.04585]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [6. 3. 0. 3. 0. 0. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: discard_down_to_3_cards - action 1
Learning step: 1.8524563312530518
desired expected reward: 79.51924133300781



action possibilites: [-1] 
expected returns: [[245.94548]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [6. 3. 0. 3. 0. 0. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: gain_card_n - action 0
Learning step: -3.6720333099365234
desired expected reward: 188.444091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[226.0445 ]
 [189.89142]
 [250.68681]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6. 3. 0. 3. 0. 0. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -5.158059120178223
desired expected reward: 240.78741455078125






Player: 1 
cards in hand: [0. 3. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  0.  3.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  0.  3.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  0.  3.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[196.10223]
 [195.22403]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 11.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  0.  3.  0. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 14.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -7.292431831359863
desired expected reward: 243.3943328857422



action possibilites: [-1] 
expected returns: [[154.28583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  0.  3.  0. 11.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 14.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 47 

action type: gain_card_n - action 9
Learning step: -3.5932457447052
desired expected reward: 184.70028686523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.033   ]
 [143.05153 ]
 [116.709206]
 [144.0611  ]
 [153.78209 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  0.  3.  0. 11.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 14.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -2.56347918510437
desired expected reward: 151.72235107421875



buy possibilites: [-1] 
expected returns: [[165.8696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  0.  3.  0. 11.  3.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 14.] 
adversary cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 57 

action type: buy - action 3.0
Learning step: -0.5705100893974304
desired expected reward: 142.48101806640625






Player: 1 
cards in hand: [ 3.  3.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 14.] 
cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.  0.  3.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3] -> size -> 22 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.  0.  3.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0. 25.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3] -> size -> 22 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.  0.  3.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 25. 30.  8.  5.  9.  8.  9.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0. 25.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3] -> size -> 22 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [15. 10. 16.  0.  0.  0.  8. 14.  0.  6.  6.  0.  0.  0.  3.  6.  1.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  5.  9.  8.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0. 25.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3] -> size -> 22 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[61.23156]
 [51.78424]
 [67.9658 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.] 
cards in discard: [ 0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  5.  9.  8.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: discard_down_to_3_cards - action 2
Learning step: -2.5529253482818604
desired expected reward: 105.22369384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.051086]
 [32.914146]
 [60.15844 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.] 
cards in discard: [ 0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  5.  9.  8.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -0.363054484128952
desired expected reward: 59.27322006225586



buy possibilites: [-1] 
expected returns: [[98.21013]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.] 
cards in discard: [ 0. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  5.  9.  8.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: -0.24282608926296234
desired expected reward: 47.80825424194336






Player: 1 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  5.  9.  8.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  5.  9.  8.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[72.48673]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 29.  0. 10.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  5.  9.  8.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 16. 10.  6.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -1.8676576614379883
desired expected reward: 96.34246826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[54.230286]
 [66.38586 ]
 [61.7853  ]
 [33.491142]
 [71.906624]
 [62.463844]
 [58.843742]
 [71.53527 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 29.  0. 10.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  5.  9.  8.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 16. 10.  6.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -0.6383840441703796
desired expected reward: 70.15489959716797



buy possibilites: [-1] 
expected returns: [[112.88416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 29.  0. 10.  0. 25. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  5.  9.  7.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 16. 10.  6.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 47 

action type: buy - action 11.0
Learning step: 1.294562578201294
desired expected reward: 73.20117950439453






Player: 1 
cards in hand: [ 3.  0. 16. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 10.  6.] 
cards in discard: [6. 3. 0. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  5.  9.  7.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  3.  3. 11.] 
adversary cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 10.  6.] 
cards in discard: [6. 3. 0. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  5.  9.  7.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  3.  3. 11.] 
adversary cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 10.  6.] 
cards in discard: [6. 3. 0. 3. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  3.  3. 11.] 
adversary cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[60.841125]
 [61.02661 ]
 [61.02661 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3. 11.] 
cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  8.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  3. 15.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -2.8219804763793945
desired expected reward: 110.06217956542969



action possibilites: [-1] 
expected returns: [[99.34277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11.] 
cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  3. 15.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 53 

action type: gain_card_n - action 6
Learning step: 3.668691635131836
desired expected reward: 27.999103546142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[82.7816 ]
 [67.03357]
 [99.96936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 11.] 
cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  3. 15.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: -0.5032215118408203
desired expected reward: 98.83955383300781






Player: 1 
cards in hand: [ 8. 14.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  3. 15.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.  8. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  3. 15.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.  8. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.36124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.  8. 11.  3.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  1.  0. 14.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.  8. 14.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1.0
Learning step: -3.2028400897979736
desired expected reward: 96.76651763916016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 8.2367935]
 [14.950932 ]
 [12.087818 ]
 [-0.7094803]
 [17.633522 ]
 [12.887432 ]
 [10.606579 ]
 [18.57282  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [ 0. 29.  0. 10.  0. 25. 11.  0.  3.  3.  0.  0.  8. 11.  3.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  1.  0. 14.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.  8. 14.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: 1.0041704177856445
desired expected reward: 16.36540985107422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  1.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0. 14.  0.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.  8. 14.  0.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11. 11.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0. 14.  0.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.  8. 14.  0.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11. 11.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0. 14.  0.] 
cards in discard: [ 6.  3.  0.  3.  0.  0.  3.  0. 16. 10.  6.  8. 14.  0.  3. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11. 11.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 11.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[66.35915 ]
 [67.29053 ]
 [67.29053 ]
 [60.766335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.  0.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0  8] -> size -> 26 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1.0
Learning step: 1.946614146232605
desired expected reward: 20.277305603027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.18962 ]
 [37.125286]
 [65.76527 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  8.  0.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0  8] -> size -> 26 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -0.410422146320343
desired expected reward: 62.521202087402344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  6  0  6 14  1 16  6  3 15 10  8  0  8
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 25.  3.] 
adversary cards in discard: [11. 11.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 25.  3.] 
adversary cards in discard: [11. 11.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  7.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 25.  3.] 
adversary cards in discard: [11. 11.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 25.  3.] 
adversary cards in discard: [11. 11.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[51.779636]
 [57.307316]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 25.  3.] 
cards in discard: [11. 11.  8.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  5.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -1.09441339969635
desired expected reward: 64.67084503173828



action possibilites: [-1] 
expected returns: [[81.84978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0. 0.] 
cards in discard: [11. 11.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  4.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 41 

action type: take_action - action 25.0
Learning step: 1.0422247648239136
desired expected reward: 58.030128479003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[61.434235]
 [71.103836]
 [67.200554]
 [46.644073]
 [75.50692 ]
 [67.65995 ]
 [64.57879 ]
 [75.18709 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0. 0.] 
cards in discard: [11. 11.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 25. 30.  8.  4.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -0.575207531452179
desired expected reward: 81.27456665039062






Player: 1 
cards in hand: [0. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [11.  8.  0.  0.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  4.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 29.  3.  3.  0.] 
adversary cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [11.  8.  0.  0.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  4.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 29.  3.  3.  0.] 
adversary cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 25. 30.  8.  4.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 29.  3.  3.  0.] 
adversary cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[105.8568 ]
 [ 94.4712 ]
 [ 98.11703]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  3.  0.] 
cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  4.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 6. 0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1.0
Learning step: -0.017393112182617188
desired expected reward: 75.16967010498047



action possibilites: [-1. 29.] 
expected returns: [[113.22454 ]
 [104.594604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0.  0.] 
cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  4.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 6. 0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 50 

action type: take_action - action 10.0
Learning step: 0.26319772005081177
desired expected reward: 94.73442840576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 99.795876]
 [106.26666 ]
 [ 81.30035 ]
 [106.25158 ]
 [114.2014  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0.  0.] 
cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 25. 30.  8.  4.  9.  6.  6.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 6. 0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: -0.8197521567344666
desired expected reward: 112.40477752685547



buy possibilites: [-1] 
expected returns: [[9.907967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0.  0.] 
cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 6. 0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 57 

action type: buy - action 8.0
Learning step: -2.2396504878997803
desired expected reward: 104.01194763183594






Player: 1 
cards in hand: [8. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 6. 0.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.  8. 10. 29.  3.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8] -> size -> 26 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 6. 0.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.  8. 10. 29.  3.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8] -> size -> 26 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 6. 0.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.  8. 10. 29.  3.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8] -> size -> 26 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[60.866272]
 [59.68421 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3.] 
cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.  8. 10. 29.  3.  3.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 16.  0.  3.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0  0] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: 2.315765857696533
desired expected reward: 12.223731994628906



action possibilites: [-1] 
expected returns: [[70.27531]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.  8. 10. 29.  3.  3.  0.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 16.  0.  3.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0  0] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 19 

action type: gain_card_n - action 0
Learning step: 0.6304338574409485
desired expected reward: 38.6456413269043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[60.63417 ]
 [63.84771 ]
 [46.353855]
 [65.498   ]
 [70.65861 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11. 11.  8.  0.  6. 25.  3.  0.  6.  3.  0.  0.  8. 10. 29.  3.  3.  0.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 16.  0.  3.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0  0] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: 0.39558908343315125
desired expected reward: 70.6708984375






Player: 1 
cards in hand: [10. 16.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0.  3.  3.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0
  8 11  6  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8
 11  6  0  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8
 11  6  0  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8
 11  6  0  0 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [25. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[109.05977]
 [117.08574]
 [108.84187]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  4.  9.  6.  5.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  1. 14. 14. 15.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0. 16. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8
 11  6  0  0 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 0.9365119934082031
desired expected reward: 71.59512329101562



action possibilites: [-1] 
expected returns: [[72.80093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  1. 14. 14. 15.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0. 16. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8
 11  6  0  0 15  0  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 61 

action type: take_action - action 25.0
Learning step: -1.0658000707626343
desired expected reward: 114.01061248779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.798733]
 [52.40749 ]
 [49.201027]
 [32.661003]
 [47.856384]
 [56.0111  ]
 [49.98491 ]
 [49.501358]
 [38.103653]
 [47.734993]
 [44.244366]
 [58.603447]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  1. 14. 14. 15.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0. 16. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8
 11  6  0  0 15  0  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: 0.4733985960483551
desired expected reward: 73.27432250976562



buy possibilites: [-1] 
expected returns: [[69.85729]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  0.  0.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  1. 14. 14. 15.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0. 16. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8
 11  6  0  0 15  0  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 91 

action type: buy - action 15.0
Learning step: 3.8827571868896484
desired expected reward: 48.66339874267578






Player: 1 
cards in hand: [ 0.  1. 14. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14. 14. 15.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0. 16. 10.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8
 11  6  0  0 15  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  8.  0.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 14.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0. 16. 10.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11
  6  0  0 15  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  8.  0.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14. 14.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0. 16. 10.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11
  6  0  0 15  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  8.  0.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14. 14.] 
cards in discard: [11.  8.  0.  0.  0.  6.  0.  0.  3.  3.  6.  0.  0.  8.  0.  8.  6.  0.
 15.  0. 16. 10.  0.  3.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11
  6  0  0 15  0  6 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  8.  0.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[31.202623]
 [31.311998]
 [28.91216 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  8.  0.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [15.  8.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11
  6  0  0 15  0  6 10] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: -0.35012856125831604
desired expected reward: 69.50716400146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.907188]
 [28.84223 ]
 [20.211601]
 [29.246534]
 [31.981462]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  8.  0.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [15.  8.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11
  6  0  0 15  0  6 10] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: 1.5454367399215698
desired expected reward: 32.74806594848633



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  8.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11
  6  0  0 15  0  6 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  5.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
expected returns: [[30.777521]
 [24.692743]
 [23.955116]
 [30.519957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 29. 11.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [10.  0.  8. 15.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1.0
Learning step: 1.4970523118972778
desired expected reward: 33.478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.224572 ]
 [-0.7434113]
 [31.01013  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 29. 11.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 25. 30.  8.  3.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [10.  0.  8. 15.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: 1.3808997869491577
desired expected reward: 32.15842056274414



buy possibilites: [-1] 
expected returns: [[-3.856776]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 29. 11.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [10.  0.  8. 15.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -262.0 

action type: buy - action 6.0
Learning step: -13.149606704711914
desired expected reward: -13.893012046813965






Player: 1 
cards in hand: [10.  0.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 15.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6] -> size -> 29 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 15.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6] -> size -> 29 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 15.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6] -> size -> 29 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.206383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 16. 14. 11.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 2.8174827098846436
desired expected reward: -1.0392932891845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.775    ]
 [28.212452 ]
 [24.912947 ]
 [ 3.6482022]
 [32.03795  ]
 [25.510174 ]
 [22.909119 ]
 [32.01777  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 16. 14. 11.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 0.8920480608940125
desired expected reward: 33.09843063354492



buy possibilites: [-1] 
expected returns: [[17.723688]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 16. 14. 11.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 56 

action type: buy - action 10.0
Learning step: 2.053328037261963
desired expected reward: 24.96242904663086






Player: 1 
cards in hand: [ 0. 16. 14. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 14. 11.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11. 10.  3.  0.  3.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 11.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11. 10.  3.  0.  3.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 11.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11. 10.  3.  0.  3.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.422473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11. 10.  3.  0.  3.  0.  0.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: discard_down_to_3_cards - action 3
Learning step: 1.8977165222167969
desired expected reward: 8.43349838256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  2.359009]
 [-14.844087]
 [ 14.000022]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11. 10.  3.  0.  3.  0.  0.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 25. 30.  8.  2.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.3037481307983398
desired expected reward: 15.726221084594727



buy possibilites: [-1] 
expected returns: [[28.011366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [15. 25. 11.  6.  0.  0.  0.  0.  0.  3. 11.  8.  0.  6.  8.  3.  0. 29.
 11. 10.  3.  0.  3.  0.  0.  6. 10.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 25. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8] -> size -> 33 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -273.0 

action type: buy - action 6.0
Learning step: -12.277541160583496
desired expected reward: -27.12161636352539






Player: 1 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6] -> size -> 31 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 25. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6] -> size -> 31 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 24. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.957658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -0.39402103424072266
desired expected reward: 27.61734390258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 1.0646145]
 [ 3.7522948]
 [-4.5984516]
 [ 5.1691637]
 [ 8.52362  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 24. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.6130096316337585
desired expected reward: 7.570667266845703



buy possibilites: [-1] 
expected returns: [[70.56821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 24. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: 0.830234944820404
desired expected reward: 1.8948471546173096






Player: 1 
cards in hand: [0. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [0. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 24. 30.  8.  1.  9.  6.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [0. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  1.  9.  6.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [0. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[41.090534]
 [33.19571 ]
 [36.881702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0.  0.] 
cards in discard: [0. 0. 6. 3. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  1.  9.  6.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  0. 14.  6.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.  8.  0.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -1.8107150793075562
desired expected reward: 68.75749206542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.961025]
 [37.469856]
 [32.624363]
 [ 9.071316]
 [39.90782 ]
 [35.57418 ]
 [31.051311]
 [39.05487 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  0.  0.] 
cards in discard: [0. 0. 6. 3. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 24. 30.  8.  1.  9.  6.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  0. 14.  6.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.  8.  0.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.42203617095947266
desired expected reward: 40.66848373413086



buy possibilites: [-1] 
expected returns: [[44.86943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  0.  0.] 
cards in discard: [0. 0. 6. 3. 6. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 24. 30.  8.  1.  9.  6.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  0. 14.  6.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.  8.  0.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -1.0884883403778076
desired expected reward: 27.872522354125977






Player: 1 
cards in hand: [ 1.  0. 14.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 14.  6.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.  8.  0.  6.  6.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 24. 30.  8.  1.  9.  6.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11.  8.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 14.  6.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.  8.  0.  6.  6.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 24. 30.  8.  1.  9.  6.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11.  8.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0] -> size -> 33 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 14.  6.  0.] 
cards in discard: [ 8. 15.  8.  3.  3.  0. 10.  0.  8. 15.  0.  8. 14.  0. 16. 11.  0.  3.
  0.  0.  3.  0.  8.  8.  0.  6.  6.  6.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11.  8.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0] -> size -> 33 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[39.07655 ]
 [38.71879 ]
 [38.71879 ]
 [32.585117]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11.  8.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -0.539633572101593
desired expected reward: 44.329795837402344



action possibilites: [-1] 
expected returns: [[86.60002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  8.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 46 

action type: gain_card_n - action 9
Learning step: 2.2695376873016357
desired expected reward: 41.84879684448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[79.2747 ]
 [71.15317]
 [84.49964]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  8.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -0.6659755706787109
desired expected reward: 85.93404388427734



buy possibilites: [-1] 
expected returns: [[3.5553572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  8.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 7.0 

action type: buy - action 0.0
Learning step: -3.5337395668029785
desired expected reward: 75.74095916748047






Player: 1 
cards in hand: [ 0.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  8.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0] -> size -> 35 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  8.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0] -> size -> 35 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  8.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0] -> size -> 35 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  8.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0] -> size -> 35 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[22.905262]
 [31.260784]
 [17.976694]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  8.  6.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 24. 30.  8.  1.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 8.  6. 15.  6.  0.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11 10] -> size -> 37 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: 1.2739745378494263
desired expected reward: 4.829331874847412



action possibilites: [-1] 
expected returns: [[114.64086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 6. 0. 0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 24. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 8.  6. 15.  6.  0.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11 10  6] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 39 

action type: take_action - action 25.0
Learning step: 2.9663808345794678
desired expected reward: 34.22715377807617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[102.20518]
 [106.33598]
 [107.46109]
 [114.76627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 6. 0. 0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 24. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 8.  6. 15.  6.  0.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11 10  6] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -1.3994678258895874
desired expected reward: 113.24139404296875



buy possibilites: [-1] 
expected returns: [[48.807827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 6. 0. 0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 29. 30. 24. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 8.  6. 15.  6.  0.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11 10  6] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.  20. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: 6.0 

action type: buy - action 0.0
Learning step: -3.712083578109741
desired expected reward: 98.49311065673828






Player: 1 
cards in hand: [ 8.  6. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 15.  6.  0.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6
  0  0 15  0  6 10  8  0  8  3  8 11 10  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 24. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11.  6. 15.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.  0. 25.  3.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0] -> size -> 36 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 29. 30. 24. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11.  6. 15.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.  0. 25.  3.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0] -> size -> 36 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 24. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11.  6. 15.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.  0. 25.  3.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0] -> size -> 36 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 23. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11.  6. 15.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.  0. 25.  3.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0] -> size -> 36 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[37.954025]
 [37.14747 ]
 [14.859569]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 15.  0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.  0. 25.  3.  3.  8.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [14.  0. 16.  0.  8.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -0.8486712574958801
desired expected reward: 47.95915603637695



action possibilites: [-1] 
expected returns: [[-1.164592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.  0. 25.  3.  3.  8.  6.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [14.  0. 16.  0.  8.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 9
Learning step: 0.5627204775810242
desired expected reward: 39.784244537353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-6.861022 ]
 [-4.246107 ]
 [-5.64847  ]
 [-3.9678955]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0. 10.  0. 29.  0.  0. 10.  0. 11.  0.  3. 11.
  8.  0. 25.  3.  3.  8.  6.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 23. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [14.  0. 16.  0.  8.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: 1.8018625974655151
desired expected reward: 0.6372705698013306






Player: 1 
cards in hand: [14.  0. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 16.  0.  8.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  8.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 29. 30. 23. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  8.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 29. 30. 23. 30.  8.  0.  9.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  8.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[49.960873]
 [42.74119 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3. 3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: discard_down_to_3_cards - action 3
Learning step: 2.198153018951416
desired expected reward: -3.299675464630127





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[40.221596]
 [43.19871 ]
 [45.869587]
 [49.149853]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3. 3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.6061344146728516
desired expected reward: 49.35475158691406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  8.  8.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0.  6. 15.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  8.  8.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0.  6. 15.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[17.933187]
 [ 8.53239 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 15.  0.] 
cards in discard: [ 3.  3.  0.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [15. 14.  0.  3. 11.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -1.2702196836471558
desired expected reward: 47.8796501159668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[10.143463]
 [14.474866]
 [13.796102]
 [16.026419]
 [13.555688]
 [12.92401 ]
 [17.004421]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 15.  0.] 
cards in discard: [ 3.  3.  0.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [15. 14.  0.  3. 11.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.2934603691101074
desired expected reward: 18.22665023803711



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15. 14.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  0.  3. 11.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  0.  3. 11.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  0.  3. 11.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.211514]
 [22.219723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [11.  3.  0.  3.  3.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0] -> size -> 40 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: 0.5614182353019714
desired expected reward: 17.565841674804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[18.931068]
 [22.874249]
 [21.928272]
 [25.156551]
 [21.460482]
 [21.210966]
 [26.312817]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [11.  3.  0.  3.  3.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0] -> size -> 40 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.07849788665771484
desired expected reward: 26.290019989013672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  3.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0. 11.  6. 15.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0. 11.  6. 15.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0. 11.  6. 15.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[ -0.88419175]
 [ -9.270038  ]
 [ -2.96074   ]
 [-10.941394  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  6. 15.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.  0. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0] -> size -> 41 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -0.5578093528747559
desired expected reward: 25.7550106048584





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.886362 ]
 [ -2.8118725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  6. 15.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.  0. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0] -> size -> 41 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.7599738240242004
desired expected reward: -0.1242181658744812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1. 0. 0.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.  0. 11.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0
  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.  0. 11.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0
 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.  0. 11.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0
 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 23. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [10. 10.  0.  0.  6.  0.  0.  6.  3. 15.  8.  6.  6. 16. 14.  0. 16.  0.
  8.  8.  0. 10.  8.  8.  0. 15. 14.  0.  3. 11.  0. 11.  3.  0.  3.  3.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0
 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[26.505684]
 [19.48686 ]
 [23.081118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0
 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 41 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: 1.037925124168396
desired expected reward: -1.773917555809021





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[17.146841]
 [20.797255]
 [22.569214]
 [26.174818]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0
 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 41 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -0.44978952407836914
desired expected reward: 26.055892944335938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0
 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 29.  3.  6. 25.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6
 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 29.  3.  6. 25.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6
 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 29.  3.  6. 25.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[39.21732]
 [38.8175 ]
 [47.54798]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  6. 25.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [15.  6.  3.  8.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6
 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: 0.030965423211455345
desired expected reward: 26.205778121948242



action possibilites: [-1] 
expected returns: [[-21.042107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  6.  6.  0.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [15.  6.  3.  8.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6
 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 28 

action type: take_action - action 25.0
Learning step: -1.4508466720581055
desired expected reward: 46.097137451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-24.964973]
 [-19.866943]
 [-23.235945]
 [-20.907967]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  6.  6.  0.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [15.  6.  3.  8.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6
 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 1.921609878540039
desired expected reward: -19.12049674987793



buy possibilites: [-1] 
expected returns: [[-17.446796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  6.  6.  0.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [15.  6.  3.  8.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6
 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 43 

action type: buy - action 3.0
Learning step: 2.7507941722869873
desired expected reward: -17.116146087646484






Player: 1 
cards in hand: [15.  6.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  8.  0.] 
cards in discard: [8. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6
 10  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.  3. 25.  0. 29.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3] -> size -> 38 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8.] 
cards in discard: [8. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10
  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.  3. 25.  0. 29.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8.] 
cards in discard: [8. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10
  8  0  8  3  8 11 10  6  3 16  0  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  2.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.  3. 25.  0. 29.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3] -> size -> 38 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8.] 
cards in discard: [8. 0. 8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10
  8  0  8  3  8 11 10  6  3 16  0  0  3  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.  3. 25.  0. 29.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3] -> size -> 38 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[49.406914]
 [49.67821 ]
 [49.67821 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.  3. 25.  0. 29.  3.  6.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  3. 16.  8.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.] 
adversary owned cards: [ 3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10
  8  0  8  3  8 11 10  6  3 16  0  0  3  8] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: 2.8888254165649414
desired expected reward: -14.557971000671387



action possibilites: [-1] 
expected returns: [[25.516554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.  3. 25.  0. 29.  3.  6.  6.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  3. 16.  8.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.] 
adversary owned cards: [ 3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10
  8  0  8  3  8 11 10  6  3 16  0  0  3  8] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 50 

action type: gain_card_n - action 7
Learning step: 1.285499930381775
desired expected reward: 37.05794906616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.50411 ]
 [20.212645]
 [21.66797 ]
 [25.51655 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 3.  3.  0.  0. 10.  0.  0.  6. 15.  0.  8.  0.  0.  0.  3. 10.  0. 11.
  6. 15. 10.  0.  0.  3.  8.  3. 25.  0. 29.  3.  6.  6.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  3. 16.  8.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.] 
adversary owned cards: [ 3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10
  8  0  8  3  8 11 10  6  3 16  0  0  3  8] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: 1.141358733177185
desired expected reward: 26.657913208007812






Player: 1 
cards in hand: [ 6.  3. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.  8.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10
  8  0  8  3  8 11 10  6  3 16  0  0  3  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8
  0  8  3  8 11 10  6  3 16  0  0  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8
  0  8  3  8 11 10  6  3 16  0  0  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8
  0  8  3  8 11 10  6  3 16  0  0  3  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-1.5293766]
 [-7.548861 ]
 [ 0.5871453]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 10. 25.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.] 
adversary owned cards: [ 3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8
  0  8  3  8 11 10  6  3 16  0  0  3  8  0] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: 0.08923454582691193
desired expected reward: 25.605789184570312



action possibilites: [-1] 
expected returns: [[-2.685978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 10.  0. 15.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.] 
adversary owned cards: [ 3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8
  0  8  3  8 11 10  6  3 16  0  0  3  8  0] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 49 

action type: take_action - action 25.0
Learning step: 2.3602073192596436
desired expected reward: 2.947371244430542





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-3.7811174]
 [-2.5148926]
 [-2.8251648]
 [-2.1210332]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 10.  0. 15.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.] 
adversary owned cards: [ 3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8
  0  8  3  8 11 10  6  3 16  0  0  3  8  0] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: 2.4768612384796143
desired expected reward: -0.20911669731140137



buy possibilites: [-1] 
expected returns: [[16.118273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 10.  0. 15.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.] 
adversary owned cards: [ 3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8
  0  8  3  8 11 10  6  3 16  0  0  3  8  0] -> size -> 38 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0 -5  0  0  8  0] 
sum of rewards: 62 

action type: buy - action 3.0
Learning step: 3.5884056091308594
desired expected reward: 1.0735125541687012






Player: 1 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8
  0  8  3  8 11 10  6  3 16  0  0  3  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  0.  6. 10.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3] -> size -> 40 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  0.  6. 10.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  0.  6. 10.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 20. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 11.  0.  6. 10.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[25.11237 ]
 [25.292624]
 [17.451801]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  6. 10.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  0.  8.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0. 10. 16.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0] -> size -> 37 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 2.1755013465881348
desired expected reward: 18.293773651123047



action possibilites: [-1] 
expected returns: [[28.911575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 10.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0. 10. 16.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0] -> size -> 37 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0 -6  0  0 16  0] 
sum of rewards: 79 

action type: gain_card_n - action 3
Learning step: 3.6060352325439453
desired expected reward: 23.49553871154785





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.756874]
 [27.344336]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 10.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 29. 30. 20. 30.  8.  0.  7.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0. 10. 16.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0] -> size -> 37 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 2.5380420684814453
desired expected reward: 31.449617385864258



buy possibilites: [-1] 
expected returns: [[3.1347508]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 10.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0. 10. 16.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0] -> size -> 37 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  50.   0.   0.  20. -30.   0.   0.   0.  -7.   0.   0.
   0.   0.] 
sum of rewards: 32.0 

action type: buy - action 0.0
Learning step: 0.8826878666877747
desired expected reward: 16.639568328857422






Player: 1 
cards in hand: [10.  0. 10. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 16.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 15.  0. 11.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1. 10. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 16.  0. 15.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 15.  0. 11.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.  0. 15.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  5.  1.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 15.  0. 11.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.  0. 15.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  8. 15.  0. 11.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
expected returns: [[-17.046019]
 [-16.647892]
 [-14.975446]
 [-17.224045]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 15.  0. 11.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11
  8  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8. 14. 11.  3.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.] 
adversary owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0  8] -> size -> 38 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 1.935211420059204
desired expected reward: 5.069962501525879



action possibilites: [-1] 
expected returns: [[-6.106349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8
  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8. 14. 11.  3.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.] 
adversary owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0  8] -> size -> 38 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action 15.0
Learning step: 4.061379909515381
desired expected reward: -10.914066314697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.669963 ]
 [-4.663129 ]
 [-5.1990895]
 [-5.31708  ]
 [-5.230603 ]
 [-6.1131363]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8
  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8. 14. 11.  3.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.] 
adversary owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0  8] -> size -> 38 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 3.6428494453430176
desired expected reward: -2.4634995460510254



buy possibilites: [-1] 
expected returns: [[-2.3817823]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8
  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8. 14. 11.  3.  0.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.] 
adversary owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0  8] -> size -> 38 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0 -7  0  0 18  0] 
sum of rewards: 80 

action type: buy - action 1.0
Learning step: 4.154576301574707
desired expected reward: -0.5085539817810059






Player: 1 
cards in hand: [ 8. 14. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 11.  3.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 14  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8
  3  8 11 10  6  3 16  0  0  3  8  0  0  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8.  3.  0. 29.  3.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8
  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1] -> size -> 42 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8.  3.  0. 29.  3.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8
  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1] -> size -> 42 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8.  3.  0. 29.  3.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8
  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1] -> size -> 42 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8.  3.  0. 29.  3.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8
  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1] -> size -> 42 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[0.78426766]
 [1.473213  ]
 [1.3742878 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 29.  3.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8
  8  0 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  8.  3.  6.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0] -> size -> 38 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 2.598536252975464
desired expected reward: 0.21675395965576172



action possibilites: [-1] 
expected returns: [[-7.7247515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  8.  3.  6.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: trash_cards_n_from_hand - action 4
Learning step: 2.5200512409210205
desired expected reward: 6.642888069152832





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.240289]
 [-10.954226]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  8.  3.  6.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1
Learning step: 3.030708074569702
desired expected reward: -4.694043159484863



buy possibilites: [-1] 
expected returns: [[-6.3809896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  8.  3.  6.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  40   0   0  20 -30   0   0   0  -6   0   0   0   0] 
sum of rewards: 22 

action type: buy - action 0.0
Learning step: 1.5684422254562378
desired expected reward: -10.671846389770508






Player: 1 
cards in hand: [11.  0.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  3.  6.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0] -> size -> 41 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  3.  6.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0] -> size -> 41 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  3.  6.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0] -> size -> 41 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[18.103313]
 [18.448797]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  6. 10.  0.  6.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.  0. 11.  0.  8.  3.  6.] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 2.631713628768921
desired expected reward: -3.7492759227752686



action possibilites: [-1] 
expected returns: [[-11.301191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  6. 10.  0.  6.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.  0. 11.  0.  8.  3.  6.] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  40   0   0  20 -30   0   0   0  -7   0   0   0   0] 
sum of rewards: 21 

action type: gain_card_n - action 0
Learning step: 0.13689641654491425
desired expected reward: 13.313431739807129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-10.242317 ]
 [-10.957083 ]
 [ -8.9355345]
 [-10.700342 ]
 [-10.757319 ]
 [-11.349456 ]
 [ -7.639002 ]
 [ -9.633421 ]
 [ -8.934492 ]
 [-11.301191 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  9.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  6. 10.  0.  6.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.  0. 11.  0.  8.  3.  6.] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1
Learning step: 3.259284257888794
desired expected reward: -8.04190731048584



buy possibilites: [-1] 
expected returns: [[-23.833338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  6. 10.  0.  6.] 
adversary cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.  0. 11.  0.  8.  3.  6.] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0 -8  0  0 32  0] 
sum of rewards: 82 

action type: buy - action 29.0
Learning step: 4.131223201751709
desired expected reward: -7.21823263168335






Player: 1 
cards in hand: [ 1.  6. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 10.  0.  6.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.  0. 11.  0.  8.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 14.  6.  6.  3.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 10.  0.  6.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.  0. 11.  0.  8.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  5.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 14.  6.  6.  3.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 10.  0.  6.] 
cards in discard: [ 8.  0.  8. 15.  6.  3.  8.  0.  8.  6. 16.  0.  0.  8.  3.  0.  8. 10.
  0. 10. 16.  0. 15.  0.  8. 11.  3.  0.  0. 11.  0.  8.  3.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 14.  6.  6.  3.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[5.675605 ]
 [2.8318264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  6.  6.  3.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11] -> size -> 40 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 3.1993355751037598
desired expected reward: -20.634002685546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[3.4082744]
 [5.675605 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  6.  6.  3.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11] -> size -> 40 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.727948784828186
desired expected reward: 7.4035563468933105



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.  0. 14.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 6  1 16  6  3 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3
  8 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.  0. 14.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 6  1 16  6 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8
 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.  0. 14.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 6  1 16  6 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8
 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.  0. 14.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 6  1 16  6 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8
 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.  0. 14.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[2.898475  ]
 [0.64002013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.  0. 14.  6.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 6  1 16  6 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8
 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1.0
Learning step: 1.6655257940292358
desired expected reward: 7.3411335945129395





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-0.30846906]
 [ 1.9099915 ]
 [ 1.9037569 ]
 [ 0.47531486]
 [ 3.0151346 ]
 [ 0.56277657]
 [-1.8109049 ]
 [ 0.64002013]
 [-0.13342977]
 [ 2.8984745 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.  0. 14.  6.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  4.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 6  1 16  6 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8
 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.7933323383331299
desired expected reward: 4.6918044090271



buy possibilites: [-1] 
expected returns: [[24.188528]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 3. 25.  0.  3.  6. 10.  0. 15. 16.  0. 11.  3.  0.  6. 10.  1. 15.  3.
  8. 11.  0.  8. 29.  3.  0. 29. 11.  0.  0.  0.  0.  0. 14.  6.  6.  3.
 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 6  1 16  6 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8
 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 40 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  40.   0.   0.   0.   0.   0.   0.   0.  -9.   0.   0.
  4.5  0. ] 
sum of rewards: 33.5 

action type: buy - action 11.0
Learning step: 2.0684852600097656
desired expected reward: 5.083620071411133






Player: 1 
cards in hand: [0. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6 15 10  8  0  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8
 11 10  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11] -> size -> 44 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  1 16  6 15 10  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10
  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11] -> size -> 44 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  1 16  6 15 10  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10
  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11] -> size -> 44 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.915682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 15.  8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 6  1 16  6 15 10  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10
  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 1.1611764430999756
desired expected reward: 25.34970474243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[18.9954  ]
 [20.835604]
 [20.262316]
 [19.72897 ]
 [22.015755]
 [20.12725 ]
 [17.520199]
 [19.96698 ]
 [19.114876]
 [22.512123]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 15.  8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 6  1 16  6 15 10  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10
  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.312095046043396
desired expected reward: 22.523212432861328



buy possibilites: [-1] 
expected returns: [[14.104197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 15.  8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 6  1 16  6 15 10  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10
  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.   40.    0.    0.    0.    0.    0.    0.    0.  -10.
   0.    0.    4.5   0. ] 
sum of rewards: 32.5 

action type: buy - action 1.0
Learning step: 0.9005640149116516
desired expected reward: 21.736173629760742






Player: 1 
cards in hand: [ 0.  6.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 15.  8.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  1 16  6 15 10  8  0  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10
  6  3 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1] -> size -> 45 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[38.9724  ]
 [34.14634 ]
 [37.022697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.  0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [10. 11.  0.  8.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15.] 
adversary owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: 1.5398484468460083
desired expected reward: 15.644044876098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[33.521744]
 [35.912853]
 [35.736744]
 [38.412273]
 [35.545597]
 [40.369976]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.  0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [10. 11.  0.  8.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15.] 
adversary owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: 0.30635300278663635
desired expected reward: 39.27875900268555



buy possibilites: [-1] 
expected returns: [[14.2808075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.  0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [10. 11.  0.  8.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15.] 
adversary owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  30   0   0   0   0   0   0   0 -11   0   0  18   0] 
sum of rewards: 35 

action type: buy - action 10.0
Learning step: 0.29403820633888245
desired expected reward: 35.83963394165039






Player: 1 
cards in hand: [10. 11.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  8.  6.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [29.  6.  3. 11. 11.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10] -> size -> 46 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  8.  6.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [29.  6.  3. 11. 11.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10] -> size -> 46 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [29.  6.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[-18.49476 ]
 [-21.453379]
 [-18.099562]
 [-18.099562]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3. 11. 11.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  7.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [11.  8.  0.  6.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.] 
adversary owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: 0.2655147612094879
desired expected reward: 14.546321868896484



action possibilites: [-1] 
expected returns: [[58.779854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3. 11.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [11.  8.  0.  6.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.] 
adversary owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  30   0   0  20   0   0   0   0 -12   0   0  16   0] 
sum of rewards: 52 

action type: gain_card_n - action 3
Learning step: 4.9370598793029785
desired expected reward: -15.35319709777832





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.13453 ]
 [59.070854]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3. 11.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [11.  8.  0.  6.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.] 
adversary owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: 0.6989731192588806
desired expected reward: 59.47882843017578



buy possibilites: [-1] 
expected returns: [[78.39145]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3. 11.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [11.  8.  0.  6.  6.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.] 
adversary owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  30   0   0  20 -30   0   0   0 -13   0   0   0   0] 
sum of rewards: 5 

action type: buy - action 0.0
Learning step: -0.29292088747024536
desired expected reward: 45.84164810180664






Player: 1 
cards in hand: [11.  8.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  6.  6.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  6 15 10  8  8 11  6  0  0 15  0  6 10  8  0  8  3  8 11 10  6  3
 16  0  0  3  8  0  0  8  0  0 11  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [25.  1.  0. 11.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16 15 10  8  8 11  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0
  0  3  8  0  0  8  0  0 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [25.  1.  0. 11.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16 15 10  8  8 11  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0
  0  3  8  0  0  8  0  0 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [25.  1.  0. 11.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16 15 10  8  8 11  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0
  0  3  8  0  0  8  0  0 11  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [25.  1.  0. 11.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [25.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[56.51799 ]
 [61.8036  ]
 [55.845478]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 11.  0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 16. 11. 10.  8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.] 
adversary owned cards: [ 1 16 15 10  8  8 11  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0
  0  3  8  0  0  8  0  0 11  3  0] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -1.6817951202392578
desired expected reward: 76.70965576171875



action possibilites: [-1] 
expected returns: [[7.458664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0. 29. 14.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 16. 11. 10.  8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.] 
adversary owned cards: [ 1 16 15 10  8  8 11  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0
  0  3  8  0  0  8  0  0 11  3  0] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action 25.0
Learning step: -1.0223608016967773
desired expected reward: 60.781253814697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-13.463041 ]
 [ -2.0130677]
 [ -7.36697  ]
 [-11.838846 ]
 [  6.22657  ]
 [-10.2498665]
 [-16.094282 ]
 [ -9.974444 ]
 [-11.51657  ]
 [  7.4586697]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0. 29. 14.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 16. 11. 10.  8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.] 
adversary owned cards: [ 1 16 15 10  8  8 11  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0
  0  3  8  0  0  8  0  0 11  3  0] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: 1.4928277730941772
desired expected reward: 8.951491355895996






Player: 1 
cards in hand: [ 1. 16. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 11. 10.  8.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16 15 10  8  8 11  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0
  0  3  8  0  0  8  0  0 11  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 15.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3  8
  0  0  8  0  0 11  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 15.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3  8
  0  0  8  0  0 11  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 15.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[11.628453 ]
 [ 3.7427647]
 [ 4.5813923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 15.  3.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.  8. 16.] 
adversary owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3  8
  0  0  8  0  0 11  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: 0.7185789346694946
desired expected reward: 8.17724323272705





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 2.766114 ]
 [ 6.5679817]
 [11.628453 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 15.  3.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.  8. 16.] 
adversary owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3  8
  0  0  8  0  0 11  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: 0.5148327946662903
desired expected reward: 12.143279075622559



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  3  8 11 10  6  3 16  0  0  3  8
  0  0  8  0  0 11  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  3.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 3.  3.  6. 10. 15.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.  8. 16. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0
  0  8  0  0 11  3  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 3.  3.  6. 10. 15.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3. 10.  8.  0.  0.  0.  8.  3.  0.  8.  0. 15. 10. 11.  0.  8.  6.  0.
  8. 11.  6.  8. 16. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0
  0  8  0  0 11  3  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 3.  3.  6. 10. 15.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  6. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[ 9.152706  ]
 [ 0.9027531 ]
 [-0.91881204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 10. 15.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 8.  0.  8.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0
  0  8  0  0 11  3  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: 0.938471257686615
desired expected reward: 12.566917419433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.0851941]
 [10.283512 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 10. 15.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 8.  0.  8.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0
  0  8  0  0 11  3  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: 1.037117838859558
desired expected reward: 11.320631980895996



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  8.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  6. 15.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [16 15  8  8  6  0 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0
  0  8  0  0 11  3  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [16. 10.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 15  8  8  6 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0  0
  8  0  0 11  3  0 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [16. 10.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 15  8  8  6 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0  0
  8  0  0 11  3  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [16. 10.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 15  8  8  6 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0  0
  8  0  0 11  3  0 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [16. 10.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [16. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[-14.188866]
 [-18.213657]
 [-18.094286]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 8.  0.  8. 11.  8.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.] 
adversary owned cards: [16 15  8  8  6 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0  0
  8  0  0 11  3  0 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: 0.5293325781822205
desired expected reward: 10.812846183776855



action possibilites: [-1. 16.] 
expected returns: [[7.11622  ]
 [2.8514056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 8.  0.  8. 11.  8.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.] 
adversary owned cards: [16 15  8  8  6 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0  0
  8  0  0 11  3  0 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 49 

action type: take_action - action 10.0
Learning step: 3.48478627204895
desired expected reward: -14.609498023986816





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[2.4080925]
 [3.623815 ]
 [4.2139754]
 [2.8514047]
 [5.58818  ]
 [2.6979613]
 [2.6348338]
 [3.4652328]
 [3.2664776]
 [7.11622  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 8.  0.  8. 11.  8.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.] 
adversary owned cards: [16 15  8  8  6 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0  0
  8  0  0 11  3  0 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: 2.15739369392395
desired expected reward: 9.27362060546875






Player: 1 
cards in hand: [ 8.  0.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 11.  8.] 
cards in discard: [ 0. 15.  8.  8.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16 15  8  8  6 15  0  6 10  8  0  8  8 11 10  6  3 16  0  0  3  8  0  0
  8  0  0 11  3  0 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.
 10. 16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 0. 15.  8.  8.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 15  8  6 15  0  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0
  0 11  3  0 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.
 10. 16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 0. 15.  8.  8.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 15  8  6 15  0  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0
  0 11  3  0 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.
 10. 16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 15  8  6 15  0  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0
  0 11  3  0 11  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.
 10. 16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[50.48931 ]
 [41.701298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 3.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.
 10. 16.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  3. 16. 15.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8.] 
adversary owned cards: [16 15  8  6 15  0  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0
  0 11  3  0 11  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: 2.1182920932769775
desired expected reward: 9.234519004821777





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.05055]
 [50.48931]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 3.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.
 10. 16.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  3. 16. 15.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8.] 
adversary owned cards: [16 15  8  6 15  0  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0
  0 11  3  0 11  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -0.06903457641601562
desired expected reward: 50.420265197753906



buy possibilites: [-1] 
expected returns: [[35.41212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 3.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.  0. 10.  0. 11.  0. 16.  0. 11. 29.  6.  3.
 11. 25.  1.  0. 11.  0. 29. 14.  0.  0.  8. 15.  3.  3.  3.  6. 10. 15.
 10. 16.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  3. 16. 15.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8.] 
adversary owned cards: [16 15  8  6 15  0  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0
  0 11  3  0 11  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  30.   0.   0.   0. -30.   0.   0.   0. -14.   0.   0.
   0.   0.] 
sum of rewards: -16.0 

action type: buy - action 0.0
Learning step: -1.9557539224624634
desired expected reward: 37.09477996826172






Player: 1 
cards in hand: [ 0.  3. 16. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16. 15.  0.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 15  8  6 15  0  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0
  0 11  3  0 11  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0] -> size -> 49 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0  0
 11  3  0 11  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0] -> size -> 49 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0  0
 11  3  0 11  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 27. 30. 19. 30.  8.  0.  6.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0] -> size -> 49 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0  0
 11  3  0 11  0  0 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 19. 30.  8.  0.  5.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0] -> size -> 49 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-4.4289374]
 [-4.9112177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 19. 30.  8.  0.  5.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  3. 16.  8.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0.] 
adversary owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0  0
 11  3  0 11  0  0 16] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -0.47365447878837585
desired expected reward: 34.9384651184082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-5.228466 ]
 [-4.884424 ]
 [-4.585609 ]
 [-4.773912 ]
 [-5.081772 ]
 [-5.2335415]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 27. 30. 19. 30.  8.  0.  5.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  3. 16.  8.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0.] 
adversary owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0  0
 11  3  0 11  0  0 16] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: 1.5129307508468628
desired expected reward: -2.916004180908203



buy possibilites: [-1] 
expected returns: [[-31.537542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  6.] 
cards in discard: [3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  3. 16.  8.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0.] 
adversary owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0  0
 11  3  0 11  0  0 16] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  40.   0.   0.   0.   0.   0.   0.   0. -15.   0.   0.
   2.   0.] 
sum of rewards: 26.0 

action type: buy - action 3.0
Learning step: 0.8196857571601868
desired expected reward: -3.7659223079681396






Player: 1 
cards in hand: [ 6.  3. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.  8.  0.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6  3 16  0  0  3  8  0  0  8  0  0
 11  3  0 11  0  0 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  2.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 11. 15.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3] -> size -> 50 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6 16  0  0  3  8  0  0  8  0  0 11
  3  0 11  0  0 16 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  1.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 11. 15.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3] -> size -> 50 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6 16  0  0  3  8  0  0  8  0  0 11
  3  0 11  0  0 16 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  1.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 11. 15.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3] -> size -> 50 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[14.418289 ]
 [12.82579  ]
 [ 7.8380103]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11. 15.] 
cards in discard: [ 3.  0. 16.  0.  0.  6.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  1.  0.  9.  8.  7. 10.  3. 10.  6.] 
adversary cards in hand: [10. 11.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0. 11. 16.  6.  8.
  0.] 
adversary owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6 16  0  0  3  8  0  0  8  0  0 11
  3  0 11  0  0 16 11] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 4.3129072189331055
desired expected reward: -27.22463607788086



action possibilites: [-1] 
expected returns: [[-11.165083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 15.] 
cards in discard: [ 3.  0. 16.  0.  0.  6. 14.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  1.  0.  9.  8.  6. 10.  3. 10.  6.] 
adversary cards in hand: [10. 11.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0. 11. 16.  6.  8.
  0.] 
adversary owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6 16  0  0  3  8  0  0  8  0  0 11
  3  0 11  0  0 16 11] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  50   0   0  20   0   0   0   0 -16   0   0  16   0] 
sum of rewards: 69 

action type: gain_card_n - action 6
Learning step: 3.0203568935394287
desired expected reward: 6.588932991027832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-23.952383]
 [-20.499962]
 [-14.817724]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 15.] 
cards in discard: [ 3.  0. 16.  0.  0.  6. 14.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3 14] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  1.  0.  9.  8.  6. 10.  3. 10.  6.] 
adversary cards in hand: [10. 11.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0. 11. 16.  6.  8.
  0.] 
adversary owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6 16  0  0  3  8  0  0  8  0  0 11
  3  0 11  0  0 16 11] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 3.605271577835083
desired expected reward: -7.559811592102051






Player: 1 
cards in hand: [10. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0. 11.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0. 11. 16.  6.  8.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6 16  0  0  3  8  0  0  8  0  0 11
  3  0 11  0  0 16 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  1.  0.  9.  8.  6. 10.  3. 10.  6.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  6. 14. 11.  0.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3 14] -> size -> 51 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0. 11.] 
cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0. 11. 16.  6.  8.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6 16  0  0  3  8  0  0  8  0  0 11
  3  0 11  0  0 16 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  5.  1.  0.  9.  8.  6. 10.  3. 10.  6.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  6. 14. 11.  0.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3 14] -> size -> 51 
adversary victory points: 4
player victory points: -1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 2 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 0 
Workshop: 4 
Chapel: 1 
Witch: 1 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 3.  0. 16.  0.  0.  6. 14. 11.  0.  6.  0. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25 29 11 11  3  3  0  6  6  0 10  3  0 11  8  8  0
 15  6 10  6  0  0 10  0  0 15  3 14  3 16  0  1  0  0 29 11  1 10 16  0
  0  3 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 18. 30.  8.  0.  5.  1.  0.  9.  8.  6. 10.  3. 10.  6.] 
adversary cards in hand: [10. 11.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  8.  8.  6.  0.  8.  0.  8. 16. 15.  3. 16.  0. 11. 16.  6.  8.
  0.  0.] 
adversary owned cards: [16 15  8  6 15  6 10  8  0  8  8 10  6 16  0  0  3  8  0  0  8  0  0 11
  3  0 11  0  0 16 11  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5 500   4  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 549 

action type: buy - action -1.0
Learning step: 28.190887451171875
desired expected reward: 13.373153686523438



