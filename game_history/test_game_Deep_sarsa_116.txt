 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[42.6403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000125 

action type: buy - action -1
Learning step: -300018.1875
desired expected reward: -299961.5





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 43.847378]
 [ 78.43928 ]
 [ 60.186214]
 [ 33.895237]
 [ 20.997356]
 [ 69.82975 ]
 [ 81.58229 ]
 [ 62.277622]
 [141.4719  ]
 [123.567726]
 [ 34.92356 ]
 [ 75.04339 ]
 [ 46.80232 ]
 [ 40.996292]
 [ 66.93354 ]
 [ 41.964863]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.1539421081543



buy possibilites: [-1] 
expected returns: [[20.43069]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 141.47186279296875






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.3637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.43069076538086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.56323 ]
 [36.105545]
 [ 9.296416]
 [37.98144 ]
 [22.981186]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.32479476928711



buy possibilites: [-1] 
expected returns: [[13.285663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 37.981441497802734






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[29.54506]
 [39.69212]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.285662651062012



action possibilites: [-1] 
expected returns: [[23.678339]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 45.18882369995117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.898521]
 [53.93932 ]
 [37.20544 ]
 [ 4.539913]
 [56.387154]
 [39.144203]
 [25.416185]
 [21.24028 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.6783390045166



buy possibilites: [-1] 
expected returns: [[24.240816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 56.387149810791016






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [10.  0.  3.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 4.8902674]
 [57.154297 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  3.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.240816116333008



action possibilites: [-1] 
expected returns: [[49.2297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0. 0.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.12076187133789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 55.700115]
 [102.00514 ]
 [ 76.392944]
 [ 30.91795 ]
 [ 92.90487 ]
 [103.455765]
 [ 80.87836 ]
 [152.4321  ]
 [ 44.558887]
 [ 57.161423]
 [ 86.460846]
 [ 49.39687 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0. 0.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.229698181152344



buy possibilites: [-1] 
expected returns: [[33.65642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0. 0.] 
cards in discard: [11.  8.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 152.43211364746094






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11 29] -> size -> 13 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11 29] -> size -> 13 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[22.487873]
 [36.000084]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.65642166137695



action possibilites: [-1] 
expected returns: [[17.35244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 38.471466064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.525267]
 [26.91537 ]
 [ 5.779971]
 [27.646538]
 [18.491217]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.352439880371094



buy possibilites: [-1] 
expected returns: [[15.98529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 27.646533966064453






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [6. 3. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 10 10  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 25.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 3. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 25.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8] -> size -> 13 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 3. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 25.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8] -> size -> 13 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 19.964886]
 [ 55.19203 ]
 [105.80348 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 25.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.985289573669434



action possibilites: [-1] 
expected returns: [[74.151634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.  0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.72482299804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 81.288734]
 [124.41051 ]
 [100.8986  ]
 [ 68.14899 ]
 [ 47.401745]
 [115.662926]
 [125.77753 ]
 [104.681145]
 [191.67508 ]
 [174.59927 ]
 [ 68.19446 ]
 [121.07192 ]
 [ 83.158844]
 [ 77.92548 ]
 [109.51386 ]
 [ 74.37308 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.  0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.1516342163086



buy possibilites: [-1] 
expected returns: [[28.94025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.  0.] 
cards in discard: [ 8.  8.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 191.67510986328125






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 6. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6] -> size -> 16 
action values: 3 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [6. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[23.983486]
 [46.280178]
 [33.496685]
 [66.52276 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  1. 10. 10.  6.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.940250396728516



action possibilites: [-1. 11.  8.] 
expected returns: [[27.854351]
 [62.176228]
 [47.83231 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  1. 10. 10.  6.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.34067153930664



action possibilites: [-1] 
expected returns: [[43.419262]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  1. 10. 10.  6.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.6123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 53.04687 ]
 [ 84.093704]
 [ 66.387535]
 [ 31.870403]
 [ 77.44285 ]
 [ 85.478905]
 [ 69.30181 ]
 [123.35057 ]
 [ 45.06934 ]
 [ 54.796303]
 [ 73.38498 ]
 [ 49.70222 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  1. 10. 10.  6.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.41926193237305



buy possibilites: [-1] 
expected returns: [[6.382476]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25 10 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  1. 10. 10.  6.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.35057067871094






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  1. 10. 10.  6.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25 10 29] -> size -> 16 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  1. 10. 10.  6.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25 10 29] -> size -> 16 
adversary victory points: 1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[32.58627 ]
 [45.330368]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 25  8 11 29  8 25 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.382475852966309



action possibilites: [-1] 
expected returns: [[-5.4697065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 41.92720413208008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 5.3109283 ]
 [11.597188  ]
 [-8.545544  ]
 [13.360549  ]
 [-0.84061456]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  7.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.4697065353393555



buy possibilites: [-1] 
expected returns: [[-10.327256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 13.360547065734863






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  8 10 10  6  3  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 25. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8] -> size -> 15 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 25. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8] -> size -> 15 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 25. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8] -> size -> 15 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11. 25. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
expected returns: [[-3.877283]
 [ 6.613801]
 [17.66005 ]
 [17.66005 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 25.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.327256202697754



action possibilites: [-1] 
expected returns: [[1.5876973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  9.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.36563491821289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 9.087095 ]
 [20.666645 ]
 [14.952247 ]
 [ 0.4153216]
 [21.982    ]
 [15.580264 ]
 [10.125104 ]
 [ 5.6291656]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  9.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.5876972675323486



buy possibilites: [-1] 
expected returns: [[22.99191]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  3.  0.  0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 21.98200035095215






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [10.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 29.  8. 29.  0.] 
adversary cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8 11] -> size -> 16 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 29.  8. 29.  0.] 
adversary cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8 11] -> size -> 16 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [8. 3. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 29.  8. 29.  0.] 
adversary cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8 11] -> size -> 16 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 8. 29.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8. 29.] 
expected returns: [[ 4.2699957]
 [ 8.732179 ]
 [25.888819 ]
 [ 8.732179 ]
 [25.888819 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8. 29.  0.] 
cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3.  6.  0. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.991910934448242



action possibilites: [-1.  8.  8. 29.] 
expected returns: [[ 6.0626907]
 [12.1109495]
 [12.1109495]
 [33.569275 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  0.  0.] 
cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3.  6.  0. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 23.2916316986084



action possibilites: [-1.  8.  8. 10.] 
expected returns: [[28.702175]
 [36.158443]
 [36.158443]
 [29.366604]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  0. 10.] 
cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 25  8 11 29  8 25 10 29  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3.  6.  0. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.569278717041016



action possibilites: [-1] 
expected returns: [[-18.77604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3.  6.  0. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 49.71121597290039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-18.502058]
 [-12.455595]
 [-24.709856]
 [-11.874777]
 [-17.647478]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  6.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3.  6.  0. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.776039123535156



buy possibilites: [-1] 
expected returns: [[12.549058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [11. 25.  0. 11. 25.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3.  6.  0. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 16  0] 
sum of rewards: 71 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -11.87478256225586






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [ 8.  3.  6.  0. 10.  0. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8] -> size -> 14 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [ 8.  3.  6.  0. 10.  0. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8] -> size -> 14 
adversary victory points: 1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 11.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.  8.] 
expected returns: [[-4.4103875]
 [-1.7939212]
 [ 6.9584084]
 [ 1.6792262]
 [ 1.6792262]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.549057960510254



action possibilites: [-1] 
expected returns: [[-17.063332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  8.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 7.72027587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-19.28775 ]
 [-25.144085]
 [-16.104292]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  8.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.063331604003906






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  8.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  8.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  8.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  8.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [25.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11.] 
expected returns: [[-11.130241 ]
 [ 34.02863  ]
 [ -4.2890725]
 [  2.6120389]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0. 11.  0.] 
cards in discard: [10. 11. 10.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -16.10429573059082



action possibilites: [-1] 
expected returns: [[-0.9128864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0. 29.  3.] 
cards in discard: [10. 11. 10.  8.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.970129013061523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 0.38823056]
 [ 8.077621  ]
 [-8.497798  ]
 [10.246876  ]
 [-2.270678  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0. 29.  3.] 
cards in discard: [10. 11. 10.  8.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  8.  5.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.912886381149292



buy possibilites: [-1] 
expected returns: [[-31.069088]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0. 29.  3.] 
cards in discard: [10. 11. 10.  8.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 10.246882438659668






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 25. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 25. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 25. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [10. 25. 10. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 29. 25.] 
expected returns: [[-25.778938 ]
 [-24.233206 ]
 [ -5.5870686]
 [-24.233206 ]
 [ -9.55337  ]
 [ -5.5870686]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 10. 29. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.  1.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -31.069087982177734



action possibilites: [-1] 
expected returns: [[-31.28343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 25.  8.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.  1.  0.  3.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -6.783707618713379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-27.254375]
 [-29.132046]
 [-26.938211]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 29. 25.  8.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.  1.  0.  3.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -31.283430099487305






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.  1.  0.  3.  0. 10.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  8. 29.  3.] 
adversary cards in discard: [25. 10. 10. 29. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.  1.  0.  3.  0. 10.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  8. 29.  3.] 
adversary cards in discard: [25. 10. 10. 29. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [ 1. 10.  3.  0.  0.  1.  3.  6.  1.  0.  3.  0. 10.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  8. 29.  3.] 
adversary cards in discard: [25. 10. 10. 29. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
adversary victory points: 1
player victory points: -1 





Player: 0 
cards in hand: [11.  8.  8. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 29.] 
expected returns: [[ 4.3288174]
 [20.51227  ]
 [11.82469  ]
 [11.82469  ]
 [36.887844 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8. 29.  3.] 
cards in discard: [25. 10. 10. 29. 25.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -26.938207626342773



action possibilites: [-1. 11.  8.  8.] 
expected returns: [[10.341405]
 [25.447218]
 [18.112078]
 [18.112078]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  3.  0.] 
cards in discard: [25. 10. 10. 29. 25.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.645408630371094



action possibilites: [-1] 
expected returns: [[5.6355658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0.] 
cards in discard: [25. 10. 10. 29. 25.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.26991653442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.045634 ]
 [20.041723 ]
 [ 3.0086915]
 [20.478859 ]
 [12.245563 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 0.] 
cards in discard: [25. 10. 10. 29. 25.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.635565757751465



buy possibilites: [-1] 
expected returns: [[14.731191]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 0.] 
cards in discard: [25. 10. 10. 29. 25.  8.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 20.478857040405273






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 6. 1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  8.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8] -> size -> 18 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  8.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8] -> size -> 18 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 1.] 
cards in discard: [23.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 8.  8.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8] -> size -> 18 
adversary victory points: 1
player victory points: -1 





Player: 0 
cards in hand: [ 8.  8.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 11.] 
expected returns: [[-32.85205 ]
 [-26.819798]
 [-26.819798]
 [-26.819798]
 [-22.820637]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.73119068145752



action possibilites: [-1] 
expected returns: [[-11.647332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -18.163875579833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -4.4841156]
 [-20.12883  ]
 [ -6.0785913]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.647332191467285



buy possibilites: [-1] 
expected returns: [[-4.808429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 0.] 
cards in discard: [10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 75.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -4.484128952026367






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0. 10.] 
cards in discard: [23.  0.  1.  3.  6.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 8. 10. 29.  0. 29.] 
adversary cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  1.] 
cards in discard: [23.  0.  1.  3.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 8. 10. 29.  0. 29.] 
adversary cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  1.] 
cards in discard: [23.  0.  1.  3.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 8. 10. 29.  0. 29.] 
adversary cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  1.] 
cards in discard: [23.  0.  1.  3.  6.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 8. 10. 29.  0. 29.] 
adversary cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 





Player: 0 
cards in hand: [ 8. 10. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 29.] 
expected returns: [[-26.537722]
 [-14.591925]
 [-20.098366]
 [ -4.351924]
 [ -4.351924]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29.  0. 29.] 
cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.808428764343262



action possibilites: [-1.  8. 10. 29.] 
expected returns: [[-3.5133913]
 [ 2.8435566]
 [-2.82724  ]
 [19.781828 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 29.  0.] 
cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 0.47614312171936035



action possibilites: [-1.  8. 10.] 
expected returns: [[16.82243 ]
 [23.547281]
 [17.842854]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  3.] 
cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3 25 11 29  8 25 10 29  8 11  8 10  8 10  8 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 19.781829833984375



action possibilites: [-1] 
expected returns: [[-46.68675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 36.54725646972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-40.832783]
 [-24.900154]
 [-36.94513 ]
 [-48.54107 ]
 [-27.741316]
 [-33.868347]
 [-43.708645]
 [-48.484756]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  8.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -46.68674850463867



buy possibilites: [-1] 
expected returns: [[-13.841533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  8.  8.  8.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -24.900135040283203






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10. 25.  8.] 
adversary cards in discard: [10.  0. 11.  8.  8.  8.  0.  1. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1] -> size -> 18 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10. 25.  8.] 
adversary cards in discard: [10.  0. 11.  8.  8.  8.  0.  1. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1] -> size -> 18 
adversary victory points: 0
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 11. 10. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10. 25.  8.] 
expected returns: [[-29.868778 ]
 [  2.2138903]
 [-15.961197 ]
 [-22.471195 ]
 [  2.2138903]
 [-15.562889 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10. 25.  8.] 
cards in discard: [10.  0. 11.  8.  8.  8.  0.  1. 29. 29.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  5. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29] -> size -> 23 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.841532707214355



action possibilites: [-1] 
expected returns: [[-33.35455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 25.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.  0.  0.  3.  6.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.3861215114593506





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-21.521996]
 [-32.945286]
 [-31.042791]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 25.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.  0.  0.  3.  6.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -33.354549407958984



buy possibilites: [-1] 
expected returns: [[-30.962502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 25.  8.  0. 10.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.  0.  0.  3.  6.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -21.522008895874023






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.  0.  0.  3.  6.  6.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [11.  1. 10.  0. 29.] 
adversary cards in discard: [ 0. 25. 11. 10. 25.  8.  0. 10.] 
adversary owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0] -> size -> 19 
adversary victory points: 0
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [23.  0.  1.  3.  6.  1. 29. 10.  0.  6.  0. 10.  1.  0.  0.  3.  6.  6.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [11.  1. 10.  0. 29.] 
adversary cards in discard: [ 0. 25. 11. 10. 25.  8.  0. 10.] 
adversary owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0] -> size -> 19 
adversary victory points: 0
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  1. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[ 2.4606135]
 [14.936793 ]
 [ 4.201248 ]
 [23.796463 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10.  0. 29.] 
cards in discard: [ 0. 25. 11. 10. 25.  8.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -30.962501525878906



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[24.95935 ]
 [37.01836 ]
 [25.262743]
 [45.165638]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10.  0. 29.] 
cards in discard: [ 0. 25. 11. 10. 25.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.51671600341797



action possibilites: [-1. 11. 10.  8.] 
expected returns: [[1.1509049]
 [9.706388 ]
 [0.7575791]
 [4.147753 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10.  0.  8.] 
cards in discard: [ 0. 25. 11. 10. 25.  8.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 45.1656379699707



action possibilites: [-1] 
expected returns: [[2.8757637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  8.] 
cards in discard: [ 0. 25. 11. 10. 25.  8.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 13.395045280456543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.8367684]
 [14.237195 ]
 [ 9.247919 ]
 [-5.002194 ]
 [-8.512633 ]
 [ 7.150613 ]
 [18.78643  ]
 [ 8.762459 ]
 [34.136276 ]
 [27.21036  ]
 [-1.9933943]
 [11.702664 ]
 [ 3.9884012]
 [-3.03318  ]
 [11.854802 ]
 [ 5.7286177]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  8.] 
cards in discard: [ 0. 25. 11. 10. 25.  8.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  8.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.8757636547088623



buy possibilites: [-1] 
expected returns: [[8.478071]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  8.] 
cards in discard: [ 0. 25. 11. 10. 25.  8.  0. 10. 10. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 34.13626480102539






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 10.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25] -> size -> 21 
adversary victory points: 0
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25] -> size -> 21 
adversary victory points: 0
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[-1.1455286]
 [ 5.8824816]
 [ 5.8824816]
 [ 5.8824816]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29  8 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.478071212768555



action possibilites: [-1] 
expected returns: [[11.832293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 13.4528226852417





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.549365]
 [19.718323]
 [-0.305943]
 [19.712856]
 [13.976356]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 29. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.832292556762695



buy possibilites: [-1] 
expected returns: [[15.502564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 19.71831703186035






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  6.  3. 10.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29.  1.] 
adversary cards in discard: [3. 8. 0. 0. 8.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3] -> size -> 21 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  6.  3. 10.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29.  1.] 
adversary cards in discard: [3. 8. 0. 0. 8.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3] -> size -> 21 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 25. 25. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 29.] 
expected returns: [[-46.107533]
 [-25.971104]
 [-25.971104]
 [-25.971104]
 [-28.497078]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25. 29.  1.] 
cards in discard: [3. 8. 0. 0. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  4. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 29.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.502564430236816



action possibilites: [-1] 
expected returns: [[14.117097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  1.  8.  0.] 
cards in discard: [3. 8. 0. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 29.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -27.37360954284668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 9.17742  ]
 [19.666145 ]
 [15.162667 ]
 [ 0.7441809]
 [23.060244 ]
 [15.195071 ]
 [11.110504 ]
 [11.581953 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 29.  1.  8.  0.] 
cards in discard: [3. 8. 0. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  8.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 29.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.117096900939941



buy possibilites: [-1] 
expected returns: [[0.9626334]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 29.  1.  8.  0.] 
cards in discard: [ 3.  8.  0.  0.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 29.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 23.060239791870117






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 29.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11] -> size -> 22 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 1.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11] -> size -> 22 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 1.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11] -> size -> 22 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 1.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11] -> size -> 22 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [ 8.  0. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29. 10.] 
expected returns: [[19.336023]
 [28.44981 ]
 [31.055725]
 [41.35359 ]
 [23.256561]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 29. 10.] 
cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10. 23.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.9626333713531494



action possibilites: [-1.  8. 11. 10. 10.] 
expected returns: [[-11.86132   ]
 [  0.29000688]
 [  0.84099555]
 [ -5.4659176 ]
 [ -5.4659176 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 10. 10.] 
cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10. 23.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.35356521606445



action possibilites: [-1] 
expected returns: [[-19.497911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10. 23.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 9.449254035949707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-19.69891 ]
 [-14.790056]
 [-25.635208]
 [-14.157803]
 [-21.363325]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  3.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10. 23.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.49791145324707



buy possibilites: [-1] 
expected returns: [[17.844965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [ 3.  8.  0.  0.  8. 11. 25. 25. 25. 29.  1.  8.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  2.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10. 23.] 
adversary cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -14.157776832580566






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  6. 10. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 10. 23.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  2.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8] -> size -> 24 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 10.  1.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  2.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8] -> size -> 24 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 10.  1.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14] -> size -> 26 
action values: 0 
buys: 2 
player value: 4 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  2.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8] -> size -> 24 
adversary victory points: 1
player victory points: -3 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 10.  1.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8] -> size -> 24 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 10.  1.] 
cards in discard: [ 0.  6.  3. 10.  6.  3.  3.  0.  0.  0.  6. 14. 29.  0.  0.  0.  6.  1.
  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8] -> size -> 24 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [ 3. 11. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[30.440132]
 [47.341713]
 [28.10088 ]
 [47.341713]
 [28.10088 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  7.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 8.  1. 14.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0] -> size -> 28 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.8449649810791



action possibilites: [-1] 
expected returns: [[31.629433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  7.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  1. 14.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0] -> size -> 28 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.52385330200195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.380219]
 [13.977649]
 [32.52328 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 10.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  7.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  1. 14.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0] -> size -> 28 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.629432678222656






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 8.  1. 14.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 14.  6.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  7.  9.  9.  1. 10. 10.] 
adversary cards in hand: [25.  0. 10.  8.  8.] 
adversary cards in discard: [10. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10] -> size -> 25 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 14.  6.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  7.  9.  9.  1. 10. 10.] 
adversary cards in hand: [25.  0. 10.  8.  8.] 
adversary cards in discard: [10. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10] -> size -> 25 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 14.  6.  1.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [25.  0. 10.  8.  8.] 
adversary cards in discard: [10. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10] -> size -> 25 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [25.  0. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8.  8.] 
expected returns: [[29.677685]
 [44.72508 ]
 [21.618925]
 [19.670547]
 [19.670547]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10.  8.  8.] 
cards in discard: [10. 11.  3. 10. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  3. 10.  7.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 29.  3.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29] -> size -> 29 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.52330017089844



action possibilites: [-1] 
expected returns: [[34.096333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  8.  0.  0.] 
cards in discard: [10. 11.  3. 10. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  2. 10.  7.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 29.  3.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 44.7250862121582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.369476]
 [45.27752 ]
 [39.324223]
 [17.166176]
 [49.534763]
 [39.198013]
 [33.136288]
 [34.236805]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  8.  0.  0.] 
cards in discard: [10. 11.  3. 10. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 28. 30.  8.  2. 10.  7.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 29.  3.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.09633255004883



buy possibilites: [-1] 
expected returns: [[7.103875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  8.  0.  0.] 
cards in discard: [10. 11.  3. 10. 11. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  2. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 29.  3.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6] -> size -> 30 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 49.53477096557617






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 29.  3.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  2. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 29.  0. 25.  8.] 
adversary cards in discard: [10. 11.  3. 10. 11. 10. 11. 25.  0. 10.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 29.  3.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  2. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 29.  0. 25.  8.] 
adversary cards in discard: [10. 11.  3. 10. 11. 10. 11. 25.  0. 10.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 29.  0. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25.  8.] 
expected returns: [[-8.446353 ]
 [-3.8879788]
 [17.787216 ]
 [25.080452 ]
 [-3.8879788]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 25.  8.] 
cards in discard: [10. 11.  3. 10. 11. 10. 11. 25.  0. 10.  8.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  2. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6] -> size -> 30 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.103875160217285



action possibilites: [-1] 
expected returns: [[12.873488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  8. 10. 29.] 
cards in discard: [10. 11.  3. 10. 11. 10. 11. 25.  0. 10.  8.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  1. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.080453872680664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 2.6886613]
 [-6.2028217]
 [11.8058815]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  8. 10. 29.] 
cards in discard: [10. 11.  3. 10. 11. 10. 11. 25.  0. 10.  8.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  1. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6] -> size -> 31 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.873488426208496






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  6.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  1. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [11. 25.  1.  8. 10.] 
adversary cards in discard: [10. 11.  3. 10. 11. 10. 11. 25.  0. 10.  8.  8.  0.  0. 25.  8. 29.  0.
  8. 10. 29.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  6.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  1. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [11. 25.  1.  8. 10.] 
adversary cards in discard: [10. 11.  3. 10. 11. 10. 11. 25.  0. 10.  8.  8.  0.  0. 25.  8. 29.  0.
  8. 10. 29.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 25.  1.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8. 10.] 
expected returns: [[25.985252]
 [38.111706]
 [51.033123]
 [33.772205]
 [28.324558]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  1.  8. 10.] 
cards in discard: [10. 11.  3. 10. 11. 10. 11. 25.  0. 10.  8.  8.  0.  0. 25.  8. 29.  0.
  8. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  1. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6] -> size -> 31 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.805892944335938



action possibilites: [-1] 
expected returns: [[-18.102283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  8. 10.  8. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6] -> size -> 32 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 51.03312301635742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-25.33722 ]
 [-21.29113 ]
 [-22.00176 ]
 [-19.445087]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  8. 10.  8. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6] -> size -> 32 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.102283477783203






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [3. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29. 29.  0. 25.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29. 29.  0. 25.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29. 29.  0. 25.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -5 





Player: 0 
cards in hand: [11. 29. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 25.] 
expected returns: [[23.55406 ]
 [32.87478 ]
 [37.232124]
 [37.232124]
 [48.3166  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  0. 25.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 23.  1.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.  3.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6  3] -> size -> 33 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -19.445072174072266



action possibilites: [-1] 
expected returns: [[5.4012575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  0.  8. 25.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 23.  1.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.  3.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6  3] -> size -> 33 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.31657791137695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.0788069]
 [ 5.459996 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 29.  0.  8. 25.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 23.  1.] 
adversary cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.  3.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6  3] -> size -> 33 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.401257514953613






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0. 23.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 23.  1.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.  3.  6.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 10.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -5 


action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 23.  1.  6.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.  3.  6.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 10.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -5 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 6. 0.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.  3.  6.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 10 10  3  6  1  6  0  1  6  1  6  0 23 29  6
  6 14  8  0 29  6  6  6  3] -> size -> 33 
action values: 2 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 10.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.  3.  6.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23.  8.] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3] -> size -> 30 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 10.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  8.  1. 14.  6.  1.  6.  0.  6.  0. 29.  3.  6.  3.  0.  0. 10.  6.
  6.  3.  3.  6.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 23.  8.] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3] -> size -> 30 
action values: 0 
buys: 2 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 10.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [ 0. 10. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[24.65271 ]
 [23.642582]
 [23.642582]
 [23.642582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0. 10.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3] -> size -> 30 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 5.459988594055176





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[20.058237]
 [29.52966 ]
 [29.452526]
 [24.314432]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0. 10.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3] -> size -> 30 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.65270233154297



buy possibilites: [-1] 
expected returns: [[11.454513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0. 10.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3] -> size -> 30 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: 191 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 29.529659271240234






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  8.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.  3.  0. 10. 10.
  0. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3] -> size -> 27 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 26. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  8.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.  3.  0. 10. 10.
  0. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3] -> size -> 27 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  8.] 
adversary cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.  3.  0. 10. 10.
  0. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3] -> size -> 27 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [11. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[19.375288]
 [35.198307]
 [20.57619 ]
 [26.097397]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3.  8.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.  3.  0. 10. 10.
  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [29. 14.  6.  0.  0.] 
adversary cards in discard: [3. 3. 6. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3] -> size -> 31 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.454512596130371



action possibilites: [-1] 
expected returns: [[38.535805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  8.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.  3.  0. 10. 10.
  0. 10. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  9.] 
adversary cards in hand: [29. 14.  6.  0.  0.] 
adversary cards in discard: [3. 3. 6. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3] -> size -> 31 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.51202392578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.670292]
 [38.5669  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  8.] 
cards in discard: [25. 11.  1.  8. 10.  8. 10. 25. 11. 29. 29.  0.  8. 25.  3.  0. 10. 10.
  0. 10. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  9.] 
adversary cards in hand: [29. 14.  6.  0.  0.] 
adversary cards in discard: [3. 3. 6. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3] -> size -> 31 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.535804748535156






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [29. 14.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  6.  0.  0.] 
cards in discard: [3. 3. 6. 6. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  9.] 
adversary cards in hand: [25. 10.  8. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15] -> size -> 28 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  0.] 
cards in discard: [3. 3. 6. 6. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  9.] 
adversary cards in hand: [10. 11.  8.] 
adversary cards in discard: [25.  8.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15] -> size -> 28 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.  0.] 
cards in discard: [3. 3. 6. 6. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  9.] 
adversary cards in hand: [10. 11.  8.] 
adversary cards in discard: [25.  8.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15] -> size -> 28 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.  0.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  8.] 
adversary cards in hand: [10. 11.  8.] 
adversary cards in discard: [25.  8.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15] -> size -> 28 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[33.11559 ]
 [29.436962]
 [51.23647 ]
 [36.582684]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.] 
cards in discard: [25.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  8.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3 15] -> size -> 32 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: discard_down_to_3_cards - action 3
Learning step: 0
desired expected reward: 178.17608642578125



action possibilites: [-1] 
expected returns: [[22.870037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [25.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3 15] -> size -> 32 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 57.28550338745117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.536547]
 [23.185202]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [25.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3 15] -> size -> 32 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.870037078857422






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8
  0 29  6  6  6  3  3 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  8. 11. 10.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15] -> size -> 29 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  8. 11. 10.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15] -> size -> 29 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  8. 11. 10.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15] -> size -> 29 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [ 1. 10.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 10.] 
expected returns: [[33.431885]
 [17.620886]
 [19.398148]
 [42.681313]
 [17.620886]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  8. 11. 10.] 
cards in discard: [25.  8. 15. 11. 10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  7.] 
adversary cards in hand: [ 1.  6.  3.  6. 10.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.185195922851562



action possibilites: [-1] 
expected returns: [[58.96372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  8. 10.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  6.] 
adversary cards in hand: [ 1.  6.  3.  6. 10.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.22262954711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[36.846283]
 [56.588966]
 [53.478413]
 [58.552303]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  8. 10.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  6.] 
adversary cards in hand: [ 1.  6.  3.  6. 10.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.96371841430664






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 1.  6.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  3.  6. 10.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  6.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  3.  6. 10.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  6.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[72.55671 ]
 [84.42928 ]
 [75.054825]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  8.  0.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  6.] 
adversary cards in hand: [ 0.  1.  6. 23.  3.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.552303314208984



action possibilites: [-1] 
expected returns: [[49.04994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  5.] 
adversary cards in hand: [ 0.  1.  6. 23.  3.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 90.15402221679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[42.574738]
 [53.25495 ]
 [52.993122]
 [48.106815]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  5.] 
adversary cards in hand: [ 0.  1.  6. 23.  3.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.0499382019043



buy possibilites: [-1] 
expected returns: [[0.03916097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  5.] 
adversary cards in hand: [ 0.  1.  6. 23.  3.] 
adversary cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 241 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 53.25494384765625






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  6. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6. 23.  3.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  5.] 
adversary cards in hand: [25.  8. 10. 10.  0.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  5.] 
adversary cards in hand: [25.  8. 10. 10.  0.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15] -> size -> 29 
action values: 0 
buys: 2 
player value: 5 
card supply: [24. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1. 10.  5.] 
adversary cards in hand: [25.  8. 10. 10.  0.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
adversary victory points: 3
player victory points: -4 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [25.  8. 10. 10.  0.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [ 3.  3.  6.  6.  0.  0. 15. 14. 29.  6.  0.  0.  8.  8.  1.  6.  3.  6.
 10. 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [25.  8. 10. 10.  0.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [25.  8. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10. 10.] 
expected returns: [[48.68936 ]
 [77.793434]
 [45.061787]
 [41.427776]
 [41.427776]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 10. 10.  0.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [14.  6.  6. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.039160966873168945



action possibilites: [-1] 
expected returns: [[89.85036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  0. 29. 10.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [14.  6.  6. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.79347229003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[74.4068 ]
 [95.15367]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.  0. 29. 10.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [14.  6.  6. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.85035705566406






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [14.  6.  6. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  6. 29. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [15. 25. 11. 29.  3.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0. 25.  8. 10. 10.  0. 29. 10.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [15. 29.  3.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0. 25.  8. 10. 10.  0. 29. 10. 25. 11.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 29. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [15. 29.  3.] 
adversary cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0. 25.  8. 10. 10.  0. 29. 10. 25. 11.] 
adversary owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [15. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[40.563564]
 [49.74614 ]
 [75.919914]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0. 25.  8. 10. 10.  0. 29. 10. 25. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [ 8.  3.  3. 23.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0 807   0] 
sum of rewards: 1012 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -20.846433639526367



action possibilites: [-1. 15.] 
expected returns: [[29.80334 ]
 [31.125355]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0. 25.  8. 10. 10.  0. 29. 10. 25. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8
 10 11  3 15 15 15 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [ 8.  3.  3. 23.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.414649963378906



action possibilites: [-1] 
expected returns: [[9.810772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0. 25.  8. 10. 10.  0. 29. 10. 25. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [ 8.  3.  3. 23.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 31.125354766845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 1.7795174 ]
 [14.405076  ]
 [10.190356  ]
 [ 8.918705  ]
 [21.921871  ]
 [ 9.211792  ]
 [27.33636   ]
 [ 0.14141822]
 [ 5.3715296 ]
 [12.949794  ]
 [ 9.763032  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0. 25.  8. 10. 10.  0. 29. 10. 25. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  6.  9.  9.  1.  9.  5.] 
adversary cards in hand: [ 8.  3.  3. 23.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.810771942138672



buy possibilites: [-1] 
expected returns: [[56.7374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  8. 15. 11. 10.  8. 15. 11.  1. 10.  8. 10. 15.  3. 11.  3.  0.  8.
  0. 25.  8. 10. 10.  0. 29. 10. 25. 11.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  5.] 
adversary cards in hand: [ 8.  3.  3. 23.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 373 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.336366653442383






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  3. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 23.  0.] 
cards in discard: [14.  6.  6. 29. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  5.] 
adversary cards in hand: [29. 11.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29] -> size -> 32 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3. 23.  0.] 
cards in discard: [14.  6.  6. 29. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  5.] 
adversary cards in hand: [29. 11.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29] -> size -> 32 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 11.  8. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8. 10. 29.] 
expected returns: [[12.647819]
 [40.348843]
 [28.803543]
 [18.761162]
 [11.942999]
 [40.348843]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  8. 10. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  5.] 
adversary cards in hand: [ 8. 15.  6.  1.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.73740005493164



action possibilites: [-1. 11.  8. 10.  8.] 
expected returns: [[ 1.5019672]
 [10.223532 ]
 [ 3.9266322]
 [ 0.7422197]
 [ 3.9266322]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10.  8.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  5.] 
adversary cards in hand: [ 8. 15.  6.  1.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.202709197998047



action possibilites: [-1] 
expected returns: [[37.362247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.] 
cards in discard: [29. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 8. 15.  6.  1.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 309 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 13.767584800720215





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.257607]
 [37.33086 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.] 
cards in discard: [29. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 8. 15.  6.  1.  0.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.] 
adversary owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.362247467041016






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  6.  1.  0.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6
  6  6  3  3 15 22  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3. 25. 11. 10. 10.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 1.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3. 25. 11. 10. 10.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 1.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3. 25. 11. 10. 10.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 1.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3. 25. 11. 10. 10.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 25. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10. 10.] 
expected returns: [[27.877459]
 [71.06764 ]
 [45.421524]
 [23.694046]
 [23.694046]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11. 10. 10.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 0. 22. 29.  0. 10.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.330867767333984



action possibilites: [-1] 
expected returns: [[61.05353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10.  0.  1.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 0. 22. 29.  0. 10.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.067626953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[49.3854  ]
 [67.440636]
 [62.07626 ]
 [72.736336]
 [61.67426 ]
 [55.409584]
 [59.21189 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10. 10.  0.  1.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  6.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 0. 22. 29.  0. 10.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.053531646728516



buy possibilites: [-1] 
expected returns: [[6.4753485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10. 10.  0.  1.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 0. 22. 29.  0. 10.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 72.73633575439453






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0. 22. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29. 10.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 29.  0. 10.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [11. 25.  8. 11. 10.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10.  3.  6.  6.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [11. 25.  8. 11. 10.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 10.  3.  6.  6.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  1.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [11. 25.  8. 11. 10.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 10.  3.  6.  6.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [11. 25.  8. 11. 10.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [11. 25.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8. 11. 10.] 
expected returns: [[16.298285]
 [24.95275 ]
 [35.07961 ]
 [20.156483]
 [24.95275 ]
 [16.656162]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  8. 11. 10.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.  8. 22.  0.
 29.  0. 10.  3.  6.  6.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.475348472595215



action possibilites: [-1] 
expected returns: [[1.3885128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11. 10.  3. 15.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.  8. 22.  0.
 29.  0. 10.  3.  6.  6.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.0796012878418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.151004 ]
 [ 1.1367824]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 11. 10.  3. 15.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.  8. 22.  0.
 29.  0. 10.  3.  6.  6.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.3885128498077393






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [6. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.  8. 22.  0.
 29.  0. 10.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 8. 15.  0. 15. 25.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.  8. 22.  0.
 29.  0. 10.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 24. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 8. 15.  0. 15. 25.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [14.  6.  6. 29. 10.  8.  3.  3. 23.  0.  4. 15.  8.  6.  1.  8. 22.  0.
 29.  0. 10.  3.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 8. 15.  0. 15. 25.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 8. 15.  0. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 15. 25.] 
expected returns: [[ 8.349712]
 [15.638068]
 [18.482094]
 [18.482094]
 [45.06959 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 15. 25.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [4. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.1367828845977783



action possibilites: [-1] 
expected returns: [[32.980694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 15. 10.  0.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [4. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 45.069602966308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.17942 ]
 [36.67359 ]
 [33.092587]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0. 15. 10.  0.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 23. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [4. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.98069381713867



buy possibilites: [-1] 
expected returns: [[52.6217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0. 15. 10.  0.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [4. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3] -> size -> 33 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 36.673583984375






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [4. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3. 10. 15. 29.  8.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.  3. 25.  8. 15.  0. 15. 10.  0.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  5.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3. 10. 15. 29.  8.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.  3. 25.  8. 15.  0. 15. 10.  0.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 0. 1.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3. 10. 15. 29.  8.] 
adversary cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.  3. 25.  8. 15.  0. 15. 10.  0.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 3. 10. 15. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.  8.] 
expected returns: [[14.24545 ]
 [10.123613]
 [17.235878]
 [31.822166]
 [13.814296]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15. 29.  8.] 
cards in discard: [29. 15. 29. 11.  8. 10.  8. 11. 25.  3. 11. 10. 10.  0.  1. 25. 11.  8.
 11. 10.  3. 15.  3. 25.  8. 15.  0. 15. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [29.  6.  8. 10.  0.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29] -> size -> 34 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.621700286865234



action possibilites: [-1. 10. 15.] 
expected returns: [[32.52916 ]
 [28.280333]
 [36.876186]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.] 
cards in discard: [8. 8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [29.  6.  8. 10.  0.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29] -> size -> 34 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.962154388427734



action possibilites: [-1] 
expected returns: [[65.26121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [8. 8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [29.  6.  8. 10.  0.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29] -> size -> 34 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 36.87618637084961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[53.243225]
 [64.61732 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [8. 8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [29.  6.  8. 10.  0.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29] -> size -> 34 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.2612075805664






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [29.  6.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  8. 10.  0.] 
cards in discard: [29.  4.  0.  3.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [11. 10. 25.  0. 11.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [11. 10. 25.  0. 11.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [11. 10. 25.  0. 11.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [11. 10. 25.  0. 11.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [11. 10. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25. 11.] 
expected returns: [[ 3.4349945]
 [15.50188  ]
 [ 6.827116 ]
 [31.548111 ]
 [15.50188  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 25.  0. 11.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 6.  3. 10. 15.  6.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.61731719970703



action possibilites: [-1] 
expected returns: [[18.376677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11. 25.  0.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 6.  3. 10. 15.  6.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.548118591308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[13.301274]
 [20.0983  ]
 [18.776556]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 11. 25.  0.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 22. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 6.  3. 10. 15.  6.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.376676559448242



buy possibilites: [-1] 
expected returns: [[60.265446]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 11. 25.  0.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 6.  3. 10. 15.  6.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 20.09831428527832






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 6.  3. 10. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10. 15.  6.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [10.  8. 11.  8. 10.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.  6.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [10.  8. 11.  8. 10.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  6.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [10.  8. 11.  8. 10.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [10.  8. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.  8. 10.] 
expected returns: [[28.260277]
 [28.231932]
 [31.933044]
 [34.884422]
 [31.933044]
 [28.231932]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  8. 10.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [29.  6.  8.  3. 22.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.265445709228516



action possibilites: [-1] 
expected returns: [[-4.4377165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8. 10.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [29.  6.  8.  3. 22.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 172 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 34.7253303527832





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 8.112958]
 [-3.070351]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8. 10.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [29.  6.  8.  3. 22.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.437716484069824



buy possibilites: [-1] 
expected returns: [[19.038725]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8. 10.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [29.  6.  8.  3. 22.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.] 
adversary owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -30   0   0   0   0] 
sum of rewards: 135 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 8.112955093383789






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [29.  6.  8.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  8.  3. 22.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8 10 10  3  6  0  1  6  1  6  0 23 29  6  6 14  8  0 29  6  6
  6  3  3 15 22  0  4  8  3 29  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3.  3. 15. 10.  1.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3.  3. 15. 10.  1.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3.  3. 15. 10.  1.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 3.  3. 15. 10.  1.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 3.  3. 15. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[94.14046 ]
 [98.582504]
 [85.33867 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 10.  1.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 6.  0.  3.  6. 14.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.  8.] 
adversary owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.038724899291992



action possibilites: [-1] 
expected returns: [[90.01211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  1.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 6.  0.  3.  6. 14.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.  8.] 
adversary owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 98.58250427246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[74.08872 ]
 [88.386665]
 [86.46552 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  1.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 21. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 6.  0.  3.  6. 14.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.  8.] 
adversary owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.0121078491211



buy possibilites: [-1] 
expected returns: [[132.16463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  1.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 6.  0.  3.  6. 14.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.  8.] 
adversary owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 88.38668060302734






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  3.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 14.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [ 0. 15. 29. 10. 11.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.  3. 15.  3.  3. 10.  1.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0  3] -> size -> 39 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 20. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [15. 29. 10.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.  3. 15.  3.  3. 10.  1.  0. 11.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0  3] -> size -> 39 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 20. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  1.  9.  4.] 
adversary cards in hand: [15. 29. 10.] 
adversary cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.  3. 15.  3.  3. 10.  1.  0. 11.] 
adversary owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0  3] -> size -> 39 
adversary victory points: 6
player victory points: 0 


Player 0 won the game! 



Player 0 bought cards:
Copper: 3 
Silver: 1 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 7 
Witch: 3 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 29. 10.] 
cards in discard: [ 8.  8. 29. 15.  3. 10.  3. 25. 11. 10.  0. 11. 25.  0.  1.  0. 11. 10.
  8.  8. 10.  3. 15.  3.  3. 10.  1.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 25 11 29 25 29  8 11  8 10  8 10  8 10  0  1  0 10 25  3 11 10  8 10
 11  3 15 15 15 15  3 29 15 11  3  3  1  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 29.  8.  0. 10.  5.  0.  7.  4.  9.  9.  0.  9.  4.] 
adversary cards in hand: [6. 0. 3. 6.] 
adversary cards in discard: [29.  4.  0.  3.  0.  1.  6.  1.  0. 29.  8. 10.  0. 15.  6.  3. 10.  6.
  0.  8. 10.] 
adversary owned cards: [ 0  0  8 10 10  3  0  1  6  1  6  0 23  6  6 14  8  0 29  6  6  6  3  3
 15  0  4  8  3 29  0  0 10] -> size -> 33 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0     -40       0       0     970       0] 
sum of rewards: 3001105 

action type: discard_down_to_3_cards - action 9
Learning step: 300101.59375
desired expected reward: 300190.8125



