 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[329.07657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    2  -20    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -523 

action type: buy - action -1
Learning step: -28.88722801208496
desired expected reward: 25.85734748840332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[309.2208 ]
 [313.57227]
 [313.93088]
 [307.3215 ]
 [313.20953]
 [319.15848]
 [314.3808 ]
 [320.6659 ]
 [312.5491 ]
 [314.73944]
 [316.96817]
 [328.80542]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.522431373596191
desired expected reward: 321.1084899902344



buy possibilites: [-1] 
expected returns: [[305.66748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -24.1385555267334
desired expected reward: 283.18292236328125






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [6. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [6. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [6. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.58945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [6. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.449485778808594
desired expected reward: 297.2179870605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[320.20224]
 [324.03632]
 [324.29785]
 [318.4899 ]
 [328.86417]
 [324.71356]
 [324.97513]
 [337.29602]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [6. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.948599815368652
desired expected reward: 322.66864013671875



buy possibilites: [-1] 
expected returns: [[322.55515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [6. 0. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -10.902620315551758
desired expected reward: 309.2995910644531






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 0] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 0] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8.  3.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 0] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.52295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -9.775372505187988
desired expected reward: 312.77978515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[286.13718]
 [290.94986]
 [291.34116]
 [284.03217]
 [290.54404]
 [297.1125 ]
 [291.83453]
 [298.77982]
 [289.8035 ]
 [292.22586]
 [294.6902 ]
 [307.78983]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.60525131225586
desired expected reward: 301.61187744140625



buy possibilites: [-1] 
expected returns: [[316.01764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 19 

action type: buy - action 14.0
Learning step: -6.429778575897217
desired expected reward: 283.37371826171875






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14] -> size -> 13 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[336.22263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.83299446105957
desired expected reward: 307.18463134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[314.7948 ]
 [319.77307]
 [320.17413]
 [312.6154 ]
 [319.35504]
 [326.1466 ]
 [320.6904 ]
 [327.8789 ]
 [318.58783]
 [321.0915 ]
 [323.64294]
 [337.1973 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.322456359863281
desired expected reward: 328.2503662109375



buy possibilites: [-1] 
expected returns: [[346.2959]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -8.5 

action type: buy - action 1.0
Learning step: -8.621996879577637
desired expected reward: 311.15106201171875






Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.4338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -11.02635383605957
desired expected reward: 335.26953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[286.79657]
 [290.71478]
 [291.01187]
 [285.06854]
 [296.11194]
 [291.41824]
 [291.71527]
 [305.8472 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.477991104125977
desired expected reward: 298.89715576171875



buy possibilites: [-1] 
expected returns: [[318.22098]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 3.0
Learning step: -7.390620708465576
desired expected reward: 283.6212158203125






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [3. 0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [3. 0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [3. 0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [3. 0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[398.19766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [3. 0. 0. 0. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 10.  0.  3.  0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.995811462402344
desired expected reward: 311.22515869140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[373.76846]
 [378.6489 ]
 [379.02808]
 [372.10977]
 [371.6231 ]
 [378.23245]
 [384.87387]
 [379.54062]
 [389.03244]
 [386.58173]
 [377.46893]
 [381.115  ]
 [379.9198 ]
 [376.16083]
 [382.42313]
 [395.68735]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [3. 0. 0. 0. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 10.  0.  3.  0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -11.560159683227539
desired expected reward: 389.1170959472656



buy possibilites: [-1] 
expected returns: [[342.75446]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [3. 0. 0. 0. 6. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 10.  0.  3.  0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -12.336308479309082
desired expected reward: 356.6293640136719






Player: 1 
cards in hand: [29. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  3.  0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [ 8.  8.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[284.52982]
 [270.60284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.932907104492188
desired expected reward: 331.821533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.53992]
 [277.2785 ]
 [277.55563]
 [271.85043]
 [282.0254 ]
 [277.9546 ]
 [278.23172]
 [290.28073]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.16403579711914
desired expected reward: 278.7107238769531



buy possibilites: [-1] 
expected returns: [[299.25653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -6.59451150894165
desired expected reward: 270.9611511230469






Player: 1 
cards in hand: [10.  3.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8 10 29  8 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.5183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -7.040013313293457
desired expected reward: 292.2165222167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[296.4719 ]
 [300.41513]
 [300.69604]
 [294.71616]
 [305.39853]
 [301.11728]
 [301.39822]
 [314.55292]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -7.74118185043335
desired expected reward: 302.1616516113281



buy possibilites: [-1] 
expected returns: [[298.8408]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 14.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 37 

action type: buy - action 1.0
Learning step: -6.446839332580566
desired expected reward: 293.9682922363281






Player: 1 
cards in hand: [ 0.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  0.  0.] 
cards in discard: [ 0. 10.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.  1.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1] -> size -> 18 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [ 0. 10.  8.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.  1.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1] -> size -> 18 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [ 0. 10.  8.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.  1.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1] -> size -> 18 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [ 0. 10.  8.  3.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  0.  1.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1] -> size -> 18 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[284.91412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [ 3.  0.  0.  3. 14.  0.  1.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -7.5787224769592285
desired expected reward: 291.2620544433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[271.295  ]
 [275.707  ]
 [276.06363]
 [269.79498]
 [269.35828]
 [275.3333 ]
 [281.35822]
 [276.52155]
 [285.10803]
 [282.88266]
 [274.65286]
 [277.9447 ]
 [276.87817]
 [273.46463]
 [279.1329 ]
 [291.578  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [ 3.  0.  0.  3. 14.  0.  1.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -7.048231601715088
desired expected reward: 277.98809814453125



buy possibilites: [-1] 
expected returns: [[262.67523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [ 3.  0.  0.  3. 14.  0.  1.  0.  0.  3.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 23.5 

action type: buy - action 11.0
Learning step: -6.982719421386719
desired expected reward: 274.3755187988281






Player: 1 
cards in hand: [ 0.  8. 14.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  8.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11] -> size -> 19 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[241.00487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3. 29.  0.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -6.720114231109619
desired expected reward: 255.9551239013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[231.78165]
 [235.67632]
 [230.21136]
 [236.05247]
 [248.35179]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3. 29.  0.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -5.8604326248168945
desired expected reward: 236.96836853027344



buy possibilites: [-1] 
expected returns: [[264.5918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 10.  3. 29.  0.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -292.0 

action type: buy - action 6.0
Learning step: -20.15725326538086
desired expected reward: 210.05410766601562






Player: 1 
cards in hand: [10. 10.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 29.  0.] 
cards in discard: [ 0.  8. 14.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 14.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [ 0.  8. 14.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 14.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [ 0.  8. 14.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  9.  8. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 14.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [ 0.  8. 14.  8.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  9.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 14.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  1. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[274.2604 ]
 [259.49365]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 14.  0.] 
cards in discard: [6. 0. 0. 3. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  9.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -6.78864049911499
desired expected reward: 257.80316162109375



action possibilites: [-1] 
expected returns: [[301.63116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [6. 0. 0. 3. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  9.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 14.0
Learning step: -4.852413177490234
desired expected reward: 255.92987060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[284.68948]
 [290.34595]
 [285.08096]
 [290.82706]
 [282.77972]
 [282.2252 ]
 [289.88483]
 [297.244  ]
 [291.41156]
 [301.61237]
 [299.0248 ]
 [289.03693]
 [293.2563 ]
 [291.89267]
 [287.51016]
 [294.65646]
 [308.65253]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [6. 0. 0. 3. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  9.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -7.100168704986572
desired expected reward: 294.531005859375



buy possibilites: [-1] 
expected returns: [[279.8522]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [ 6.  0.  0.  3.  3.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 32.5 

action type: buy - action 11.0
Learning step: -7.2039361000061035
desired expected reward: 295.3082580566406






Player: 1 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  3.  3.  3. 11. 14.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  3.  3.  3. 11. 14.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  3.  3.  3. 11. 14.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[227.87044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  3.  3.  3. 11. 14.  6.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10. 14.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -8.546541213989258
desired expected reward: 271.3056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[212.01527]
 [215.62749]
 [215.92006]
 [210.70714]
 [220.56789]
 [216.33614]
 [216.62871]
 [229.1655 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  3.  3.  3. 11. 14.  6.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10. 14.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -5.916482448577881
desired expected reward: 218.35325622558594



buy possibilites: [-1] 
expected returns: [[284.89105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  3.  3.  3. 11. 14.  6.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10. 14.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: -5.290715217590332
desired expected reward: 206.7245635986328






Player: 1 
cards in hand: [ 0. 29.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10. 14.] 
cards in discard: [ 8.  0. 10.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10. 14.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 14.  8.] 
cards in discard: [ 8.  0. 10.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [ 8.  0. 10.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  8 10 29  8 10  0 14 10] -> size -> 15 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0. 10.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  3  3  8 10 29  8 10  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0. 10.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  3  3  8 10 29  8 10  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[262.00256]
 [252.06487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 10 29  8 10  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -8.010226249694824
desired expected reward: 276.8808288574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[244.94994]
 [248.931  ]
 [249.22774]
 [243.59123]
 [243.19206]
 [248.58318]
 [253.99022]
 [249.65372]
 [257.5334 ]
 [255.38948]
 [247.95457]
 [250.92378]
 [249.95047]
 [246.88405]
 [251.99432]
 [263.6052 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 10 29  8 10  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -7.155726909637451
desired expected reward: 256.8959045410156



buy possibilites: [-1] 
expected returns: [[262.4436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  0.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 10 29  8 10  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 16.0 

action type: buy - action 15.0
Learning step: -5.894734859466553
desired expected reward: 246.09957885742188






Player: 1 
cards in hand: [ 0.  8. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 10 29  8 10  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8 29  8  0 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8 29  8  0 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8 29  8  0 10  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[268.9877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [15.  0.  0. 11.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8.  0. 10.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  3  3  8 29  8  0 10  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -6.730212688446045
desired expected reward: 255.71339416503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[247.41753]
 [252.28993]
 [245.43446]
 [252.76187]
 [267.72336]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [15.  0.  0. 11.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8.  0. 10.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  3  3  8 29  8  0 10  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -7.205883026123047
desired expected reward: 259.10382080078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  8.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0. 10.  0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 29  8  0 10  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  1.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  0.  3.] 
cards in discard: [0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  8 29  8  0 10  0] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  1.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.] 
cards in discard: [0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  8 29  8  0 10  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  1.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8. 29.] 
owned cards: [ 3  3  8 29  8  0 10  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  1.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8. 29.] 
owned cards: [ 3  3  8 29  8  0 10  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  1.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8. 29.] 
owned cards: [ 3  3  8 29  8  0 10  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  1.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [14.  3.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[222.02711]
 [204.42812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  1.] 
cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 29  8  0 10  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -8.23413372039795
desired expected reward: 259.4892578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[198.70477]
 [203.1255 ]
 [203.51836]
 [196.79565]
 [202.7706 ]
 [208.8477 ]
 [203.96385]
 [210.35938]
 [202.12502]
 [204.35666]
 [206.61609]
 [218.71994]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  1.] 
cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 29  8  0 10  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -5.95518159866333
desired expected reward: 213.66339111328125



buy possibilites: [-1] 
expected returns: [[197.69505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  1.] 
cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 29  8  0 10  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 40 

action type: buy - action 29.0
Learning step: -4.069831371307373
desired expected reward: 206.28956604003906






Player: 1 
cards in hand: [0. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 29  8  0 10  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 11.  3.  0.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6. 29. 14.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29] -> size -> 24 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 29  8  0 10  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 11.  3.  0.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6. 29. 14.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29] -> size -> 24 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 8. 0.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 29  8  0 10  0  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 11.  3.  0.] 
adversary cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6. 29. 14.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[166.31908]
 [157.16551]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  3.  0.] 
cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6. 29. 14.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 29  8  0 10  0  0  3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.38429594039917
desired expected reward: 191.31076049804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[149.28836]
 [153.52596]
 [147.58684]
 [153.96864]
 [167.5413 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  3.  0.] 
cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6. 29. 14.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 29  8  0 10  0  0  3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -4.807027339935303
desired expected reward: 159.06295776367188



buy possibilites: [-1] 
expected returns: [[175.92363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  3.  0.] 
cards in discard: [15.  0.  0. 11.  1.  0.  3.  3.  0.  0.  6. 29. 14.  3.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 29  8  0 10  0  0  3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -5.106137752532959
desired expected reward: 144.1822509765625






Player: 1 
cards in hand: [ 3.  3.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 29  8  0 10  0  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  8 29  8  0 10  0  0  3] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 3  3  8 29  8  0 10  0  0  3] -> size -> 10 
action values: 2 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.  8.] 
owned cards: [ 8 29  8 10  0  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.  8.  8.] 
owned cards: [ 8 29  8 10  0  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.  8.  8.] 
owned cards: [ 8 29  8 10  0  0  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.  8.  8.] 
owned cards: [ 8 29  8 10  0  0  3  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[253.44257]
 [243.77756]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8. 10.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  8 10  0  0  3  0] -> size -> 8 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -2.250835418701172
desired expected reward: 173.67279052734375



action possibilites: [-1] 
expected returns: [[223.21431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  8 10  0  0  3  0] -> size -> 8 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 54 

action type: gain_card_n - action 4
Learning step: -3.6121468544006348
desired expected reward: 223.0772247314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[200.77898]
 [205.59586]
 [206.01805]
 [198.67068]
 [211.84467]
 [206.52704]
 [206.94925]
 [222.60506]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  8 10  0  0  3  0] -> size -> 8 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -4.5799078941345215
desired expected reward: 218.6343994140625



buy possibilites: [-1] 
expected returns: [[210.84671]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [16. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  8 10  0  0  3  0] -> size -> 8 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 56 

action type: buy - action 11.0
Learning step: -3.048182725906372
desired expected reward: 208.79647827148438






Player: 1 
cards in hand: [10. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  8 10  0  0  3  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  0.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29  8 10  0  0  3  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  0.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29  8 10  0  0  3  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  0.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  8.  9.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  0.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11] -> size -> 27 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[254.29666]
 [238.8471 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  0.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8.  9.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -4.620649814605713
desired expected reward: 206.22605895996094



action possibilites: [-1] 
expected returns: [[305.41983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  8.  9.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 14.0
Learning step: -3.5954368114471436
desired expected reward: 233.75221252441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[279.56866]
 [285.4682 ]
 [285.99472]
 [277.70642]
 [277.16074]
 [285.00546]
 [293.12827]
 [286.60532]
 [298.13535]
 [295.1266 ]
 [284.12317]
 [288.51965]
 [287.13193]
 [282.5233 ]
 [290.11954]
 [306.3039 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 26. 30.  8.  8.  9.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -7.3803229331970215
desired expected reward: 298.0395202636719



buy possibilites: [-1] 
expected returns: [[294.8566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 36.0 

action type: buy - action 16.0
Learning step: -5.815999507904053
desired expected reward: 279.189453125






Player: 1 
cards in hand: [3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [ 0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [ 0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16] -> size -> 28 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[207.49759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -9.75727367401123
desired expected reward: 285.0993347167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[193.69745]
 [197.51906]
 [197.8432 ]
 [192.40868]
 [192.01755]
 [197.21259]
 [202.45804]
 [198.25096]
 [205.71037]
 [203.76764]
 [196.63239]
 [199.47694]
 [198.57509]
 [195.594  ]
 [200.51532]
 [210.97902]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -5.302713871002197
desired expected reward: 198.4998016357422



buy possibilites: [-1] 
expected returns: [[154.90858]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 16.0 

action type: buy - action 14.0
Learning step: -5.546176433563232
desired expected reward: 191.08621215820312






Player: 1 
cards in hand: [ 3.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  0. 15.  3.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 29  8 10  0  0  3  0  3] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  0. 15.  3.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  8 10  0  0  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  0. 15.  3.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  8 10  0  0  0  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  0. 15.  3.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14] -> size -> 29 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[195.84541]
 [185.42307]
 [183.11487]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 15.  3.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -2.6777284145355225
desired expected reward: 152.23085021972656



action possibilites: [-1] 
expected returns: [[167.48717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.  3.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 47 

action type: gain_card_n - action 1
Learning step: -2.696368932723999
desired expected reward: 173.60023498535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[146.05394]
 [144.16254]
 [165.5076 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.  3.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -3.0431251525878906
desired expected reward: 164.4440460205078



buy possibilites: [-1] 
expected returns: [[161.36868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.  3.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  0  0  0  3] -> size -> 7 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 8.0 

action type: buy - action 0.0
Learning step: -3.204022169113159
desired expected reward: 142.8498992919922






Player: 1 
cards in hand: [8. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  0  0  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  3.  0.  1.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.  0. 11.  6.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0] -> size -> 31 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  3.  0.  1.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.  0. 11.  6.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0] -> size -> 31 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  3.  0.  1.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.  0. 11.  6.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0] -> size -> 31 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  3  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  3.  0.  1.] 
adversary cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.  0. 11.  6.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0] -> size -> 31 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29.  3.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[97.63077 ]
 [93.409706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0.  1.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.  0. 11.  6.  0. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -5.017164707183838
desired expected reward: 156.3515167236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[85.1756 ]
 [86.81197]
 [86.94124]
 [84.50032]
 [88.91071]
 [87.12002]
 [87.24928]
 [93.53405]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0.  1.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.  0. 11.  6.  0. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -2.006232738494873
desired expected reward: 95.62454986572266



buy possibilites: [-1] 
expected returns: [[106.26305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0.  1.] 
cards in discard: [16. 11. 11.  0.  0.  0.  3. 16. 14.  0.  0.  3.  0. 14.  0.  0.  0.  1.
  6.  1.  0. 11.  6.  0. 15.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 1.0
Learning step: -0.14968033134937286
desired expected reward: 86.66230010986328






Player: 1 
cards in hand: [ 8.  8.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1] -> size -> 32 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8 10  3  0] -> size -> 5 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8 10  3  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1] -> size -> 32 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[175.59537]
 [167.97768]
 [160.66774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -0.6364494562149048
desired expected reward: 105.62659454345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[157.32133]
 [161.23904]
 [161.58727]
 [155.5998 ]
 [166.32767]
 [161.99615]
 [162.34438]
 [174.9593 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 26. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -4.173887252807617
desired expected reward: 170.74658203125



buy possibilites: [-1] 
expected returns: [[197.11917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 14.  1.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 25. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 31.0 

action type: buy - action 3.0
Learning step: -2.0941829681396484
desired expected reward: 159.49310302734375






Player: 1 
cards in hand: [ 8.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [16.  6.  1. 11.  0.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [16.  6.  1. 11.  0.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 25. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [16.  6.  1. 11.  0.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3] -> size -> 33 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [16.  6.  1. 11.  0.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3] -> size -> 33 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [16.  6.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[172.50974]
 [157.60445]
 [163.28891]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  1. 11.  0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -4.2412028312683105
desired expected reward: 192.8779754638672



action possibilites: [-1] 
expected returns: [[221.45839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  1.  0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 75 

action type: gain_card_n - action 10
Learning step: 0.8741615414619446
desired expected reward: 158.04721069335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[214.44719]
 [217.02475]
 [217.21596]
 [213.17603]
 [220.30975]
 [217.50143]
 [217.69266]
 [226.11197]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  1.  0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  7.  8. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: -3.2113845348358154
desired expected reward: 218.24700927734375



buy possibilites: [-1] 
expected returns: [[189.91302]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  1.  0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 40.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 61.0 

action type: buy - action 8.0
Learning step: -3.5520293712615967
desired expected reward: 213.9494171142578






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 14.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 14.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  8.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 14.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  8.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 14.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[88.10887]
 [80.13609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 14.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  8.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -5.713298797607422
desired expected reward: 184.19972229003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.28014 ]
 [80.286804]
 [77.46133 ]
 [80.49434 ]
 [87.7936  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 14.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  8.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -0.4881454408168793
desired expected reward: 84.7988052368164



buy possibilites: [-1] 
expected returns: [[116.528244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 14.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   30.    0.    0.    0.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -273.0 

action type: buy - action 6.0
Learning step: -14.9011812210083
desired expected reward: 62.56015396118164






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8  6] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  7.  7. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8  6] -> size -> 36 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  7.  6. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8  6] -> size -> 36 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[77.8532 ]
 [68.65558]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  0 14  1  3  0  3  1 11  6 11  0 15 29
  0 16 11 16 14  1  0  1  3 15  8  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  7.  6. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -2.7736899852752686
desired expected reward: 113.75455474853516



action possibilites: [-1] 
expected returns: [[83.11551]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  7.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0 -1  0  0  4  0] 
sum of rewards: 62 

action type: gain_card_n - action 3
Learning step: -2.52750563621521
desired expected reward: 147.42457580566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[71.163185]
 [73.258934]
 [73.41975 ]
 [70.2207  ]
 [75.93682 ]
 [73.64683 ]
 [73.80766 ]
 [80.56967 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  7.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: 0.4657142758369446
desired expected reward: 83.58122253417969



buy possibilites: [-1] 
expected returns: [[66.16007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0 -2  0  0 18  0] 
sum of rewards: 75 

action type: buy - action 11.0
Learning step: 1.4417610168457031
desired expected reward: 77.37857055664062






Player: 1 
cards in hand: [0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11] -> size -> 37 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11] -> size -> 37 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11] -> size -> 37 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.951443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -0.5940961837768555
desired expected reward: 65.56597900390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.618927]
 [26.914665]
 [27.107407]
 [23.84622 ]
 [23.604261]
 [26.729443]
 [29.888195]
 [27.356562]
 [31.849127]
 [30.669958]
 [26.370129]
 [28.0819  ]
 [27.549309]
 [25.743008]
 [28.709024]
 [35.02202 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 26. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 0.8839969635009766
desired expected reward: 34.83544158935547



buy possibilites: [-1] 
expected returns: [[105.02743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  40.   0.   0.   0.   0.   0.   0.   0.  -3.   0.   0.
  4.5  0. ] 
sum of rewards: 40.5 

action type: buy - action 1.0
Learning step: 3.042383909225464
desired expected reward: 29.957050323486328






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  1. 15.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.  1.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11  1] -> size -> 38 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  1. 15.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.  1.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11  1] -> size -> 38 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  1. 15.] 
adversary cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.  1.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11  1] -> size -> 38 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[41.010048]
 [37.04132 ]
 [36.12348 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  1. 15.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.  1.  0.  1.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0
 16 11 16 14  1  0  1  3 15  8  6  8 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -2.4421727657318115
desired expected reward: 102.58525848388672



action possibilites: [-1] 
expected returns: [[24.526186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.  1.  0.  1.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action 15.0
Learning step: 1.6956652402877808
desired expected reward: 37.81914138793945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.772608]
 [20.049402]
 [20.154617]
 [18.338997]
 [18.203176]
 [19.943308]
 [21.693716]
 [20.290716]
 [22.780182]
 [22.126068]
 [19.74182 ]
 [20.692186]
 [20.395935]
 [19.394407]
 [21.039597]
 [24.526184]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.  1.  0.  1.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  5. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: 2.1890714168548584
desired expected reward: 26.71525764465332



buy possibilites: [-1] 
expected returns: [[30.331108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.] 
cards in discard: [ 3. 29.  3.  0. 14.  1. 15.  8. 11. 16.  6.  1.  0.  6.  0.  0.  3.  3.
 14.  8. 11. 16.  0.  0.  0.  1.  0.  1.  0.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 40.  0.  0. 20.  0.  0.  0.  0. -3.  0.  0.  2.  0.] 
sum of rewards: 58.0 

action type: buy - action 8.0
Learning step: 2.5679142475128174
desired expected reward: 22.85863494873047






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 16. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8] -> size -> 38 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 16. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8] -> size -> 38 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 16. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[211.5693 ]
 [200.46132]
 [204.6998 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 11.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: 4.9875407218933105
desired expected reward: 35.31864929199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[198.19127]
 [201.28574]
 [201.53839]
 [196.8109 ]
 [205.27248]
 [201.876  ]
 [202.12863]
 [212.14198]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16. 11.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -3.8931610584259033
desired expected reward: 204.2430877685547



buy possibilites: [-1] 
expected returns: [[197.09465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16. 11.  0.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  40.   0.   0.   0. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: 5.0 

action type: buy - action 0.0
Learning step: -5.22493314743042
desired expected reward: 192.96632385253906






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 14.  0.  3.  0.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0] -> size -> 39 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 14.  0.  3.  0.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0] -> size -> 39 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 14.  0.  3.  0.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0] -> size -> 39 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 1. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[182.22011]
 [170.72202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  3.  0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -3.9766037464141846
desired expected reward: 193.1180419921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[166.81688]
 [170.09937]
 [170.38461]
 [165.28384]
 [169.82498]
 [174.51622]
 [170.75648]
 [175.67891]
 [169.28946]
 [171.04172]
 [172.76399]
 [182.11926]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.  3.  0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 25. 30.  8.  7.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -3.181497573852539
desired expected reward: 176.8518524169922



buy possibilites: [-1] 
expected returns: [[160.02745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.  3.  0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   30.    0.    0.    0.    0.    0.    0.    0.   -5.
    0. -300.    0.    0.] 
sum of rewards: -277.0 

action type: buy - action 6.0
Learning step: -18.24346923828125
desired expected reward: 141.63827514648438






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[188.60635]
 [177.20222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -2.5604939460754395
desired expected reward: 157.46694946289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[166.91234]
 [170.33897]
 [170.61638]
 [165.38579]
 [174.7781 ]
 [170.99863]
 [171.27605]
 [182.39777]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -3.980537176132202
desired expected reward: 181.05628967285156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [29.  1.  0. 15.  6.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [29.  1.  0. 15.  6.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [29.  1.  0. 15.  6.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [29.  1.  0. 15.  6.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29.  1.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[165.79662]
 [163.58974]
 [162.51366]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 15.  6.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -4.028848171234131
desired expected reward: 178.368896484375



action possibilites: [-1. 15.] 
expected returns: [[164.28775]
 [155.26509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  6.  3.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action 29.0
Learning step: -2.180103063583374
desired expected reward: 161.40960693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[141.95673]
 [145.06789]
 [145.31078]
 [140.69833]
 [144.78802]
 [149.2467 ]
 [145.68045]
 [150.3655 ]
 [144.2416 ]
 [145.92339]
 [147.5649 ]
 [156.45303]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  6.  3.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 25. 30. 25. 30.  8.  6.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: -2.509662628173828
desired expected reward: 161.77810668945312



buy possibilites: [-1] 
expected returns: [[158.39635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  6.  3.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [14. 25. 30. 25. 30.  8.  5.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   20.    0.    0.   20.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -269.0 

action type: buy - action 6.0
Learning step: -16.92099952697754
desired expected reward: 123.77735137939453






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  5.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3.  8.  1.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6  6] -> size -> 41 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  5.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3.  8.  1.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6  6] -> size -> 41 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  5.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3.  8.  1.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6  6] -> size -> 41 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [14.  0.  3.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[119.95995 ]
 [110.35094 ]
 [111.397865]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  8.  1.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 14  1  3  0  3  1 11  6 11  0 15 29  0 16
 11 16 14  1  0  1  3 15  8  6  8 11  1  8  0  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  5.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -4.501077175140381
desired expected reward: 153.895263671875



action possibilites: [-1] 
expected returns: [[240.62196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  5.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: trash_cards_n_from_hand - action 11
Learning step: 1.0121532678604126
desired expected reward: 115.04896545410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[225.01613]
 [223.9427 ]
 [240.02043]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 30. 25. 30.  8.  5.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -5.553619384765625
desired expected reward: 235.06834411621094



buy possibilites: [-1] 
expected returns: [[251.7147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 25. 30. 25. 30.  8.  4.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -4.
    0. -300.    0.    0.] 
sum of rewards: -289.0 

action type: buy - action 6.0
Learning step: -19.98355484008789
desired expected reward: 203.9591522216797






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  4.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8.  1. 16.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6] -> size -> 39 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 25. 30. 25. 30.  8.  4.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8.  1. 16.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6] -> size -> 39 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 25. 30.  8.  4.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8.  1. 16.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6] -> size -> 39 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [11.  0.  8.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
expected returns: [[110.79054]
 [104.76067]
 [102.26515]
 [101.72953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  1. 16.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 25. 30.  8.  4.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -10.470015525817871
desired expected reward: 241.24468994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.35434 ]
 [101.300934]
 [101.45263 ]
 [ 98.478004]
 [104.12388 ]
 [101.67377 ]
 [101.82545 ]
 [109.98896 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  1. 16.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 30. 25. 30.  8.  4.  8.  6.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.4807987213134766
desired expected reward: 107.30973052978516



buy possibilites: [-1] 
expected returns: [[90.826164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  1. 16.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 8 

action type: buy - action 11.0
Learning step: -2.7626049518585205
desired expected reward: 101.36126708984375






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11.  6. 11. 15.  0.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0. 11. 11.  0.  8.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 25. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11.  6. 11. 15.  0.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0. 11. 11.  0.  8.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11] -> size -> 40 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 25. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11.  6. 11. 15.  0.] 
adversary cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0. 11. 11.  0.  8.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11] -> size -> 40 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11.  6. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[70.73925 ]
 [63.301   ]
 [63.301   ]
 [61.824574]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11. 15.  0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0. 11. 11.  0.  8.  1. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -3.3276824951171875
desired expected reward: 87.49848175048828



action possibilites: [-1] 
expected returns: [[70.37054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 15.  0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0. 11. 11.  0.  8.  1. 16.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  9  0] 
sum of rewards: 18 

action type: gain_card_n - action 1
Learning step: -0.5792682766914368
desired expected reward: 60.67283630371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.137722]
 [52.563145]
 [70.37054 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 15.  0.] 
cards in discard: [ 0.  0.  0. 16. 11.  0.  6.  1. 14.  0.  3.  0.  1.  0.  3.  3.  8.  6.
 29.  1.  0. 15.  6.  3.  6.  8.  0. 11. 11.  0.  8.  1. 16.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -1.4293922185897827
desired expected reward: 68.94114685058594






Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1] -> size -> 41 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1] -> size -> 41 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1] -> size -> 41 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[163.71811]
 [152.93942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.28396913409233093
desired expected reward: 70.0865707397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.15848]
 [155.2956 ]
 [150.8728 ]
 [155.61249]
 [166.06386]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 30. 25. 30.  8.  4.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.740355014801025
desired expected reward: 155.46389770507812



buy possibilites: [-1] 
expected returns: [[210.8947]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [6.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -10.    0.    0.    0.    0.    0.    0.    0.   -7.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -18.94850730895996
desired expected reward: 131.9242706298828






Player: 1 
cards in hand: [0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0. 11.  0.] 
adversary cards in discard: [6. 6. 0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6] -> size -> 42 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0. 11.  0.] 
adversary cards in discard: [6. 6. 0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0. 11.  0.] 
adversary cards in discard: [6. 6. 0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6] -> size -> 42 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0. 11.  0.] 
adversary cards in discard: [6. 6. 0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6] -> size -> 42 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [15.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[179.20383]
 [166.97064]
 [169.2777 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0. 11.  0.] 
cards in discard: [6. 6. 0. 8. 0. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -7.542279243469238
desired expected reward: 203.3524169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[166.12137]
 [170.53766]
 [170.9025 ]
 [164.14227]
 [170.17693]
 [176.24529]
 [171.39212]
 [177.72403]
 [169.47295]
 [171.75697]
 [173.96127]
 [186.04839]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0. 11.  0.] 
cards in discard: [6. 6. 0. 8. 0. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -5.711616516113281
desired expected reward: 170.35629272460938



buy possibilites: [-1] 
expected returns: [[177.50969]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0. 11.  0.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0  -8   0   0  32   0] 
sum of rewards: 8 

action type: buy - action 14.0
Learning step: -4.079679012298584
desired expected reward: 165.39324951171875






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14] -> size -> 43 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14] -> size -> 43 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[133.67119 ]
 [123.885666]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14
  1  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -6.789170742034912
desired expected reward: 170.72052001953125



action possibilites: [-1] 
expected returns: [[155.61917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 15.0
Learning step: -2.4509403705596924
desired expected reward: 120.59648895263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[136.61102]
 [140.69284]
 [141.03322]
 [135.22108]
 [134.78468]
 [140.35614]
 [145.96748]
 [141.48027]
 [149.43727]
 [147.32445]
 [139.70781]
 [142.73055]
 [141.82065]
 [138.5837 ]
 [143.85466]
 [154.97498]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  4. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -4.369795799255371
desired expected reward: 151.24937438964844



buy possibilites: [-1] 
expected returns: [[139.49135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -10.   0.   0.  20.   0.   0.   0.   0.  -8.   0.   0.
   2.   0.] 
sum of rewards: -2.0 

action type: buy - action 8.0
Learning step: -4.035458564758301
desired expected reward: 137.44480895996094






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  0.  1.  6.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8] -> size -> 43 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  0.  1.  6.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8] -> size -> 43 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 24. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  0.  1.  6.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8] -> size -> 43 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  0.  1.  6.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8] -> size -> 43 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[138.43782]
 [129.99493]
 [132.79156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  1.  6.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -4.760791301727295
desired expected reward: 134.73056030273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[129.85704]
 [132.49236]
 [132.66843]
 [128.64758]
 [135.821  ]
 [132.97069]
 [133.14676]
 [141.57545]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  1.  6.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 24. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -4.712449073791504
desired expected reward: 133.72535705566406



buy possibilites: [-1] 
expected returns: [[91.73953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  1.  6.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0  -9   0   0  18   0] 
sum of rewards: -7 

action type: buy - action 1.0
Learning step: -4.85373067855835
desired expected reward: 127.63859558105469






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [1. 6. 0. 3. 3.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1] -> size -> 44 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [1. 6. 0. 3. 3.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1] -> size -> 44 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [1. 6. 0. 3. 3.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1] -> size -> 44 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [1. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[136.60933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 3. 3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -2.3132667541503906
desired expected reward: 89.42626953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[125.15172 ]
 [127.8008  ]
 [127.99403 ]
 [123.945244]
 [131.17401 ]
 [128.29121 ]
 [128.48447 ]
 [137.23933 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3. 3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  7. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -4.725070476531982
desired expected reward: 131.88426208496094



buy possibilites: [-1] 
expected returns: [[96.80612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3. 3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  6. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0 -10   0   0  18   0] 
sum of rewards: -8 

action type: buy - action 10.0
Learning step: -4.646086692810059
desired expected reward: 123.83839416503906






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  6. 10.  8.] 
adversary cards in hand: [11.  6.  0. 11.  8.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10] -> size -> 45 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  6. 10.  8.] 
adversary cards in hand: [11.  6.  0. 11.  8.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10] -> size -> 45 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  6. 10.  8.] 
adversary cards in hand: [11.  6.  0. 11.  8.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10] -> size -> 45 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11.  6.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[76.99541]
 [72.49457]
 [72.49457]
 [70.25149]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 11.  8.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  6. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -3.9926278591156006
desired expected reward: 92.81349182128906



action possibilites: [-1] 
expected returns: [[42.6589]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  8.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0 -11   0   0   9   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: -2.555774688720703
desired expected reward: 69.7562255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.02289 ]
 [35.392487]
 [42.658905]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  8.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -1.072854995727539
desired expected reward: 41.58604431152344



buy possibilites: [-1] 
expected returns: [[68.706345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  8.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -10.   0.   0.  20. -30.   0.   0.   0. -12.   0.   0.
   0.   0.] 
sum of rewards: -38.0 

action type: buy - action 0.0
Learning step: -2.1552517414093018
desired expected reward: 33.867637634277344






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  1.  1. 29.  3.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0] -> size -> 47 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  1.  1. 29.  3.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0] -> size -> 47 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  1.  1. 29.  3.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0] -> size -> 47 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [14.  1.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[109.86499 ]
 [102.285576]
 [106.06088 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  1. 29.  3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -1.8450199365615845
desired expected reward: 66.861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[100.78516 ]
 [102.762505]
 [102.935135]
 [100.02412 ]
 [102.59765 ]
 [105.38672 ]
 [103.15771 ]
 [106.060875]
 [102.285576]
 [103.330345]
 [104.34197 ]
 [109.864975]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  1. 29.  3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.9555251598358154
desired expected reward: 105.90946960449219



buy possibilites: [-1] 
expected returns: [[124.244415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  1. 29.  3.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -10.    0.    0.    0.    0.    0.    0.    0.  -13.
   0.    0.    4.5   0. ] 
sum of rewards: -24.5 

action type: buy - action 10.0
Learning step: -3.596017599105835
desired expected reward: 99.73432159423828






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [16. 16.  0.  0. 11.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.
 10. 14.  1.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10] -> size -> 48 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [16. 16.  0.  0. 11.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.
 10. 14.  1.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10] -> size -> 48 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [16. 16.  0.  0. 11.] 
adversary cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.
 10. 14.  1.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10] -> size -> 48 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [16. 16.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11.] 
expected returns: [[172.44737]
 [167.18257]
 [167.18257]
 [169.18144]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  0.  0. 11.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.
 10. 14.  1.  1. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1 11  6 11  0 15 29  0 16 11 16 14  1
  0  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  8.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -3.206380844116211
desired expected reward: 121.03803253173828



action possibilites: [-1] 
expected returns: [[87.863785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.
 10. 14.  1.  1. 29.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0 -13   0   0  16   0] 
sum of rewards: 7 

action type: gain_card_n - action 5
Learning step: -1.1473934650421143
desired expected reward: 68.33917999267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.785866]
 [80.752815]
 [77.98903 ]
 [80.98514 ]
 [87.86377 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.
 10. 14.  1.  1. 29.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 30. 25. 30.  8.  3.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -2.3580498695373535
desired expected reward: 85.5057373046875



buy possibilites: [-1] 
expected returns: [[104.83833]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [ 6.  6.  0.  8.  0.  3. 14. 15.  1.  0. 11.  0.  8. 15.  0.  0.  3.  1.
  8. 11.  0.  1.  6. 10.  1.  6.  0.  3.  3. 10.  0. 11.  6.  0. 11.  8.
 10. 14.  1.  1. 29.  3. 16.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -20.    0.    0.   20.    0.    0.    0.    0.  -14.
    0. -300.    0.    0.] 
sum of rewards: -321.0 

action type: buy - action 6.0
Learning step: -17.472867965698242
desired expected reward: 58.16173553466797






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  3. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6] -> size -> 49 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  3. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6] -> size -> 49 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  3. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6] -> size -> 49 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[188.471  ]
 [176.89644]
 [180.74792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 11.  6.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -2.5697414875030518
desired expected reward: 102.26859283447266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[171.012  ]
 [169.4618 ]
 [186.75542]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 11.  6.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -6.630822658538818
desired expected reward: 178.28543090820312



buy possibilites: [-1] 
expected returns: [[171.08737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 11.  6.] 
cards in discard: [0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -20.   0.   0.   0. -30.   0.   0.   0. -15.   0.   0.
   0.   0.] 
sum of rewards: -72.0 

action type: buy - action 0.0
Learning step: -8.301132202148438
desired expected reward: 162.71083068847656






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [29.  0.  1.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0] -> size -> 50 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [29.  0.  1.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0] -> size -> 50 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [29.  0.  1.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0] -> size -> 50 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [29.  0.  1.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0] -> size -> 50 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [29.  0.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[91.04155]
 [82.69809]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0.  6.] 
cards in discard: [ 0.  0.  8.  3. 11.  6.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -7.984935283660889
desired expected reward: 163.10243225097656



action possibilites: [-1.] 
expected returns: [[123.054565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -6 

action type: take_action - action 29.0
Learning step: -1.5837793350219727
desired expected reward: 79.46636199951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 96.1516  ]
 [100.57003 ]
 [ 96.4798  ]
 [100.97178 ]
 [ 94.672874]
 [ 94.22019 ]
 [100.213844]
 [106.33661 ]
 [101.43701 ]
 [110.076515]
 [107.79964 ]
 [ 99.56188 ]
 [102.83655 ]
 [101.83877 ]
 [ 98.33871 ]
 [104.05972 ]
 [116.152756]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 4. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: -4.196773052215576
desired expected reward: 118.85779571533203



buy possibilites: [-1] 
expected returns: [[63.3528]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -20.   0.   0.  20.   0.   0.   0.   0. -16.   0.   0.
   8.   0.] 
sum of rewards: -15.0 

action type: buy - action 14.0
Learning step: -4.3026556968688965
desired expected reward: 95.25921630859375






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [11. 10.  8. 14.  8.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [11. 10.  8. 14.  8.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [11. 10.  8. 14.  8.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [11. 10.  8. 14.  8.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [11. 10.  8. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 14.  8.] 
expected returns: [[90.216   ]
 [83.63732 ]
 [80.726425]
 [80.515686]
 [79.325966]
 [80.515686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 14.  8.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -2.6540679931640625
desired expected reward: 60.69873046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.33624]
 [75.10566]
 [89.11029]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8. 14.  8.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -4.047926425933838
desired expected reward: 86.16806030273438



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [15.  1.  6.  3. 16.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [15.  1.  6.  3. 16.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
adversary victory points: -2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [15.  1.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[39.60138]
 [37.48791]
 [36.82962]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  6.  3. 16.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -4.949530124664307
desired expected reward: 84.16075897216797



action possibilites: [-1] 
expected returns: [[105.554985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  3. 16.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 15.0
Learning step: 0.15059147775173187
desired expected reward: 37.63850402832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 96.557655]
 [ 98.354034]
 [ 95.88285 ]
 [ 98.58481 ]
 [105.55497 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  3. 16.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 23. 30. 25. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -3.39411997795105
desired expected reward: 102.1608657836914



buy possibilites: [-1] 
expected returns: [[128.9976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  3. 16.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0 -17   0   0   8   0] 
sum of rewards: -5 

action type: buy - action 3.0
Learning step: -2.265256643295288
desired expected reward: 96.08879089355469






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 15.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14  3] -> size -> 52 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 15.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14  3] -> size -> 52 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 15.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14  3] -> size -> 52 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[46.43382 ]
 [41.443348]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 15.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0
  1  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16
  6  0 14  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -6.258821487426758
desired expected reward: 122.73878479003906



action possibilites: [-1] 
expected returns: [[98.31234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 15.0
Learning step: 0.3747810423374176
desired expected reward: 41.818138122558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[81.154724]
 [84.932045]
 [81.45686 ]
 [85.297935]
 [79.89561 ]
 [79.51086 ]
 [84.637726]
 [89.901085]
 [85.694145]
 [93.081955]
 [91.13595 ]
 [84.11404 ]
 [86.898674]
 [86.06002 ]
 [83.05761 ]
 [87.955086]
 [98.31235 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  7.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -2.7671849727630615
desired expected reward: 95.54515838623047



buy possibilites: [-1] 
expected returns: [[104.16607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -10.   0.   0.  20.   0.   0.   0.   0. -17.   0.   0.
   8.   0.] 
sum of rewards: -5.0 

action type: buy - action 16.0
Learning step: -2.138150215148926
desired expected reward: 82.49958038330078






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [14.  8. 16.  3.  0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16] -> size -> 52 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [14.  8. 16.  3.  0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16] -> size -> 52 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [14.  8. 16.  3.  0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16] -> size -> 52 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [14.  8. 16.  3.  0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16] -> size -> 52 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [14.  8. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
expected returns: [[66.28084 ]
 [64.161736]
 [64.422676]
 [64.26377 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 16.  3.  0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -4.549237251281738
desired expected reward: 99.61682891845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.74714]
 [63.4784 ]
 [66.28084]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 16.  3.  0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.6610031127929688
desired expected reward: 63.61981201171875



buy possibilites: [-1] 
expected returns: [[28.964397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 16.  3.  0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -10.   0.   0.   0. -30.   0.   0.   0. -18.   0.   0.
   0.   0.] 
sum of rewards: -64.0 

action type: buy - action 0.0
Learning step: -5.735657691955566
desired expected reward: 58.01146697998047






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [11.  0.  6. 10.  3.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0] -> size -> 53 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [11.  0.  6. 10.  3.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0] -> size -> 53 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [11.  0.  6. 10.  3.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0] -> size -> 53 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [11.  0.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[79.24864 ]
 [74.909935]
 [72.90595 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 10.  3.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 24. 30.  8.  2.  6.  5.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -0.5417532324790955
desired expected reward: 28.422643661499023



action possibilites: [-1] 
expected returns: [[62.397346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  3.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 24. 30.  8.  2.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0 -19   0   0   9   0] 
sum of rewards: -6 

action type: gain_card_n - action 4
Learning step: -2.3844916820526123
desired expected reward: 67.38414764404297





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[50.204338]
 [62.39734 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  3.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 24. 30.  8.  2.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -1.6471351385116577
desired expected reward: 60.75020980834961



buy possibilites: [-1] 
expected returns: [[40.672863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  3.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 24. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -20.    0.    0.   20.    0.    0.    0.    0.  -20.
    0. -300.    0.    0.] 
sum of rewards: -327.0 

action type: buy - action 6.0
Learning step: -17.945077896118164
desired expected reward: 32.259254455566406






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 24. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 16.  6.  6. 11.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6] -> size -> 55 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 24. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 16.  6.  6. 11.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6] -> size -> 55 
adversary victory points: -2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[91.15151]
 [85.89233]
 [87.70736]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  6. 11.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 24. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -1.3951715230941772
desired expected reward: 39.27769088745117



action possibilites: [-1] 
expected returns: [[57.188442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  6.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0 -21   0   0   4   0] 
sum of rewards: -13 

action type: gain_card_n - action 1
Learning step: -3.6631805896759033
desired expected reward: 82.33523559570312





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[50.357445]
 [57.188446]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  6.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -1.4461898803710938
desired expected reward: 55.742252349853516






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 6. 1. 0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.  3. 11.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3] -> size -> 56 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 6. 1. 0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.  3. 11.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3] -> size -> 56 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [0. 1. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.02612]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 1. 0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.  3. 11.  0. 16.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -1.8138344287872314
desired expected reward: 55.37460708618164





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[77.15043 ]
 [75.82861 ]
 [77.25622 ]
 [75.2698  ]
 [75.12263 ]
 [77.016106]
 [78.958725]
 [77.408134]
 [80.16342 ]
 [79.43324 ]
 [76.783714]
 [77.83651 ]
 [77.51392 ]
 [76.39169 ]
 [78.228546]
 [82.02613 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 1. 0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.  3. 11.  0. 16.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3] -> size -> 56 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.1499171257019043
desired expected reward: 78.87620544433594



buy possibilites: [-1] 
expected returns: [[49.35251]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 1. 0.] 
cards in discard: [ 0.  0.  8.  3. 11.  6. 14. 29.  0.  1.  0.  6.  0. 11. 10.  8. 14.  8.
  3. 15.  1.  6.  3. 16. 16. 15.  0.  3.  1.  0. 14.  8. 16.  3.  0. 11.
  6. 11.  0.  6. 10.  3.  3. 11.  0. 16.  6.  6. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -10.    0.    0.    0.    0.    0.    0.    0.  -22.
   0.    0.   12.5   0. ] 
sum of rewards: -25.5 

action type: buy - action 22.0
Learning step: -3.872183322906494
desired expected reward: 70.28010559082031






Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  1.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22] -> size -> 57 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 23. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  1.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22] -> size -> 57 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  1.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22] -> size -> 57 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[154.62335]
 [139.82993]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 10.  1.] 
cards in discard: [] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -0.4477909207344055
desired expected reward: 48.90471649169922



action possibilites: [-1. 10.] 
expected returns: [[139.13464]
 [125.06369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  1. 10.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22] -> size -> 57 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action 10.0
Learning step: -4.31238317489624
desired expected reward: 135.51754760742188





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[119.52866 ]
 [115.70197 ]
 [119.94712 ]
 [114.02053 ]
 [113.6119  ]
 [119.1803  ]
 [125.231125]
 [120.39188 ]
 [128.88512 ]
 [126.64711 ]
 [118.57233 ]
 [121.781555]
 [120.81034 ]
 [117.42361 ]
 [122.99313 ]
 [134.88127 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  1. 10.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22] -> size -> 57 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3. 10.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: -4.5157999992370605
desired expected reward: 134.61883544921875



buy possibilites: [-1] 
expected returns: [[106.93531]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  1. 10.] 
cards in discard: [25.] 
cards in deck: 51 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -20.    0.    0.   20.    0.    0.    0.    0.  -23.
   0.    0.   12.5   0. ] 
sum of rewards: -16.5 

action type: buy - action 25.0
Learning step: -4.863211631774902
desired expected reward: 124.02190399169922






Player: 1 
cards in hand: [8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 1. 11.  0. 16.  6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25] -> size -> 58 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 1. 11.  0. 16.  6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25] -> size -> 58 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 1. 11.  0. 16.  6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25] -> size -> 58 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 1. 11.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[74.87576 ]
 [66.15862 ]
 [60.535378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0. 16.  6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -4.627474308013916
desired expected reward: 102.3078384399414





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[52.998417]
 [53.336037]
 [47.975018]
 [58.465717]
 [53.77586 ]
 [54.163616]
 [67.279205]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0. 16.  6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 22. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.2850728034973145
desired expected reward: 71.5906982421875



buy possibilites: [-1] 
expected returns: [[85.87176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0. 16.  6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 21. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -24.   0.   0.
   2.   0.] 
sum of rewards: -27.0 

action type: buy - action 3.0
Learning step: -2.0846872329711914
desired expected reward: 51.251346588134766






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 11.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3] -> size -> 59 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 11.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3] -> size -> 59 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 11.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3] -> size -> 59 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[35.617817]
 [30.393585]
 [32.136215]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  3. 11.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  1.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -3.8046422004699707
desired expected reward: 82.0671157836914



action possibilites: [-1] 
expected returns: [[66.34684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3  6] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -10    0    0   20    0    0    0    0  -25    0 -300
    0    0] 
sum of rewards: -321 

action type: gain_card_n - action 2
Learning step: -15.988504409790039
desired expected reward: 12.637653350830078





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[66.34684]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3  6] -> size -> 60 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -1.6245380640029907
desired expected reward: 64.72230529785156






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3  6] -> size -> 60 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3  6] -> size -> 60 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3  6] -> size -> 60 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[59.553913]
 [55.435352]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1
  3 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6
  0 14  3 16  0 11  6  3 22 25  3  6] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -2.8216984272003174
desired expected reward: 63.525142669677734



action possibilites: [-1] 
expected returns: [[88.27423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.5118994116783142
desired expected reward: 53.449493408203125





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[88.27423]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6] -> size -> 59 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -2.227541446685791
desired expected reward: 86.04669189453125






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 1.  3. 11.  1.  0.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6] -> size -> 59 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [ 1.  3. 11.  1.  0.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6] -> size -> 59 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[80.950714]
 [77.68716 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  1.  0.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -3.322067975997925
desired expected reward: 82.84473419189453



action possibilites: [-1] 
expected returns: [[65.7983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0 -25   0   0   9   0] 
sum of rewards: -12 

action type: gain_card_n - action 0
Learning step: -2.8439064025878906
desired expected reward: 71.64346313476562





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[57.985535]
 [58.162758]
 [54.739044]
 [57.78359 ]
 [60.867527]
 [58.40789 ]
 [62.77076 ]
 [61.625046]
 [57.439396]
 [59.097492]
 [58.585114]
 [56.815075]
 [59.721813]
 [65.7983  ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1] -> size -> 60 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  5. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -1.7499245405197144
desired expected reward: 64.04837799072266



buy possibilites: [-1] 
expected returns: [[44.902378]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -10.   0.   0.  20.   0.   0.   0.   0. -26.   0.   0.
   8.   0.] 
sum of rewards: -14.0 

action type: buy - action 14.0
Learning step: -2.56166672706604
desired expected reward: 54.87773513793945






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0. 22.  8.  6. 16.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0. 22.  8.  6. 16.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0. 22.  8.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 16.] 
expected returns: [[49.463055]
 [42.250927]
 [43.511288]
 [43.01168 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  8.  6. 16.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -2.0377395153045654
desired expected reward: 42.86463928222656





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[49.463055]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  8.  6. 16.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.160234212875366
desired expected reward: 47.30282211303711



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.860828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -2.6687841415405273
desired expected reward: 46.79426956176758





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[18.653183]
 [18.884071]
 [21.706102]
 [19.121782]
 [19.352676]
 [26.860815]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14] -> size -> 61 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 22. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -1.6699069738388062
desired expected reward: 25.190921783447266



buy possibilites: [-1] 
expected returns: [[57.81498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0 -27   0   0  18   0] 
sum of rewards: -25 

action type: buy - action 1.0
Learning step: -0.881822407245636
desired expected reward: 17.771366119384766






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [16. 10. 11. 16.  6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [16. 10. 11. 16.  6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [16. 10. 11. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 11. 16.] 
expected returns: [[58.707012]
 [55.665024]
 [55.974976]
 [56.84137 ]
 [55.665024]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10. 11. 16.  6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -2.415818929672241
desired expected reward: 55.39916229248047



action possibilites: [-1. 16. 11. 16.] 
expected returns: [[45.25134 ]
 [42.372936]
 [43.385696]
 [42.372936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11. 16.  6.  6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 10.0
Learning step: -1.6216057538986206
desired expected reward: 54.35336685180664





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[45.25134]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11. 16.  6.  6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: -1.0444118976593018
desired expected reward: 44.20692825317383






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0. 14. 14. 11. 15.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0. 14. 14. 11. 15.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 14. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 11. 15.] 
expected returns: [[60.96323 ]
 [49.56683 ]
 [49.56683 ]
 [54.161655]
 [52.609222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 14. 11. 15.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -1.8542379140853882
desired expected reward: 43.39710235595703





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[60.963253]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 14. 11. 15.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.476489543914795
desired expected reward: 58.48676300048828



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [3. 8. 6. 0. 6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [3. 8. 6. 0. 6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [3. 8. 6. 0. 6.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [3. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[80.87326]
 [74.43527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0. 6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -2.0977931022644043
desired expected reward: 58.86545944213867





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[79.97758]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0. 6.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.9993834495544434
desired expected reward: 76.97819519042969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [15.  1. 14.  6. 29.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.  3.  8.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [15.  1. 14.  6. 29.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.  3.  8.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [15.  1. 14.  6. 29.] 
adversary cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.  3.  8.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [15.  1. 14.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 29.] 
expected returns: [[97.862885]
 [91.626144]
 [89.57968 ]
 [93.32504 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 14.  6. 29.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.  3.  8.
  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -2.6995036602020264
desired expected reward: 77.278076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[90.214874]
 [90.432465]
 [97.862885]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 14.  6. 29.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.  3.  8.
  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1] -> size -> 62 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 21. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.5994014739990234
desired expected reward: 94.26348876953125



buy possibilites: [-1] 
expected returns: [[104.026764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 14.  6. 29.] 
cards in discard: [25. 10.  0.  1.  0.  1. 10.  3.  1. 11.  0. 16.  6.  6. 11.  0.  8.  3.
  3.  8.  3.  3.  0.  1. 14. 11.  1.  3.  1.  0.  0. 22.  8.  6. 16.  1.
  0.  0.  0.  3.  6. 10. 16. 11. 16.  6.  6.  0. 14. 14. 11. 15.  3.  8.
  6.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -28   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 3.0
Learning step: -3.4201416969299316
desired expected reward: 86.79473114013672






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  3.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3] -> size -> 63 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  3.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3] -> size -> 63 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  3.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3] -> size -> 63 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[125.43634 ]
 [112.967255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 14.  1.] 
cards in discard: [] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -2.7631995677948
desired expected reward: 101.26356506347656





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[113.29356 ]
 [113.57913 ]
 [117.57792 ]
 [113.92403 ]
 [114.209595]
 [125.50468 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 14.  1.] 
cards in discard: [] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3] -> size -> 63 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.895026445388794
desired expected reward: 121.54129791259766



buy possibilites: [-1] 
expected returns: [[96.7003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 14.  1.] 
cards in discard: [1.] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -29   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 1.0
Learning step: -4.288918972015381
desired expected reward: 109.00460052490234






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [11.  0.  8.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 64 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [11.  0.  8.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.] 
adversary owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 64 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [11.  0.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
expected returns: [[27.998993]
 [24.423092]
 [22.627766]
 [23.58481 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  3. 15.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3  0  3  1  6 11  0 15 29  0 16 11 16 14  1  0  1  3
 15  8  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0
 14  3 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -4.526927947998047
desired expected reward: 92.17337036132812



action possibilites: [-1] 
expected returns: [[116.64938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.] 
cards in deck: 53 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 2.36791729927063
desired expected reward: 22.501789093017578





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[113.85979]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.] 
cards in deck: 53 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 62 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -2.5206239223480225
desired expected reward: 114.1287612915039






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 11.  1.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.] 
adversary owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 62 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 11.  1.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.] 
adversary owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 62 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 11.  1.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.] 
adversary owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 62 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-1.1715264]
 [-1.3974097]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 11.  1.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -5.9717793464660645
desired expected reward: 107.88800811767578



action possibilites: [-1] 
expected returns: [[94.415016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1.] 
cards in deck: 48 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -28   0   0   9   0] 
sum of rewards: -4 

action type: gain_card_n - action 0
Learning step: 1.9942083358764648
desired expected reward: 0.5967986583709717





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[86.53175 ]
 [86.685585]
 [83.98132 ]
 [86.36385 ]
 [89.34456 ]
 [86.89442 ]
 [91.28849 ]
 [90.11798 ]
 [86.08014 ]
 [87.532906]
 [87.04825 ]
 [85.549576]
 [88.17405 ]
 [94.41502 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1.] 
cards in deck: 48 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1] -> size -> 63 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  6.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -1.9875383377075195
desired expected reward: 92.42747497558594



buy possibilites: [-1] 
expected returns: [[94.52114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16.] 
cards in deck: 48 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16] -> size -> 64 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -29.   0.   0.
   8.   0.] 
sum of rewards: -6.0 

action type: buy - action 16.0
Learning step: -2.5226666927337646
desired expected reward: 83.84117889404297






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16] -> size -> 64 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16] -> size -> 64 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[31.593327]
 [28.349133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -4.300117492675781
desired expected reward: 90.22102355957031





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[28.424183]
 [28.478539]
 [29.410717]
 [28.564636]
 [28.618998]
 [31.593327]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16] -> size -> 64 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  3.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -1.1707184314727783
desired expected reward: 30.422607421875



buy possibilites: [-1] 
expected returns: [[22.201328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8] -> size -> 65 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  2.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -30.   0.   0.
   2.   0.] 
sum of rewards: -33.0 

action type: buy - action 8.0
Learning step: -2.578702449798584
desired expected reward: 25.98594093322754






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  2.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 1.  8. 11. 16.  0.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8] -> size -> 65 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  2.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 1.  8. 11. 16.  0.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8] -> size -> 65 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  2.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [ 1.  8. 11. 16.  0.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8] -> size -> 65 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 11. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 16.] 
expected returns: [[16.528952]
 [13.47096 ]
 [14.2941  ]
 [13.262739]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11. 16.  0.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8
  6  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3
 16  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  2.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0342167615890503
desired expected reward: 21.167112350463867



action possibilites: [-1] 
expected returns: [[76.66953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8  6
  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16
  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -30   0   0   4   0] 
sum of rewards: -11 

action type: gain_card_n - action 1
Learning step: -2.4453110694885254
desired expected reward: 69.96219635009766





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[69.13041]
 [69.35963]
 [76.66954]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 11.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8  6
  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16
  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8] -> size -> 65 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 19. 30. 20. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -1.4649381637573242
desired expected reward: 75.20459747314453



buy possibilites: [-1] 
expected returns: [[79.12638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 11.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8  6
  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16
  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   1  10   0   0  20   0   0   0   0 -31   0   0   8   0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -1.5261770486831665
desired expected reward: 67.60423278808594






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [16.  8.  6.  3.  8.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.] 
adversary owned cards: [ 0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8  6
  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16
  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 66 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [16.  8.  6.  3.  8.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.] 
adversary owned cards: [ 0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8  6
  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16
  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 66 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [16.  8.  6.  3.  8.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.] 
adversary owned cards: [ 0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8  6
  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16
  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 66 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [16.  8.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
expected returns: [[30.586912]
 [26.54209 ]
 [26.800789]
 [26.800789]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  6.  3.  8.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  3  0  3  1  6  0 15 29  0 16 11 16 14  1  0  1  3 15  8  6
  8 11  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16
  0 11  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -3.030618667602539
desired expected reward: 76.09576416015625



action possibilites: [-1] 
expected returns: [[110.470726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0  3  0  3  1  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11
  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11
  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: trash_cards_n_from_hand - action 7
Learning step: 3.0246589183807373
desired expected reward: 29.243301391601562





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[110.470726]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0  3  0  3  1  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11
  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11
  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 64 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -1.1879452466964722
desired expected reward: 109.28278350830078






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [22. 10. 16.  0.  1.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8.] 
adversary owned cards: [ 0  3  3  0  3  0  3  1  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11
  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11
  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 64 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [22. 10. 16.  0.  1.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8.] 
adversary owned cards: [ 0  3  3  0  3  0  3  1  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11
  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11
  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 64 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [22. 10. 16.  0.  1.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8.] 
adversary owned cards: [ 0  3  3  0  3  0  3  1  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11
  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11
  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 64 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [22. 10. 16.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10. 16.] 
expected returns: [[30.325481]
 [27.584122]
 [28.122818]
 [27.890245]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 10. 16.  0.  1.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  3  0  3  1  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11
  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11
  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -4.030916690826416
desired expected reward: 106.43981170654297



action possibilites: [-1. 22. 16. 11.] 
expected returns: [[13.648671 ]
 [ 8.779863 ]
 [ 9.1123085]
 [10.184269 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 16.  0.  1. 11.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  0  3  0  3  1  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11
  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11
  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 64 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action 10.0
Learning step: 0.6817094683647156
desired expected reward: 28.80453872680664



action possibilites: [-1. 16. 11.] 
expected returns: [[37.96564 ]
 [24.491007]
 [29.582525]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1. 11.  3.  1.  6.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 22. 14.] 
owned cards: [ 0  3  3  0  3  0  3  1  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11
  1  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11
  6  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 77 

action type: LIBRARY: skip_action_card - action 0
Learning step: 4.070812702178955
desired expected reward: 13.602970123291016



action possibilites: [-1] 
expected returns: [[41.550034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1.  6.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 22. 14. 16.] 
owned cards: [ 0  3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1
  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6
  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  20   0   0  80   0   0   0   0 -29   0   0  25   0] 
sum of rewards: 93 

action type: gain_card_n - action 11
Learning step: 2.9042725563049316
desired expected reward: 56.51634216308594





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[33.90993 ]
 [34.07745 ]
 [36.549274]
 [34.292084]
 [34.4596  ]
 [41.55003 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.  6.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 22. 14. 16.] 
owned cards: [ 0  3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1
  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6
  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22] -> size -> 64 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 97 

action type: take_action - action -1
Learning step: 3.5837604999542236
desired expected reward: 45.133792877197266






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.] 
adversary owned cards: [ 0  3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1
  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6
  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22] -> size -> 64 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.] 
adversary owned cards: [ 0  3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1
  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6
  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22] -> size -> 64 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[11.586304]
 [ 8.476427]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  3. 15.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1
  8  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6
  3 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -1.0002750158309937
desired expected reward: 40.54975891113281



action possibilites: [-1] 
expected returns: [[48.797924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22] -> size -> 63 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action 15.0
Learning step: 2.5241315364837646
desired expected reward: 11.000564575195312





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[39.27466 ]
 [39.488644]
 [42.633392]
 [39.724842]
 [39.938835]
 [48.797924]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22] -> size -> 63 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 19. 30. 19. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: 0.3540712296962738
desired expected reward: 49.15199661254883



buy possibilites: [-1] 
expected returns: [[43.16741]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3] -> size -> 64 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 19. 30. 18. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  30.   0.   0.  20.   0.   0.   0.   0. -29.   0.   0.
   2.   0.] 
sum of rewards: 21.0 

action type: buy - action 3.0
Learning step: 0.04683418199419975
desired expected reward: 39.535484313964844






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 18. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 3. 10.  0. 10.  6.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.] 
adversary owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3] -> size -> 64 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 18. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 3. 10.  0. 10.  6.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.] 
adversary owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3] -> size -> 64 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[48.859882]
 [42.880077]
 [42.880077]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.  6.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 18. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: 0.255179226398468
desired expected reward: 43.42259216308594



action possibilites: [-1. 10.] 
expected returns: [[50.78372]
 [43.94914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  6.  0.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3] -> size -> 64 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 18. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 49 

action type: take_action - action 10.0
Learning step: 1.3750826120376587
desired expected reward: 44.25517654418945





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[43.547886]
 [43.773647]
 [50.78372 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6.  0.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3] -> size -> 64 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 19. 30. 18. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: 0.9012476205825806
desired expected reward: 51.68498229980469



buy possibilites: [-1] 
expected returns: [[29.183014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6.  0.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3  3] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 17. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  40   0   0  20   0   0   0   0 -30   0   0   8   0] 
sum of rewards: 37 

action type: buy - action 3.0
Learning step: 0.3292226791381836
desired expected reward: 43.87712478637695






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 17. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 1. 25. 29.  6.  3.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.  3. 10.  3.  0. 10.  6.  0.] 
adversary owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3  3] -> size -> 65 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 17. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 1. 25. 29.  6.  3.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.  3. 10.  3.  0. 10.  6.  0.] 
adversary owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3  3] -> size -> 65 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 17. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 1. 25. 29.  6.  3.] 
adversary cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.  3. 10.  3.  0. 10.  6.  0.] 
adversary owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3  3] -> size -> 65 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [ 1. 25. 29.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[75.16821]
 [72.41112]
 [71.36938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 29.  6.  3.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.  3. 10.  3.  0. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3  3] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 17. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: 2.1351020336151123
desired expected reward: 31.318115234375





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[68.2173 ]
 [68.43878]
 [75.16821]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 29.  6.  3.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.  3. 10.  3.  0. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3  3] -> size -> 65 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 19. 30. 17. 30.  8.  0.  5.  4.  1.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -0.21526794135570526
desired expected reward: 74.95294189453125



Player 0 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 7 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 3 
Workshop: 5 
Chapel: 5 
Witch: 1 
Poacher: 1 
Militia: 5 
Market: 0 
Village: 2 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 25. 29.  6.  3.] 
cards in discard: [ 1.  0.  3.  6. 14.  1.  8.  3. 15.  1. 16. 11.  1.  3.  0.  1.  8.  0.
  6.  0.  0. 16.  8.  3. 16.  1.  8. 11.  8.  3.  8. 22. 10. 22. 14. 16.
  0. 11.  3.  1.  6.  3. 15.  3.  6.  3.  3. 10.  3.  0. 10.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  3  0  3  0 15 29  0 11 16 14  1  0  1  3 15  8  6  8 11  1  8
  0  6  6  6 11  1  6 14  8  1 10 10  0 10 16  6  0 14  3 16  0 11  6  3
 22 25  3  6  1 14  1  3  1  1 16  8  8  3 22  3  3  8] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 17. 30.  8.  0.  5.  4.  0.  9.  8.  4. 10.  4.  8.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5 500   4  40   0   0   0   0   0   0   0 -31   0   0   4   0] 
sum of rewards: 512 

action type: buy - action 8.0
Learning step: 22.17806053161621
desired expected reward: 90.61685180664062



