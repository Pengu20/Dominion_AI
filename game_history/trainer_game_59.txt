 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.6768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -4  -50    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -559 

action type: buy - action -1
Learning step: -28.43674087524414
desired expected reward: -18.701961517333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[278.28207]
 [287.11865]
 [256.75815]
 [287.52112]
 [306.6606 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.101424217224121
desired expected reward: 299.1541748046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[327.75143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.986584663391113
desired expected reward: 298.6740417480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[299.29224]
 [311.74316]
 [307.84906]
 [285.0698 ]
 [277.69162]
 [305.1662 ]
 [319.89352]
 [308.66513]
 [330.42004]
 [313.9714 ]
 [289.37793]
 [298.96143]
 [305.46585]
 [284.9653 ]
 [303.36475]
 [326.61096]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.759057998657227
desired expected reward: 321.1941223144531



buy possibilites: [-1] 
expected returns: [[320.92]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.212556838989258
desired expected reward: 300.45257568359375






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[302.316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.36658000946045
desired expected reward: 311.5534362792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[286.28256]
 [295.35938]
 [291.59872]
 [269.75595]
 [290.43692]
 [300.24152]
 [293.3829 ]
 [296.94186]
 [278.40466]
 [290.03152]
 [288.6058 ]
 [303.91006]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.609271049499512
desired expected reward: 292.69830322265625



buy possibilites: [-1] 
expected returns: [[305.44345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -7.7704925537109375
desired expected reward: 287.58892822265625






Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[346.28806]
 [326.22275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.7867255210876465
desired expected reward: 297.65673828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[319.37985]
 [330.81454]
 [327.49744]
 [299.10242]
 [338.69397]
 [328.0558 ]
 [325.3146 ]
 [345.92642]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.037202835083008
desired expected reward: 336.40545654296875



buy possibilites: [-1] 
expected returns: [[337.3495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.812427520751953
desired expected reward: 319.2433776855469






Player: 1 
cards in hand: [ 0.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11.  0.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[301.6092 ]
 [281.40436]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.356325149536133
desired expected reward: 326.9931640625



action possibilites: [-1] 
expected returns: [[286.6204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 1 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 2
Learning step: -6.511557102203369
desired expected reward: 259.69873046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[256.8109 ]
 [263.31354]
 [239.24185]
 [264.49692]
 [277.49136]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 1 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.09708023071289
desired expected reward: 278.5233154296875



buy possibilites: [-1] 
expected returns: [[282.04147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 1 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 15 

action type: buy - action 8.0
Learning step: -6.128912448883057
desired expected reward: 258.3680114746094






Player: 1 
cards in hand: [ 0. 11.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 11.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[299.80618]
 [284.18716]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 8.  0. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.228839874267578
desired expected reward: 273.8126220703125



action possibilites: [-1] 
expected returns: [[270.97177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 8.  0. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 0
Learning step: -6.296547889709473
desired expected reward: 248.57168579101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[241.327  ]
 [252.67505]
 [249.98993]
 [221.84676]
 [261.23685]
 [249.7825 ]
 [247.83513]
 [269.05658]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 8.  0. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -7.559091091156006
desired expected reward: 263.4126892089844






Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [ 8.  0. 11.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 11  0  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8.  0. 11.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0. 11.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0. 11.  3. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [8. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[245.8209 ]
 [229.65639]
 [229.65639]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 11.  3. 11.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -8.817712783813477
desired expected reward: 260.2388916015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[222.4418 ]
 [229.8752 ]
 [203.95642]
 [230.64473]
 [247.01611]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 11.  3. 11.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.767299175262451
desired expected reward: 237.2869415283203



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [ 8.  0. 11.  3. 11.  0.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [ 8.  0. 11.  3. 11.  0.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [ 8.  0. 11.  3. 11.  0.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[265.57507]
 [249.70978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -7.224255561828613
desired expected reward: 239.79188537597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[242.88786]
 [254.50276]
 [250.8687 ]
 [223.0472 ]
 [261.89438]
 [251.68748]
 [248.60443]
 [268.91064]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 1 8 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.191733360290527
desired expected reward: 255.8799285888672



buy possibilites: [-1] 
expected returns: [[261.38275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [8. 8. 3. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 1 8 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  3. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -7.2532639503479
desired expected reward: 244.4342498779297






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  3. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  3. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  2. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 1 8 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[274.50244]
 [257.49518]
 [257.49518]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 1 8 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  2. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [8. 8. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.769842624664307
desired expected reward: 253.6129150390625



action possibilites: [-1] 
expected returns: [[229.95274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8 8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  2. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [8. 8. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 14
Learning step: -7.13839054107666
desired expected reward: 235.10813903808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[202.18355]
 [187.45331]
 [218.62056]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  2. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [8. 8. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.110049724578857
desired expected reward: 222.8426971435547






Player: 1 
cards in hand: [ 8.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  0.] 
cards in discard: [8. 8. 0. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  2. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [8.] 
adversary owned cards: [0 0 0 0 3 8 8 8] -> size -> 8 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  0.] 
cards in discard: [8. 8. 0. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  2. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [8.] 
adversary owned cards: [0 0 0 0 3 8 8 8] -> size -> 8 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  0.] 
cards in discard: [8. 8. 0. 0. 0. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  1. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [8.] 
adversary owned cards: [0 0 0 0 3 8 8 8] -> size -> 8 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[230.94267]
 [214.74214]
 [214.74214]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 8 8 8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  1. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8. 11.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  8.  8.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -7.135188579559326
desired expected reward: 211.4853973388672



action possibilites: [-1] 
expected returns: [[207.07094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  1. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8. 11.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  8.  8.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.816311836242676
desired expected reward: 218.6918487548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[179.80743]
 [187.97765]
 [185.47159]
 [165.30226]
 [193.35094]
 [186.01898]
 [183.95596]
 [197.7572 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  1. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8. 11.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  8.  8.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -6.371354103088379
desired expected reward: 200.6995849609375



buy possibilites: [-1] 
expected returns: [[208.63551]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8 6] -> size -> 8 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8. 11.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  8.  8.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -315.0 

action type: buy - action 6.0
Learning step: -18.95149803161621
desired expected reward: 138.9644775390625






Player: 1 
cards in hand: [11.  0.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8. 11.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  8.  8.  0.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 8 8 6] -> size -> 8 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 11.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  8.  8.  0.  3. 10.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 8 8 6] -> size -> 8 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 11.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  8.  8.  0.  3. 10.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 8 8 6] -> size -> 8 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[211.11049]
 [195.84256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 8 8 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -7.603445529937744
desired expected reward: 201.03207397460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[187.88043]
 [197.8943 ]
 [194.38266]
 [172.0503 ]
 [204.34682]
 [195.39078]
 [192.59328]
 [209.59239]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 8 8 6] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -7.844983100891113
desired expected reward: 201.97015380859375



buy possibilites: [-1] 
expected returns: [[194.14024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  6 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -17 

action type: buy - action 10.0
Learning step: -6.111509323120117
desired expected reward: 186.48178100585938






Player: 1 
cards in hand: [10.  8.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  6 10] -> size -> 9 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  6 10] -> size -> 9 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  6 10] -> size -> 9 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  6 10] -> size -> 9 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[209.84166]
 [197.5557 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  6 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 3. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -6.901084899902344
desired expected reward: 187.23916625976562



action possibilites: [-1] 
expected returns: [[187.49442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8 10] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 3. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.0948052406311035
desired expected reward: 196.1737823486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[151.30113]
 [160.37453]
 [157.3944 ]
 [136.26598]
 [166.05795]
 [158.15569]
 [155.62393]
 [170.58147]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 3. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -6.020900249481201
desired expected reward: 181.4735107421875



buy possibilites: [-1] 
expected returns: [[162.81564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8 10 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 3. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 10.0
Learning step: -3.41784405708313
desired expected reward: 152.20606994628906






Player: 1 
cards in hand: [8. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 8. 0.] 
cards in discard: [ 0. 10.  8.  8.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8 10 10] -> size -> 9 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 8. 0.] 
cards in discard: [ 0. 10.  8.  8.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8 10 10] -> size -> 9 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[209.5802 ]
 [194.40337]
 [197.23999]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8 10 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0.  0.  8.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -4.893787384033203
desired expected reward: 157.92185974121094



action possibilites: [-1] 
expected returns: [[205.38078]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8 10] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0.  0.  8.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 10
Learning step: -5.336148738861084
desired expected reward: 189.80816650390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[187.29784]
 [171.1422 ]
 [201.32542]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8 10] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0.  0.  8.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -6.796970367431641
desired expected reward: 198.5838165283203



buy possibilites: [-1] 
expected returns: [[190.57794]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8 10  6] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  8. 10.  8.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  3.] 
adversary cards in discard: [ 0. 10.  8.  8.  8.  0.  0.  8.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -326.0 

action type: buy - action 6.0
Learning step: -20.56910514831543
desired expected reward: 150.57305908203125






Player: 1 
cards in hand: [11. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  3.] 
cards in discard: [ 0. 10.  8.  8.  8.  0.  0.  8.  3.  3.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  8. 10.  8.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8 10  6] -> size -> 7 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [ 0. 10.  8.  8.  8.  0.  0.  8.  3.  3.  8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8 10  6] -> size -> 7 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [ 0. 10.  8.  8.  8.  0.  0.  8.  3.  3.  8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8 10  6] -> size -> 7 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [ 0. 10.  8.  8.  8.  0.  0.  8.  3.  3.  8.  0. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8 10  6] -> size -> 7 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[195.70515]
 [181.34645]
 [184.32036]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8 10  6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -8.171683311462402
desired expected reward: 182.40626525878906



action possibilites: [-1.  8.  8.] 
expected returns: [[143.30116]
 [133.36113]
 [133.36113]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8  8 10  6] -> size -> 7 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 10.0
Learning step: -7.412610054016113
desired expected reward: 170.7424774169922



action possibilites: [-1.] 
expected returns: [[171.87086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  8 10  6] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.7012557983398438
desired expected reward: 131.66574096679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[137.33774]
 [147.25229]
 [143.6155 ]
 [120.16129]
 [152.81953]
 [144.92178]
 [141.752  ]
 [157.49919]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  8 10  6] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -6.149051189422607
desired expected reward: 165.72181701660156



buy possibilites: [-1] 
expected returns: [[177.7695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  8 10  6  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -3.3309617042541504
desired expected reward: 140.2845458984375






Player: 1 
cards in hand: [11.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3] -> size -> 7 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3] -> size -> 7 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[176.22878]
 [162.72478]
 [160.73177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -7.456437587738037
desired expected reward: 170.3130645751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[150.38786]
 [136.93567]
 [170.0323 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -7.4138336181640625
desired expected reward: 165.03472900390625



buy possibilites: [-1] 
expected returns: [[158.99728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  6.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -21.069345474243164
desired expected reward: 115.8663101196289






Player: 1 
cards in hand: [ 8. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  0.  0.] 
cards in discard: [11.  0.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6] -> size -> 8 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6] -> size -> 8 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11.  0.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6] -> size -> 8 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  0.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6] -> size -> 8 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  0.  0.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6] -> size -> 8 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[181.14772]
 [172.1586 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11. 10.  8.  3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -6.734992504119873
desired expected reward: 152.26229858398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[159.22275]
 [167.06651]
 [164.05928]
 [144.54216]
 [171.3686 ]
 [165.23714]
 [162.54878]
 [175.00229]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11. 10.  8.  3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -8.237966537475586
desired expected reward: 174.52301025390625



buy possibilites: [-1] 
expected returns: [[192.3185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11. 10.  8.  3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -38 

action type: buy - action 1.0
Learning step: -5.926158905029297
desired expected reward: 161.1403350830078






Player: 1 
cards in hand: [ 8. 11. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  8.  3.] 
cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.] 
cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.] 
cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  6.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[142.24284]
 [131.69432]
 [128.89563]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  6. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.  8. 11. 10.  8.] 
adversary owned cards: [ 0  0  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -8.864391326904297
desired expected reward: 183.4541015625



action possibilites: [-1.  8.] 
expected returns: [[146.51582]
 [134.08037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.  8. 11. 10.  8.] 
adversary owned cards: [ 0  0  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: -4.58538818359375
desired expected reward: 125.45758056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[127.14811]
 [132.94586]
 [113.12354]
 [133.28587]
 [145.21996]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.  8. 11. 10.  8.] 
adversary owned cards: [ 0  0  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -5.668984413146973
desired expected reward: 140.84683227539062






Player: 1 
cards in hand: [3. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 8. 0.] 
cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.  8. 11. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 11 11  0  8  8  0  8  8  8 15  0 29  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.  8. 11. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.  8. 11. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0.  0.  0. 15.  0. 29.  8.  3.  0.  8. 11. 10.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[183.8408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0] -> size -> 17 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1.0
Learning step: -4.39218282699585
desired expected reward: 140.82777404785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[159.89433]
 [167.07607]
 [164.37181]
 [151.44249]
 [147.0082 ]
 [163.2835 ]
 [171.33052]
 [165.38992]
 [177.93884]
 [168.17522]
 [153.49382]
 [159.15616]
 [163.05498]
 [150.9238 ]
 [161.79929]
 [174.87943]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6  1] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 28. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0] -> size -> 17 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -6.883841037750244
desired expected reward: 178.3968505859375



buy possibilites: [-1] 
expected returns: [[162.47678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6  1  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -13.0 

action type: buy - action 3.0
Learning step: -4.965357780456543
desired expected reward: 159.4064483642578






Player: 1 
cards in hand: [ 0.  0. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  6.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1  3] -> size -> 10 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  1. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  6.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1  3] -> size -> 10 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  0. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  6.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1  3] -> size -> 10 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  0. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  6.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1  3] -> size -> 10 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  6  3  6  1  3] -> size -> 10 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  6. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[147.51006]
 [132.20255]
 [134.68202]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 10.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  6  3  6  1  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  8.  8. 15.  0.] 
adversary cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -5.772167205810547
desired expected reward: 156.70460510253906



action possibilites: [-1] 
expected returns: [[114.92047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 3 1 3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  8.  8. 15.  0.] 
adversary cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.5006351470947266
desired expected reward: 145.2262725830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.34111 ]
 [ 77.71683 ]
 [105.267334]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 3 1 3] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  7. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  8.  8. 15.  0.] 
adversary cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -2.323190450668335
desired expected reward: 112.59728240966797



buy possibilites: [-1] 
expected returns: [[136.02792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 3 1 3 6] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  8.  8. 15.  0.] 
adversary cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5    0    1    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -284 

action type: buy - action 6.0
Learning step: -15.025214195251465
desired expected reward: 62.69159698486328






Player: 1 
cards in hand: [ 8.  8.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 15.  0.] 
cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 11 11  0  8  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [0 0 0 8 3 1 3 6] -> size -> 8 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.] 
cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 11 11  0  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [0 0 0 8 3 1 3 6] -> size -> 8 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.] 
cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 11 11  0  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [0 0 0 8 3 1 3 6] -> size -> 8 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[129.78938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [6. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 3 1 3 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.  8.  8. 15.] 
adversary owned cards: [ 0 10 11 11  0  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -4.0903639793396
desired expected reward: 131.93756103515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[110.939354]
 [118.125725]
 [115.356964]
 [102.5169  ]
 [ 97.88653 ]
 [114.27779 ]
 [122.20354 ]
 [128.65567 ]
 [119.27378 ]
 [104.6983  ]
 [110.07701 ]
 [114.06502 ]
 [101.93849 ]
 [112.821655]
 [125.31848 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [6. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 3 1 3 6] -> size -> 8 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.  8.  8. 15.] 
adversary owned cards: [ 0 10 11 11  0  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -4.096754550933838
desired expected reward: 125.28245544433594



buy possibilites: [-1] 
expected returns: [[86.93933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [ 6.  8.  3. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.  8.  8. 15.] 
adversary owned cards: [ 0 10 11 11  0  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 46 

action type: buy - action 23.0
Learning step: -1.2477153539657593
desired expected reward: 108.82928466796875






Player: 1 
cards in hand: [ 0.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 10.] 
cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.  8.  8. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 11 11  0  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23] -> size -> 9 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  8.] 
cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.  8.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 11 11  0  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23] -> size -> 9 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.  8.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 11  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23] -> size -> 9 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 15. 29. 11.  0.  0.  3.  0.  8.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 11  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23] -> size -> 9 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[123.256134]
 [113.09627 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [15.  8. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -1.847420334815979
desired expected reward: 85.09191131591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[102.37814 ]
 [110.27523 ]
 [107.492935]
 [ 90.23732 ]
 [114.733505]
 [105.90444 ]
 [118.555984]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  8.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [15.  8. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -4.030074596405029
desired expected reward: 121.12957763671875



buy possibilites: [-1] 
expected returns: [[83.9296]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  7.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [15.  8. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 14 

action type: buy - action 11.0
Learning step: -3.148259162902832
desired expected reward: 111.58524322509766






Player: 1 
cards in hand: [15.  8. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.  8. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10.  8. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  7.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 15.  8.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8. 15.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 11  0  8  8  8 15  0 29  3  0  0  8 15] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  7.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10 11  8  8  8 15  0 29  3  0  0  8 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  7.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [10 11  8  8  8  0 29  3  0  0  8 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  7.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [10 11  8  8  8  0 29  3  0  0  8 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  7.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  6.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 23.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[75.54852]
 [65.67747]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  6.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [11. 10. 15.  8.  8.] 
adversary owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -2.935596227645874
desired expected reward: 80.99401092529297



action possibilites: [-1.] 
expected returns: [[79.92772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  6.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [11. 10. 15.  8.  8.] 
adversary owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 18 

action type: take_action - action 23.0
Learning step: -0.28493309020996094
desired expected reward: 59.381202697753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[69.46047 ]
 [74.87453 ]
 [72.40368 ]
 [63.290237]
 [59.831257]
 [71.853836]
 [77.82281 ]
 [83.20416 ]
 [75.68585 ]
 [64.67941 ]
 [68.44396 ]
 [71.454765]
 [62.626465]
 [70.50296 ]
 [79.861275]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11] -> size -> 10 
action values: 0 
buys: 2 
player value: 5 
card supply: [25. 28. 30. 27. 30.  8.  6. 10.  6.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [11. 10. 15.  8.  8.] 
adversary owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -1.577767014503479
desired expected reward: 78.3499526977539



buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ 94.05812 ]
 [ 99.17866 ]
 [ 97.15499 ]
 [ 85.503624]
 [102.783066]
 [ 96.24608 ]
 [105.6859  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 26. 30.  8.  6. 10.  6.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [11. 10. 15.  8.  8.] 
adversary owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0.1311653107404709
desired expected reward: 72.53483581542969






Player: 1 
cards in hand: [ 0.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  0.] 
cards in discard: [11. 10. 15.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  6. 10.  6.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [23.  3. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3] -> size -> 11 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [11. 10. 15.  8.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  6. 10.  5.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [23.  3. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3] -> size -> 11 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [11. 10. 15.  8.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 26. 30.  8.  6. 10.  5.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [23.  3. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3] -> size -> 11 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [11. 10. 15.  8.  8. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [23.  3. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3] -> size -> 11 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [23.  3. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.  8.] 
expected returns: [[58.1107  ]
 [49.568184]
 [56.19796 ]
 [52.813324]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9. 10.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -3.7606430053710938
desired expected reward: 101.92523956298828



action possibilites: [-1] 
expected returns: [[74.88469]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  8.  0.] 
cards in discard: [14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 43 

action type: gain_card_n - action 7
Learning step: 1.6957340240478516
desired expected reward: 44.479156494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.81437]
 [55.21805]
 [73.78768]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  8.  0.] 
cards in discard: [14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -0.932699978351593
desired expected reward: 73.95198822021484



buy possibilites: [-1] 
expected returns: [[72.803024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  8.  0.] 
cards in discard: [14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -1.7026504278182983
desired expected reward: 62.111717224121094






Player: 1 
cards in hand: [11.  0.  8.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  3.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8  8  8  0 29  3  0  0  8 15 11 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [6. 0. 1. 3. 3.] 
adversary cards in discard: [14.  0. 11. 23.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  8 29  0  0  8 15 11 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [6. 0. 1. 3. 3.] 
adversary cards in discard: [14.  0. 11. 23.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  8 29  0  0  8 15 11 11 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [6. 0. 1. 3. 3.] 
adversary cards in discard: [14.  0. 11. 23.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [6. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.64139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 3. 3.] 
cards in discard: [14.  0. 11. 23.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8.  0.  8. 29. 10.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [10  8  8  8 29  0  0  8 15 11 11 11] -> size -> 12 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -0.3062477111816406
desired expected reward: 72.49678039550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ 87.52764 ]
 [ 97.350555]
 [ 94.33963 ]
 [ 72.559326]
 [103.57722 ]
 [ 92.289856]
 [109.107544]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 3. 3.] 
cards in discard: [14.  0. 11. 23.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  4.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8.  0.  8. 29. 10.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [10  8  8  8 29  0  0  8 15 11 11 11] -> size -> 12 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.534083127975464
desired expected reward: 107.86164855957031



buy possibilites: [-1] 
expected returns: [[67.01486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 3. 3.] 
cards in discard: [14.  0. 11. 23.  3.  8.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8.  0.  8. 29. 10.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [10  8  8  8 29  0  0  8 15 11 11 11] -> size -> 12 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 35 

action type: buy - action 11.0
Learning step: -1.9210258722305298
desired expected reward: 101.65617370605469






Player: 1 
cards in hand: [ 8.  0.  8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 29. 10.] 
cards in discard: [8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 29  0  0  8 15 11 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  8 15 11 11 11] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  8 15 11 11 11] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [8. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  8 15 11 11 11  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 23.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 23.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[53.88318]
 [44.75923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11. 11.  0. 15. 11.] 
adversary cards in discard: [ 8.  8.  0.  8. 10.] 
adversary owned cards: [10  8  8  0  8 15 11 11 11  0] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -1.392585039138794
desired expected reward: 65.62227630615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[46.2072  ]
 [51.47236 ]
 [48.5458  ]
 [38.023598]
 [48.453163]
 [53.2716  ]
 [51.84678 ]
 [41.194023]
 [47.638435]
 [46.437042]
 [53.52504 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11. 11.  0. 15. 11.] 
adversary cards in discard: [ 8.  8.  0.  8. 10.] 
adversary owned cards: [10  8  8  0  8 15 11 11 11  0] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.7425029873847961
desired expected reward: 52.83363723754883



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 11.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 15. 11.] 
cards in discard: [ 8.  8.  0.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  8 15 11 11 11  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 14.  0.  3.] 
adversary cards in discard: [ 3. 23.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.] 
cards in discard: [ 8.  8.  0.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 14.  0.  3.] 
adversary cards in discard: [ 3. 23.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11.] 
cards in discard: [ 8.  8.  0.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 14.  0.  3.] 
adversary cards in discard: [ 3. 23.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[93.95643 ]
 [71.867516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  0.  3.] 
cards in discard: [ 3. 23.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 11. 11. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: 0.04067192226648331
desired expected reward: 53.565704345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[78.79473]
 [83.48762]
 [67.34066]
 [94.91099]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  0.  3.] 
cards in discard: [ 3. 23.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 11. 11. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.9493976831436157
desired expected reward: 90.99417114257812



buy possibilites: [-1] 
expected returns: [[87.09911]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  0.  3.] 
cards in discard: [ 3. 23.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 11. 11. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -2.6300063133239746
desired expected reward: 76.16471862792969






Player: 1 
cards in hand: [ 8. 11. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11. 15.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  3. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 11. 15.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  3. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 11. 15.  0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 15 11 11 11  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  3. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[66.87145 ]
 [65.590546]
 [65.590546]
 [61.10566 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 11.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15. 11.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -2.106548309326172
desired expected reward: 84.99256896972656



action possibilites: [-1] 
expected returns: [[47.975365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  8.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15. 11.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 53 

action type: gain_card_n - action 6
Learning step: 1.4077590703964233
desired expected reward: 47.84149169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.24537 ]
 [34.29561 ]
 [47.634094]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  8.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15. 11.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: 0.3787159025669098
desired expected reward: 48.35408020019531



buy possibilites: [-1] 
expected returns: [[56.051117]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  8.] 
cards in discard: [29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15. 11.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: buy - action 0.0
Learning step: -0.44393330812454224
desired expected reward: 40.65773391723633






Player: 1 
cards in hand: [15. 11.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  8.  8. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 15 11 11 11  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [29.  0. 11.  3.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 15. 11.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  8 15 11 11 11  0  0] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [29.  0. 11.  3.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 11.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 3 
card supply: [20. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [29.  0. 11.  3.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
action values: 1 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [29.  0. 11.  3.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.33435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [29.  0. 11.  3.  3. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0. 11. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: 0.5708336234092712
desired expected reward: 56.621952056884766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[102.4757 ]
 [108.24123]
 [106.24138]
 [ 91.56626]
 [111.52897]
 [105.09306]
 [113.5011 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [29.  0. 11.  3.  3. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 26. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0. 11. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.3704051971435547
desired expected reward: 109.7802505493164



buy possibilites: [-1] 
expected returns: [[84.7566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [29.  0. 11.  3.  3. 11.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 25. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  0. 11. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 30.0 

action type: buy - action 3.0
Learning step: -1.9050445556640625
desired expected reward: 104.33631896972656






Player: 1 
cards in hand: [11.  0. 11. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 11.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 15 11 11 11  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 14. 23.] 
adversary cards in discard: [29.  0. 11.  3.  3. 11.  8.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  8.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  8 15 11 11 11  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 14. 23.] 
adversary cards in discard: [29.  0. 11.  3.  3. 11.  8.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  8.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  8 15 11 11 11  0  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 14. 23.] 
adversary cards in discard: [29.  0. 11.  3.  3. 11.  8.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  0. 14. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
expected returns: [[95.312675]
 [75.62119 ]
 [80.74376 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 14. 23.] 
cards in discard: [29.  0. 11.  3.  3. 11.  8.  3.  0.  0.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -1.4818233251571655
desired expected reward: 83.27477264404297



action possibilites: [-1. 14.] 
expected returns: [[56.579044]
 [39.112473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3] -> size -> 18 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action 23.0
Learning step: -0.9315870404243469
desired expected reward: 77.5131607055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[40.96277 ]
 [46.46295 ]
 [44.949654]
 [34.812195]
 [31.776512]
 [43.518883]
 [51.00164 ]
 [56.111275]
 [47.62984 ]
 [36.788536]
 [41.128963]
 [43.939503]
 [34.802814]
 [43.044754]
 [54.747963]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3] -> size -> 18 
action values: 0 
buys: 2 
player value: 5 
card supply: [20. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 0.06904564052820206
desired expected reward: 56.64807891845703



buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.394905]
 [32.164856]
 [56.00753 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 14.  3.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 54 

action type: buy - action 29.0
Learning step: 1.324911117553711
desired expected reward: 48.954750061035156



buy possibilites: [-1] 
expected returns: [[99.41991]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 14.  3.] 
cards in discard: [29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 15 11 11 11  0  3] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 8.0 

action type: buy - action 0.0
Learning step: 0.4672033488750458
desired expected reward: 43.86209487915039






Player: 1 
cards in hand: [ 8. 15.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8.  8. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 15 11 11 11  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3 29  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  8 11 11 11  0  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3 29  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  8 11 11 11  0  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3 29  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[51.09401 ]
 [46.27803 ]
 [49.611626]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  1  3  6 23 11  3 14  0 11  0 29  0  3 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  3. 11. 11.  0.] 
adversary cards in discard: [ 8.  8.  8. 10.] 
adversary owned cards: [10  8  8  8 11 11 11  0  3] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -3.0000789165496826
desired expected reward: 96.41983032226562



action possibilites: [-1] 
expected returns: [[21.788136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  3. 11. 11.  0.] 
adversary cards in discard: [ 8.  8.  8. 10.] 
adversary owned cards: [10  8  8  8 11 11 11  0  3] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.7091335654258728
desired expected reward: 34.33112335205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.689418]
 [ 7.559415]
 [23.284458]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  6. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  3. 11. 11.  0.] 
adversary cards in discard: [ 8.  8.  8. 10.] 
adversary owned cards: [10  8  8  8 11 11 11  0  3] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: 1.1721616983413696
desired expected reward: 22.960296630859375



buy possibilites: [-1] 
expected returns: [[34.45924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  5. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  3. 11. 11.  0.] 
adversary cards in discard: [ 8.  8.  8. 10.] 
adversary owned cards: [10  8  8  8 11 11 11  0  3] -> size -> 9 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -273.0 

action type: buy - action 6.0
Learning step: -13.252638816833496
desired expected reward: -5.693232536315918






Player: 1 
cards in hand: [11.  3. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11. 11.  0.] 
cards in discard: [ 8.  8.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 11 11 11  0  3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  5. 10.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  3.  3. 11. 29.] 
adversary cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.] 
adversary owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0.] 
cards in discard: [ 8.  8.  8. 10. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  8 11 11 11  0  3 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  5.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  3.  3. 11. 29.] 
adversary cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.] 
adversary owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 11.  0.] 
cards in discard: [ 8.  8.  8. 10. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  8 11 11 11  0  3 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  5.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  3.  3. 11. 29.] 
adversary cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.] 
adversary owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 11.  0.] 
cards in discard: [ 8.  8.  8. 10. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  8 11 11 11  0  3 16  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 24. 30.  8.  5.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  3.  3. 11. 29.] 
adversary cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.] 
adversary owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[31.131393]
 [28.780083]
 [26.565418]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 11. 29.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 30.  8.  5.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -0.7292386293411255
desired expected reward: 33.72999954223633



action possibilites: [-1. 11.] 
expected returns: [[37.95932 ]
 [36.102707]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  3.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 24. 30.  8.  5.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: discard_n_cards - action 1
Learning step: 0.9605466723442078
desired expected reward: 25.44359016418457



action possibilites: [-1] 
expected returns: [[40.803673]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 24. 30.  8.  4.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5    0    1    0    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -264 

action type: gain_card_n - action 3
Learning step: -13.889813423156738
desired expected reward: 18.268085479736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.90793 ]
 [24.013515]
 [40.92755 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 24. 30.  8.  4.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: 0.49320030212402344
desired expected reward: 41.296875



buy possibilites: [-1] 
expected returns: [[103.72462]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [29.  0. 23.  0.  1.  0. 14.  3.  6.  8.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 24. 30.  8.  4.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.   0.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 6.0 

action type: buy - action 0.0
Learning step: 1.088407039642334
desired expected reward: 31.996341705322266






Player: 1 
cards in hand: [ 8. 11.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  8. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 11 11 11  0  3 16  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  4.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 11.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  8 11 11 11  0  3 16  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 11.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  8 11 11 11  0  3 16  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 11.] 
cards in discard: [6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  8 11 11 11  0  3 16  0  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[11.264674  ]
 [ 3.404238  ]
 [-0.94606805]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  3  6 23  3 14  0 11  0 29  0  3 29  0  6  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3. 16.] 
adversary cards in discard: [ 6.  0. 11.  8.  8.  8. 11.] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0  6  0] -> size -> 13 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -4.793888092041016
desired expected reward: 98.93072509765625



action possibilites: [-1] 
expected returns: [[11.301456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3. 16.] 
adversary cards in discard: [ 6.  0. 11.  8.  8.  8. 11.] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0  6  0] -> size -> 13 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: trash_cards_n_from_hand - action 4
Learning step: 1.9238560199737549
desired expected reward: -5.467608451843262





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 2.9805148 ]
 [-0.63845205]
 [11.564095  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3. 16.] 
adversary cards in discard: [ 6.  0. 11.  8.  8.  8. 11.] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0  6  0] -> size -> 13 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: 0.8504263758659363
desired expected reward: 12.151883125305176



buy possibilites: [-1] 
expected returns: [[-10.35554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3. 16.] 
adversary cards in discard: [ 6.  0. 11.  8.  8.  8. 11.] 
adversary owned cards: [10  8  8  8 11 11 11  0  3 16  0  6  0] -> size -> 13 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -4.0 

action type: buy - action 0.0
Learning step: -0.582025408744812
desired expected reward: 2.398489475250244






Player: 1 
cards in hand: [ 0.  0. 10.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 16.] 
cards in discard: [ 6.  0. 11.  8.  8.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 11 11 11  0  3 16  0  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  7.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 11.  6.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 6.  0. 11.  8.  8.  8. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  8 11 11 11  0 16  0  6  0 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 11.  6.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0] -> size -> 19 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 6.  0. 11.  8.  8.  8. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  8 11 11 11  0 16  0  6  0 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 11.  6.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0] -> size -> 19 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 6.  0. 11.  8.  8.  8. 11. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  8 11 11 11  0 16  0  6  0 29  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 11.  6.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0] -> size -> 19 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[72.28954 ]
 [62.474834]
 [66.93221 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 11.  6.] 
cards in discard: [ 0.  8. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 11 11 11  0 16  0  6  0 29  0] -> size -> 14 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: 2.8089425563812256
desired expected reward: -7.546597480773926





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.040943]
 [36.109264]
 [71.569695]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 11.  6.] 
cards in discard: [ 0.  8. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 24. 30.  8.  3.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 11 11 11  0 16  0  6  0 29  0] -> size -> 14 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -1.5148731470108032
desired expected reward: 69.47254943847656



buy possibilites: [-1] 
expected returns: [[68.243614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 11.  6.] 
cards in discard: [ 0.  8. 14.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 24. 30.  8.  2.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  8 11 11 11  0 16  0  6  0 29  0] -> size -> 14 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 6.0
Learning step: -15.019981384277344
desired expected reward: 21.089263916015625






Player: 1 
cards in hand: [ 8. 10.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8 11 11 11  0 16  0  6  0 29  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 24. 30.  8.  2.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 6. 0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6] -> size -> 20 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 11 11  0 16  0  6  0 29  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 24. 30.  8.  2.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 6. 0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6] -> size -> 20 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 11 11  0 16  0  6  0 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 24. 30.  8.  2.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 6. 0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6] -> size -> 20 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 11 11  0 16  0  6  0 29  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 24. 30.  8.  2.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 6. 0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6] -> size -> 20 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.538731]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0. 16. 29.] 
adversary cards in discard: [0. 8. 8. 0.] 
adversary owned cards: [ 8  8  8 11 11  0 16  0  6  0 29  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: buy - action -1
Learning step: -2.972724199295044
desired expected reward: 65.27088928222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 6.6968155]
 [ 7.4002542]
 [ 7.3896084]
 [ 2.983383 ]
 [ 6.8100986]
 [ 9.471591 ]
 [ 7.8356657]
 [ 5.707674 ]
 [ 7.2486153]
 [ 7.1626005]
 [12.170973 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 24. 30.  8.  2.  9.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0. 16. 29.] 
adversary cards in discard: [0. 8. 8. 0.] 
adversary owned cards: [ 8  8  8 11 11  0 16  0  6  0 29  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0.0022073269356042147
desired expected reward: 8.422497749328613



buy possibilites: [-1] 
expected returns: [[57.580235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 1.] 
cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0. 16. 29.] 
adversary cards in discard: [0. 8. 8. 0.] 
adversary owned cards: [ 8  8  8 11 11  0 16  0  6  0 29  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 37 

action type: buy - action 16.0
Learning step: 2.786942720413208
desired expected reward: 9.597037315368652






Player: 1 
cards in hand: [ 0. 11.  0. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 16. 29.] 
cards in discard: [0. 8. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11  0 16  0  6  0 29  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6. 29.  3.  3. 23.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6. 16.  3.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.] 
cards in discard: [ 0.  8.  8.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8  8 11 11  0 16  0  6  0 29  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6. 29.  3.  3. 23.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6. 16.  3.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  8.  0. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 24. 30.  8.  1.  8.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6. 29.  3.  3. 23.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6. 16.  3.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
adversary victory points: 0
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  8.  0. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 24. 30.  8.  1.  8.  3.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6. 29.  3.  3. 23.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6. 16.  3.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
adversary victory points: 0
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  8.  0. 11.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6. 29.  3.  3. 23.] 
adversary cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6. 16.  3.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
adversary victory points: 0
player victory points: -2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  3.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23.] 
expected returns: [[5.554168 ]
 [2.3481002]
 [2.0616775]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3.  3. 23.] 
cards in discard: [ 0.  8. 14.  0.  6.  0. 29.  3. 11.  6. 16.  3.  6.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  8. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11] -> size -> 14 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action -1
Learning step: -2.0871365070343018
desired expected reward: 55.493099212646484



action possibilites: [-1. 23.] 
expected returns: [[21.901398]
 [12.622362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 23.  0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 24. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  8. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11] -> size -> 14 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 3
Learning step: 2.10571551322937
desired expected reward: 2.9092860221862793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[18.527786 ]
 [20.540455 ]
 [10.4920025]
 [25.266933 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 23.  0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 24. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  8. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11] -> size -> 14 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 1.086440920829773
desired expected reward: 22.987823486328125



buy possibilites: [-1] 
expected returns: [[15.950165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 23.  0.] 
cards in discard: [3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  8. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11] -> size -> 14 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 54 

action type: buy - action 3.0
Learning step: 2.0318562984466553
desired expected reward: 22.57230567932129






Player: 1 
cards in hand: [ 6.  8. 11.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 11.  6.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  3.  8.  0. 16.] 
adversary cards in discard: [ 3.  3. 29.  6.  3. 23.  0.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16  3] -> size -> 22 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 11.  6.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  3.  8.  0. 16.] 
adversary cards in discard: [ 3.  3. 29.  6.  3. 23.  0.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16  3] -> size -> 22 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 11.  6.  8.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  3.  8.  0. 16.] 
adversary cards in discard: [ 3.  3. 29.  6.  3. 23.  0.] 
adversary owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16  3] -> size -> 22 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[ -9.636896]
 [-11.685455]
 [-11.653242]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  0. 16.] 
cards in discard: [ 3.  3. 29.  6.  3. 23.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  1  3  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6 16  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 16.  0. 11.  0.] 
adversary cards in discard: [ 0.  6.  8. 11.  6.  8.] 
adversary owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11  0] -> size -> 15 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1
Learning step: 0.2744309604167938
desired expected reward: 16.22459602355957



action possibilites: [-1] 
expected returns: [[8.194395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  3. 29.  6.  3. 23.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 16.  0. 11.  0.] 
adversary cards in discard: [ 0.  6.  8. 11.  6.  8.] 
adversary owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11  0] -> size -> 15 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 24 

action type: trash_cards_n_from_hand - action 9
Learning step: 1.917559027671814
desired expected reward: -8.746143341064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 1.8288465]
 [-4.414501 ]
 [14.350033 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  3. 29.  6.  3. 23.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 16.  0. 11.  0.] 
adversary cards in discard: [ 0.  6.  8. 11.  6.  8.] 
adversary owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11  0] -> size -> 15 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 24 

action type: take_action - action -1
Learning step: 0.8953750729560852
desired expected reward: 9.089770317077637



buy possibilites: [-1] 
expected returns: [[65.73669]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  3. 29.  6.  3. 23.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 8. 16.  0. 11.  0.] 
adversary cards in discard: [ 0.  6.  8. 11.  6.  8.] 
adversary owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11  0] -> size -> 15 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -6.0 

action type: buy - action 0.0
Learning step: 1.0876320600509644
desired expected reward: 2.9164986610412598






Player: 1 
cards in hand: [ 8. 16.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0. 11.  0.] 
cards in discard: [ 0.  6.  8. 11.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  0  6  0 29  0  0  6 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 23. 30.  8.  1.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 29.  0.] 
adversary cards in discard: [ 3.  3. 29.  6.  3. 23.  0.  0.  8.  0.] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0] -> size -> 20 
adversary victory points: -1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.] 
cards in discard: [ 0.  6.  8. 11.  6.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 23. 30.  8.  0.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 29.  0.] 
adversary cards in discard: [ 3.  3. 29.  6.  3. 23.  0.  0.  8.  0.] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0] -> size -> 20 
adversary victory points: -1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.] 
cards in discard: [ 0.  6.  8. 11.  6.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 23. 30.  8.  0.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 29.  0.] 
adversary cards in discard: [ 3.  3. 29.  6.  3. 23.  0.  0.  8.  0.] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0] -> size -> 20 
adversary victory points: -1
player victory points: -3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[25.604088]
 [22.136175]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 29.  0.] 
cards in discard: [ 3.  3. 29.  6.  3. 23.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 23. 30.  8.  0.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6] -> size -> 15 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 14 

action type: buy - action -1
Learning step: -2.064056873321533
desired expected reward: 63.672630310058594



action possibilites: [-1.] 
expected returns: [[74.208565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 3.  3. 29.  6.  3. 23.  0.  0.  8.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 23. 30.  8.  0.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6] -> size -> 15 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 34 

action type: discard_n_cards - action 0
Learning step: 2.601231336593628
desired expected reward: 17.970458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[65.0948  ]
 [68.90536 ]
 [67.95763 ]
 [71.74606 ]
 [67.233246]
 [74.51429 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 3.  3. 29.  6.  3. 23.  0.  0.  8.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 23. 30.  8.  0.  8.  2.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6] -> size -> 15 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 34 

action type: take_action - action -1.0
Learning step: -0.443960577249527
desired expected reward: 73.76460266113281



buy possibilites: [-1] 
expected returns: [[21.731247]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 3.  3. 29.  6.  3. 23.  0.  0.  8.  0.  0.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6] -> size -> 15 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 52 

action type: buy - action 11.0
Learning step: -0.49835091829299927
desired expected reward: 71.24772644042969






Player: 1 
cards in hand: [ 6.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  6.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11] -> size -> 21 
adversary victory points: -1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  6.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11] -> size -> 21 
adversary victory points: -1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  6.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11] -> size -> 21 
adversary victory points: -1
player victory points: -3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  6.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[14.636843]
 [14.162514]
 [11.608456]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  6. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  6. 11. 16.] 
adversary cards in discard: [ 1. 11.  6.  0.  0. 29.] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1] -> size -> 16 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 14 

action type: buy - action -1
Learning step: -0.07476940006017685
desired expected reward: 21.656476974487305



action possibilites: [-1] 
expected returns: [[-7.4579153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 14.] 
cards in discard: [15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 11.  6. 11. 16.] 
adversary cards in discard: [ 1. 11.  6.  0.  0. 29.] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1] -> size -> 16 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 50 

action type: gain_card_n - action 8
Learning step: 1.6469529867172241
desired expected reward: 15.351832389831543





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.63806 ]
 [ -7.788706]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 14.] 
cards in discard: [15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 11.  6. 11. 16.] 
adversary cards in discard: [ 1. 11.  6.  0.  0. 29.] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1] -> size -> 16 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 34 

action type: take_action - action -1
Learning step: 1.8470152616500854
desired expected reward: -5.610899925231934



buy possibilites: [-1] 
expected returns: [[47.542286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 14.] 
cards in discard: [15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 11.  6. 11. 16.] 
adversary cards in discard: [ 1. 11.  6.  0.  0. 29.] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1] -> size -> 16 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1  20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: buy - action 0.0
Learning step: 1.9016045331954956
desired expected reward: -10.736458778381348






Player: 1 
cards in hand: [ 0. 11.  6. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 11. 16.] 
cards in discard: [ 1. 11.  6.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  6.  9.  9.  7. 10.  7.] 
adversary cards in hand: [29.  1.  0.  8.  3.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0] -> size -> 23 
adversary victory points: -1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11. 16.] 
cards in discard: [ 1. 11.  6.  0.  0. 29. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [29.  1.  0.  8.  3.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0] -> size -> 23 
adversary victory points: -1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11. 16.] 
cards in discard: [ 1. 11.  6.  0.  0. 29. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [29.  1.  0.  8.  3.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.] 
adversary owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0] -> size -> 23 
adversary victory points: -1
player victory points: -3 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [29.  1.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[67.86038 ]
 [59.674316]
 [56.47095 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  8.  3.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 8. 8. 8.] 
adversary cards in discard: [ 1. 11.  6.  0.  0. 29. 29. 11.  0.  6. 11. 16.] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1 29] -> size -> 17 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 14 

action type: buy - action -1
Learning step: -0.36216601729393005
desired expected reward: 47.180118560791016



action possibilites: [-1] 
expected returns: [[-5.4865603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 8. 8. 8.] 
adversary cards in discard: [ 1. 11.  6.  0.  0. 29. 29. 11.  0.  6. 11. 16.] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1 29] -> size -> 17 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 34 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.7316379547119141
desired expected reward: 45.432167053222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.3337474]
 [-2.8943017]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 8. 8. 8.] 
adversary cards in discard: [ 1. 11.  6.  0.  0. 29. 29. 11.  0.  6. 11. 16.] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1 29] -> size -> 17 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 34 

action type: take_action - action -1
Learning step: 1.8837347030639648
desired expected reward: -3.60282564163208



buy possibilites: [-1] 
expected returns: [[1.0990155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 8. 8. 8.] 
adversary cards in discard: [ 1. 11.  6.  0.  0. 29. 29. 11.  0.  6. 11. 16.] 
adversary owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1 29] -> size -> 17 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 4.0 

action type: buy - action 0.0
Learning step: 0.491415411233902
desired expected reward: -4.842336177825928






Player: 1 
cards in hand: [6. 0. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 8. 8.] 
cards in discard: [ 1. 11.  6.  0.  0. 29. 29. 11.  0.  6. 11. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6  0 29  0  0  6 11  0  6  1 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 29.  0.  0.  6.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0] -> size -> 23 
adversary victory points: -1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8.] 
cards in discard: [ 1. 11.  6.  0.  0. 29. 29. 11.  0.  6. 11. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 29.  0.  0.  6.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0] -> size -> 23 
adversary victory points: -1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8.] 
cards in discard: [ 1. 11.  6.  0.  0. 29. 29. 11.  0.  6. 11. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 29.  0.  0.  6.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0] -> size -> 23 
adversary victory points: -1
player victory points: -3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.658375]
 [18.362688]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  6.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29] -> size -> 16 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 14 

action type: buy - action -1
Learning step: 1.0762604475021362
desired expected reward: 2.1752758026123047



action possibilites: [-1.] 
expected returns: [[37.341114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.  0. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29] -> size -> 16 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 34 

action type: discard_n_cards - action 0
Learning step: 2.0098745822906494
desired expected reward: 12.61588191986084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[28.701544]
 [33.791286]
 [32.70907 ]
 [37.7196  ]
 [31.684034]
 [40.750957]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.  0. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 23. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29] -> size -> 16 
adversary victory points: -3
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 34 

action type: take_action - action -1.0
Learning step: 0.6135812997817993
desired expected reward: 37.95469665527344



buy possibilites: [-1] 
expected returns: [[-13.258568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.  0. 23.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 22. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29] -> size -> 16 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 47.0 

action type: buy - action 3.0
Learning step: 0.4162285029888153
desired expected reward: 33.12530517578125






Player: 1 
cards in hand: [11.  0.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 22. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 11.  6.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.  0. 23.  3. 29.  0.  0.
  6.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  8.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 30. 22. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 11.  6.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.  0. 23.  3. 29.  0.  0.
  6.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  8.  6.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 11.  6.] 
adversary cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.  0. 23.  3. 29.  0.  0.
  6.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
adversary victory points: 0
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-1.5943844]
 [-1.0958786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  6.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.  0. 23.  3. 29.  0.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11.  8. 16. 29.  8.] 
adversary cards in discard: [ 3. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3] -> size -> 17 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action -1
Learning step: 1.3830660581588745
desired expected reward: -11.87550163269043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-1.6578221]
 [-1.0478957]
 [-1.3376064]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  6.] 
cards in discard: [15.  0. 11.  3.  6.  6. 14.  0.  8. 29.  0.  3.  0. 23.  3. 29.  0.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11.  8. 16. 29.  8.] 
adversary cards in discard: [ 3. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3] -> size -> 17 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.7998789548873901
desired expected reward: -0.794500470161438



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8. 16. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 16. 29.  8.] 
cards in discard: [ 3. 11.  0.  0.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
adversary victory points: 0
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 16. 29.  8.] 
cards in discard: [ 3. 11.  0.  0.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
adversary victory points: 0
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 16. 29.  8.] 
cards in discard: [ 3. 11.  0.  0.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
adversary victory points: 0
player victory points: -2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[32.758575]
 [20.70821 ]
 [30.744083]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 1. 11.  6. 29.  0.] 
adversary cards in discard: [ 3. 11.  0.  0.  8.  6.  0. 11.  8. 16. 29.  8.] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0] -> size -> 18 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action -1.0
Learning step: 1.352734923362732
desired expected reward: 1.0255526304244995



action possibilites: [-1] 
expected returns: [[38.473324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 1. 11.  6. 29.  0.] 
adversary cards in discard: [ 3. 11.  0.  0.  8.  6.  0. 11.  8. 16. 29.  8.] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0] -> size -> 18 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: gain_card_n - action 0
Learning step: 0.019408607855439186
desired expected reward: 21.944232940673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[31.904919]
 [34.6474  ]
 [41.588634]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 21. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 1. 11.  6. 29.  0.] 
adversary cards in discard: [ 3. 11.  0.  0.  8.  6.  0. 11.  8. 16. 29.  8.] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0] -> size -> 18 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6463512778282166
desired expected reward: 39.11967468261719



buy possibilites: [-1] 
expected returns: [[28.061348]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [0. 3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 1. 11.  6. 29.  0.] 
adversary cards in discard: [ 3. 11.  0.  0.  8.  6.  0. 11.  8. 16. 29.  8.] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0] -> size -> 18 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 54 

action type: buy - action 3.0
Learning step: 1.5990110635757446
desired expected reward: 36.24639892578125






Player: 1 
cards in hand: [ 1. 11.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6. 29.  0.] 
cards in discard: [ 3. 11.  0.  0.  8.  6.  0. 11.  8. 16. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  6. 29. 23.  3.] 
adversary cards in discard: [ 0.  3. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3] -> size -> 26 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  6. 29.  0.] 
cards in discard: [ 3. 11.  0.  0.  8.  6.  0. 11.  8. 16. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 27. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  6. 29. 23.  3.] 
adversary cards in discard: [ 0.  3. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3] -> size -> 26 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  6. 29.  0.] 
cards in discard: [ 3. 11.  0.  0.  8.  6.  0. 11.  8. 16. 29.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  6. 29. 23.  3.] 
adversary cards in discard: [ 0.  3. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3] -> size -> 26 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 29. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23.] 
expected returns: [[25.120586]
 [22.497126]
 [19.990646]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29. 23.  3.] 
cards in discard: [ 0.  3. 11.  0. 14.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11. 29.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1
Learning step: 0.4042983949184418
desired expected reward: 28.465646743774414



action possibilites: [-1. 23.] 
expected returns: [[-3.1533103]
 [-4.4383883]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23.  6.] 
cards in discard: [ 0.  3. 11.  0. 14.  0.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11. 29.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: discard_n_cards - action 1
Learning step: 1.1248375177383423
desired expected reward: 22.940732955932617



action possibilites: [-1.] 
expected returns: [[3.1379468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 0.  3. 11.  0. 14.  0.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3] -> size -> 26 
action values: 1 
buys: 1 
player value: 2 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11. 29.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 40  0  0  0  0  0  0  0  0  1] 
sum of rewards: 67 

action type: take_action - action 23.0
Learning step: 3.6425232887268066
desired expected reward: -0.7958617210388184





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[0.7736075]
 [0.4191749]
 [1.2816551]
 [1.8097861]
 [1.6155236]
 [3.4597127]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 0.  3. 11.  0. 14.  0.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3] -> size -> 26 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 6. 27. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11. 29.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1.0
Learning step: 3.181272506713867
desired expected reward: 6.319219589233398



buy possibilites: [ 0. -1.] 
expected returns: [[-6.0939503]
 [ 1.4248946]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 0.  3. 11.  0. 14.  0.  3.  0.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [11. 29.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 75 

action type: buy - action 1.0
Learning step: 3.6825923919677734
desired expected reward: 4.101779937744141






Player: 1 
cards in hand: [11. 29.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  8.  1.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 11.  0. 14.  0.  3.  0.  3.  1. 29. 23.  6.  6.  0.] 
adversary owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3  1] -> size -> 27 
adversary victory points: 1
player victory points: -2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 3 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 1 
Workshop: 3 
Chapel: 4 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 1 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [ 0.  3. 11.  0. 14.  0.  3.  0.  3.  1. 29. 23.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 23  3 14 11  0 29  0  3 29  0  6  6  0  0  6  3  0 11 15  0  0  3
  0  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  8.  0.  0. 10.  5.  9.  9.  7. 10.  7.] 
adversary cards in hand: [29.  0.  6.  6.] 
adversary cards in discard: [11.] 
adversary owned cards: [ 8  8  8 11 11 16  6 29  0  0  6 11  0  6  1 29  3  0  0 11] -> size -> 20 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[ -5 500   1  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 526 

action type: buy - action -1.0
Learning step: 26.2287540435791
desired expected reward: 27.65365219116211



