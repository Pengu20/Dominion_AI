 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[73.12283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      20       0       0
       0       0    -270       0       0      64       0] 
sum of rewards: 2999899 

action type: buy - action 29.0
Learning step: 299986.53125
desired expected reward: 300020.21875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[74.84569]
 [85.24346]
 [79.71028]
 [69.56692]
 [85.34869]
 [80.39142]
 [74.94457]
 [69.56692]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 71.03013610839844



buy possibilites: [-1] 
expected returns: [[64.04235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.34867858886719






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[84.754105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.04235076904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 90.698784]
 [102.65674 ]
 [ 96.275116]
 [ 84.19407 ]
 [ 92.01286 ]
 [102.78115 ]
 [ 97.006485]
 [110.363144]
 [ 90.19179 ]
 [ 90.82102 ]
 [102.126274]
 [ 84.19407 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.2779541015625



buy possibilites: [-1] 
expected returns: [[35.072517]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 110.36314392089844






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[41.552925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.07251739501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[46.222763]
 [55.033165]
 [50.351295]
 [41.60163 ]
 [55.136475]
 [50.858124]
 [46.323433]
 [41.60163 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.88349914550781



buy possibilites: [-1] 
expected returns: [[33.996506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 55.136474609375






Player: 1 
cards in hand: [ 0.  0.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[54.308884]
 [76.968735]
 [70.58327 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 11.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  8. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.99650573730469



action possibilites: [-1. 11.] 
expected returns: [[ 92.006744]
 [111.34048 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  8. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.47793579101562



action possibilites: [-1] 
expected returns: [[49.289513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  8. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 118.582275390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.15271 ]
 [66.03293 ]
 [60.301018]
 [49.443237]
 [56.390472]
 [66.14243 ]
 [60.994118]
 [72.64899 ]
 [54.68888 ]
 [55.2622  ]
 [65.56911 ]
 [49.443237]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  8. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.289512634277344



buy possibilites: [-1] 
expected returns: [[28.548433]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  8. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 72.64898681640625






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 3.  8. 16.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 3.  8. 16.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 3.  8. 16.  0.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.574036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.548433303833008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.079704]
 [45.01616 ]
 [40.70672 ]
 [32.87361 ]
 [45.11171 ]
 [41.16941 ]
 [37.16471 ]
 [32.87361 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.901620864868164



buy possibilites: [-1] 
expected returns: [[15.649269]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.11170959472656






Player: 1 
cards in hand: [0. 1. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 0.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[43.197586]
 [60.407562]
 [55.82473 ]
 [55.82473 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 11.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [14.  0.  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.649269104003906



action possibilites: [-1. 11. 11.] 
expected returns: [[65.63382]
 [78.66697]
 [78.66697]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [14.  0.  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.9141845703125



action possibilites: [-1] 
expected returns: [[16.21614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [14.  0.  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 83.55209350585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.702684]
 [27.61191 ]
 [23.930119]
 [17.222727]
 [27.711752]
 [24.27445 ]
 [20.788279]
 [17.222727]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [14.  0.  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.216140747070312



buy possibilites: [-1] 
expected returns: [[39.692215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  9. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [14.  0.  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.711740493774414






Player: 1 
cards in hand: [ 3.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  3.] 
cards in discard: [14.  0.  1.  8.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  9. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [14.  0.  1.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  9. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [14.  0.  1.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  9. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [14.  0.  1.  8.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  8. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[40.006958]
 [44.030495]
 [55.395752]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  8. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.69221496582031



action possibilites: [-1. 10. 11.] 
expected returns: [[25.255873]
 [29.40793 ]
 [36.75679 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  8. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 53.103553771972656



action possibilites: [-1] 
expected returns: [[27.48982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  8. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.57012939453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.944427]
 [40.302147]
 [36.268936]
 [29.185057]
 [40.383102]
 [36.72666 ]
 [33.01709 ]
 [29.185057]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  6.  8. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.48982048034668



buy possibilites: [-1] 
expected returns: [[26.723558]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5.  8. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.38310241699219






Player: 1 
cards in hand: [14.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5.  8. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5.  8. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[66.68761 ]
 [82.877754]
 [72.52487 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 10.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5.  8. 10.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.72355842590332



action possibilites: [-1] 
expected returns: [[20.67309]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5.  8. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 74.981689453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.427149]
 [37.976234]
 [34.079247]
 [26.259336]
 [38.080673]
 [34.428566]
 [30.531591]
 [26.259336]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5.  8. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.6730899810791



buy possibilites: [-1] 
expected returns: [[8.075002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4.  8. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 38.080657958984375






Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [14.  0. 16.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  3  8  1 14  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4.  8. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 11.] 
adversary cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [14.  0. 16.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4.  8. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 11.] 
adversary cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [14.  0. 16.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4.  8. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 11.] 
adversary cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 2.1999054]
 [13.95788  ]
 [10.910504 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3. 11.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4.  8. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 3. 0. 3. 8.] 
adversary cards in discard: [14.  0. 16.  0.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.07500171661377



action possibilites: [-1. 11.] 
expected returns: [[ 5.0368023]
 [12.161547 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4.  8. 10.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 3. 0. 3. 8.] 
adversary cards in discard: [14.  0. 16.  0.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.204938888549805



action possibilites: [-1] 
expected returns: [[8.115654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4.  8. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [1. 3. 0. 3. 8.] 
adversary cards in discard: [14.  0. 16.  0.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 14.507030487060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 9.882673 ]
 [14.917616 ]
 [12.370201 ]
 [ 7.3221083]
 [15.02002  ]
 [12.463205 ]
 [ 9.981059 ]
 [ 7.3221083]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4.  8. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [1. 3. 0. 3. 8.] 
adversary cards in discard: [14.  0. 16.  0.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.115653991699219



buy possibilites: [-1] 
expected returns: [[10.169849]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 10. 11. 11.  0.  0.  0. 10. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [1. 3. 0. 3. 8.] 
adversary cards in discard: [14.  0. 16.  0.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 15.02001953125






Player: 1 
cards in hand: [1. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 8.] 
cards in discard: [14.  0. 16.  0.  0.  8.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 8.] 
cards in discard: [14.  0. 16.  0.  0.  8.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11. 11. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 29. 11.] 
expected returns: [[17.849396]
 [24.447256]
 [24.447256]
 [24.447256]
 [26.78262 ]
 [24.447256]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 29. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.169849395751953



action possibilites: [-1. 11. 11. 11. 11. 11.] 
expected returns: [[21.206736]
 [28.875704]
 [28.875704]
 [28.875704]
 [28.875704]
 [28.875704]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 11. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.918508529663086



action possibilites: [-1] 
expected returns: [[17.376253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 11.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.538122177124023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.274258]
 [20.188843]
 [20.188843]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11. 11.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.376253128051758



buy possibilites: [-1] 
expected returns: [[21.834833]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11. 11.] 
cards in discard: [10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 23.274255752563477






Player: 1 
cards in hand: [ 0.  8.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  1. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16 10  3  8  1 14  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10. 10.  0.  3.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10. 10.  0.  3.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10. 10.  0.  3.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10. 10.  0.  3.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[0.56063986]
 [4.2047844 ]
 [4.2047844 ]
 [4.2047844 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.  3.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [11.  8.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.8348331451416



action possibilites: [-1. 10. 10.] 
expected returns: [[1.4191661]
 [4.8887672]
 [4.8887672]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [11.  8.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -2.2512378692626953



action possibilites: [-1. 10. 11.] 
expected returns: [[ 4.619707 ]
 [ 7.2425117]
 [11.01555  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 11.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0] -> size -> 26 
action values: 3 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [11.  8.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 4.88875675201416



action possibilites: [-1. 10.] 
expected returns: [[ 8.016169]
 [10.507697]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [11.  8.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 12.974689483642578



action possibilites: [-1.] 
expected returns: [[10.637189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10] -> size -> 27 
action values: 3 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [11.  8.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 10.507698059082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[13.314945 ]
 [19.006763 ]
 [16.157883 ]
 [ 9.9169445]
 [19.117294 ]
 [16.274359 ]
 [13.425476 ]
 [ 9.9169445]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [11.  8.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.637188911437988



buy possibilites: [-1] 
expected returns: [[11.312143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [11.  8.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 19.11729621887207






Player: 1 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [11.  8.  0.  1. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11. 10.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [11.  8.  0.  1. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11. 10.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [11.  8.  0.  1. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11. 10.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[16.597178]
 [24.811014]
 [19.528568]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 10.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 16.] 
adversary cards in discard: [11.  8.  0.  1. 10.  0.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.312143325805664



action possibilites: [-1] 
expected returns: [[7.8214035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.
 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 16.] 
adversary cards in discard: [11.  8.  0.  1. 10.  0.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 27.51245880126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.961244]
 [13.31542 ]
 [ 8.318005]
 [13.433369]
 [ 8.318005]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.
 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 16.] 
adversary cards in discard: [11.  8.  0.  1. 10.  0.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.821403503417969



buy possibilites: [-1] 
expected returns: [[22.341902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.
 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 16.] 
adversary cards in discard: [11.  8.  0.  1. 10.  0.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 13.433374404907227






Player: 1 
cards in hand: [14.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 16.] 
cards in discard: [11.  8.  0.  1. 10.  0.  0.  0.  3.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 10  3  8  1 14  8 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 29.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.
 10.  8. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.] 
cards in discard: [11.  8.  0.  1. 10.  0.  0.  0.  3.  3.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 29.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.
 10.  8. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [11.  8.  0.  1. 10.  0.  0.  0.  3.  3.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  9.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 29.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.
 10.  8. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [11.  8.  0.  1. 10.  0.  0.  0.  3.  3.  8.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 29.] 
adversary cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.
 10.  8. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[ 5.0899925]
 [ 7.434596 ]
 [13.854906 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 29.] 
cards in discard: [10.  0. 29. 11. 11. 11. 11. 11. 10. 11. 10. 10. 11. 10.  0.  3.  0.  0.
 10.  8. 11.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.341901779174805



action possibilites: [-1. 10. 10.] 
expected returns: [[16.575062]
 [19.405733]
 [19.405733]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.854913711547852



action possibilites: [-1. 10.] 
expected returns: [[ 8.502033 ]
 [11.5349865]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 19.405725479125977



action possibilites: [-1.] 
expected returns: [[6.293887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
action values: 3 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 11.534980773925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 9.759716 ]
 [16.062727 ]
 [12.820904 ]
 [ 9.359166 ]
 [ 6.33461  ]
 [10.303389 ]
 [16.154173 ]
 [13.092981 ]
 [19.93967  ]
 [19.53913  ]
 [ 9.450603 ]
 [12.964033 ]
 [ 9.851151 ]
 [ 7.4913235]
 [15.753626 ]
 [ 6.33461  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7. 10.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.293887138366699



buy possibilites: [-1] 
expected returns: [[-0.04695606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7.  9.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 19.939661026000977






Player: 1 
cards in hand: [ 8.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7.  9.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25] -> size -> 31 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  9.  9.  1.  7.  9.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25] -> size -> 31 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  7.  9.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25] -> size -> 31 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[-12.027889]
 [ -7.482403]
 [-10.749215]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  7.  9.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 14. 11.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.04695606231689453



action possibilites: [-1] 
expected returns: [[1.268878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  7.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 14. 11.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -5.048631191253662





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 5.5639353]
 [10.618102 ]
 [ 8.022043 ]
 [ 2.8188863]
 [10.692646 ]
 [ 8.234537 ]
 [ 2.8188863]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  7.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 14. 11.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.2688779830932617



buy possibilites: [-1] 
expected returns: [[0.7693095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  7.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 14. 11.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 10.692649841308594






Player: 1 
cards in hand: [ 3.  0.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14. 11.] 
cards in discard: [ 3.  8.  0.  3. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  7.  9.  8.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  8.  0.  3. 10.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  8.  0.  3. 10.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  8.  0.  3. 10.  0. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[-4.0064764]
 [ 1.1412554]
 [ 1.1412554]
 [-2.1304321]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11. 10.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  6. 16.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  0. 14.  3. 11.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.7693095207214355



action possibilites: [-1] 
expected returns: [[2.5232677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  6. 16.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  0. 14.  3. 11.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 1.0622596740722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[4.823371 ]
 [3.1578102]
 [3.1578102]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  6. 16.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  0. 14.  3. 11.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.5232677459716797



buy possibilites: [-1] 
expected returns: [[-4.3578076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  6. 16.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  0. 14.  3. 11.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 4.823369979858398






Player: 1 
cards in hand: [ 0.  8.  1.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  6. 16.] 
cards in discard: [ 3.  8.  0.  3. 10.  0. 14.  3. 11.  3.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  6. 16.] 
cards in discard: [ 3.  8.  0.  3. 10.  0. 14.  3. 11.  3.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0] -> size -> 35 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  6. 16.] 
cards in discard: [ 3.  8.  0.  3. 10.  0. 14.  3. 11.  3.  0.  0. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0] -> size -> 35 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 10. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11. 11.] 
expected returns: [[ 7.9810905]
 [10.544242 ]
 [10.544242 ]
 [14.860529 ]
 [14.860529 ]
 [14.860529 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11. 11.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.357807636260986



action possibilites: [-1] 
expected returns: [[21.198692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 14.783788681030273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.028389]
 [21.1126  ]
 [21.1126  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.198692321777344



buy possibilites: [-1] 
expected returns: [[13.720228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -20   0   0   0   0] 
sum of rewards: -35 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 24.02838897705078






Player: 1 
cards in hand: [ 0. 10. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  3.  8. 10. 29.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0] -> size -> 37 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0] -> size -> 37 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 26. 30.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0] -> size -> 37 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [4.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.] 
adversary cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0] -> size -> 37 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[ 7.81092 ]
 [10.41305 ]
 [17.247936]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3.  6.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0  -20    0    0
  712    0] 
sum of rewards: 567 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 35.752044677734375



action possibilites: [-1. 10.] 
expected returns: [[20.091932]
 [22.662783]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3.  6.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.902223587036133



action possibilites: [-1. 11.] 
expected returns: [[19.982294]
 [27.064638]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3.  6.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 22.66277503967285



action possibilites: [-1.] 
expected returns: [[9.895239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.  3. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3.  6.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0  -30    0    0
   27    0] 
sum of rewards: -68 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 26.98087501525879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.38121 ]
 [ 9.895243]
 [ 9.895243]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.  3. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3.  6.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.895238876342773



buy possibilites: [-1] 
expected returns: [[8.650631]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 29. 10. 10.  3.  0.  0.  0.  0. 10. 11. 11.  0.  0. 10.  0.  1.  0.
 11.  0.  3. 11. 10.  1.  0. 11. 10. 10. 11. 11. 11.  8.  3. 10.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3.  6.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   60.    0.    0.    0.    0.  -40.
    0.    0.    0.    0.] 
sum of rewards: -105.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 12.381202697753906






Player: 1 
cards in hand: [ 3.  8. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 16.  3.  6.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0] -> size -> 39 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 16.  3.  6.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0] -> size -> 39 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 16.  3.  6.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0] -> size -> 39 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[ 9.226955]
 [18.598137]
 [11.798349]
 [16.321083]
 [16.321083]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  3. 14.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.650630950927734



action possibilites: [-1. 10. 11.] 
expected returns: [[-0.10322952]
 [ 1.9758716 ]
 [ 6.269497  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.] 
cards in discard: [11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  3. 14.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.242204666137695



action possibilites: [-1] 
expected returns: [[-3.5878599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [11.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  3. 14.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0  -50    0    0
   27    0] 
sum of rewards: -108 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 6.183750152587891





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-1.5836349 ]
 [ 0.84030914]
 [-3.4807186 ]
 [ 0.9564462 ]
 [-3.4807186 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [11.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 26. 29.  8.  9.  9.  0.  7.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  3. 14.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.587859869003296



buy possibilites: [-1] 
expected returns: [[-15.868504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [11.  0.  1.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  9.  0.  6.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  8.  0.  3. 14.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0  -60    0    0
   16    0] 
sum of rewards: -129 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 0.9564518928527832






Player: 1 
cards in hand: [ 1.  8.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  3. 14.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  9.  0.  6.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29. 10.  0.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  3. 14.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 26. 29.  8.  9.  9.  0.  6.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29. 10.  0.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  3. 14.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29. 10.  0.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[-10.5009   ]
 [ -5.994936 ]
 [ -4.255099 ]
 [ -9.0810375]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 10.  0.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.  1.  8.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -15.86850357055664



action possibilites: [-1.] 
expected returns: [[2.351943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.  1.  8.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -6.036548614501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[ 6.668809 ]
 [12.944401 ]
 [ 9.792852 ]
 [ 3.1324573]
 [ 7.1088943]
 [ 9.986948 ]
 [16.06555  ]
 [ 6.3334723]
 [12.622231 ]
 [ 3.1324573]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  8.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.  1.  8.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.351943016052246



buy possibilites: [-1] 
expected returns: [[12.074799]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  7.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.  1.  8.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0  -70    0    0
  128    0] 
sum of rewards: -47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 16.065549850463867






Player: 1 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.  1.  8.  0.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  7.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.  3.  1.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.  1.  8.  0.  3. 14.
 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.  3.  1.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.  1.  8.  0.  3. 14.
 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.  3.  1.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 4. 14.  0. 10.  0.  0.  0.  3.  8. 16.  3.  6.  1.  1.  8.  0.  3. 14.
 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.  3.  1.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[ 9.599495]
 [12.023386]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  3.  1.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.074798583984375



action possibilites: [-1. 10.] 
expected returns: [[ 8.840368]
 [11.157385]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  1. 10.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 12.023393630981445



action possibilites: [-1.] 
expected returns: [[14.692919]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 1. 3.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
action values: 3 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 11.157388687133789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[16.633902]
 [21.503891]
 [19.09108 ]
 [16.246563]
 [13.951622]
 [16.858084]
 [19.154911]
 [24.22053 ]
 [23.828243]
 [16.349018]
 [18.927923]
 [14.77725 ]
 [21.222885]
 [13.951622]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 3.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 24. 30. 26. 29.  8.  9.  9.  0.  6.  9.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.69291877746582



buy possibilites: [-1] 
expected returns: [[17.340143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 3.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 29.  8.  9.  9.  0.  6.  8.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0  -80    0    0
  250    0] 
sum of rewards: 85 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 24.220535278320312






Player: 1 
cards in hand: [ 0. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 29.  8.  9.  9.  0.  6.  8.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  0. 10.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25] -> size -> 43 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 26. 29.  8.  9.  9.  0.  6.  8.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  0. 10.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25] -> size -> 43 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  9.  9.  0.  6.  8.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  0. 10.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25] -> size -> 43 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 9.38274 ]
 [17.37488 ]
 [12.274126]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  0. 10.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  9.  9.  0.  6.  8.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  8.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0  3] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.34014320373535



action possibilites: [-1] 
expected returns: [[33.36685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 10.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  9.  0.  6.  8.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  8.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0  3] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0  -90    0    0
   27    0] 
sum of rewards: -198 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 17.297809600830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[37.81655 ]
 [45.152367]
 [41.7175  ]
 [33.366867]
 [38.541573]
 [42.08766 ]
 [48.512222]
 [37.42823 ]
 [44.836975]
 [33.366867]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 10.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 23. 30. 25. 29.  8.  9.  9.  0.  6.  8.  6.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  8.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0  3] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.366851806640625



buy possibilites: [-1] 
expected returns: [[8.747002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 10.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  8.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0  3] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0 -100    0    0
  128    0] 
sum of rewards: -107 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 48.51222229003906






Player: 1 
cards in hand: [ 0. 14.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  8.  3.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1
 29  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 25.  8. 10.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29] -> size -> 45 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 25.  8. 10.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29] -> size -> 45 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 25. 29.  8.  9.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 25.  8. 10.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29] -> size -> 45 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11.  0. 25.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8. 10.] 
expected returns: [[-9.385536 ]
 [-3.8366652]
 [-1.6974125]
 [-5.5634766]
 [-7.38054  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.  8. 10.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.747001647949219



action possibilites: [-1] 
expected returns: [[3.8730612]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 10. 10. 11.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  8.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -1.6974279880523682





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[6.3526  ]
 [3.873064]
 [3.873064]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 10. 10. 11.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 25. 29.  8.  8.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.873061180114746



buy possibilites: [-1] 
expected returns: [[-7.5384607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 10. 10. 11.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 29.  8.  8.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0. -110.
    0.    0.    0.    0.] 
sum of rewards: -215.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 6.352594375610352






Player: 1 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  8.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3. 11.  0. 11.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.  0. 25. 11.  0.  8. 10.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0] -> size -> 46 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 30. 25. 29.  8.  8.  9.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3. 11.  0. 11.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.  0. 25. 11.  0.  8. 10.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0] -> size -> 46 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3. 11.  0. 11.] 
adversary cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.  0. 25. 11.  0.  8. 10.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0] -> size -> 46 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10.  3. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[34.550026]
 [37.017868]
 [41.38109 ]
 [41.38109 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0. 11.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.  0. 25. 11.  0.  8. 10.
 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 29. 14.  4.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.538460731506348



action possibilites: [-1] 
expected returns: [[47.818115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.  0. 25. 11.  0.  8. 10.
 10. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 29. 14.  4.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -168 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 41.32269287109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.108574]
 [47.81813 ]
 [47.81813 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 11.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.  0. 25. 11.  0.  8. 10.
 10. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 29. 14.  4.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.818115234375



buy possibilites: [-1] 
expected returns: [[46.94005]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 11.] 
cards in discard: [11.  0.  1.  8. 29. 11. 10.  0. 11. 10. 29. 29.  0.  0.  0. 25. 10. 10.
  1.  0.  3.  1.  3.  1. 29. 11.  0.  1.  0. 10.  0. 25. 11.  0.  8. 10.
 10. 11.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 29. 14.  4.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.  -90.    0.    0.   20.    0.    0.    0.    0. -130.
    0.    0.    0.    0.] 
sum of rewards: -205.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 51.10856628417969






Player: 1 
cards in hand: [ 1. 29. 14.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 14.  4.  3.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  1.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0] -> size -> 48 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 14.  4.  3.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 22. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  1.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0] -> size -> 48 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  1.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[ 7.2113934]
 [ 9.435995 ]
 [13.335121 ]
 [ 9.435995 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.  1. 29.
 14.  4.  3.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.94004821777344



action possibilites: [-1] 
expected returns: [[-13.600798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 10.] 
cards in discard: [1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.  1. 29.
 14.  4.  3.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: -188 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 13.256418228149414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[ -9.838554 ]
 [ -5.9359665]
 [ -7.846011 ]
 [-12.113202 ]
 [ -7.8827906]
 [-12.113202 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0. 10.] 
cards in discard: [1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 21. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.  1. 29.
 14.  4.  3.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.600797653198242



buy possibilites: [-1] 
expected returns: [[-19.067205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0. 10.] 
cards in discard: [1. 1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.  1. 29.
 14.  4.  3.] 
adversary owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -150    0    0
   54    0] 
sum of rewards: -171 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -5.935971260070801






Player: 1 
cards in hand: [16.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  6. 11.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.  1. 29.
 14.  4.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0
  3  6 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 29.  8.  8.  8.  0.  6.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 29.  0. 10. 25.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1] -> size -> 50 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.  1. 29.
 14.  4.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 29.  8.  8.  8.  0.  5.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 29.  0. 10. 25.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1] -> size -> 50 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.  1. 29.
 14.  4.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 20. 30. 25. 29.  8.  8.  8.  0.  5.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 29.  0. 10. 25.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1] -> size -> 50 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.] 
cards in discard: [ 3.  0. 10.  3.  3.  0.  8. 14.  0.  6. 16.  0.  0.  3.  1.  0.  1. 29.
 14.  4.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 20. 30. 25. 29.  8.  8.  8.  0.  5.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 29.  0. 10. 25.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1] -> size -> 50 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 29.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 25.] 
expected returns: [[ 5.4890404]
 [ 6.933057 ]
 [12.082285 ]
 [ 6.933057 ]
 [12.312473 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 10. 25.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 25. 29.  8.  8.  8.  0.  5.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16. 14.  6. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -19.06720542907715



action possibilites: [-1] 
expected returns: [[6.2606945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 10.  1.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10.] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 25. 29.  8.  7.  8.  0.  5.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16. 14.  6. 29.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6] -> size -> 29 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.312467575073242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[16.454792]
 [19.561575]
 [18.062796]
 [14.749786]
 [16.504494]
 [18.033913]
 [20.90682 ]
 [16.251558]
 [19.358347]
 [14.749786]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 10.  1.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10.] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 20. 30. 25. 29.  8.  7.  8.  0.  5.  8.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16. 14.  6. 29.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6] -> size -> 29 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.26069450378418



buy possibilites: [-1] 
expected returns: [[35.883575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 10.  1.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 25. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16. 14.  6. 29.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6] -> size -> 29 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -160    0    0
  128    0] 
sum of rewards: -107 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 20.90682029724121






Player: 1 
cards in hand: [16. 14.  6. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  6. 29.  8.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 25. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29] -> size -> 51 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 14.  6. 29.  8.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 20. 30. 25. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29] -> size -> 51 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 14.  6. 29.  8.] 
cards in discard: [6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 25. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29] -> size -> 51 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[10.675641]
 [13.906214]
 [19.536478]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 25. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [3. 1. 1. 0. 6.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.883575439453125



action possibilites: [-1] 
expected returns: [[5.1984444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 25. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [3. 1. 1. 0. 6.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: -188 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 18.749675750732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 9.110352 ]
 [12.762398 ]
 [ 5.1984262]
 [12.743105 ]
 [ 5.1984262]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 19. 30. 25. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [3. 1. 1. 0. 6.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.198444366455078



buy possibilites: [-1] 
expected returns: [[16.168312]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [3. 1. 1. 0. 6.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0] -> size -> 30 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -180    0    0
   16    0] 
sum of rewards: -179 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 12.762414932250977






Player: 1 
cards in hand: [3. 1. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1. 0. 6.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  8. 11.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3] -> size -> 53 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0. 6.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 19. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  8. 11.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3] -> size -> 53 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0. 6.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 5 
card supply: [17. 19. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  8. 11.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3] -> size -> 53 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11. 10.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 11.] 
expected returns: [[ 3.314516]
 [12.128506]
 [ 6.480936]
 [ 9.24923 ]
 [12.128506]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 11.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.168312072753906



action possibilites: [-1] 
expected returns: [[-1.8612864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 18. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -190    0    0
   27    0] 
sum of rewards: -178 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 12.00825309753418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 1.1140003]
 [-1.8612761]
 [-1.8612761]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 18. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.8612864017486572



buy possibilites: [-1] 
expected returns: [[41.875854]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0. -200.
    0.    0.    0.    0.] 
sum of rewards: -215.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 1.1139779090881348






Player: 1 
cards in hand: [3. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0] -> size -> 55 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  5.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0] -> size -> 55 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  0.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0] -> size -> 55 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[19.827032]
 [32.909058]
 [32.909058]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.8758544921875



action possibilites: [-1. 29.] 
expected returns: [[ 7.2281914]
 [19.734167 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.627206802368164



action possibilites: [-1.] 
expected returns: [[1.3430157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 17.302791595458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[3.5521855]
 [7.4698553]
 [5.563936 ]
 [1.343019 ]
 [3.7545156]
 [5.6385393]
 [9.409617 ]
 [3.3217745]
 [7.265662 ]
 [1.343019 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  4.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.3430156707763672



buy possibilites: [-1] 
expected returns: [[-5.658575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -210    0    0
  128    0] 
sum of rewards: -77 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 9.409615516662598






Player: 1 
cards in hand: [16.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  3.  0.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 29. 11. 11. 11.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29] -> size -> 56 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  3.  0.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 29. 11. 11. 11.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29] -> size -> 56 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 11.] 
expected returns: [[59.187393]
 [74.0906  ]
 [70.53237 ]
 [70.53237 ]
 [70.53237 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 11. 11. 11.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.658575057983398



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[63.94983 ]
 [80.298386]
 [80.298386]
 [80.298386]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29] -> size -> 56 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 18. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 70.41539764404297



action possibilites: [-1] 
expected returns: [[52.573715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 17. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: -188 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 80.13933563232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.77038 ]
 [52.573708]
 [52.573708]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 17. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.57371520996094



buy possibilites: [-1] 
expected returns: [[-0.35168028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 17. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   40.    0.    0.    0.    0. -230.
    0.    0.    0.    0.] 
sum of rewards: -225.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 56.7703857421875






Player: 1 
cards in hand: [ 0.  3. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  8. 11.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  1.  0. 11.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0] -> size -> 58 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  8.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  1.  0. 11.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0] -> size -> 58 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  8.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 17. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  1.  0. 11.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0] -> size -> 58 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  8.] 
cards in discard: [ 6.  0. 16. 14.  6. 29.  8.  0.  3.  1.  1.  0.  6.  8.  3.  3.  8.  0.
  0. 16.  0. 10.  3.  0. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8 14  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 17. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  1.  0. 11.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0] -> size -> 58 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 4.436919 ]
 [ 6.9239664]
 [11.0716095]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0. 11.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 17. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  7. 10.  0. 10. 10.] 
adversary cards in hand: [8. 1. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8 14  0] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.35168027877807617



action possibilites: [-1] 
expected returns: [[-6.923523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  7. 10.  0. 10. 10.] 
adversary cards in hand: [8. 1. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8 14  0] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -240    0    0
   27    0] 
sum of rewards: -228 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 11.002324104309082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[-5.5538125]
 [-3.1951442]
 [-4.356672 ]
 [-6.9235177]
 [-5.418358 ]
 [-4.313522 ]
 [-2.0416121]
 [-5.6942797]
 [-3.3270917]
 [-6.9235177]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 16. 30. 24. 29.  8.  7.  8.  0.  4.  8.  3.  7. 10.  0. 10. 10.] 
adversary cards in hand: [8. 1. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8 14  0] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.92352294921875



buy possibilites: [-1] 
expected returns: [[-12.037191]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 24. 29.  8.  7.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [8. 1. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8 14  0] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -250    0    0
  128    0] 
sum of rewards: -137 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -2.0416061878204346






Player: 1 
cards in hand: [8. 1. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0. 4.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 10  3  8  1 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3
  6 16  8  0  6  0  0  8 14  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 24. 29.  8.  7.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 25.  3.  0. 10.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1. 29. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29] -> size -> 60 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 24. 29.  8.  7.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 25.  3.  0. 10.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1. 29. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29] -> size -> 60 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 16. 30. 24. 29.  8.  7.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 25.  3.  0. 10.] 
adversary cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1. 29. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29] -> size -> 60 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[18.957088]
 [33.844025]
 [23.00178 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  3.  0. 10.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1. 29. 11.  0. 10.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 24. 29.  8.  7.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  8. 14. 14. 16.] 
adversary cards in discard: [8. 4.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.037191390991211



action possibilites: [-1] 
expected returns: [[25.060358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 10. 11. 10.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1. 29. 11.  0. 10.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 24. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  8. 14. 14. 16.] 
adversary cards in discard: [8. 4. 6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.844032287597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[28.431055]
 [34.558388]
 [31.520224]
 [25.060354]
 [31.598413]
 [25.060354]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10. 11. 10.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1. 29. 11.  0. 10.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29] -> size -> 60 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 16. 30. 24. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  8. 14. 14. 16.] 
adversary cards in discard: [8. 4. 6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.06035804748535



buy possibilites: [-1] 
expected returns: [[6.28006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10. 11. 10.] 
cards in discard: [ 1.  1. 11. 10.  1.  0. 10. 29. 25. 10. 29.  0. 10.  1.  0.  1.  3. 11.
  0. 10.  3.  0.  1.  0. 11. 10.  8. 11.  0.  0.  8.  0.  0. 29. 29. 29.
  1.  1.  0.  1.  0. 29. 11. 11. 11.  1. 29. 11.  0. 10.  1.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 15. 30. 24. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  8. 14. 14. 16.] 
adversary cards in discard: [8. 4. 6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -260    0    0
   54    0] 
sum of rewards: -221 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 34.55839538574219






Player: 1 
cards in hand: [ 6.  8. 14. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 14. 14. 16.] 
cards in discard: [8. 4. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 15. 30. 24. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [29.  3. 10. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1] -> size -> 61 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 14. 16.] 
cards in discard: [8. 4. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 15. 30. 24. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10.  3.] 
adversary cards in discard: [ 3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1] -> size -> 61 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 14. 16.] 
cards in discard: [8. 4. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 15. 30. 24. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10.  3.] 
adversary cards in discard: [ 3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1] -> size -> 61 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 14. 16.] 
cards in discard: [8. 4. 6. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10.  3.] 
adversary cards in discard: [ 3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1] -> size -> 61 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-1.9204502]
 [11.425197 ]
 [ 1.7832365]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3.] 
cards in discard: [ 3. 10.] 
cards in deck: 56 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3] -> size -> 33 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0 -260    0    0
 1390    0] 
sum of rewards: 1095 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -25.499309539794922



action possibilites: [-1.] 
expected returns: [[7.0516415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 10. 10.  1.] 
cards in deck: 55 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3] -> size -> 33 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.071168899536133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[9.335142]
 [6.696495]
 [6.696495]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 10. 10.  1.] 
cards in deck: 55 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1] -> size -> 61 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3] -> size -> 33 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.051641464233398



buy possibilites: [-1] 
expected returns: [[-14.0205765]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 10. 10.  1.  0.] 
cards in deck: 55 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3] -> size -> 33 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0. -270.
    0.    0.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 9.335138320922852






Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0] -> size -> 62 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0] -> size -> 62 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [13. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0] -> size -> 62 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0] -> size -> 62 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  1. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[37.122368]
 [44.923897]
 [44.923897]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 11. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 15. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  6.  3.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.020576477050781



action possibilites: [-1] 
expected returns: [[22.308401]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  6.  3.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -280    0    0
   27    0] 
sum of rewards: -268 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 44.83392333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[26.268908]
 [34.770203]
 [30.10124 ]
 [25.781183]
 [22.308407]
 [26.872686]
 [30.416807]
 [41.02601 ]
 [40.361435]
 [25.898191]
 [30.200361]
 [23.632776]
 [34.263504]
 [22.308407]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1] -> size -> 63 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 14. 30. 23. 29.  8.  6.  8.  0.  4.  8.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  6.  3.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.308401107788086



buy possibilites: [-1] 
expected returns: [[-9.605221]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25.] 
cards in deck: 50 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 23. 29.  8.  6.  8.  0.  4.  7.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  6.  3.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -290    0    0
  250    0] 
sum of rewards: -55 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 41.02601623535156






Player: 1 
cards in hand: [ 0.  8. 11.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  6.  3.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 23. 29.  8.  6.  8.  0.  4.  7.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29.  0. 11.  1.  1.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25] -> size -> 64 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  6.  3.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 14. 30. 23. 29.  8.  6.  8.  0.  4.  7.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29.  0. 11.  1.  1.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25] -> size -> 64 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  6.  3.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  4.  7.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29.  0. 11.  1.  1.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25] -> size -> 64 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  0. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[43.805023]
 [58.209938]
 [55.090996]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  1.  1.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  4.  7.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0] -> size -> 35 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.605220794677734



action possibilites: [-1.] 
expected returns: [[24.254553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25] -> size -> 64 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  4.  7.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0] -> size -> 35 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 54.96453094482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[27.463022]
 [33.291664]
 [30.380281]
 [27.017488]
 [24.254545]
 [27.775389]
 [30.489721]
 [36.63073 ]
 [36.185204]
 [27.132807]
 [30.247122]
 [25.264393]
 [32.96145 ]
 [24.254545]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25] -> size -> 64 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  4.  7.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0] -> size -> 35 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.254552841186523



buy possibilites: [-1] 
expected returns: [[-1.7380512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  4.  6.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0] -> size -> 35 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -300    0    0
  250    0] 
sum of rewards: -65 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 36.63072967529297






Player: 1 
cards in hand: [ 0. 16.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  6.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  4.  6.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25] -> size -> 65 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.  6.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  4.  6.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25] -> size -> 65 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.  6.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  3.  6.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25] -> size -> 65 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[30.906794]
 [41.81318 ]
 [41.81318 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 23. 29.  8.  6.  8.  0.  3.  6.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29. 14.  8.  0.  3.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.  8.  0. 16.  0.  3.  6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8] -> size -> 36 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.738051176071167



action possibilites: [-1] 
expected returns: [[-5.902704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 23. 29.  8.  6.  8.  0.  3.  6.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29. 14.  8.  0.  3.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.  8.  0. 16.  0.  3.  6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8] -> size -> 36 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -310    0    0
   27    0] 
sum of rewards: -298 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 41.69059753417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[-3.5067751 ]
 [ 0.6448164 ]
 [-1.4791446 ]
 [-5.9026957 ]
 [-3.1736019 ]
 [-1.3185554 ]
 [ 2.8925347 ]
 [-3.717864  ]
 [ 0.43540192]
 [-5.9026957 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1] -> size -> 66 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 13. 30. 23. 29.  8.  6.  8.  0.  3.  6.  2.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29. 14.  8.  0.  3.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.  8.  0. 16.  0.  3.  6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8] -> size -> 36 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.902703762054443



buy possibilites: [-1] 
expected returns: [[-4.599341]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29] -> size -> 67 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29. 14.  8.  0.  3.] 
adversary cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.  8.  0. 16.  0.  3.  6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8] -> size -> 36 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -320    0    0
  128    0] 
sum of rewards: -207 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 2.892523765563965






Player: 1 
cards in hand: [29. 14.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  8.  0.  3.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.  8.  0. 16.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [11.  1. 29. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29] -> size -> 67 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  8.  0.  3.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.  8.  0. 16.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 13. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [11.  1. 29. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29] -> size -> 67 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  8.  0.  3.] 
cards in discard: [ 8.  4.  6.  3. 14.  6.  8. 14. 16. 23. 10.  0.  0.  0.  0.  1.  0.  0.
  8. 11.  6.  3.  8.  0. 16.  0.  3.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 13. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [11.  1. 29. 11. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29] -> size -> 67 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11.  1. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 11.] 
expected returns: [[ 0.13947487]
 [15.472889  ]
 [19.000948  ]
 [15.472889  ]
 [15.472889  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29. 11. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 13. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.599340915679932



action possibilites: [-1. 11. 11.] 
expected returns: [[-1.5622234]
 [ 4.535616 ]
 [ 4.535616 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29] -> size -> 67 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 13. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.185562133789062



action possibilites: [-1] 
expected returns: [[4.367344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1] -> size -> 68 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 12. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -330    0    0
   27    0] 
sum of rewards: -298 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 4.485907554626465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[ 7.113474]
 [12.129923]
 [ 9.780734]
 [ 4.367338]
 [ 9.617587]
 [ 4.367338]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1] -> size -> 68 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 12. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.367343902587891



buy possibilites: [-1] 
expected returns: [[-2.1753054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1] -> size -> 69 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0] -> size -> 37 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -340    0    0
   54    0] 
sum of rewards: -281 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 12.129922866821289






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  1.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1] -> size -> 69 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  1.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1] -> size -> 69 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  1.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1] -> size -> 69 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-36.066605]
 [-33.247932]
 [-27.058622]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  1.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11
 10  0 10 11 10  8 25 10 11  1  0  1  0  1  0  1  8 29 25  1 29  0  1  0
  1  1 29  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.1753053665161133



action possibilites: [-1] 
expected returns: [[-42.4618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: -14.082464218139648





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-40.44725 ]
 [-42.461807]
 [-42.461807]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1] -> size -> 66 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -42.46179962158203



buy possibilites: [-1] 
expected returns: [[-31.61897]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0] -> size -> 67 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0] -> size -> 38 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -320    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -40.447242736816406






Player: 1 
cards in hand: [ 0.  3. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3.  3.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [25.  3.  8. 10. 10.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0] -> size -> 67 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  3.  3.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [25.  3.  8. 10. 10.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0] -> size -> 67 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  3.  3.] 
cards in discard: [0. 0. 0. 0. 3. 3. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [25.  3.  8. 10. 10.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0] -> size -> 67 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [25.  3.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10. 10.] 
expected returns: [[ 1.1882572]
 [15.732088 ]
 [ 8.6474   ]
 [ 5.280802 ]
 [ 5.280802 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  8. 10. 10.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 23. 29.  8.  6.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 11.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0  0] -> size -> 39 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -31.61897087097168



action possibilites: [-1] 
expected returns: [[-26.306181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 10.  0. 25.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0] -> size -> 67 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 11.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.73211669921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-16.680508]
 [-26.306204]
 [-26.306204]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10. 10.  0. 25.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0] -> size -> 67 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 11.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.306180953979492



buy possibilites: [-1] 
expected returns: [[6.757228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10. 10.  0. 25.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 11.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.] 
adversary owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0. -330.
    0.    0.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.680469512939453






Player: 1 
cards in hand: [ 0.  8.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 11.  8.] 
cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 10  3  8 14  8 11  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8
  0  6  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29. 10. 10.  0. 29.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29. 10. 10.  0. 29.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [29. 10. 10.  0. 29.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [29. 10. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 29.] 
expected returns: [[-37.82596 ]
 [-27.402027]
 [-34.769318]
 [-34.769318]
 [-27.402027]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  0. 29.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [8. 0. 8. 4. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.757227897644043



action possibilites: [-1. 10. 10.] 
expected returns: [[-29.148405]
 [-26.593016]
 [-26.593016]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [8. 0. 8. 4. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -29.57526397705078



action possibilites: [-1. 10. 10.] 
expected returns: [[-30.011446]
 [-28.078062]
 [-28.078062]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [8. 0. 8. 4. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -26.593019485473633



action possibilites: [-1. 10.] 
expected returns: [[-27.500723]
 [-25.062605]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
action values: 3 
buys: 0 
player value: 1 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [8. 0. 8. 4. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -28.078065872192383



action possibilites: [-1.] 
expected returns: [[-28.110687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
action values: 4 
buys: 0 
player value: 1 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [8. 0. 8. 4. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -25.062604904174805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-26.063454]
 [-21.40729 ]
 [-23.83559 ]
 [-26.409365]
 [-28.110683]
 [-25.897655]
 [-23.78092 ]
 [-18.661   ]
 [-19.055885]
 [-26.317184]
 [-24.017668]
 [-27.567163]
 [-21.69699 ]
 [-28.110683]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0] -> size -> 68 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  6.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [8. 0. 8. 4. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -28.110687255859375



buy possibilites: [-1] 
expected returns: [[-33.807793]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0 25] -> size -> 69 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  5.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [8. 0. 8. 4. 6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   80    0    0    0    0 -340    0    0
  250    0] 
sum of rewards: -15 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -18.66099739074707






Player: 1 
cards in hand: [8. 0. 8. 4. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 4. 6.] 
cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  5.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  0. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1. 25. 29. 10. 10. 10.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0 25] -> size -> 69 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 4. 6.] 
cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  5.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  0. 11.] 
adversary cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1. 25. 29. 10. 10. 10.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0 25] -> size -> 69 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[75.98344]
 [92.99697]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  0. 11.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1. 25. 29. 10. 10. 10.
  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0 25] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 11. 30. 23. 29.  8.  5.  8.  0.  3.  5.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 16. 23.  0.  6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.  8.  0.
  8.  4.  6.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -33.80779266357422



action possibilites: [-1] 
expected returns: [[114.15915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1. 25. 29. 10. 10. 10.
  0.  0.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0 25  1] -> size -> 70 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 10. 30. 23. 29.  8.  5.  8.  0.  3.  5.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 16. 23.  0.  6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.  8.  0.
  8.  4.  6.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -350    0    0
   27    0] 
sum of rewards: -308 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 92.84445190429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[117.88948 ]
 [124.66737 ]
 [121.18151 ]
 [114.15917 ]
 [118.454895]
 [121.45938 ]
 [128.34877 ]
 [117.55381 ]
 [124.32178 ]
 [114.15917 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1. 25. 29. 10. 10. 10.
  0.  0.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0 25  1] -> size -> 70 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 10. 30. 23. 29.  8.  5.  8.  0.  3.  5.  1.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 16. 23.  0.  6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.  8.  0.
  8.  4.  6.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.15914916992188



Game is draw!



Player 0 bought cards:
Copper: 11 
Silver: 3 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 2 
Witch: 5 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 3. 10. 10.  1.  0. 29.  3.  1. 25. 11.  0.  1.  1. 11. 11.  1. 25. 29.
  0.  1.  0.  1. 29. 11.  0.  0.  1. 11. 11. 29.  1.  1. 29. 11.  1. 11.
  0.  8. 10.  0. 25.  3.  8. 10. 10.  0. 25. 29.  1. 25. 29. 10. 10. 10.
  0.  0.  1.  1. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 29 11 10 11 10 11 10 11 10 11 10  0
 10 11 10  8 25 10 11  0  1  0  1  0  1  8 29 25  1 29  0  1  0  1  1 29
  1  3  1  0 29  1  0  1 29  1  0  1 25 25  1 29  1  1  0  0 25  1 29] -> size -> 71 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 10. 30. 23. 29.  8.  5.  8.  0.  3.  5.  0.  7.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 16. 23.  0.  6.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  0.  0.  3. 14.  3.  3.  6.  8.  8.  8.  8.  0.
  8.  4.  6.] 
adversary owned cards: [16 10  3  8 14  8  0  6  0  3 14  3  3  4  0  1 29  0  3  6 16  8  0  6
  0  0  8 14  0  6  3 23  0  8  0  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -360    0    0
   64    0] 
sum of rewards: -281 

action type: buy - action 29.0
Learning step: -40.93487548828125
desired expected reward: 87.41387939453125



