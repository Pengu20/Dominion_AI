 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.776127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000165 

action type: buy - action 0.0
Learning step: -119994.6640625
desired expected reward: -120292.8046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 27.703876]
 [ 46.897278]
 [ 38.909428]
 [-27.36163 ]
 [ 46.57416 ]
 [ 35.700943]
 [ 41.041615]
 [ 34.181   ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.4659309387207



buy possibilites: [-1] 
expected returns: [[27.286278]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 46.897274017333984






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.345646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.286277770996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 15.24703 ]
 [ 34.575115]
 [ 27.2303  ]
 [-43.78495 ]
 [ 37.311092]
 [ 36.39417 ]
 [ 24.65007 ]
 [ 42.164494]
 [ -8.959366]
 [ 30.669575]
 [ 20.206396]
 [ 21.7758  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.49053955078125



buy possibilites: [-1] 
expected returns: [[22.300205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.16448211669922






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [10.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.027973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 3] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.30020523071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 13.623495 ]
 [ 32.405285 ]
 [ 11.374327 ]
 [ 23.811255 ]
 [ -3.5027952]
 [-33.65245  ]
 [ 33.94657  ]
 [ 31.935455 ]
 [ 22.476946 ]
 [ 43.46807  ]
 [ 38.71476  ]
 [-11.450985 ]
 [ 26.814667 ]
 [ 26.526896 ]
 [  2.5741506]
 [ 18.197943 ]
 [ 19.359493 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 3] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.447206497192383



buy possibilites: [-1] 
expected returns: [[17.925316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 3] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 57.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 43.468074798583984






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [25.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [25.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [25.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[56.564823]
 [73.78998 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [25.  0.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 3 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.925315856933594



action possibilites: [-1.] 
expected returns: [[26.282322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 3 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 73.16522216796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 22.999065 ]
 [ 38.745415 ]
 [ 31.946934 ]
 [-13.751526 ]
 [ 41.024242 ]
 [ 39.595436 ]
 [ 30.948284 ]
 [ 45.033867 ]
 [  2.3809462]
 [ 35.271507 ]
 [ 26.664268 ]
 [ 27.817474 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 3 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.28232192993164



buy possibilites: [-1] 
expected returns: [[44.471874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25.  0.  0.  0.  1.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 3 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 45.033843994140625






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[19.23651]
 [39.08219]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.47187423706055



action possibilites: [-1] 
expected returns: [[40.10953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.30852127075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[32.519436 ]
 [50.145634 ]
 [42.671345 ]
 [-3.6922464]
 [50.562122 ]
 [49.132866 ]
 [39.811665 ]
 [56.36794  ]
 [11.381079 ]
 [44.51956  ]
 [38.240383 ]
 [37.69772  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.10953140258789



buy possibilites: [-1] 
expected returns: [[34.305138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 56.367942810058594






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  0. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  0. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.  6. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  0. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 1.  3. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[60.57889]
 [76.44589]
 [76.44589]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  0. 29.] 
cards in discard: [29. 25.  0.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.305137634277344



action possibilites: [-1. 29.] 
expected returns: [[36.3165  ]
 [49.696453]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 29.  0.] 
cards in discard: [29. 25.  0.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.30469512939453



action possibilites: [-1.] 
expected returns: [[42.381622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [29. 25.  0.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 49.69645690917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[39.687828]
 [53.46888 ]
 [38.585415]
 [47.583405]
 [26.451048]
 [ 8.811081]
 [56.34679 ]
 [54.76153 ]
 [46.625347]
 [63.848156]
 [58.21158 ]
 [21.470404]
 [48.03432 ]
 [50.45004 ]
 [32.13622 ]
 [41.049973]
 [43.837772]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [29. 25.  0.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.381622314453125



buy possibilites: [-1] 
expected returns: [[100.875015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [29. 25.  0.  0.  0.  3.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 127.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 63.848140716552734






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.034874]
 [39.643906]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.87501525878906



action possibilites: [-1.] 
expected returns: [[19.376406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.09739303588867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 16.295868  ]
 [ 30.72808   ]
 [ 22.781576  ]
 [  0.27119112]
 [-20.39214   ]
 [ 32.012604  ]
 [ 29.988663  ]
 [ 23.527853  ]
 [ 39.19336   ]
 [ 34.533104  ]
 [ -5.988128  ]
 [ 21.672523  ]
 [ 25.268076  ]
 [  4.0795074 ]
 [ 15.791756  ]
 [ 22.28444   ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.376405715942383



buy possibilites: [-1] 
expected returns: [[37.970936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 39.19337844848633






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29. 29.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29. 29.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29. 29.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25. 29. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[47.719143]
 [67.24594 ]
 [61.465977]
 [61.465977]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.  0.  3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29.  6.  3.  8.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1 14] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.9709358215332



action possibilites: [-1] 
expected returns: [[43.89064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3.  3. 25.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29.  6.  3.  8.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 14.  3.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1 14  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 66.30035400390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.803288 ]
 [-4.5942264]
 [45.190506 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  3.  3. 25.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29.  6.  3.  8.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3. 14.  3.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1 14  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.89064025878906






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [10. 29.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  6.  3.  8.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 14.  3.  0.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  8.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 10  6 29  1 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  3.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[18.644135]
 [29.8545  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.190494537353516



action possibilites: [-1. 29.] 
expected returns: [[33.520206]
 [47.22202 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.985965728759766



action possibilites: [-1.] 
expected returns: [[23.808853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.22201919555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 25.333738]
 [ 38.71193 ]
 [ 23.337624]
 [ 30.774319]
 [ 14.280193]
 [-12.720226]
 [ 38.387764]
 [ 36.83379 ]
 [ 30.706299]
 [ 45.220764]
 [ 40.597122]
 [  7.354838]
 [ 30.769794]
 [ 32.883705]
 [ 16.052519]
 [ 27.96339 ]
 [ 27.995182]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.808853149414062



buy possibilites: [-1] 
expected returns: [[46.93044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 127.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 45.22078323364258






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [ 0. 29.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0. 29.] 
adversary cards in discard: [25. 29. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0. 29.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0. 29.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0. 29.  8.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.15363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  8.  3.  3. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 655   0] 
sum of rewards: 650 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 77.20404815673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.888935]
 [69.74757 ]
 [17.085852]
 [66.51779 ]
 [65.19034 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  8.  3.  3. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.47791290283203



buy possibilites: [-1] 
expected returns: [[94.823006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  8.  3.  3. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 69.74754333496094






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 0. 29.  8.  3.  3. 14.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 0. 29.  8.  3.  3. 14.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 0. 29.  8.  3.  3. 14.  0.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3] -> size -> 19 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0. 25.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 77.98926]
 [100.08333]
 [100.08333]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 25.  0.] 
cards in discard: [25. 29. 29.  3.  1.  0.  0.  0. 25. 29.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  8. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.82300567626953



action possibilites: [-1] 
expected returns: [[29.862534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  7. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 100.68506622314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.118265]
 [32.438667]
 [-9.444799]
 [32.569942]
 [29.488396]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  7. 10. 10.  9.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.862533569335938



buy possibilites: [-1] 
expected returns: [[38.15698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0. 29.  3.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  7. 10. 10.  8.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.569942474365234






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  7. 10. 10.  8.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [ 8. 25.  0.  3. 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 26. 30.  8.  7. 10. 10.  8.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [ 8. 25.  0.  3. 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  7. 10. 10.  8.  6.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [ 8. 25.  0.  3. 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [29.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[68.70241 ]
 [84.302475]
 [84.302475]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0.  0.] 
cards in discard: [ 8. 25.  0.  3. 25.  0. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  7. 10. 10.  8.  6.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.156978607177734



action possibilites: [-1. 29. 25.] 
expected returns: [[27.28558 ]
 [40.020195]
 [43.40955 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 25.] 
cards in discard: [ 8. 25.  0.  3. 25.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  7. 10. 10.  8.  6.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.73890686035156



action possibilites: [-1] 
expected returns: [[89.38135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.  0.] 
cards in discard: [ 8. 25.  0.  3. 25.  0. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  6. 10. 10.  8.  6.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.4095573425293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 83.79064 ]
 [ 98.89819 ]
 [ 82.86048 ]
 [ 93.30534 ]
 [ 69.72635 ]
 [ 50.554882]
 [100.40154 ]
 [ 99.70453 ]
 [ 89.97179 ]
 [107.5832  ]
 [103.9326  ]
 [ 64.09116 ]
 [ 94.44671 ]
 [ 94.75847 ]
 [ 75.803444]
 [ 87.06159 ]
 [ 91.52312 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.  0.] 
cards in discard: [ 8. 25.  0.  3. 25.  0. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 26. 30.  8.  6. 10. 10.  8.  6.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.38134765625



buy possibilites: [-1] 
expected returns: [[60.02878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.  0.] 
cards in discard: [ 8. 25.  0.  3. 25.  0. 29.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  6. 10. 10.  8.  5.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 127.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 107.58319854736328






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [29.  0.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  3.  0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  6. 10. 10.  8.  5.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  6. 10. 10.  8.  5.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 26. 30.  8.  6. 10. 10.  8.  5.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  6. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3. 25.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[17.025341]
 [32.719177]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  6. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  8.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6. 10. 29.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.02878189086914



action possibilites: [-1] 
expected returns: [[3.7371173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  3. 25. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  8.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6. 10. 29.  0.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.23786926269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -3.2518294]
 [  3.839562 ]
 [-38.327133 ]
 [  3.4385543]
 [  3.8512397]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1.  3. 25. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  8.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6. 10. 29.  0.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.737117290496826






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.  3.  0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6. 10. 29.  0.  6.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [25.  3.  3.  1.  3. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6. 10. 29.  0.  6.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6. 10. 29.  0.  6.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 26. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  0.  6. 10. 29.  0.  6.  3.  0.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 25. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.990385]
 [27.454235]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 93.35086822509766



action possibilites: [-1] 
expected returns: [[8.034622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 33.88957595825195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -0.5543237]
 [-34.452312 ]
 [  8.82081  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.034622192382812






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  0.] 
adversary cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 25. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  0.] 
adversary cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 19 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  0.] 
adversary cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 19 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[25.971329]
 [36.75661 ]
 [40.069283]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0.  0.] 
cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  5. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  6. 14. 10.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 8.820808410644531



action possibilites: [-1] 
expected returns: [[92.75378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 29.  3.] 
cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  4. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  6. 14. 10.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 39.643245697021484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 86.49174 ]
 [100.18276 ]
 [ 94.072266]
 [ 52.157368]
 [101.040695]
 [ 93.05307 ]
 [ 96.285225]
 [ 92.0369  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0. 29.  3.] 
cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  4. 10. 10.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  6. 14. 10.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.75377655029297



buy possibilites: [-1] 
expected returns: [[40.960102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0. 29.  3.] 
cards in discard: [25.  3.  3.  1.  3. 25. 25.  0. 29.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  4. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  6. 14. 10.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.04067993164062






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  6. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6. 14. 10.] 
cards in discard: [ 0. 29.  3.  0.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  4. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  6. 14. 10.] 
cards in discard: [ 0. 29.  3.  0.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  4. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  6. 14. 10.] 
cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  4. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 3.  8.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[-8.920978 ]
 [-7.8262434]
 [ 7.994903 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  1. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  4. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0] -> size -> 27 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.96010208129883



action possibilites: [-1] 
expected returns: [[12.135311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  1.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  3. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 7.660506725311279





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  8.597761 ]
 [ 21.563156 ]
 [ 14.6999035]
 [-30.68861  ]
 [ 21.313774 ]
 [ 15.295284 ]
 [ 17.38352  ]
 [ 15.249472 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  1.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 25. 30.  8.  3. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.135311126708984



buy possibilites: [-1] 
expected returns: [[6.191748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  1.  0. 25. 25.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  3. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 21.563156127929688






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  3. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 25. 30.  8.  3. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[27.770138]
 [37.52058 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  3. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.  6.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6] -> size -> 28 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.191748142242432



action possibilites: [-1. 25.] 
expected returns: [[42.21684]
 [56.88931]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 25.] 
cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8.  3. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.  6.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6] -> size -> 28 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.07423400878906



action possibilites: [-1] 
expected returns: [[34.40122]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0.  0. 29.] 
cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.  6.  3.  0.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.8892936706543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 30.650429]
 [ 44.79115 ]
 [ 38.437073]
 [-11.611942]
 [ 46.432335]
 [ 45.58299 ]
 [ 36.9132  ]
 [ 47.123177]
 [  8.066704]
 [ 40.057034]
 [ 29.268345]
 [ 34.708652]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0.  0. 29.] 
cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  8.  5.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.  6.  3.  0.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.40121841430664



buy possibilites: [-1] 
expected returns: [[8.371206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0.  0. 29.] 
cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  8.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.  6.  3.  0.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.123165130615234






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.  6.  3.  0.  0.
  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  8.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 25. 29.] 
adversary cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25. 29. 29. 25.  0.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.  6.  3.  0.  0.
  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  8.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 25. 29.] 
adversary cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25. 29. 29. 25.  0.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [ 0. 29.  3.  0.  0.  0.  6.  0.  6.  8.  6. 14. 10.  6.  6.  3.  0.  0.
  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 25. 29.] 
adversary cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25. 29. 29. 25.  0.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 0. 11.  3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[68.423645]
 [77.73599 ]
 [86.7189  ]
 [80.15656 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 25. 29.] 
cards in discard: [ 1. 25.  3.  8.  1.  0. 25. 25. 29. 29. 25.  0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.371206283569336



action possibilites: [-1] 
expected returns: [[-2.2295196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29. 29.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.71891021728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -5.1681337]
 [-56.571415 ]
 [  2.5536637]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 29. 29.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.2295196056365967






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 25. 25.  1.] 
adversary cards in discard: [25.  0. 11.  3. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 25. 25.  1.] 
adversary cards in discard: [25.  0. 11.  3. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
adversary victory points: 4
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  3. 25. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-30.75739]
 [-16.62875]
 [-16.62875]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25. 25.  1.] 
cards in discard: [25.  0. 11.  3. 29. 29.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  3. 29.] 
adversary cards in discard: [6. 6. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.553678035736084



action possibilites: [-1] 
expected returns: [[38.207714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25.  1.  3. 25.] 
cards in discard: [25.  0. 11.  3. 29. 29.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  3. 29.] 
adversary cards in discard: [6. 6. 6. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -16.62874984741211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[32.960674 ]
 [44.839844 ]
 [39.02191  ]
 [48.419758 ]
 [45.324135 ]
 [39.867188 ]
 [49.579838 ]
 [15.0240555]
 [41.81892  ]
 [33.297382 ]
 [38.86292  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25.  1.  3. 25.] 
cards in discard: [25.  0. 11.  3. 29. 29.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  3. 29.] 
adversary cards in discard: [6. 6. 6. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.20771408081055



buy possibilites: [-1] 
expected returns: [[16.161697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25.  1.  3. 25.] 
cards in discard: [25.  0. 11.  3. 29. 29.  8. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  3. 29.] 
adversary cards in discard: [6. 6. 6. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 49.5798454284668






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  3. 29.] 
cards in discard: [6. 6. 6. 0. 3. 3. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [25.  0. 11.  3. 29. 29.  8. 29. 25.  1.  3. 25.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29] -> size -> 23 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  8.  3. 29.] 
cards in discard: [6. 6. 6. 0. 3. 3. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [25.  0. 11.  3. 29. 29.  8. 29. 25.  1.  3. 25.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29] -> size -> 23 
adversary victory points: 4
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[23.10199 ]
 [40.732372]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.  0.] 
cards in discard: [25.  0. 11.  3. 29. 29.  8. 29. 25.  1.  3. 25.  1.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  0. 10.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.161697387695312



action possibilites: [-1] 
expected returns: [[31.285114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0.  0. 29.] 
cards in discard: [25.  0. 11.  3. 29. 29.  8. 29. 25.  1.  3. 25.  1.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  0. 10.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.732383728027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[26.190231]
 [39.244396]
 [33.1937  ]
 [42.663567]
 [41.253635]
 [33.349808]
 [43.72398 ]
 [ 5.394853]
 [36.291286]
 [26.172901]
 [32.690323]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0.  0. 29.] 
cards in discard: [25.  0. 11.  3. 29. 29.  8. 29. 25.  1.  3. 25.  1.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  0. 10.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.285114288330078



buy possibilites: [-1] 
expected returns: [[59.750637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0.  0. 29.] 
cards in discard: [25.  0. 11.  3. 29. 29.  8. 29. 25.  1.  3. 25.  1.  3. 25. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  0. 10.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 353 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.7239875793457






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  0. 10.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  3  0 29 14  6  0  3  3  6 10  6 10  6  3
  0  6  0  6  6  8  6  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  7.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [25.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-37.95863 ]
 [-34.95537 ]
 [-25.258762]
 [-25.258762]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.75063705444336



action possibilites: [-1. 25. 25.] 
expected returns: [[19.086428]
 [29.402866]
 [29.402866]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 25.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -39.05307388305664



action possibilites: [-1] 
expected returns: [[29.431934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 11.  0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.402854919433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.30396  ]
 [38.76131  ]
 [30.616661 ]
 [39.94804  ]
 [37.211517 ]
 [32.041126 ]
 [41.719513 ]
 [ 3.3714223]
 [32.91159  ]
 [23.691303 ]
 [28.933372 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25. 11.  0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.431934356689453



buy possibilites: [-1] 
expected returns: [[6.3485885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25. 11.  0.] 
cards in discard: [29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 343 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 41.71953582763672






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.  0.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 25.  8.  3.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29] -> size -> 25 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 25.  8.  3.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29] -> size -> 25 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 25.  8.  3.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29] -> size -> 25 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 25.  8.  3.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29] -> size -> 25 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [29.  3. 25.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
expected returns: [[ 6.1158633]
 [16.312119 ]
 [20.241589 ]
 [ 7.0195127]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25.  8.  3.] 
cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.  0.
 10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.348588466644287



action possibilites: [-1] 
expected returns: [[-0.6219387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  3. 29.  1.] 
cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.  0.
 10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.241588592529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-5.380606  ]
 [ 2.5858588 ]
 [ 0.5651827 ]
 [ 0.53268814]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.  3. 29.  1.] 
cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.  0.
 10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.6219387054443359



buy possibilites: [-1] 
expected returns: [[15.173946]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.  3. 29.  1.] 
cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  6.  3.] 
adversary cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.  0.
 10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 241 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 2.585862636566162






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 14.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  6.  3.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.  0.
 10.  0.  0.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  1. 25.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.  3. 25. 29.  3.  8.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3] -> size -> 26 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  6.  3.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.  0.
 10.  0.  0.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  1. 25.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.  3. 25. 29.  3.  8.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3] -> size -> 26 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  6.  3.] 
cards in discard: [ 6.  6.  6.  0.  3.  3.  6.  0.  6.  8.  3. 29.  8. 10.  8.  0.  0.  0.
 10.  0.  0.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  1. 25.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.  3. 25. 29.  3.  8.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3] -> size -> 26 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 3.  0. 29.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[53.41967]
 [67.02667]
 [72.64545]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  1. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.  3. 25. 29.  3.  8.  3. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.173946380615234



action possibilites: [-1] 
expected returns: [[59.283245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  1.  3. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.  3. 25. 29.  3.  8.  3. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 72.64543151855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[51.007282]
 [64.42163 ]
 [55.915306]
 [63.889774]
 [58.810146]
 [59.17525 ]
 [60.702793]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  1.  3. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.  3. 25. 29.  3.  8.  3. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.28324508666992



buy possibilites: [-1] 
expected returns: [[35.951878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  1.  3. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0. 25. 11.  0.  3. 25. 29.  3.  8.  3. 29.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 64.42160034179688






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1] -> size -> 27 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1] -> size -> 27 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  3.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1] -> size -> 27 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 3. 25. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[25.300728]
 [37.281307]
 [34.066418]
 [34.066418]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3. 14.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.95187759399414



action possibilites: [-1] 
expected returns: [[17.093697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3. 14.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.28129196166992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[11.488281]
 [23.938406]
 [17.068705]
 [22.729305]
 [17.240776]
 [19.149704]
 [17.433775]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3. 14.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.09369659423828



buy possibilites: [-1] 
expected returns: [[33.011417]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  0.  1. 25.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3. 14.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 23.938398361206055






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3. 14.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6
  0  6  6  8  6  6  8  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0. 25. 25.  0.] 
adversary cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1] -> size -> 28 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0. 25. 25.  0.] 
adversary cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1] -> size -> 28 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0. 25. 25.  0.] 
adversary cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1] -> size -> 28 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [29.  0. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[-20.527792 ]
 [-12.626535 ]
 [ -6.8282595]
 [ -6.8282595]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 25.  0.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 8.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.011417388916016



action possibilites: [-1] 
expected returns: [[11.820597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0. 29.  3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 8.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -6.828292369842529





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 6.78223 ]
 [12.891418]
 [13.112942]
 [11.445608]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  0. 29.  3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  6.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 8.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.820596694946289



buy possibilites: [-1] 
expected returns: [[4.308377]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  0. 29.  3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 8.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 13.112939834594727






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 8.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  8. 29. 11.] 
adversary cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8] -> size -> 29 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 8.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  8. 29. 11.] 
adversary cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8] -> size -> 29 
adversary victory points: 5
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 29.  8. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 11.] 
expected returns: [[37.75625 ]
 [52.37325 ]
 [35.303032]
 [52.37325 ]
 [44.521187]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8. 29. 11.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.308376789093018



action possibilites: [-1.  8. 11.] 
expected returns: [[32.35089 ]
 [32.97079 ]
 [37.289276]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.514976501464844



action possibilites: [-1] 
expected returns: [[60.62495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 339 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.63084411621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[55.26484 ]
 [61.303806]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.62495040893555






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  1. 29.] 
adversary cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29. 15.
 29. 11.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15] -> size -> 30 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  1. 29.] 
adversary cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29. 15.
 29. 11.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15] -> size -> 30 
adversary victory points: 5
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 25.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[65.92795]
 [86.51451]
 [80.73917]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  1. 29.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29. 15.
 29. 11.  3.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.30380630493164



action possibilites: [-1] 
expected returns: [[50.168743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.  1.  3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29. 15.
 29. 11.  3.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.5145263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[45.87492 ]
 [59.198437]
 [43.880394]
 [52.79271 ]
 [32.056774]
 [60.565662]
 [58.558758]
 [51.65363 ]
 [66.435936]
 [63.247448]
 [26.312191]
 [53.249565]
 [54.54055 ]
 [36.63303 ]
 [47.0063  ]
 [52.66347 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29.  1.  3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29. 15.
 29. 11.  3.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  5.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.16874313354492



buy possibilites: [-1] 
expected returns: [[69.23302]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29.  1.  3.] 
cards in discard: [ 1. 25.  3. 29. 29.  0.  1. 25.  8. 25. 29.  0. 25.  0. 29.  3. 29. 15.
 29. 11.  3.  8.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 317.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 66.43594360351562






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6. 29.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  8.  0.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3  6 10  6 10  6  3  0  6  0
  6  6  8  6  6  8  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 15. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25] -> size -> 31 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 15. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25] -> size -> 31 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 15. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25] -> size -> 31 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 1. 15. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29. 25.] 
expected returns: [[27.847244]
 [19.041073]
 [36.93328 ]
 [36.93328 ]
 [41.45651 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 29. 29. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.23301696777344



action possibilites: [-1] 
expected returns: [[38.482986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.45649337768555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[32.447968]
 [44.875538]
 [37.93755 ]
 [43.50591 ]
 [38.15876 ]
 [39.89358 ]
 [40.25426 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.48298645019531



buy possibilites: [-1] 
expected returns: [[47.5274]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 29. 29. 29.  0.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 44.87554168701172






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.  8. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  1.  3.] 
adversary cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1] -> size -> 32 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.  8. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 24. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  1.  3.] 
adversary cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1] -> size -> 32 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [ 0.  6. 10.  0.  3.  3.  8. 10.  0. 14.  0.  0.  3.  6.  8.  6.  0.  6.
  0.  0.  8. 29.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  1.  3.] 
adversary cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1] -> size -> 32 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[16.667868]
 [34.334713]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  1.  3.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.527400970458984



action possibilites: [-1] 
expected returns: [[41.56389]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 29.  0.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.33470916748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.327133]
 [46.91448 ]
 [40.084427]
 [17.59773 ]
 [48.525013]
 [46.877254]
 [39.84184 ]
 [55.39236 ]
 [49.612076]
 [11.686802]
 [38.20564 ]
 [42.011368]
 [22.086386]
 [31.978798]
 [37.74318 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  3. 29.  0.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  4.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.56388854980469



buy possibilites: [-1] 
expected returns: [[16.309208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  3. 29.  0.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 445 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 55.39237594604492






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29.  8.  0.  1.] 
adversary cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25] -> size -> 33 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29.  8.  0.  1.] 
adversary cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25] -> size -> 33 
adversary victory points: 5
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 29.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8.] 
expected returns: [[63.00893]
 [80.15103]
 [74.26272]
 [64.01279]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  8.  0.  1.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.309207916259766



action possibilites: [-1] 
expected returns: [[51.741398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  1. 29. 25.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.15103149414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[46.097507]
 [59.724834]
 [53.35621 ]
 [59.621784]
 [52.20727 ]
 [55.06592 ]
 [52.704323]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0.  1. 29. 25.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.741397857666016



buy possibilites: [-1] 
expected returns: [[38.034855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0.  1. 29. 25.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 59.72481155395508






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [3. 0. 3. 0. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  3.] 
adversary cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.  1. 25.
 29.  8.  0.  1. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1] -> size -> 34 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [3. 0. 3. 0. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  3.] 
adversary cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.  1. 25.
 29.  8.  0.  1. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1] -> size -> 34 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [3. 0. 3. 0. 6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  3.] 
adversary cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.  1. 25.
 29.  8.  0.  1. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1] -> size -> 34 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [ 8.  3. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[72.313644]
 [71.10469 ]
 [89.56163 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25.  1.  3.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.  1. 25.
 29.  8.  0.  1. 29. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 10.] 
adversary cards in discard: [3. 0. 3. 0. 6. 0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.034854888916016



action possibilites: [-1] 
expected returns: [[55.62798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  1.  3. 11.  3.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.  1. 25.
 29.  8.  0.  1. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 10.] 
adversary cards in discard: [3. 0. 3. 0. 6. 0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 89.56165313720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[48.16196]
 [56.76995]
 [54.62974]
 [56.44021]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  1.  3. 11.  3.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.  1. 25.
 29.  8.  0.  1. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 10.] 
adversary cards in discard: [3. 0. 3. 0. 6. 0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.62797927856445



buy possibilites: [-1] 
expected returns: [[80.41121]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  1.  3. 11.  3.] 
cards in discard: [ 1. 25.  1. 15. 29. 29. 29.  0. 25. 25.  0.  0.  1.  3. 29.  0.  1. 25.
 29.  8.  0.  1. 29. 25.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 10.] 
adversary cards in discard: [3. 0. 3. 0. 6. 0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0] -> size -> 34 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 241 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 56.769954681396484






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 10.] 
cards in discard: [3. 0. 3. 0. 6. 0. 6. 0. 0. 3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11. 25.  3. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 10.] 
cards in discard: [3. 0. 3. 0. 6. 0. 6. 0. 0. 3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  5.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11. 25.  3. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 10.] 
cards in discard: [3. 0. 3. 0. 6. 0. 6. 0. 0. 3. 0. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11. 25.  3. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [11. 25.  3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25. 29.] 
expected returns: [[21.375175]
 [20.937696]
 [23.606361]
 [23.606361]
 [27.233837]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3. 25. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0  8] -> size -> 35 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.41120910644531



action possibilites: [-1. 11. 25. 25.] 
expected returns: [[33.54645]
 [37.66912]
 [44.66503]
 [44.66503]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25.  0.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0  8] -> size -> 35 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.459320068359375



action possibilites: [-1] 
expected returns: [[25.744053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0. 25.  3.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0  8] -> size -> 35 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 44.66502380371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[16.826439]
 [22.71978 ]
 [23.173267]
 [25.931015]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  0. 25.  3.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0  8] -> size -> 35 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.74405288696289






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6
  6  8  6  6  8  0  0  0  3  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 25. 29.  3. 15.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 25. 29.  3. 15.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 25. 29.  3. 15.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 25. 29.  3. 15.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 1. 25. 29.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 15.] 
expected returns: [[22.83223 ]
 [34.946796]
 [31.567799]
 [15.723366]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 29.  3. 15.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1] -> size -> 35 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.931015014648438



action possibilites: [-1] 
expected returns: [[43.094185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3. 15.  8. 29.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1] -> size -> 35 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.94677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[38.102505]
 [45.434772]
 [44.787613]
 [42.360447]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3. 15.  8. 29.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 22. 30. 22. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1] -> size -> 35 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.09418487548828



buy possibilites: [-1] 
expected returns: [[14.705818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3. 15.  8. 29.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 21. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  8.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1] -> size -> 35 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 45.43475341796875






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.  3.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 21. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1.  1. 25. 29.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3] -> size -> 36 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  3.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 30. 21. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1.  1. 25. 29.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3] -> size -> 36 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.  3.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1.  1. 25. 29.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3] -> size -> 36 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [ 0.  1.  1. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 2.5923705]
 [22.365284 ]
 [16.074606 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 25. 29.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 14. 29.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.  0.  0. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1  0] -> size -> 36 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.705818176269531



action possibilites: [-1] 
expected returns: [[54.447067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 29.  0. 29.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 14. 29.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.  0.  0. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1  0] -> size -> 36 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.365291595458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[48.654785]
 [63.498425]
 [46.26464 ]
 [56.282448]
 [33.492413]
 [65.549866]
 [62.858997]
 [55.561607]
 [72.2418  ]
 [68.36569 ]
 [27.243671]
 [56.866684]
 [58.313824]
 [38.44181 ]
 [49.74508 ]
 [57.275448]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 29.  0. 29.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  3.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 14. 29.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.  0.  0. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1  0] -> size -> 36 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.44706726074219



buy possibilites: [-1] 
expected returns: [[19.120527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 29.  0. 29.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  2.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 14. 29.] 
adversary cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.  0.  0. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1  0] -> size -> 36 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   20.    0.    0.    0.    0.  -20.
   0.    0.   62.5   0. ] 
sum of rewards: 297.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 72.24180603027344






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  6. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 14. 29.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.  0.  0. 10.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0 29 14  0  3  3 10  6 10  6  3  0  6  0  6  6
  8  6  6  8  0  0  0  3  0  8  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  2.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  3.  1.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25] -> size -> 37 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.  0.  0. 10.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  2.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  3.  1.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25] -> size -> 37 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 3.  0.  3.  0.  6.  0.  6.  0.  0.  3.  0.  8.  6.  6.  0.  0. 10.  1.
  8.  0.  0.  0.  0.  0. 10.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  2.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  3.  1.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25] -> size -> 37 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [ 1. 25.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 88.880844]
 [110.6002  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  3.  1.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  2.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0] -> size -> 34 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.120527267456055



action possibilites: [-1] 
expected returns: [[89.3347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  1. 29.  3.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  2.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0] -> size -> 34 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 110.6002197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 81.47624 ]
 [ 94.49912 ]
 [ 87.66345 ]
 [ 66.74684 ]
 [ 96.242836]
 [ 94.10823 ]
 [ 87.67346 ]
 [102.08939 ]
 [ 98.4045  ]
 [ 61.32034 ]
 [ 87.03652 ]
 [ 89.658844]
 [ 70.87669 ]
 [ 81.05224 ]
 [ 90.70099 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  1. 29.  3.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  2.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0] -> size -> 34 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.33470153808594



buy possibilites: [-1] 
expected returns: [[110.17297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  1. 29.  3.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  1.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0] -> size -> 34 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -30   0   0 250   0] 
sum of rewards: 475 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 102.08941650390625






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  1.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  1.  3. 25.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29. 25. 25.  1.  0.  3.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25] -> size -> 38 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 21. 30.  8.  0. 10.  9.  4.  1.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  1.  3. 25.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29. 25. 25.  1.  0.  3.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25] -> size -> 38 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  1.  3. 25.] 
adversary cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29. 25. 25.  1.  0.  3.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25] -> size -> 38 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 8.  0.  1.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[51.2552  ]
 [52.480434]
 [76.7956  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1.  3. 25.] 
cards in discard: [ 3. 29. 25. 11. 25.  0. 25.  3.  3. 25.  1. 29.  3. 15.  8. 29. 25. 25.
  0.  1.  1. 29.  0. 29. 25. 25.  1.  0.  3.  1. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [3. 0. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.1729736328125



action possibilites: [-1] 
expected returns: [[8.122206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [3. 0. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 76.79560852050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  3.0909715]
 [ 15.852821 ]
 [  8.977951 ]
 [ 17.455084 ]
 [ 15.477339 ]
 [  9.309753 ]
 [ 19.106083 ]
 [-17.26544  ]
 [ 11.055992 ]
 [  2.0258174]
 [  9.553654 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  2.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [3. 0. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.12220573425293



buy possibilites: [-1] 
expected returns: [[11.661606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1.  3.  0. 29.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [3. 0. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -40   0   0 128   0] 
sum of rewards: 313 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 19.106056213378906






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 3.] 
cards in discard: [3. 0. 0. 3. 6. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  1.  0. 25.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29] -> size -> 39 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 3.] 
cards in discard: [3. 0. 0. 3. 6. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  1.  0. 25.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29] -> size -> 39 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  1.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[49.482563]
 [50.402054]
 [64.29564 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  1.  0. 25.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 6. 6. 8. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.661605834960938



action possibilites: [-1] 
expected returns: [[35.785774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 1. 0. 3. 1.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 6. 6. 8. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 64.29561614990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[32.80916 ]
 [44.563408]
 [30.323246]
 [38.4052  ]
 [19.525743]
 [46.29012 ]
 [44.489273]
 [38.360626]
 [52.052277]
 [47.4812  ]
 [14.053934]
 [37.71727 ]
 [40.361195]
 [23.248907]
 [31.946053]
 [36.64323 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 1. 0. 3. 1.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  1.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 6. 6. 8. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.78577423095703



buy possibilites: [-1] 
expected returns: [[33.989254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 1. 0. 3. 1.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 6. 6. 8. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   20.    0.    0.    0.    0.  -50.
   0.    0.   62.5   0. ] 
sum of rewards: 237.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 52.05228042602539






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 6. 6. 8. 0. 3. 3. 3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  0. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25] -> size -> 40 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 6. 6. 8. 0. 3. 3. 3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  0. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25] -> size -> 40 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3 22] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [29. 25.  0. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25] -> size -> 40 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [29. 25.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 29.] 
expected returns: [[68.31296]
 [78.26608]
 [83.3937 ]
 [83.3937 ]
 [78.26608]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 25. 29.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3 22] -> size -> 36 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.989253997802734



action possibilites: [-1] 
expected returns: [[106.176506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 29. 11.  0.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3 22] -> size -> 36 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.39369201660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[100.92244]
 [109.08759]
 [107.10268]
 [107.33186]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25. 29. 11.  0.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 20. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3 22] -> size -> 36 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.17650604248047



buy possibilites: [-1] 
expected returns: [[92.383255]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25. 29. 11.  0.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 19. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3 22] -> size -> 36 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 109.08757019042969






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [8. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 8. 6. 0.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  3  0  0  3  3 10  6 10  6  3  0  6  0  6  6  8  6
  6  8  0  0  0  3  0  8  1  0  3 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 19. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15.  3. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3] -> size -> 41 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 19. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15.  3. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3] -> size -> 41 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 22. 30. 19. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15.  3. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3] -> size -> 41 
adversary victory points: 8
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 19. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15.  3. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3] -> size -> 41 
adversary victory points: 8
player victory points: 1 





Player: 0 
cards in hand: [ 3. 15.  3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 29.] 
expected returns: [[141.88673]
 [130.65677]
 [159.49467]
 [156.76747]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 25. 29.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 19. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  1.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0] -> size -> 35 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.38325500488281



action possibilites: [-1] 
expected returns: [[91.407364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 29. 29.  1.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 19. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  1.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0] -> size -> 35 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 159.49468994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[80.0708 ]
 [95.82441]
 [92.1873 ]
 [91.40735]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3. 29. 29.  1.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 22. 30. 19. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  1.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0] -> size -> 35 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.40736389160156



buy possibilites: [-1] 
expected returns: [[110.78281]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3. 29. 29.  1.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 18. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  1.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0] -> size -> 35 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 201 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 95.82440185546875






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.  1.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 18. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 25. 29. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.  3. 25.  3. 15.  3. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  1.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 22. 30. 18. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 25. 29. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.  3. 25.  3. 15.  3. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  1.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 25. 29. 25. 29.] 
adversary cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.  3. 25.  3. 15.  3. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 2 





Player: 0 
cards in hand: [ 3. 25. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 29.] 
expected returns: [[102.43587 ]
 [115.179115]
 [113.16384 ]
 [115.179115]
 [113.16384 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 25. 29.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.  3. 25.  3. 15.  3. 29. 29.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  8.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.  3.  0.  6.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3] -> size -> 36 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.78280639648438



action possibilites: [-1] 
expected returns: [[71.27092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25. 29. 25.  3.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.  3. 25.  3. 15.  3. 29. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  8.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.  3.  0.  6.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3] -> size -> 36 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 115.17912292480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[61.56123 ]
 [71.270935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 25. 29. 25.  3.] 
cards in discard: [29. 25.  8.  0.  1.  3.  0. 29. 25. 25.  8.  1.  1.  0.  3.  1.  3. 25.
 29.  0. 25. 29. 11.  0.  3. 25.  3. 15.  3. 29. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  8.] 
adversary cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.  3.  0.  6.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3] -> size -> 36 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.27091979980469






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  6.  8.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.  3.  0.  6.  6. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25. 25.  3. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.  3.  0.  6.  6. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25. 25.  3. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.  3.  0.  6.  6. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  4.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25. 25.  3. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [ 3.  0.  0.  3.  6.  6.  8.  0.  3.  3.  3. 22.  0.  0.  0.  0.  0.  0.
  8.  8.  6.  3.  0.  6.  6. 10.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25. 25.  3. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 2 





Player: 0 
cards in hand: [25. 25.  3. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[46.730816]
 [59.71751 ]
 [59.71751 ]
 [59.71751 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  3. 25.  1.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3  8] -> size -> 37 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.27091979980469



action possibilites: [-1] 
expected returns: [[25.9211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 25.  1. 29.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3  8] -> size -> 37 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 59.71751022338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[20.095716]
 [25.890896]
 [25.618935]
 [26.67047 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 25.  1. 29.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3  8] -> size -> 37 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.921100616455078






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8
  0  0  0  3  0  8  1  0  3 22  0  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [29.  1.  8. 29. 25.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [29.  1.  8. 29. 25.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [29.  1.  8. 29. 25.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [29.  1.  8. 29. 25.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [29.  1.  8. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 25.] 
expected returns: [[30.69844 ]
 [40.95292 ]
 [31.471584]
 [40.95292 ]
 [47.49735 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  8. 29. 25.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0] -> size -> 36 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.670448303222656



action possibilites: [-1] 
expected returns: [[40.005383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  8. 29.  0. 29.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0] -> size -> 36 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 47.49734878540039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[37.251987]
 [49.24242 ]
 [44.66993 ]
 [50.072773]
 [42.37095 ]
 [46.380592]
 [43.278255]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  8. 29.  0. 29.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 17. 30.  8.  0. 10.  9.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0] -> size -> 36 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.0053825378418



buy possibilites: [-1] 
expected returns: [[55.37273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  8. 29.  0. 29.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 17. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0] -> size -> 36 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -80   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 50.07276153564453






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 17. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25.  0.  3. 29.  3.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11] -> size -> 43 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 17. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25.  0.  3. 29.  3.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11] -> size -> 43 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [0. 8. 3. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 22. 30. 17. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25.  0.  3. 29.  3.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11] -> size -> 43 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [25.  0.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[79.80415]
 [94.46208]
 [91.05502]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 29.  3.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 17. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0] -> size -> 37 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.37273025512695



action possibilites: [-1] 
expected returns: [[65.42174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0. 25.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 17. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0] -> size -> 37 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.46207427978516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[59.89002]
 [67.2603 ]
 [66.32416]
 [67.20929]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  0. 25.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 22. 30. 17. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0] -> size -> 37 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.42173767089844



buy possibilites: [-1] 
expected returns: [[88.09157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  0. 25.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 16. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0] -> size -> 37 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 67.26030731201172






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 16. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  1. 25.  3.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.  3. 25.  0.
  3. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11  3] -> size -> 44 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 22. 30. 16. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  1. 25.  3.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.  3. 25.  0.
  3. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11  3] -> size -> 44 
adversary victory points: 10
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 16. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  1. 25.  3.] 
adversary cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.  3. 25.  0.
  3. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11  3] -> size -> 44 
adversary victory points: 10
player victory points: 1 





Player: 0 
cards in hand: [ 3.  1.  1. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[114.009895]
 [125.78775 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 25.  3.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.  3. 25.  0.
  3. 29.  3.  0. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 16. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0. 0. 8. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.09156799316406



action possibilites: [-1] 
expected returns: [[118.510605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1.  3.  1. 29.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.  3. 25.  0.
  3. 29.  3.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 16. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0. 0. 8. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 125.78775024414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[108.94538 ]
 [122.6719  ]
 [105.83082 ]
 [115.32299 ]
 [ 93.31578 ]
 [124.95557 ]
 [122.50179 ]
 [115.93535 ]
 [127.42282 ]
 [ 87.732956]
 [115.14371 ]
 [118.03624 ]
 [ 97.84141 ]
 [108.658966]
 [118.51058 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1.  3.  1. 29.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.  3. 25.  0.
  3. 29.  3.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 22. 30. 16. 30.  8.  0. 10.  8.  3.  0.  1.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0. 0. 8. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.51060485839844



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 6 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 2 
Chapel: 2 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  1.  1.  3.  1. 29.] 
cards in discard: [25. 25.  3. 25.  1. 29.  3. 11. 25. 29.  1.  8. 29.  0. 29.  3. 25.  0.
  3. 29.  3.  0. 25. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 29 29 25 25 25  3  8 25 11  1 29 29 29
 29  3  1  1  8 15 25  1 25  1  3  3 25 25 29 25  3  3 11  3 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 16. 30.  8.  0. 10.  8.  3.  0.  0.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 0. 0. 6. 0. 6. 3. 0. 0. 8. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  8  3  0  0  3  3 10 10  6  3  0  6  0  6  6  8  6  6  8  0  0
  0  3  0  8  1  0  3 22  0  3  8  0  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[     -5 3000000       0     270       0       0      20       0       0
       0       0    -100       0       0      64       0] 
sum of rewards: 3000249 

action type: buy - action 29.0
Learning step: 120004.859375
desired expected reward: 120132.28125



