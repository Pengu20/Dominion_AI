 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.64911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      90       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000085 

action type: buy - action -1
Learning step: 120006.296875
desired expected reward: 119933.8515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[47.34291 ]
 [64.79642 ]
 [62.17178 ]
 [28.115063]
 [85.19719 ]
 [70.220856]
 [67.59622 ]
 [65.48071 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 66.00947570800781



buy possibilites: [-1] 
expected returns: [[71.70026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.19717407226562






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[77.414276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.70025634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[59.594814]
 [76.07292 ]
 [73.56172 ]
 [41.521553]
 [74.07254 ]
 [95.84361 ]
 [81.36369 ]
 [96.58769 ]
 [62.425945]
 [78.79979 ]
 [79.02301 ]
 [76.73541 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.81617736816406



buy possibilites: [-1] 
expected returns: [[70.95035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 96.58770751953125






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 97.331085]
 [118.42996 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.95034790039062



action possibilites: [-1.] 
expected returns: [[87.07936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 115.63523864746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 76.037186]
 [ 90.61095 ]
 [ 88.38197 ]
 [ 59.76991 ]
 [ 88.839935]
 [107.79364 ]
 [ 95.21541 ]
 [108.45134 ]
 [ 78.55492 ]
 [ 92.98645 ]
 [ 93.18619 ]
 [ 91.200775]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.07936096191406



buy possibilites: [-1] 
expected returns: [[91.97325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 108.45135498046875






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [29. 29.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [29. 29.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [29. 29.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 83.887146]
 [103.15216 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [29. 29.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.97325134277344



action possibilites: [-1] 
expected returns: [[81.82677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 101.48075866699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 71.83583]
 [ 87.91539]
 [ 85.43437]
 [ 54.50947]
 [106.9353 ]
 [ 93.02446]
 [ 90.54346]
 [ 88.71791]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.82676696777344



buy possibilites: [-1] 
expected returns: [[75.81416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  3.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 106.93533325195312






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 88.35481]
 [104.68414]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.81416320800781



action possibilites: [-1] 
expected returns: [[92.41893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 103.58464050292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 81.27353 ]
 [ 94.94655 ]
 [ 92.78731 ]
 [ 67.19742 ]
 [ 93.232605]
 [111.565384]
 [ 99.40256 ]
 [112.216995]
 [ 83.50577 ]
 [ 97.24335 ]
 [ 97.44968 ]
 [ 95.59021 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.41893005371094



buy possibilites: [-1] 
expected returns: [[110.28557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.21701049804688






Player: 1 
cards in hand: [ 3.  0. 11.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  1. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1. 29.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[123.479034]
 [142.81058 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.28556823730469



action possibilites: [-1] 
expected returns: [[117.734436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 140.96929931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.65251 ]
 [122.631454]
 [120.061676]
 [ 86.38165 ]
 [142.37529 ]
 [127.923935]
 [125.354126]
 [123.45961 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.73443603515625



buy possibilites: [-1] 
expected returns: [[128.74846]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 142.37530517578125






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0. 11.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3. 29.  3. 10.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0. 10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0. 11.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3. 29.  3. 10.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0. 10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[ 95.57933 ]
 [111.64925 ]
 [111.64925 ]
 [ 97.210144]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  3. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.7484588623047



action possibilites: [-1. 29. 10. 29.] 
expected returns: [[ 96.70749 ]
 [111.851746]
 [ 98.037704]
 [111.851746]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 10. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 107.50514221191406



action possibilites: [-1. 10. 29.] 
expected returns: [[104.1626 ]
 [105.9738 ]
 [123.54314]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.85173034667969



action possibilites: [-1. 10.] 
expected returns: [[142.95326]
 [144.54568]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 123.54315185546875



action possibilites: [-1. 11.] 
expected returns: [[141.3003 ]
 [159.81296]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11] -> size -> 19 
action values: 2 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 144.54568481445312



action possibilites: [-1.] 
expected returns: [[146.75293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 162.40521240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[133.57959]
 [149.20865]
 [146.8342 ]
 [118.72241]
 [116.55612]
 [147.33974]
 [168.186  ]
 [154.18726]
 [185.21713]
 [168.99968]
 [136.32849]
 [145.23622]
 [151.72125]
 [129.65875]
 [151.9922 ]
 [150.05382]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 146.7529296875



buy possibilites: [-1] 
expected returns: [[166.7816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 185.2171173095703






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 10. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 10. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 10. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[151.21494]
 [153.02269]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [10. 25. 29. 29. 29. 10. 11.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 166.78160095214844



action possibilites: [-1. 11.] 
expected returns: [[144.09818]
 [161.1029 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [10. 25. 29. 29. 29. 10. 11.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 146.73146057128906



action possibilites: [-1.] 
expected returns: [[113.99881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 25. 29. 29. 29. 10. 11.  3.  3.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 163.53512573242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.381134]
 [113.79175 ]
 [111.46245 ]
 [ 80.910614]
 [131.68195 ]
 [118.59474 ]
 [116.26543 ]
 [114.471085]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 25. 29. 29. 29. 10. 11.  3.  3.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.99880981445312



buy possibilites: [-1] 
expected returns: [[105.447174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 25. 29. 29. 29. 10. 11.  3.  3.  0.  0. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5. 10.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 131.6819610595703






Player: 1 
cards in hand: [ 0.  3.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 29.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5. 10.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 29.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5. 10.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 29.] 
cards in discard: [29.  0.  3.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [25. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[ 85.23033 ]
 [114.03595 ]
 [100.01166 ]
 [ 86.669815]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  8.  0.  3.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.44717407226562



action possibilites: [-1] 
expected returns: [[82.07237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  8.  0.  3.  1.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 111.12611389160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[68.71623 ]
 [82.243286]
 [80.19064 ]
 [53.44922 ]
 [97.93919 ]
 [86.46477 ]
 [84.412125]
 [82.9837  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  8.  0.  3.  1.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.07237243652344



buy possibilites: [-1] 
expected returns: [[105.609375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0. 10.  0.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  4.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  8.  0.  3.  1.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 97.93917846679688






Player: 1 
cards in hand: [ 3.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [29.  0.  3.  0.  0.  0.  8.  0.  3.  1.  0. 29.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  4.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 29. 10.  3.] 
adversary cards in discard: [11. 25. 11. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [29.  0.  3.  0.  0.  0.  8.  0.  3.  1.  0. 29.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  4.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 29. 10.  3.] 
adversary cards in discard: [11. 25. 11. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [29.  0.  3.  0.  0.  0.  8.  0.  3.  1.  0. 29.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 29. 10.  3.] 
adversary cards in discard: [11. 25. 11. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[114.5533  ]
 [132.02905 ]
 [132.81181 ]
 [116.314514]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 10.  3.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.609375



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[121.606995]
 [137.35222 ]
 [123.1754  ]
 [123.1754  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3. 10.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 127.40475463867188



action possibilites: [-1] 
expected returns: [[73.6344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 139.58682250976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.56867 ]
 [71.129395]
 [45.249203]
 [77.48532 ]
 [73.81691 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.6343994140625



buy possibilites: [-1] 
expected returns: [[54.511803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 77.48533630371094






Player: 1 
cards in hand: [ 1.  3.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29. 29.] 
adversary cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29. 29.] 
adversary cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29. 29.] 
adversary cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 6.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29. 29.] 
adversary cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 29.] 
expected returns: [[14.694027]
 [15.626965]
 [24.13929 ]
 [24.568592]
 [24.568592]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29. 29.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.511802673339844



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[ 8.379101]
 [ 9.472385]
 [19.126062]
 [19.604465]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29.  0.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.568592071533203



action possibilites: [-1. 10. 11.] 
expected returns: [[ 2.6860805]
 [ 3.7534027]
 [13.601414 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.  3.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 19.604461669921875



action possibilites: [-1] 
expected returns: [[-12.784271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 15.140907287597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-23.268576 ]
 [-14.676871 ]
 [-16.01413  ]
 [-32.418034 ]
 [-15.724601 ]
 [ -4.217042 ]
 [-11.925514 ]
 [ -3.7438726]
 [-21.829966 ]
 [-13.262774 ]
 [-13.112046 ]
 [-14.236372 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.784271240234375



buy possibilites: [-1] 
expected returns: [[-26.745647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [11. 25. 11. 10.  0.  0. 10.  0. 10.  8. 29. 11.  0. 10.  3. 10. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -3.743870496749878






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  1.  3.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  1.  3.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  4.  8.  9.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  3.  8.  9.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[79.16829 ]
 [95.45216 ]
 [94.730515]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  3.  8.  9.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -26.745647430419922



action possibilites: [-1. 11.] 
expected returns: [[66.387115]
 [83.12918 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  3.  8.  9.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 89.7884521484375



action possibilites: [-1] 
expected returns: [[110.67102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  3.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.45512390136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.96254]
 [114.19217]
 [112.03682]
 [ 83.88939]
 [131.39896]
 [118.71066]
 [116.47641]
 [114.8407 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  3.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.6710205078125



buy possibilites: [-1] 
expected returns: [[53.57288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  2.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 131.39892578125






Player: 1 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.  3.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  2.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.  3.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  2.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 0. 29.  1.  3.  0.  8.  6. 11.  3.  0.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  2.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[30.018757]
 [32.752148]
 [31.147419]
 [31.147419]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10 11 10 25 10 11 11
 10  8 10 29 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  2.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.572879791259766



action possibilites: [-1] 
expected returns: [[77.402054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  2.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 30.81238555908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[61.382854]
 [72.42961 ]
 [46.71777 ]
 [78.775085]
 [75.18732 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  2.  8.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.40205383300781



buy possibilites: [-1] 
expected returns: [[31.402649]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  2.  7.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 78.77508544921875






Player: 1 
cards in hand: [ 1.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  2.  7.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  2.  7.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 29.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  2.  7.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8] -> size -> 30 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[-0.20779037]
 [11.027882  ]
 [10.558713  ]
 [ 0.866591  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  2.  7.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  1.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.40264892578125



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[-9.482887 ]
 [ 1.3181639]
 [-8.410463 ]
 [-8.410463 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  2.  7.  9.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  1.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 11.027875900268555



action possibilites: [-1] 
expected returns: [[4.8849583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  2.  7.  9.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  1.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 2.7970685958862305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -6.080472 ]
 [  3.287589 ]
 [  1.7832956]
 [-15.950371 ]
 [ 14.82115  ]
 [  6.3849735]
 [  4.8806715]
 [  3.7583466]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  2.  7.  9.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  1.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.884958267211914



buy possibilites: [-1] 
expected returns: [[-9.96672]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  1.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 14.821136474609375






Player: 1 
cards in hand: [ 0.  0. 11.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  1.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11. 10. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  1.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11. 10. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  1.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11. 10. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11. 11. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[-47.731163]
 [-36.04324 ]
 [-36.04324 ]
 [-46.719597]
 [-46.719597]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10.  0.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 6.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1  1] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.966719627380371



action possibilites: [-1] 
expected returns: [[-26.759186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 6.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1  1] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -34.410972595214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-34.166668]
 [-40.849903]
 [-27.382809]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.  0.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 6.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1  1] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.759185791015625






Player: 1 
cards in hand: [8. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 6.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  6  3  0 11  1  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [25. 29. 10. 11. 29.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10. 10. 11. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [25. 29. 10. 11. 29.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10. 10. 11. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [25. 29. 10. 11. 29.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10. 10. 11. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25. 29. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 11. 29.] 
expected returns: [[-54.4684  ]
 [-49.44023 ]
 [-51.744686]
 [-54.221355]
 [-52.136784]
 [-51.744686]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 10. 11. 29.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.  8.  8.  0.  0. 10. 10. 11. 29. 11.  0.
  0. 10. 10. 10. 11. 11. 10. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -27.38280487060547



action possibilites: [-1] 
expected returns: [[70.008484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -49.44023895263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.428616]
 [31.801373]
 [57.21326 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 11. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.00848388671875






Player: 1 
cards in hand: [ 0. 29.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 11.  0.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.  8.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 11.  0.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.  8.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  7.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 11.  0.] 
cards in discard: [ 1.  1.  0.  0.  3. 29.  1.  0.  0. 11.  3.  1.  8.  3.  0.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  6.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[32.425663]
 [33.628193]
 [44.9424  ]
 [44.9424  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  6.  9.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.213253021240234



action possibilites: [-1] 
expected returns: [[34.528934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  6.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.66232681274414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.642025]
 [30.159695]
 [ 5.35021 ]
 [36.01148 ]
 [32.696606]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  6.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.528934478759766



buy possibilites: [-1] 
expected returns: [[9.822762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  5.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 36.0114860534668






Player: 1 
cards in hand: [29.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  5.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  5.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  1.  5.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 10.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 11.] 
expected returns: [[-18.941645]
 [-10.514784]
 [-18.12368 ]
 [-18.12368 ]
 [-10.514784]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 10. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 1. 1. 0.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.822761535644531



action possibilites: [-1] 
expected returns: [[-18.645256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 3. 1. 1. 0.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -9.18896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-26.660248]
 [-35.046307]
 [-18.811914]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 3. 1. 1. 0.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.64525604248047






Player: 1 
cards in hand: [3. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 1. 0.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 10.  3. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8 15] -> size -> 36 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 1. 0.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 10.  3. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8 15] -> size -> 36 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 1. 0.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 10.  3. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8 15] -> size -> 36 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29. 10.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10.] 
expected returns: [[-19.363575]
 [-13.645379]
 [-19.031738]
 [-19.031738]
 [-19.031738]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3. 10. 10.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 11.  6.  8.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -18.811914443969727



action possibilites: [-1. 10. 10. 10.  8.] 
expected returns: [[-37.626083]
 [-37.264805]
 [-37.264805]
 [-37.264805]
 [-36.460636]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  8.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 10 29 10 11 10 25 10 11 11 10
  8 10 29 10 11  8 10 11 10 15  8 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 11.  6.  8.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -19.837955474853516



action possibilites: [-1] 
expected returns: [[-17.888088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 11.  6.  8.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -37.99563217163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-28.859724]
 [-38.429794]
 [-18.40343 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 11.  6.  8.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.88808822631836






Player: 1 
cards in hand: [ 0.  1. 11.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  6.  8.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  0. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15] -> size -> 34 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  6.  8.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  0. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15] -> size -> 34 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-7.1941347]
 [-1.9239728]
 [-1.9239728]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29.  1.  3. 11.  8.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -18.403427124023438



action possibilites: [-1] 
expected returns: [[-31.628613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  1.  3. 11.  8.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -1.130357265472412





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-36.241905]
 [-30.911871]
 [-31.724491]
 [-41.45778 ]
 [-24.72944 ]
 [-29.246851]
 [-30.45814 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  1.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  1.  3. 11.  8.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -31.628612518310547



buy possibilites: [-1] 
expected returns: [[-38.68658]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  0.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  1.  3. 11.  8.] 
adversary cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -24.72943687438965






Player: 1 
cards in hand: [29.  1.  3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 11.  8.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  0.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15. 11. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.
  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  8.  9.  0.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15. 11. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.
  3.  8. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15. 11. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.
  3.  8. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15. 11. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 0. 16. 29.  0.  0.  3.  0.  0.  3.  3.  1.  1.  0.  0.  1. 11.  6.  8.
  3.  8. 16.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15. 11. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11] -> size -> 36 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 29. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10. 10.] 
expected returns: [[-34.23226 ]
 [-32.867332]
 [-27.381315]
 [-33.75236 ]
 [-33.75236 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 10. 10.] 
cards in discard: [25. 29. 10. 11. 29.  0.  3. 15.  8. 11. 10.  0.  0. 11. 15. 11. 10.  3.
 10. 11.  3. 29.  8. 10. 15. 11. 11.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -38.686580657958984



action possibilites: [-1.  8. 10. 11.] 
expected returns: [[56.815372]
 [60.00207 ]
 [58.145256]
 [70.553375]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.] 
cards in discard: [ 0. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -34.67742919921875



action possibilites: [-1] 
expected returns: [[47.385983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [ 0. 10. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 60.002079010009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.73126 ]
 [25.83852 ]
 [47.240246]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [ 0. 10. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.385982513427734






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 15.  0. 10.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11 15] -> size -> 37 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 15.  0. 10.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11 15] -> size -> 37 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 15.  0. 10.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11 15] -> size -> 37 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  0. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10.] 
expected returns: [[10.519058]
 [11.378752]
 [11.551319]
 [11.378752]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  0. 10.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10
 29 10 11  8 10 11 10 15  8 15 15 11 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0. 29. 16.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.240238189697266



action possibilites: [-1] 
expected returns: [[36.665382]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29
 10 11  8 10 11 10 15  8 15 15 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0. 29. 16.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 11.551322937011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[21.303026]
 [34.279896]
 [32.2973  ]
 [ 6.960823]
 [32.726223]
 [38.368748]
 [50.14989 ]
 [23.61626 ]
 [36.61699 ]
 [34.950153]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29
 10 11  8 10 11 10 15  8 15 15 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0. 29. 16.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.665382385253906



buy possibilites: [-1] 
expected returns: [[5.607889]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29
 10 11  8 10 11 10 15  8 15 15 11 15 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0. 29. 16.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -20   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 50.1498908996582






Player: 1 
cards in hand: [ 1.  0. 29. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 16.  0.] 
cards in discard: [0. 3. 3. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 11  0  3 29  8  3  0 11  1  1  1  6  8
 16  0 16  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29
 10 11  8 10 11 10 15  8 15 15 11 15 29] -> size -> 37 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  0  3 29  8  3  0 11  1  1  1  6  8 16
  0 16  1  0 23] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  3. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29
 10 11  8 10 11 10 15  8 15 15 11 15 29] -> size -> 37 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  0  3 29  8  3  0 11  1  1  1  6  8 16
  0 16  1  0 23] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  5.  9.  3. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29
 10 11  8 10 11 10 15  8 15 15 11 15 29] -> size -> 37 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  0  3 29  8  3  0 11  1  1  1  6  8 16
  0 16  1  0 23  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  3. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29
 10 11  8 10 11 10 15  8 15 15 11 15 29] -> size -> 37 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[17.296667]
 [18.8084  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29
 10 11  8 10 11 10 15  8 15 15 11 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  3. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0.  8.  1. 29.  1.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  0  3 29  8  3  0 11  1  1  1  6  8 16
  0 16  1  0 23  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.607889175415039



action possibilites: [-1] 
expected returns: [[33.36485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  3. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0.  8.  1. 29.  1.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  0  3 29  8  3  0 11  1  1  1  6  8 16
  0 16  1  0 23  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 18.808399200439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[20.174936 ]
 [32.293743 ]
 [30.439194 ]
 [ 6.6620274]
 [30.842075 ]
 [36.13713  ]
 [47.44367  ]
 [22.333242 ]
 [34.485626 ]
 [32.929466 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  3. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0.  8.  1. 29.  1.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  0  3 29  8  3  0 11  1  1  1  6  8 16
  0 16  1  0 23  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.36484909057617



buy possibilites: [-1] 
expected returns: [[24.683363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0.  8.  1. 29.  1.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  0  3 29  8  3  0 11  1  1  1  6  8 16
  0 16  1  0 23  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -20   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.443668365478516






Player: 1 
cards in hand: [ 0.  8.  1. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 29.  1.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  0  3 29  8  3  0 11  1  1  1  6  8 16
  0 16  1  0 23  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29.  3. 29. 29. 11.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29] -> size -> 37 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29.  3. 29. 29. 11.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29] -> size -> 37 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29.  3. 29. 29. 11.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29] -> size -> 37 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29.  3. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 11.] 
expected returns: [[-19.256153]
 [ -8.953381]
 [ -8.953381]
 [ -8.953381]
 [ -9.416185]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 29. 11.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  6. 16. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.68336296081543



action possibilites: [-1. 29. 11.] 
expected returns: [[12.0033245]
 [23.086714 ]
 [22.601791 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  6. 16. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -19.699012756347656



action possibilites: [-1. 11.] 
expected returns: [[-12.131522]
 [ -3.908316]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  6. 16. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.519020080566406



action possibilites: [-1] 
expected returns: [[-21.984104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 3.  6. 16. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 59 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -10.182233810424805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-30.913103]
 [-24.09184 ]
 [-39.05841 ]
 [-19.810577]
 [-22.234436]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  4.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 3.  6. 16. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.98410415649414



buy possibilites: [-1] 
expected returns: [[-29.318045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 3.  6. 16. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -19.810577392578125






Player: 1 
cards in hand: [ 3.  6. 16. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16. 11.  0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16
  1  0 23  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  8.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 11. 25. 11. 10.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 11. 25. 11. 10.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 11. 25. 11. 10.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 11. 25. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25. 11. 10.] 
expected returns: [[ 0.35907078]
 [ 6.506853  ]
 [ 6.506853  ]
 [12.143501  ]
 [ 6.506853  ]
 [ 0.814342  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 25. 11. 10.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.  0. 16.  3.
  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -29.318044662475586



action possibilites: [-1] 
expected returns: [[-14.568257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 10. 15. 11.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.  0. 16.  3.
  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.143518447875977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-20.150108]
 [-25.94965 ]
 [-14.568239]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11. 10. 15. 11.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.  0. 16.  3.
  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.568257331848145






Player: 1 
cards in hand: [1. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.  0. 16.  3.
  6. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11. 25. 11. 11. 11. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.  0. 16.  3.
  6. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  3.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11. 25. 11. 11. 11. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 23.  8. 16.  1.  0.  0.  8.  0. 29.  0. 16.  3.
  6. 11.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  2.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11. 25. 11. 11. 11. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[-23.824116]
 [-23.130684]
 [-16.016579]
 [-16.016579]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  0.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11. 25. 11. 11. 11. 10. 15. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  2.  9.  2. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 16.  1. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -14.568257331848145



action possibilites: [-1] 
expected returns: [[-17.354197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11. 25. 11. 11. 11. 10. 15. 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  2.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 16.  1. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 29 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -22.09040641784668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-22.94541 ]
 [-18.594284]
 [-29.475246]
 [-16.13203 ]
 [-17.354187]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11. 25. 11. 11. 11. 10. 15. 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  2.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 16.  1. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.354196548461914



buy possibilites: [-1] 
expected returns: [[-19.479614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [ 0. 10. 15. 29. 11.  8. 10. 29. 15. 10.  0. 10. 29. 15.  3.  3.  0. 29.
 10.  3.  8. 15.  8. 29. 29. 11. 25. 11. 11. 11. 10. 15. 11. 15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 16.  1. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6  8] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -16.132043838500977






Player: 1 
cards in hand: [ 0. 16.  1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1. 11.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1
  0 23  8  0  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  8.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 41 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.] 
cards in discard: [16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1  0
 23  8  0  6  8 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  7.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 41 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.] 
cards in discard: [16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1  0
 23  8  0  6  8 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 28. 30.  8.  7.  7.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 41 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.] 
cards in discard: [16.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1  0
 23  8  0  6  8 16  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7.  7.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 41 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 10. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.  8.] 
expected returns: [[29.7882 ]
 [42.41277]
 [30.86739]
 [30.86739]
 [32.53477]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7.  7.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [6. 8. 8. 0. 1.] 
adversary cards in discard: [16.  1. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1  0
 23  8  0  6  8 16  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -19.4796142578125



action possibilites: [-1. 10.  8.] 
expected returns: [[46.599106]
 [47.543964]
 [48.919857]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [10.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 10 25 10 11 11 10  8 10 29 10
 11  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 30.  8.  7.  7.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [6. 8. 8. 0. 1.] 
adversary cards in discard: [16.  1. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1  0
 23  8  0  6  8 16  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.232196807861328



action possibilites: [-1] 
expected returns: [[44.309174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 25 10 11 11 10  8 10 29 10 11
  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 30.  8.  7.  7.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [6. 8. 8. 0. 1.] 
adversary cards in discard: [16.  1. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1  0
 23  8  0  6  8 16  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 47.67766189575195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.374752]
 [40.520237]
 [19.373833]
 [45.52067 ]
 [42.69661 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 25 10 11 11 10  8 10 29 10 11
  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 28. 30.  8.  7.  7.  0.  1.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [6. 8. 8. 0. 1.] 
adversary cards in discard: [16.  1. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1  0
 23  8  0  6  8 16  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.309173583984375



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 6 
Witch: 1 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0.] 
cards in discard: [10.  8.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 29 11 29 11 25 10 11 11 10  8 10 29 10 11
  8 10 11 10 15  8 15 15 11 15 29 29 15  8 15  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7.  7.  0.  0.  9.  2. 10.  9.  0. 10.  4.] 
adversary cards in hand: [6. 8. 8. 0. 1.] 
adversary cards in discard: [16.  1. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3 29  8  3  0 11  1  1  6  8 16  0 16  1  0
 23  8  0  6  8 16  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      40       0       0
       0       0     -60       0       0       8       0] 
sum of rewards: 3000013 

action type: buy - action 8.0
Learning step: 119998.6953125
desired expected reward: 120044.21875



