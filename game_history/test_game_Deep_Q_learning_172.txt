 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.04468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      60       0       0      40       0       0
       0       0    -190       0       0       0       0] 
sum of rewards: 2999905 

action type: gain_card_n - action 0
Learning step: 120000.2578125
desired expected reward: 119898.6640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 27.472084]
 [ 46.36818 ]
 [ 39.386967]
 [ 12.297594]
 [-36.839508]
 [ 48.08604 ]
 [ 46.6903  ]
 [ 34.258488]
 [ 58.94358 ]
 [ 54.882847]
 [  5.049818]
 [ 44.223953]
 [ 41.304405]
 [ 20.919855]
 [ 34.2306  ]
 [ 32.394863]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.95219421386719



buy possibilites: [-1] 
expected returns: [[38.587914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 58.943580627441406






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.89664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.587913513183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 20.211555]
 [ 33.20104 ]
 [-51.266388]
 [ 28.06615 ]
 [ 25.360907]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.559005737304688



buy possibilites: [-1] 
expected returns: [[35.421207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 33.20105743408203






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[35.3825  ]
 [59.162292]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.421207427978516



action possibilites: [-1] 
expected returns: [[13.464033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.620140075683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  8.04519 ]
 [ 24.777668]
 [ 20.299536]
 [-54.87943 ]
 [ 27.569424]
 [ 27.7482  ]
 [ 14.275299]
 [ 33.965157]
 [-14.256484]
 [ 22.262573]
 [ 13.872667]
 [ 14.697159]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.464033126831055



buy possibilites: [-1] 
expected returns: [[29.931332]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 33.96516036987305






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [8. 0. 3. 0. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [8. 0. 3. 0. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.166829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29. 25.  3.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.931331634521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -8.512469 ]
 [ 12.038797 ]
 [  2.2932148]
 [-76.87328  ]
 [ 14.543015 ]
 [  4.3921423]
 [ 10.041593 ]
 [  2.729207 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29. 25.  3.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.379280090332031



buy possibilites: [-1] 
expected returns: [[11.751226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29. 25.  3.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 14.543045043945312






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11] -> size -> 14 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11] -> size -> 14 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.170252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.751226425170898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  7.845209]
 [ 25.93661 ]
 [ 19.11642 ]
 [-56.12938 ]
 [ 27.060425]
 [ 15.394173]
 [ 22.024694]
 [ 12.536129]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.290117263793945



buy possibilites: [-1] 
expected returns: [[10.19466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.0604248046875






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  3. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  7.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  3. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  7.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  3. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  3.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  6.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  3. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [25.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 4.71418 ]
 [30.899609]
 [25.66341 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 29.  0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  6.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.194660186767578



action possibilites: [-1] 
expected returns: [[38.080017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  6.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 36.920284 ]
 [ 54.026287 ]
 [ 47.584583 ]
 [-15.785803 ]
 [ 58.21122  ]
 [ 55.809364 ]
 [ 44.366028 ]
 [ 62.128647 ]
 [  5.2033205]
 [ 50.256817 ]
 [ 38.48952  ]
 [ 40.93864  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  6.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.08001708984375



buy possibilites: [-1] 
expected returns: [[-1.5052485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  0.  0.] 
cards in discard: [11.  3.  0.  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.12867736816406






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [6. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-0.6638689]
 [10.482021 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.5052485466003418



action possibilites: [-1] 
expected returns: [[12.008038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 13.545524597167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 11.438963]
 [ 19.230919]
 [-34.09842 ]
 [ 17.781555]
 [ 14.050709]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.008037567138672



buy possibilites: [-1] 
expected returns: [[3.8460732]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1] -> size -> 18 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 19.230913162231445






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [6. 1. 0. 3. 0. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [6. 1. 0. 3. 0. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  6.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [6. 1. 0. 3. 0. 8. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  6.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[-2.4577594]
 [ 8.439734 ]
 [15.427166 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 29.] 
cards in discard: [10.  3. 11.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  6.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0. 8. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.8460731506347656



action possibilites: [-1. 11.] 
expected returns: [[20.74445 ]
 [29.269531]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  3.] 
cards in discard: [10.  3. 11.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  6.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0. 8. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.185056686401367



action possibilites: [-1] 
expected returns: [[27.767517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.  3. 11.  3.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  6.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0. 8. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.637550354003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 25.721952]
 [ 39.893604]
 [ 35.239655]
 [-24.877537]
 [ 40.05796 ]
 [ 30.81837 ]
 [ 37.287235]
 [ 29.21149 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.  3. 11.  3.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  6.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0. 8. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.76751708984375



buy possibilites: [-1] 
expected returns: [[24.089458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.  3. 11.  3.  0.  0.  3. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  5.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [6. 1. 0. 3. 0. 8. 0. 8. 3. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.057945251464844






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [6. 1. 0. 3. 0. 8. 0. 8. 3. 6. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  5.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 6.  1.  0.  3.  0.  8.  0.  8.  3.  6.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 6.  1.  0.  3.  0.  8.  0.  8.  3.  6.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 6.  1.  0.  3.  0.  8.  0.  8.  3.  6.  3.  0.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  4.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[14.587376]
 [35.862   ]
 [32.51642 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29.  0.] 
cards in discard: [10.  3. 11.  3.  0.  0.  3. 10. 11. 29. 11.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  4.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8 11  0] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.089458465576172



action possibilites: [-1] 
expected returns: [[-7.729053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8 11  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.19147491455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-13.036177 ]
 [  4.1738214]
 [ -9.592022 ]
 [-86.957535 ]
 [  6.886754 ]
 [  3.851862 ]
 [ -3.1760554]
 [  9.746442 ]
 [-46.62212  ]
 [ -1.051589 ]
 [-14.942679 ]
 [ -5.6883326]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8 11  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.729053020477295



buy possibilites: [-1] 
expected returns: [[18.59642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3.  0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8 11  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 9.746437072753906






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 11.  0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  6  3  0 11  6  1  8 11  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29] -> size -> 21 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29] -> size -> 21 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29] -> size -> 21 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 4.871067]
 [15.198431]
 [10.568527]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  3.  3.] 
cards in discard: [29. 25.  0.  0. 29.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.596420288085938



action possibilites: [-1] 
expected returns: [[13.572617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.] 
cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 15.970279693603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 13.757309 ]
 [-19.79258  ]
 [ 14.5199585]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  3.] 
cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.572616577148438






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [6. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10. 11.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10] -> size -> 22 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [6. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10. 11.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10] -> size -> 22 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10. 11.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10] -> size -> 22 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[14.118139]
 [32.682446]
 [26.069736]
 [26.069736]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 11.  0.] 
cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10. 11.  3. 10.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [6. 8. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.519968032836914



action possibilites: [-1. 11. 11.] 
expected returns: [[63.041977]
 [64.42508 ]
 [64.42508 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10. 11.  3. 10.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  4.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [6. 8. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.73699188232422



action possibilites: [-1] 
expected returns: [[60.233276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10. 11.  3. 10.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [6. 8. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 68.39414978027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[51.36381 ]
 [66.388725]
 [60.102837]
 [12.346647]
 [70.558235]
 [68.052925]
 [58.00839 ]
 [73.56374 ]
 [28.806034]
 [62.862625]
 [52.275154]
 [58.711044]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10. 11.  3. 10.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [6. 8. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.2332763671875



buy possibilites: [-1] 
expected returns: [[31.217697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [29. 25.  0.  0. 29.  0.  3.  0. 10. 11.  3. 10.  3.  3. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [6. 8. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 343 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.56376647949219






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [6. 8. 0. 8. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 10. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29] -> size -> 24 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [6. 8. 0. 8. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 10. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29] -> size -> 24 
adversary victory points: 5
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 10. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 10.] 
expected returns: [[29.645767]
 [34.089172]
 [34.089172]
 [39.242912]
 [34.089172]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [6. 8. 0. 8. 3. 0. 0. 0. 6. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.217697143554688



action possibilites: [-1] 
expected returns: [[31.327892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [6. 8. 0. 8. 3. 0. 0. 0. 6. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.50812530517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 30.140953]
 [-17.823608]
 [ 32.76043 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [6. 8. 0. 8. 3. 0. 0. 0. 6. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.327892303466797






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 11.] 
cards in discard: [6. 8. 0. 8. 3. 0. 0. 0. 6. 3. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  8.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10] -> size -> 25 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [6. 8. 0. 8. 3. 0. 0. 0. 6. 3. 1. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10] -> size -> 25 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [6. 8. 0. 8. 3. 0. 0. 0. 6. 3. 1. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  7. 10.  3.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10] -> size -> 25 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [6. 8. 0. 8. 3. 0. 0. 0. 6. 3. 1. 8. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7. 10.  3.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10] -> size -> 25 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.144936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10. 11. 10. 10. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7. 10.  3.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.76043701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  0.6431527]
 [ 15.938831 ]
 [  4.7055826]
 [-68.56941  ]
 [ 22.970009 ]
 [ 14.239052 ]
 [ 19.965359 ]
 [ 16.194218 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10. 11. 10. 10. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  7. 10.  3.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.587997436523438



buy possibilites: [-1] 
expected returns: [[33.96766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 22.970016479492188






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11] -> size -> 26 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11] -> size -> 26 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11] -> size -> 26 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [29. 29. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[44.422707]
 [62.204376]
 [62.204376]
 [62.204376]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  3.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.96765899658203



action possibilites: [-1. 29. 29. 11.] 
expected returns: [[43.538155]
 [57.227936]
 [57.227936]
 [52.67286 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3. 11.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.07887268066406



action possibilites: [-1. 29. 11.] 
expected returns: [[58.253105]
 [73.012085]
 [67.46074 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 11.  0.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.227943420410156



action possibilites: [-1. 11.] 
expected returns: [[58.24694 ]
 [68.006256]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 73.0121078491211



action possibilites: [-1] 
expected returns: [[86.33358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 70.76666259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 83.84945 ]
 [ 99.21875 ]
 [ 82.60823 ]
 [ 94.45286 ]
 [ 69.19209 ]
 [ 38.979996]
 [100.855576]
 [100.285774]
 [ 88.47984 ]
 [109.13812 ]
 [104.67085 ]
 [ 62.852356]
 [ 96.54926 ]
 [ 94.65929 ]
 [ 77.16815 ]
 [ 86.97871 ]
 [ 88.96315 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.33358001708984



buy possibilites: [-1] 
expected returns: [[72.29171]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 317.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 109.13810729980469






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [1. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  1  8 11  0  6  8  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 11. 25. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3. 10. 25. 29. 29. 29. 11.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 11. 25. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3. 10. 25. 29. 29. 29. 11.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 11. 25. 11.] 
adversary cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3. 10. 25. 29. 29. 29. 11.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [29.  0. 11. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25. 11.] 
expected returns: [[22.241266]
 [41.52726 ]
 [34.22443 ]
 [46.47531 ]
 [34.22443 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 25. 11.] 
cards in discard: [10. 11. 10. 10. 10.  3. 11.  0.  0.  3.  0.  3. 10. 25. 29. 29. 29. 11.
  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  7. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.29170989990234



action possibilites: [-1] 
expected returns: [[29.270298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.475284576416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 26.853432]
 [-19.870161]
 [ 31.603806]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6] -> size -> 20 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.27029800415039






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  8.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10. 10. 29.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  8.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10. 10. 29.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  8.  0.  0.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 10. 10. 29.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [10.  0. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[25.912596]
 [31.582432]
 [31.582432]
 [31.582432]
 [40.702038]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10. 29.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.603797912597656



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[57.75578 ]
 [62.950302]
 [62.950302]
 [62.950302]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.  3.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.16537094116211



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[55.225494]
 [64.01319 ]
 [64.01319 ]
 [64.01319 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3. 10.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 62.950294494628906



action possibilites: [-1. 10. 10.] 
expected returns: [[45.411617]
 [53.750893]
 [53.750893]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.  0.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 3 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 64.01318359375



action possibilites: [-1. 10.] 
expected returns: [[53.48729]
 [66.02928]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 4 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 53.75088882446289



action possibilites: [-1.] 
expected returns: [[49.313057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 5 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 66.029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.62375 ]
 [57.204136]
 [53.445774]
 [12.89957 ]
 [60.228493]
 [58.72106 ]
 [49.384274]
 [63.07009 ]
 [26.922665]
 [54.78221 ]
 [47.48665 ]
 [46.763607]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.31305694580078



buy possibilites: [-1] 
expected returns: [[48.703934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0 100   0   0   0   0   0   0   0 128   0] 
sum of rewards: 433 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 63.070091247558594






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 1.  6.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0 11  6  8 11  0  6  8  1  0  6  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  3.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29] -> size -> 29 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0  6  8 11  0  6  8  0  6  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  3.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29] -> size -> 29 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0  6  8 11  0  6  8  0  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  3.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29] -> size -> 29 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0  6  8 11  0  6  8  0  6  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  3.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29] -> size -> 29 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [11. 11.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[61.363663]
 [67.78844 ]
 [67.78844 ]
 [63.642532]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10.  3.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0  6  8 11  0  6  8  0  6  1  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.70393371582031



action possibilites: [-1] 
expected returns: [[57.683754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0  6  8 11  0  6  8  0  6  1  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 252 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 69.98533630371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.62207 ]
 [21.783371]
 [58.5701  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  3.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6  3  0  6  8 11  0  6  8  0  6  1  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.683753967285156






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [8. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0. 0.] 
cards in discard: [0. 8. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6  3  0  6  8 11  0  6  8  0  6  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.
 10. 11. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [0. 8. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.
 10. 11. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 8. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.
 10. 11. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 8. 6. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.
 10. 11. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [29.  0.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[75.12013]
 [88.61017]
 [88.28616]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 25.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.
 10. 11. 11.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.57012939453125



action possibilites: [-1. 25. 29.] 
expected returns: [[83.34288 ]
 [99.215675]
 [96.99227 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25. 29.] 
cards in discard: [25. 29.  0. 11. 11. 11.  3. 29. 29. 10. 10. 10. 10.  0.  3.  0.  3.  0.
 10. 11. 11.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  6. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 88.61016082763672



action possibilites: [-1] 
expected returns: [[36.77294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.21566772460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 36.070522]
 [ 49.747658]
 [ 42.42948 ]
 [-20.938936]
 [ 48.201786]
 [ 41.156723]
 [ 43.551846]
 [ 37.98006 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.77294158935547



buy possibilites: [-1] 
expected returns: [[34.569942]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29. 11. 10.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 49.747650146484375






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [0. 8. 6. 0. 0. 8. 6. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1] -> size -> 31 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [0. 8. 6. 0. 0. 8. 6. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1] -> size -> 31 
adversary victory points: 5
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[30.470036]
 [44.21013 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.569942474365234



action possibilites: [-1. 29.] 
expected returns: [[14.932407]
 [30.257027]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.210121154785156



action possibilites: [-1. 10.] 
expected returns: [[17.54218]
 [23.37191]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.257030487060547



action possibilites: [-1.] 
expected returns: [[32.21578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1] -> size -> 31 
action values: 2 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 23.371912002563477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.972614 ]
 [38.41532  ]
 [33.44508  ]
 [11.458855 ]
 [-9.110664 ]
 [41.78235  ]
 [39.821182 ]
 [30.221344 ]
 [49.527897 ]
 [45.083755 ]
 [ 6.1295233]
 [36.076313 ]
 [35.365437 ]
 [18.807627 ]
 [27.36161  ]
 [31.723217 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.21577835083008



buy possibilites: [-1] 
expected returns: [[36.216743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 515 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 49.52791976928711






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  3.] 
adversary cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  2.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  3.] 
adversary cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  8.  6.  6.  8.  0. 11.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  1.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  3.] 
adversary cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 3. 25. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[32.858765]
 [60.198494]
 [52.232986]
 [48.348167]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11. 10.  3.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  5. 10.  1.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11] -> size -> 20 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.21674346923828



action possibilites: [-1] 
expected returns: [[47.88518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  3. 11.  0.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 6. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.198486328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.859478]
 [ 1.662993]
 [46.915565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  3. 11.  0.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 6. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.88518142700195






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 1. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 6. 3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.
 25.  3. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.
 25.  3. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 3.] 
cards in discard: [ 6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.
 25.  3. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [10. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[41.267506]
 [42.724648]
 [46.47104 ]
 [46.47104 ]
 [42.724648]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 11. 10.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.
 25.  3. 11. 10.  3. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10] -> size -> 22 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.91558837890625



action possibilites: [-1] 
expected returns: [[57.948864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.
 25.  3. 11. 10.  3. 11.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10] -> size -> 22 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.29441833496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.14902 ]
 [17.575901]
 [59.108047]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 1. 29. 25.  0.  0.  3. 29. 11. 10. 25. 29. 29. 10.  0.  3.  0.  3.  0.
 25.  3. 11. 10.  3. 11.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10] -> size -> 22 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.9488639831543






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [ 6. 10.  0.  1.  6.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 25.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10] -> size -> 33 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [ 6. 10.  0.  1.  6.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 25.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10] -> size -> 33 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 25.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10] -> size -> 33 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [ 1. 25.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[34.529755]
 [55.38268 ]
 [39.519806]
 [50.624084]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  4. 10.  1.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 6. 6. 8. 0.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10  0] -> size -> 23 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.10803985595703



action possibilites: [-1] 
expected returns: [[31.022507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  1.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 6. 6. 8. 0.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 24 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 55.03765869140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 25.390982]
 [ 38.30511 ]
 [ 31.664558]
 [-39.251785]
 [ 39.798645]
 [ 31.435898]
 [ 35.162346]
 [ 29.114769]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  1.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 6. 6. 8. 0.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 24 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.022506713867188



buy possibilites: [-1] 
expected returns: [[30.141499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10. 29.  3.  3.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 6. 6. 8. 0.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 24 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 39.798614501953125






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 8. 0.] 
cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  3  0  6  8 11  0  6  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [29.  3. 10. 29.  0.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11] -> size -> 34 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [29.  3. 10. 29.  0.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11] -> size -> 34 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [29.  3. 10. 29.  0.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11] -> size -> 34 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [29.  3. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[17.915817]
 [31.337448]
 [22.956059]
 [31.337448]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10. 29.  0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.  8.  8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.141498565673828



action possibilites: [-1. 10.] 
expected returns: [[ 9.104811]
 [15.493877]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.  8.  8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.862873077392578



action possibilites: [-1.] 
expected returns: [[19.201845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.  8.  8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 15.493894577026367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 14.665087 ]
 [ 28.037308 ]
 [ 22.24351  ]
 [-20.206715 ]
 [ 30.556309 ]
 [ 19.47733  ]
 [ 32.80867  ]
 [ -6.0192876]
 [ 23.530798 ]
 [ 14.880035 ]
 [ 18.271301 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.  8.  8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.201845169067383



buy possibilites: [-1] 
expected returns: [[42.339005]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.  8.  8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 373 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.80867385864258






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11. 29. 10.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29] -> size -> 35 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [ 6. 10.  0.  1.  6.  6.  3.  0.  0.  8.  0.  3.  0.  6.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11. 29. 10.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29] -> size -> 35 
adversary victory points: 5
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 29. 10.] 
expected returns: [[71.74325 ]
 [81.632256]
 [76.38855 ]
 [81.632256]
 [86.20668 ]
 [76.38855 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 29. 10.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 6. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.33900451660156



action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[111.99403]
 [118.56185]
 [118.56185]
 [113.95542]
 [113.95542]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 6. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 81.99443054199219



action possibilites: [-1] 
expected returns: [[86.759575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 0. 6. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 299 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 121.12922668457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.11249 ]
 [44.095005]
 [87.03493 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 0. 6. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.75957489013672






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 1. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29. 11.  3.  0.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15] -> size -> 36 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  7.  7.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29. 11.  3.  0.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15] -> size -> 36 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1. 8.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  6.  7.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29. 11.  3.  0.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15] -> size -> 36 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [10. 29. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[80.57019]
 [80.41315]
 [90.9151 ]
 [84.46083]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.  3.  0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  6.  7.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [8. 6. 0. 6. 1. 8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.03492736816406



action possibilites: [-1. 10. 11.] 
expected returns: [[81.945145]
 [83.336105]
 [87.690796]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  6.  7.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [8. 6. 0. 6. 1. 8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 85.82593536376953



action possibilites: [-1] 
expected returns: [[105.5076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  6.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [8. 6. 0. 6. 1. 8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.85518646240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.28925 ]
 [105.80755 ]
 [ 63.436386]
 [103.03128 ]
 [106.5243  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  6.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [8. 6. 0. 6. 1. 8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.50759887695312






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [8. 6. 0. 6. 1. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  6.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 25. 25.  3. 11.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0. 15. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [8. 6. 0. 6. 1. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  6.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 25. 25.  3. 11.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0. 15. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [8. 6. 0. 6. 1. 8. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 25. 25.  3. 11.] 
adversary cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0. 15. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 0. 25. 25.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11.] 
expected returns: [[45.674244]
 [56.85946 ]
 [56.85946 ]
 [48.679455]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  3. 11.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0. 15. 29. 11. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  3. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 11. 10.  3.  8.] 
adversary cards in discard: [8. 6. 0. 6. 1. 8. 8. 0. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8] -> size -> 23 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 106.5242919921875



action possibilites: [-1] 
expected returns: [[43.223553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 11. 11. 10.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0. 15. 29. 11. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  2. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 11. 10.  3.  8.] 
adversary cards in discard: [8. 6. 0. 6. 1. 8. 8. 0. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6] -> size -> 24 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.859458923339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.925705 ]
 [ 0.9973135]
 [43.22357  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3. 11. 11. 10.] 
cards in discard: [11. 25.  1.  0. 10. 29.  3.  3. 29. 29. 29. 10.  3.  0.  0.  0. 10. 15.
 29. 11. 11. 10. 10.  0. 15. 29. 11. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  2. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 11. 10.  3.  8.] 
adversary cards in discard: [8. 6. 0. 6. 1. 8. 8. 0. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6] -> size -> 24 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.22355270385742






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  8.] 
cards in discard: [8. 6. 0. 6. 1. 8. 8. 0. 0. 6. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  2. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [25. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  3.  8.] 
cards in discard: [8. 6. 0. 6. 1. 8. 8. 0. 0. 6. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  2. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [25. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  3.  8.] 
cards in discard: [8. 6. 0. 6. 1. 8. 8. 0. 0. 6. 3. 0. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 27. 30.  8.  2. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [25. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [25. 25. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 10. 11.] 
expected returns: [[ 4.649337]
 [21.206545]
 [21.206545]
 [11.474264]
 [13.427969]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 30.  8.  2. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [ 8.  6.  0.  6.  1.  8.  8.  0.  0.  6.  3.  0.  6.  0.  0. 11. 10.  3.
  8.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0] -> size -> 25 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.22355270385742



action possibilites: [-1] 
expected returns: [[30.45803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [ 8.  6.  0.  6.  1.  8.  8.  0.  0.  6.  3.  0.  6.  0.  0. 11. 10.  3.
  8.  6.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 21.206527709960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 24.850273]
 [-25.816732]
 [ 31.020187]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10. 11.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 27. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [ 8.  6.  0.  6.  1.  8.  8.  0.  0.  6.  3.  0.  6.  0.  0. 11. 10.  3.
  8.  6.] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.458030700683594






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  8.] 
cards in discard: [ 8.  6.  0.  6.  1.  8.  8.  0.  0.  6.  3.  0.  6.  0.  0. 11. 10.  3.
  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  8.] 
cards in discard: [ 8.  6.  0.  6.  1.  8.  8.  0.  0.  6.  3.  0.  6.  0.  0. 11. 10.  3.
  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 27. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  8.] 
cards in discard: [ 8.  6.  0.  6.  1.  8.  8.  0.  0.  6.  3.  0.  6.  0.  0. 11. 10.  3.
  8.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [10.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[23.413513]
 [25.75568 ]
 [25.75568 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0. 10.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6  3] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.020164489746094



action possibilites: [-1. 10. 11.] 
expected returns: [[22.571484]
 [25.908684]
 [30.58554 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 11.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6  3] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 25.755691528320312



action possibilites: [-1. 10.] 
expected returns: [[21.230854]
 [25.527006]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6  3] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 309 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.05197525024414



action possibilites: [-1. 11.] 
expected returns: [[25.981384]
 [35.241974]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6  3] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 25.526988983154297



action possibilites: [-1.] 
expected returns: [[42.433025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6  3] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  80   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 339 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.07029724121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.816547 ]
 [-6.1590147]
 [41.933    ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6  3] -> size -> 27 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.43302536010742






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  3  0  8 11  0  8  0  6  1  0  0  6 11  6 10  0  6  8  8  6
  0  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15] -> size -> 39 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15] -> size -> 39 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15] -> size -> 39 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15] -> size -> 39 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [29.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[108.19031]
 [122.10045]
 [122.10045]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  3.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [8. 3. 6. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.933013916015625



action possibilites: [-1. 11.] 
expected returns: [[63.72995 ]
 [72.007095]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [8. 3. 6. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 115.70018005371094



action possibilites: [-1] 
expected returns: [[67.318085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [8. 3. 6. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 74.58682250976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[61.647125]
 [68.74666 ]
 [27.353485]
 [66.01319 ]
 [68.33479 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 26. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [8. 3. 6. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.31808471679688



buy possibilites: [-1] 
expected returns: [[60.774277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [8. 3. 6. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 231 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 68.74665832519531






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [8. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 3. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3  0  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [11. 11. 10. 29. 15.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3] -> size -> 41 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [11. 11. 10. 29. 15.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3] -> size -> 41 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [11. 11. 10. 29. 15.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3] -> size -> 41 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [11. 11. 10. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 29. 15.] 
expected returns: [[61.13542 ]
 [63.73561 ]
 [63.73561 ]
 [60.81202 ]
 [71.922646]
 [54.80715 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 29. 15.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [ 6.  0.  8. 11.  0.] 
adversary cards in discard: [0. 8. 0. 8. 6. 3.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.77427673339844



action possibilites: [-1. 11. 11. 10. 15.] 
expected returns: [[41.846992]
 [45.402275]
 [45.402275]
 [42.28588 ]
 [35.728283]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 15.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [ 6.  0.  8. 11.  0.] 
adversary cards in discard: [0. 8. 0. 8. 6. 3.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 65.5931167602539



action possibilites: [-1] 
expected returns: [[107.68945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 6.  0.  8. 11.  0.] 
adversary cards in discard: [0. 8. 0. 8. 6. 3.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 299 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 47.83855056762695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[101.36244 ]
 [ 66.801605]
 [107.68945 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 15.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 6.  0.  8. 11.  0.] 
adversary cards in discard: [0. 8. 0. 8. 6. 3.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.689453125






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 11.  0.] 
cards in discard: [0. 8. 0. 8. 6. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15. 29. 11. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15] -> size -> 42 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8. 11.  0.] 
cards in discard: [0. 8. 0. 8. 6. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15. 29. 11. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15] -> size -> 42 
adversary victory points: 6
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[82.53608]
 [84.2236 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15. 29. 11. 11. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 107.689453125



action possibilites: [-1. 29.] 
expected returns: [[71.45458]
 [84.10477]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15. 29. 11. 11. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 84.22357177734375



action possibilites: [-1. 15.] 
expected returns: [[32.358086]
 [28.761116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15. 29. 11. 11. 10. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15] -> size -> 42 
action values: 2 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 77.97114562988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.039955 ]
 [37.984974 ]
 [32.848373 ]
 [-8.954466 ]
 [41.08456  ]
 [29.21484  ]
 [45.46744  ]
 [ 6.5945683]
 [34.494576 ]
 [28.761116 ]
 [32.35808  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15. 29. 11. 11. 10. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.358062744140625



buy possibilites: [-1] 
expected returns: [[16.134739]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [25. 25. 10. 11.  0. 10. 29. 15. 15. 10. 11. 10. 11.  3.  3.  0. 29. 15.
  3. 29. 11.  3.  0.  3.  1. 15. 29. 11. 11. 10. 15.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -80   0   0 128   0] 
sum of rewards: 353 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 45.467430114746094






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [11.  6.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  1.] 
cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [15. 29. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29] -> size -> 43 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  1.] 
cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  5.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [15. 29. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29] -> size -> 43 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  1.] 
cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [15. 29. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29] -> size -> 43 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [15. 29. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 10. 25.] 
expected returns: [[ 3.715767 ]
 [ 4.0009813]
 [15.147997 ]
 [ 7.1194286]
 [12.39234  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 10. 25.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 8.  6. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.  8. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.13473892211914



action possibilites: [-1. 15. 10. 15.] 
expected returns: [[28.632057]
 [22.519686]
 [32.00317 ]
 [22.519686]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 15.] 
cards in discard: [25.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 8.  6. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.  8. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.2017927169799805



action possibilites: [-1. 15. 15.] 
expected returns: [[28.025318]
 [22.004578]
 [22.004578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  3.] 
cards in discard: [25.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29] -> size -> 43 
action values: 2 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 8.  6. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.  8. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 32.00316619873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 20.94003 ]
 [ 29.05088 ]
 [-51.631794]
 [ 26.325905]
 [ 27.284737]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  3.] 
cards in discard: [25.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 8.  6. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.  8. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.025318145751953



buy possibilites: [-1] 
expected returns: [[74.67206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  3.] 
cards in discard: [25.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 8.  6. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.  8. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 29.050880432128906






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 8.  6. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  8.  0.] 
cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.  8. 11.  6.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 10. 29. 15. 29.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.  8.  0.] 
cards in discard: [ 0.  8.  0.  8.  6.  3.  6.  0.  8. 11.  0.  8. 11.  6.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 10. 29. 15. 29.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
adversary victory points: 7
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10. 29. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15. 29.] 
expected returns: [[51.73982 ]
 [53.78323 ]
 [62.417908]
 [47.9805  ]
 [62.417908]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 15. 29.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.67205810546875



action possibilites: [-1. 10. 15. 10.] 
expected returns: [[91.07173]
 [91.02232]
 [83.13566]
 [91.02232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15. 10.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 59.565399169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[85.94454 ]
 [91.994354]
 [50.008633]
 [90.62457 ]
 [92.49137 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15. 10.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.07172393798828






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3. 11. 15. 15.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3. 11. 15. 15.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
adversary victory points: 7
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3. 11. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15.] 
expected returns: [[69.205444]
 [75.20418 ]
 [63.705246]
 [63.705246]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 15. 15.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 6. 11.  8.  0.  0.] 
adversary cards in discard: [3. 0. 6. 3. 6.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.49137878417969



action possibilites: [-1] 
expected returns: [[95.75117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 15.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 6. 11.  8.  0.  0.] 
adversary cards in discard: [3. 0. 6. 3. 6.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -100    0    0
   64    0] 
sum of rewards: 279 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.58235931396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[89.87261 ]
 [53.815647]
 [96.71332 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15. 15.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 6. 11.  8.  0.  0.] 
adversary cards in discard: [3. 0. 6. 3. 6.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.75116729736328






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8.  0.  0.] 
cards in discard: [3. 0. 6. 3. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29.  1. 10. 10. 11.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15] -> size -> 45 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  8.  0.  0.] 
cards in discard: [3. 0. 6. 3. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29.  1. 10. 10. 11.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15] -> size -> 45 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  8.  0.  0.] 
cards in discard: [3. 0. 6. 3. 6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29.  1. 10. 10. 11.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15] -> size -> 45 
adversary victory points: 7
player victory points: -3 





Player: 0 
cards in hand: [29.  1. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 11.] 
expected returns: [[42.552734]
 [61.43538 ]
 [48.25132 ]
 [48.25132 ]
 [53.114975]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 10. 10. 11.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [8. 1. 0. 0. 8.] 
adversary cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.71333312988281



action possibilites: [-1. 10. 10. 11. 15.] 
expected returns: [[ 97.42676 ]
 [ 98.11108 ]
 [ 98.11108 ]
 [102.701836]
 [ 90.508   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 15.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [8. 1. 0. 0. 8.] 
adversary cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 49.48150634765625



action possibilites: [-1] 
expected returns: [[123.703674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [8. 1. 0. 0. 8.] 
adversary cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -110    0    0
   64    0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 104.42947387695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[116.543724]
 [ 82.04027 ]
 [123.70366 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [8. 1. 0. 0. 8.] 
adversary cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.] 
adversary owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.70367431640625






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [8. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0. 8.] 
cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  0  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8.] 
cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
adversary victory points: 7
player victory points: -3 





Player: 0 
cards in hand: [ 3. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[44.99019 ]
 [67.725876]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  3.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.  0.  8.  1.  0.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 123.70367431640625



action possibilites: [-1.] 
expected returns: [[130.60072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.  0.  8.  1.  0.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 49.7270393371582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[118.0338  ]
 [135.29855 ]
 [128.14922 ]
 [ 67.98922 ]
 [126.928375]
 [132.95941 ]
 [130.60072 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.  0.  8.  1.  0.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 130.60072326660156



buy possibilites: [-1] 
expected returns: [[100.02407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.  0.  8.  1.  0.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -120    0    0
   54    0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 135.29855346679688






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 8. 6.] 
cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.  0.  8.  1.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 11. 10.  3. 25.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 8. 6.] 
cards in discard: [ 3.  0.  6.  3.  6.  0.  6. 11.  8.  0.  0.  0.  8.  1.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 11. 10.  3. 25.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11. 10.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
expected returns: [[ 0.13687801]
 [ 7.9881    ]
 [ 3.9479485 ]
 [17.956299  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3. 25.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  1. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 6.  0.  6. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.0240707397461



action possibilites: [-1] 
expected returns: [[32.042877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3. 11. 29.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 6.  0.  6. 10. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.956310272216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.914867]
 [32.042854]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  3. 11. 29.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 6.  0.  6. 10. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.042877197265625






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  6. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 10. 11.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0. 10.  3. 25.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3. 25.  0.
 11. 10.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11.  0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  4.  7.  3. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0. 10.  3. 25.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3. 25.  0.
 11. 10.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  4.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0. 10.  3. 25.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3. 25.  0.
 11. 10.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  4.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0. 10.  3. 25.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3. 25.  0.
 11. 10.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 14.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0. 10.  3. 25.] 
adversary cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3. 25.  0.
 11. 10.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -4 





Player: 0 
cards in hand: [11.  0. 10.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
expected returns: [[24.803024]
 [31.239883]
 [27.272911]
 [39.434437]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3. 25.] 
cards in discard: [25.  3. 29. 10. 15.  0. 15.  3. 29. 29.  0. 10. 15. 10. 15. 11.  0.  3.
 15. 15.  1. 15. 29. 11. 10. 10. 15. 29.  1. 29.  3.  0.  0.  3. 25.  0.
 11. 10.  3. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8] -> size -> 28 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.042877197265625



action possibilites: [-1] 
expected returns: [[51.537895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8] -> size -> 28 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 39.434444427490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.754993]
 [52.16012 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8] -> size -> 28 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.53789520263672






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 8.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 15. 15. 29. 15.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 8.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 24. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 15. 15. 29. 15.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 8.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 15. 15. 29. 15.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
adversary victory points: 7
player victory points: -3 





Player: 0 
cards in hand: [ 3. 15. 15. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 29. 15.] 
expected returns: [[ 96.51766 ]
 [ 87.142624]
 [ 87.142624]
 [105.067406]
 [ 87.142624]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 29. 15.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  8.  8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.16012191772461



action possibilites: [-1. 15. 15. 10.] 
expected returns: [[110.79841 ]
 [106.51962 ]
 [106.51962 ]
 [112.279434]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 23. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  8.  8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 102.83795166015625



action possibilites: [-1. 15. 15. 29.] 
expected returns: [[115.31213]
 [110.13795]
 [110.13795]
 [125.54521]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 29.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 23. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  8.  8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 112.27943420410156



action possibilites: [-1. 10.] 
expected returns: [[121.01613]
 [121.61058]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 2 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 23. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  8.  8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 124.62492370605469



action possibilites: [-1. 15.] 
expected returns: [[115.530014]
 [111.19258 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 3 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 23. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  8.  8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 121.61058044433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[111.28532 ]
 [116.721855]
 [114.84079 ]
 [114.82291 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1] -> size -> 47 
action values: 3 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 23. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  8.  8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.52999877929688



buy possibilites: [-1] 
expected returns: [[77.51509]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
action values: 3 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  8.  8.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  330    0    0   80    0    0    0    0 -130    0    0
   16    0] 
sum of rewards: 291 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 116.72187042236328






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  8.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  9. 10.  2. 10.  2.] 
adversary cards in hand: [10.  0. 25. 29. 11.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10.  0. 25. 29. 11.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10.  0. 25. 29. 11.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3 14  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10.  0. 25. 29. 11.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
adversary victory points: 8
player victory points: -3 





Player: 0 
cards in hand: [10.  0. 25. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29. 11.] 
expected returns: [[57.803764]
 [58.15457 ]
 [71.48808 ]
 [68.27636 ]
 [62.623634]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25. 29. 11.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 1. 0. 8. 0.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.  0. 11.
  0.  0.  8.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3 14  0] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.51509094238281



action possibilites: [-1] 
expected returns: [[115.37549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 11.  3.  3.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 1. 0. 8. 0.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.  0. 11.
  0.  0.  8.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3 14  0] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.48809051513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[109.05671]
 [115.37546]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29. 11.  3.  3.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 1. 0. 8. 0.] 
adversary cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.  0. 11.
  0.  0.  8.  8.] 
adversary owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3 14  0] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.37548828125






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [8. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 8. 0.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.  0. 11.
  0.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  8 11  8  0  1  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0
  0  6 14  8  3 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 1.  0. 10. 25.  3.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.  0. 11.
  0.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 11  8  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14
  8  3 14  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 1.  0. 10. 25.  3.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 14.  8. 10. 11.  6.  0.  6.  0.  3.  0.  0.  6.  6.  8. 14.  0. 11.
  0.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 11  8  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14
  8  3 14  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 1.  0. 10. 25.  3.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
adversary victory points: 8
player victory points: -3 





Player: 0 
cards in hand: [ 1.  0. 10. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[ 96.44237]
 [ 95.90012]
 [107.45545]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 25.  3.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 3. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11  8  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14
  8  3 14  0] -> size -> 28 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 115.37548828125



action possibilites: [-1] 
expected returns: [[56.81292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  3. 15.  0.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 3. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11  8  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14
  8  3 14  0] -> size -> 28 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.45547485351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[52.02978 ]
 [70.06615 ]
 [64.70542 ]
 [75.30175 ]
 [58.550484]
 [78.31495 ]
 [26.985699]
 [66.564255]
 [55.22231 ]
 [56.812954]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  3. 15.  0.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  3.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 3. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11  8  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14
  8  3 14  0] -> size -> 28 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.81291961669922



buy possibilites: [-1] 
expected returns: [[44.97596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  3. 15.  0.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  2.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 3. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11  8  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14
  8  3 14  0] -> size -> 28 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -140    0    0
  128    0] 
sum of rewards: 333 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 78.3149185180664






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 3. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 11  8  0  0  6 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14
  8  3 14  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  2.  8. 10.  2. 10.  2.] 
adversary cards in hand: [11. 11.  3.  0. 29.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29] -> size -> 49 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  0  0 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  2.  8. 10.  2. 10.  2.] 
adversary cards in hand: [11. 11.  3.  0. 29.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29] -> size -> 49 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  0  0 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  2.  8. 10.  2. 10.  2.] 
adversary cards in hand: [11. 11.  3.  0. 29.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29] -> size -> 49 
adversary victory points: 8
player victory points: -3 





Player: 0 
cards in hand: [11. 11.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[-64.67309 ]
 [-54.168106]
 [-54.168106]
 [-36.313046]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0. 29.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  2.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11  8  0  0 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14
  0] -> size -> 25 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.97595977783203



action possibilites: [-1. 11. 11.] 
expected returns: [[7.1494465]
 [8.69681  ]
 [8.69681  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  2.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11  8  0  0 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14
  0] -> size -> 25 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -48.397315979003906



action possibilites: [-1] 
expected returns: [[32.321507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11  8  0  0 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14
  0] -> size -> 25 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  330    0    0   40    0    0    0    0 -150    0    0
   64    0] 
sum of rewards: 279 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 11.118621826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[16.70319 ]
 [23.418571]
 [26.14618 ]
 [32.32146 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11  8  0  0 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14
  0] -> size -> 25 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.32150650024414






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  0.] 
cards in discard: [8. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  0  0 11  6 10  0  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 1.  0. 29. 11.  0.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 1.  0. 29. 11.  0.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 1.  0. 29. 11.  0.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 1.  0. 29. 11.  0.] 
adversary cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
adversary victory points: 8
player victory points: -3 





Player: 0 
cards in hand: [ 1.  0. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[49.756645]
 [61.63189 ]
 [55.3762  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 11.  0.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [14.  6.  8.  6.  6.] 
adversary cards in discard: [8. 3. 0. 8.] 
adversary owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 22 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.32150650024414



action possibilites: [-1. 29.] 
expected returns: [[40.926266]
 [49.189354]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.  1. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [14.  6.  8.  6.  6.] 
adversary cards in discard: [8. 3. 0. 8.] 
adversary owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 22 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.62602233886719



action possibilites: [-1.] 
expected returns: [[16.37399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.  1. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [14.  6.  8.  6.  6.] 
adversary cards in discard: [8. 3. 0. 8.] 
adversary owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 22 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.749794006347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[10.989864]
 [18.949722]
 [15.674063]
 [16.37398 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.  1. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29] -> size -> 50 
action values: 1 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 22. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [14.  6.  8.  6.  6.] 
adversary cards in discard: [8. 3. 0. 8.] 
adversary owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 22 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.37398910522461



buy possibilites: [-1] 
expected returns: [[2.481104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 11.  0. 10.  3. 10. 11.  3. 15. 15. 15.  3. 29. 10. 29. 10. 15. 25.
 10.  0. 29. 11.  3.  3. 29. 25.  1.  0. 10.  3. 15.  0.  3. 29. 29. 29.
 11. 11.  0.  1. 11.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [14.  6.  8.  6.  6.] 
adversary cards in discard: [8. 3. 0. 8.] 
adversary owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 22 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  360    0    0   40    0    0    0    0 -160    0    0
   16    0] 
sum of rewards: 251 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 18.949718475341797






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [14.  6.  8.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  8.  6.  6.] 
cards in discard: [8. 3. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  6 10  6  8  8  6  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 15. 15. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [8. 3. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 15. 15. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [8. 3. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 15. 15. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [8. 3. 0. 8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 15. 15. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [ 0. 15. 15. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 10.] 
expected returns: [[29.732895]
 [22.880856]
 [22.880856]
 [22.880856]
 [31.273296]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15. 15. 10.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10.  8.  6.  0.  0.] 
adversary cards in discard: [ 8.  3.  0.  8.  0.  8. 14.] 
adversary owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0] -> size -> 20 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.4811038970947266



action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[38.65881 ]
 [30.640045]
 [30.640045]
 [30.640045]
 [30.640045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10.  8.  6.  0.  0.] 
adversary cards in discard: [ 8.  3.  0.  8.  0.  8. 14.] 
adversary owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0] -> size -> 20 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 31.27330780029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.989609]
 [37.939255]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10.  8.  6.  0.  0.] 
adversary cards in discard: [ 8.  3.  0.  8.  0.  8. 14.] 
adversary owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0] -> size -> 20 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.65882110595703






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [10.  8.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.  0.  0.] 
cards in discard: [ 8.  3.  0.  8.  0.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  3.  3. 25.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  0.  0.] 
cards in discard: [ 8.  3.  0.  8.  0.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  3.  3. 25.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  0.  0.] 
cards in discard: [ 8.  3.  0.  8.  0.  8. 14.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  3.  3. 25.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [ 3.  3.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[72.140976]
 [89.253685]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  3. 25.] 
cards in discard: [10.  0. 15. 15. 15. 15.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 8.  3.  0.  8.  0.  8. 14.  3. 10.  8.  6.  0.  0.] 
adversary owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0  3] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.939266204833984



action possibilites: [-1] 
expected returns: [[90.20639]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  3.  0. 10.] 
cards in discard: [10.  0. 15. 15. 15. 15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 8.  3.  0.  8.  0.  8. 14.  3. 10.  8.  6.  0.  0.] 
adversary owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0  3] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 89.25367736816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[83.84   ]
 [89.40499]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  3.  0. 10.] 
cards in discard: [10.  0. 15. 15. 15. 15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [ 8.  3.  0.  8.  0.  8. 14.  3. 10.  8.  6.  0.  0.] 
adversary owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0  3] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.20639038085938






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 6.] 
cards in discard: [ 8.  3.  0.  8.  0.  8. 14.  3. 10.  8.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  8  0  6  3  0  8  0  0  6 14  8  3 14  0  0  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10. 25.  3.  3. 15.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  3.  0.  8.  0.  8. 14.  3. 10.  8.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10. 25.  3.  3. 15.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  3.  0.  8.  0.  8. 14.  3. 10.  8.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10. 25.  3.  3. 15.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  3.  0.  8.  0.  8. 14.  3. 10.  8.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [10. 25.  3.  3. 15.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [10. 25.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 15.] 
expected returns: [[50.172268]
 [37.243637]
 [62.630974]
 [24.782883]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3.  3. 15.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 8.  8.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0] -> size -> 20 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.40498352050781



action possibilites: [-1] 
expected returns: [[79.97832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 15. 29. 29.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 8.  8.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0] -> size -> 20 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.63097381591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[72.42363 ]
 [80.811165]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 15. 29. 29.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 8.  8.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0] -> size -> 20 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.97831726074219






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 14. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 15.  3.  1. 11.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 14.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [ 0. 15.  3.  1. 11.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0. 14.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [ 0. 15.  3.  1. 11.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [ 0. 15.  3.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[29.14    ]
 [21.8094  ]
 [39.849922]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  1. 11.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14.] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.8111801147461



action possibilites: [-1] 
expected returns: [[54.428986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  1.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14.] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 36.228694915771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[49.20542 ]
 [62.197304]
 [56.039463]
 [54.858658]
 [58.16125 ]
 [54.42898 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  1.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14.] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.428985595703125



buy possibilites: [-1] 
expected returns: [[70.92037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  1.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14.] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -180    0    0
   54    0] 
sum of rewards: 129 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 62.19733428955078






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  6.] 
cards in discard: [10. 11.  8.  8.  0. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [29.  0.  3. 25. 11.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [10. 11.  8.  8.  0. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [29.  0. 25.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [10. 11.  8.  8.  0. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8. 10.  1. 10.  2.] 
adversary cards in hand: [29.  0. 25.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [10. 11.  8.  8.  0. 14. 23.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [29.  0. 25.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 4.8833084]
 [26.67588  ]
 [35.085335 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23] -> size -> 22 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0    0    0    0    0    0 -180    0    0
 1897    0] 
sum of rewards: 1952 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -4.304137229919434



action possibilites: [-1] 
expected returns: [[47.651485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 10.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23] -> size -> 22 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.085323333740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[40.93745 ]
 [47.651485]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 10. 10.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.] 
adversary owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23] -> size -> 22 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.651485443115234






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  8  0  0  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [29. 29. 29. 29. 10.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [29. 29. 29. 29. 10.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [29. 29. 29. 29. 10.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  8  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [29. 29. 29. 29. 10.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [29. 29. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29. 10.] 
expected returns: [[ 2.0596113]
 [15.122284 ]
 [15.122284 ]
 [15.122284 ]
 [15.122284 ]
 [ 5.591674 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 10.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.  0.  8.  3.  8.] 
adversary owned cards: [ 8 11 10  8  8  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.651485443115234



action possibilites: [-1. 29. 29.] 
expected returns: [[27.528183]
 [36.00623 ]
 [36.00623 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.  0.  8.  3.  8.] 
adversary owned cards: [ 8 11 10  8  8  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.208199501037598



action possibilites: [-1.] 
expected returns: [[20.383986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.  0.  8.  3.  8.] 
adversary owned cards: [ 8 11 10  8  8  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.776283264160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[14.90868 ]
 [19.678295]
 [18.965496]
 [20.383976]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 1 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.  0.  8.  3.  8.] 
adversary owned cards: [ 8 11 10  8  8  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.38398551940918






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  0.  0.] 
cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  8  8  0  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [29.  0. 29. 10.  0.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  8  8  8  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [29.  0. 29. 10.  0.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 11.  8.  8.  0. 14. 23. 14.  0.  0.  0.  6.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  8  8  8  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [29.  0. 29. 10.  0.] 
adversary cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [29.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[73.96501]
 [84.50696]
 [84.50696]
 [75.63311]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10.  0.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11. 29. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8. 14.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  8  8  8  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 19 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.38398551940918



action possibilites: [-1. 29.] 
expected returns: [[26.459515]
 [38.883823]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11. 29. 29.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8. 14.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  8  8  8  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 19 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 80.76008605957031



action possibilites: [-1.] 
expected returns: [[18.084375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11. 29. 29.  3.  0. 10.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8. 14.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  8  8  8  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 19 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.342872619628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  9.753825]
 [ 24.263784]
 [ 12.51325 ]
 [ 27.212166]
 [ 16.93652 ]
 [ 30.41454 ]
 [-17.223286]
 [ 21.038359]
 [  9.993021]
 [ 18.084362]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11. 29. 29.  3.  0. 10.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  1.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8. 14.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  8  8  8  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 19 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.084375381469727



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 3 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 0 
Witch: 3 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1.] 
cards in discard: [10.  0. 15. 15. 15. 15. 25.  3.  3.  3.  3.  0. 10. 25. 10.  3.  3. 15.
 29. 29.  1.  1. 11.  0. 15.  3.  1.  3. 11. 25. 29.  0. 10. 10. 29. 10.
 29. 11. 29. 29.  3.  0. 10.  0. 15. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  3 29 11 11 29 10  3 10 11 29 10 11 29
 10 11 10 25 29 10  1 25 10 11 29 15 15 15 15 15  3 15 29  3 15 15  1  3
 29 29  3  1  1 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 20. 30.  8.  0. 10.  0.  3.  7.  0.  8.  9.  1. 10.  2.] 
adversary cards in hand: [ 8. 14.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  8  8  8  0  6 14  8  3 14  0  0  0  3  0 10 23  0] -> size -> 19 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[     -5 3000000       0     240       0       0      40       0       0
       0       0    -190       0       0      64       0] 
sum of rewards: 3000149 

action type: buy - action 29.0
Learning step: 120004.734375
desired expected reward: 120035.1484375



