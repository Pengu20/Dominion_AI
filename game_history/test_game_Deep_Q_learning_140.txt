 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[104.81885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0       20        0
        0        0        0        0        0        0       27        0] 
sum of rewards: -3000318 

action type: buy - action 11.0
Learning step: -120006.9609375
desired expected reward: -120150.9921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 95.926834]
 [113.43068 ]
 [104.70178 ]
 [ 72.84009 ]
 [121.17319 ]
 [112.23642 ]
 [103.40173 ]
 [104.54622 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 106.13404846191406



buy possibilites: [-1] 
expected returns: [[96.45574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 121.17320251464844






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[111.57933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.45574188232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[105.86415 ]
 [118.02889 ]
 [109.560875]
 [ 86.277664]
 [115.07558 ]
 [125.39592 ]
 [117.12839 ]
 [131.17026 ]
 [ 94.327545]
 [108.6853  ]
 [108.05607 ]
 [112.05228 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 112.48372650146484



buy possibilites: [-1] 
expected returns: [[109.66849]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 131.1702880859375






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 99.92738]
 [115.82121]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.66848754882812



action possibilites: [-1] 
expected returns: [[109.11047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.75120544433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.351204]
 [113.55264 ]
 [ 82.01528 ]
 [120.52809 ]
 [108.68179 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 109.1104736328125



buy possibilites: [-1] 
expected returns: [[102.83077]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 120.52808380126953






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[104.72163 ]
 [123.327576]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.83077239990234



action possibilites: [-1.] 
expected returns: [[95.8051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 123.71138000488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 88.473015]
 [106.158966]
 [ 96.48079 ]
 [ 72.108315]
 [ 66.777306]
 [101.65188 ]
 [113.27636 ]
 [105.675644]
 [138.04567 ]
 [118.850945]
 [ 77.94457 ]
 [ 92.43105 ]
 [ 96.03973 ]
 [ 75.70957 ]
 [ 94.903145]
 [ 98.04692 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.80509948730469



buy possibilites: [-1] 
expected returns: [[131.14703]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  0.  3.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 138.04563903808594






Player: 1 
cards in hand: [ 0.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [11.  3.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.953804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.14703369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[119.60326]
 [134.62589]
 [126.0043 ]
 [ 96.79421]
 [131.9285 ]
 [137.55386]
 [133.34393]
 [141.42719]
 [109.0023 ]
 [124.83887]
 [122.94437]
 [120.93266]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 120.13818359375



buy possibilites: [-1] 
expected returns: [[118.6496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 141.42718505859375






Player: 1 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 11.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 11.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[108.39787]
 [100.24118]
 [128.29987]
 [122.30083]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 11.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.64959716796875



action possibilites: [-1. 10. 11.] 
expected returns: [[130.82022 ]
 [122.929504]
 [146.87555 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 126.87837219238281



action possibilites: [-1] 
expected returns: [[143.89476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 156.97813415527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[128.38477]
 [147.78015]
 [138.56465]
 [106.94728]
 [158.86354]
 [147.73279]
 [138.55362]
 [145.25778]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 143.89476013183594



buy possibilites: [-1] 
expected returns: [[161.10672]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 158.863525390625






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0. 11.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 25.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0. 11.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 25.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0. 11.  0.  0.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  8.  7.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 25.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11. 25.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
expected returns: [[108.65173 ]
 [124.38327 ]
 [143.25801 ]
 [119.636955]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  8.  7.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 161.10671997070312



action possibilites: [-1] 
expected returns: [[107.24827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  7.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.1600341796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.44461 ]
 [108.895134]
 [ 70.20235 ]
 [117.49037 ]
 [110.15999 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  7.  9.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.2482681274414



buy possibilites: [-1] 
expected returns: [[114.15042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  7.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 117.4903564453125






Player: 1 
cards in hand: [ 0. 16. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  0.  3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  7.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  7.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  7.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.  0.] 
cards in discard: [ 6. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  6.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8] -> size -> 19 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[144.34488]
 [149.33385]
 [162.8902 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29.  0.] 
cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  6.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 16.  0.] 
adversary cards in discard: [ 6. 11. 10.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.15042114257812



action possibilites: [-1. 10. 10.] 
expected returns: [[135.76819]
 [131.2021 ]
 [131.2021 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  6.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 16.  0.] 
adversary cards in discard: [ 6. 11. 10.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 162.05496215820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[130.43591 ]
 [141.51376 ]
 [133.08548 ]
 [109.275116]
 [139.75397 ]
 [150.5341  ]
 [140.32242 ]
 [155.8091  ]
 [116.707825]
 [131.85132 ]
 [132.38757 ]
 [137.309   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  6.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 16.  0.] 
adversary cards in discard: [ 6. 11. 10.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 135.76821899414062



buy possibilites: [-1] 
expected returns: [[180.59267]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 16.  0.] 
adversary cards in discard: [ 6. 11. 10.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 155.80911254882812






Player: 1 
cards in hand: [ 0. 11.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 16.  0.] 
cards in discard: [ 6. 11. 10.  0. 16.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0. 29. 29.  0.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 6. 11. 10.  0. 16.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0. 29. 29.  0.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 6. 11. 10.  0. 16.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0. 29. 29.  0.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 6. 11. 10.  0. 16.  0.  3.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0. 29. 29.  0.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[109.80636 ]
 [124.76796 ]
 [119.224106]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  3.] 
cards in discard: [ 8. 25. 11.  8.  3.  0.  3.  0. 29. 29.  0.  0. 10.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 180.59266662597656



action possibilites: [-1. 11.  8.] 
expected returns: [[126.95531 ]
 [141.65797 ]
 [126.948166]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 124.51350402832031



action possibilites: [-1] 
expected returns: [[124.9068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 151.53636169433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 90.14781 ]
 [123.01132 ]
 [114.92784 ]
 [ 48.728935]
 [138.46718 ]
 [124.83795 ]
 [116.625374]
 [127.72551 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  6.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.90679931640625



buy possibilites: [-1] 
expected returns: [[128.49707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 138.46714782714844






Player: 1 
cards in hand: [16.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0 11 10 16  6 11  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  8.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[126.775116]
 [147.40073 ]
 [147.40073 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 29.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.4970703125



action possibilites: [-1. 29.] 
expected returns: [[191.93459]
 [209.90958]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 146.78485107421875



action possibilites: [-1.] 
expected returns: [[147.72476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 209.90963745117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[144.35324 ]
 [155.15736 ]
 [136.64508 ]
 [147.1355  ]
 [130.22679 ]
 [125.081055]
 [152.41388 ]
 [161.03113 ]
 [154.09363 ]
 [184.6992  ]
 [165.84174 ]
 [131.78523 ]
 [143.42389 ]
 [146.37202 ]
 [131.91379 ]
 [146.42815 ]
 [147.87572 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 147.72476196289062



buy possibilites: [-1] 
expected returns: [[161.03775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3.  8. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 184.69921875






Player: 1 
cards in hand: [0. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [ 1. 16.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25. 10. 11.  3. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3.  8. 25. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [ 1. 16.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9.  8.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25. 10. 11.  3. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3.  8. 25. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [ 1. 16.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25. 10. 11.  3. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3.  8. 25. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [25. 10. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 10.] 
expected returns: [[159.72638]
 [195.5614 ]
 [141.32722]
 [167.43323]
 [141.32722]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11.  3. 10.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3.  8. 25. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 11.  0.] 
adversary cards in discard: [ 1. 16.  3.  0.  0.  0.  0.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 161.03775024414062



action possibilites: [-1] 
expected returns: [[150.05832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 10.  0.  8.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3.  8. 25. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8.  8.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 11.  0.] 
adversary cards in discard: [ 1. 16.  3.  0.  0.  0.  0.  3.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 196.0306396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[102.01094]
 [ 82.4648 ]
 [151.27719]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3. 10.  0.  8.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3.  8. 25. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  8.  8.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 11.  0.] 
adversary cards in discard: [ 1. 16.  3.  0.  0.  0.  0.  3.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.05831909179688






Player: 1 
cards in hand: [11.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  0.] 
cards in discard: [ 1. 16.  3.  0.  0.  0.  0.  3.  3.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8.  8.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 1. 16.  3.  0.  0.  0.  0.  3.  3.  3.  6.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 1. 16.  3.  0.  0.  0.  0.  3.  3.  3.  6.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 1. 16.  3.  0.  0.  0.  0.  3.  3.  3.  6.  6. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[110.4899 ]
 [121.02037]
 [127.75908]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.27725219726562



action possibilites: [-1. 11.] 
expected returns: [[106.56095]
 [119.20292]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 126.320556640625



action possibilites: [-1] 
expected returns: [[131.50237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 127.21217346191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[105.35814 ]
 [137.06865 ]
 [125.78505 ]
 [ 56.024986]
 [128.78278 ]
 [146.13106 ]
 [138.78268 ]
 [151.10654 ]
 [103.84471 ]
 [127.499084]
 [132.57742 ]
 [134.3802  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.5023651123047



buy possibilites: [-1] 
expected returns: [[134.57613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 151.10653686523438






Player: 1 
cards in hand: [ 3.  3.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 25. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 25. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16. 10.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 25. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 25. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25. 29. 10.] 
expected returns: [[151.03004]
 [158.55385]
 [163.08588]
 [187.22113]
 [168.03856]
 [150.18341]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 25. 29. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  7.  5.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.5761260986328



action possibilites: [-1] 
expected returns: [[122.771515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 29. 10.  8. 25.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  5.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 187.02566528320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.589066]
 [ 86.6849  ]
 [123.63849 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 29. 10.  8. 25.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  5.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.77151489257812






Player: 1 
cards in hand: [ 6. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  5.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  5.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  5.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  4.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[136.42743]
 [144.20276]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  4.  7.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1.  0.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 123.63847351074219



action possibilites: [-1] 
expected returns: [[183.26324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  4.  7.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  1.  0.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 150.22793579101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[176.63536]
 [186.68546]
 [182.75922]
 [154.65729]
 [190.8899 ]
 [186.43253]
 [182.44572]
 [186.81543]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  4.  7.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  1.  0.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 183.26324462890625



buy possibilites: [-1] 
expected returns: [[165.2998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  7.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  1.  0.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 190.88990783691406






Player: 1 
cards in hand: [11.  1.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  3.  0.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  7.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25. 10. 11. 11.
  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  3.  0.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  7.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25. 10. 11. 11.
  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  3.  0.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25. 10. 11. 11.
  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[121.64397 ]
 [114.213776]
 [114.213776]
 [136.37512 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10. 29.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 25.  8. 11. 29. 10.  8. 25. 10. 11. 11.
  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 16.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.  8. 11.  1.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 165.2998046875



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[115.43296 ]
 [102.985725]
 [102.985725]
 [102.985725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 16.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.  8. 11.  1.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 136.3750762939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 70.81092 ]
 [101.42588 ]
 [ 31.111738]
 [114.65603 ]
 [116.25441 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 16.] 
adversary cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.  8. 11.  1.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.4329605102539






Player: 1 
cards in hand: [ 0.  6.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  3. 16.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.  8. 11.  1.  0.
  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 11.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  3. 16.] 
cards in discard: [ 0.  3.  3.  0. 16. 10.  6.  8. 11. 11.  6.  0.  0.  0.  8. 11.  1.  0.
  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 11.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[146.15295]
 [180.41635]
 [157.28433]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25. 11.] 
cards in discard: [29.  0. 10.  3. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 16.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.25443267822266



action possibilites: [-1] 
expected returns: [[121.34541]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 29.  3.] 
cards in discard: [29.  0. 10.  3. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  6.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 16.  3.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 180.41635131835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[114.80455]
 [124.65085]
 [118.35032]
 [ 98.88282]
 [133.3253 ]
 [123.51947]
 [117.21895]
 [124.22327]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 29.  3.] 
cards in discard: [29.  0. 10.  3. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  6.  7.  3.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 16.  3.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.34541320800781



buy possibilites: [-1] 
expected returns: [[124.56624]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 29.  3.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 16.  3.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 133.32530212402344






Player: 1 
cards in hand: [ 6. 16.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  0. 16.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6
  8 11  8  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0. 10.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.] 
cards in discard: [ 6. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0. 10.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.] 
cards in discard: [ 6. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0. 10.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.] 
cards in discard: [ 6. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0. 10.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[160.75294]
 [170.33519]
 [172.41193]
 [161.49942]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0. 10.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.56623840332031



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[186.07373]
 [195.36795]
 [183.96194]
 [195.57527]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10. 29.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 172.41195678710938



action possibilites: [-1. 11. 10.  8.] 
expected returns: [[201.20386]
 [212.3302 ]
 [197.12779]
 [204.68208]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  8.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 195.57525634765625



action possibilites: [-1] 
expected returns: [[171.18414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 219.78244018554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[173.13681]
 [175.59235]
 [169.3593 ]
 [170.15965]
 [172.8918 ]
 [183.27391]
 [175.49268]
 [188.22972]
 [159.10413]
 [169.2363 ]
 [169.91582]
 [173.9838 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  8.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 171.18414306640625



buy possibilites: [-1] 
expected returns: [[156.89685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  8.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 303 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 188.22970581054688






Player: 1 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 25.  8. 10. 11.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10. 29. 29. 29.
 11.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  2.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 25.  8. 10. 11.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10. 29. 29. 29.
 11.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  1.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 25.  8. 10. 11.] 
adversary cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10. 29. 29. 29.
 11.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10. 11.] 
expected returns: [[142.19984]
 [173.59944]
 [147.68025]
 [141.85893]
 [154.17746]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8. 10. 11.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10. 29. 29. 29.
 11.  0.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  6.  7.  1.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 11.  1. 16.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0 11] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 156.8968505859375



action possibilites: [-1] 
expected returns: [[141.59093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11.  3. 11.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10. 29. 29. 29.
 11.  0.  0. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  5.  7.  1.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 11.  1. 16.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0 11  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 173.59942626953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[135.21686]
 [125.43788]
 [144.62744]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11.  3. 11.] 
cards in discard: [29.  0. 10.  3. 10. 10. 11. 25.  0.  0.  0. 11. 29.  3. 10. 29. 29. 29.
 11.  0.  0. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  5.  7.  1.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 11.  1. 16.  0.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0 11  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.59092712402344






Player: 1 
cards in hand: [ 8. 11.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  1. 16.  0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 11 10 16  6 11  3  3  1  0  6 16  0  0  6  8
 11  8  6 10  0 11  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  5.  7.  1.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5.  7.  1.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 28. 30.  8.  5.  7.  1.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5.  7.  0.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[115.55594]
 [135.9718 ]
 [124.14671]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 11.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5.  7.  0.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  6.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 144.62745666503906



action possibilites: [-1] 
expected returns: [[95.73667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4.  7.  0.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  6.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.97186279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[80.35422]
 [89.3022 ]
 [66.04729]
 [98.64258]
 [97.90206]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  4.  7.  0.  6.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  6.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.7366714477539



buy possibilites: [-1] 
expected returns: [[115.638626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.  0.  3.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  6.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 98.64256286621094






Player: 1 
cards in hand: [11. 11.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.  6.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8] -> size -> 31 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  3.  6.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8] -> size -> 31 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  3.  6.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8] -> size -> 31 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 10.] 
expected returns: [[148.06975]
 [150.91042]
 [158.48419]
 [157.8372 ]
 [150.91042]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  8. 10.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 6.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0. 11. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6  0] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 115.63862609863281



action possibilites: [-1] 
expected returns: [[153.68996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 6.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0. 11. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6  0] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 164.33619689941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[157.5405 ]
 [145.45465]
 [154.53679]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 6.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0. 11. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6  0] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 153.68995666503906



buy possibilites: [-1] 
expected returns: [[148.88318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 6.] 
adversary cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0. 11. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6  0] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. 180.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 195.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 157.54052734375






Player: 1 
cards in hand: [0. 3. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 6.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0. 11. 11.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 10 16  6 11  3  3  1  0  6 16  0  0  6  8 11
  8  6 10  0 11  6  1 11  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 25.  0. 10.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0. 11. 11.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10
  0 11  6  1 11  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 25.  0. 10.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0. 11. 11.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10
  0 11  6  1 11  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 25.  0. 10.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 10.  0. 16.  6.  0. 16. 11.  0.  0. 10.  3.  0.  6.  1. 11. 16.  8.
  1.  0.  6.  0. 11. 11.  0.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10
  0 11  6  1 11  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 25.  0. 10.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 10. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25. 10.] 
expected returns: [[163.0284 ]
 [147.97256]
 [147.97256]
 [187.6841 ]
 [147.97256]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25.  0. 10.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  4.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [16.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10
  0 11  6  1 11  6  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.8831787109375



action possibilites: [-1] 
expected returns: [[118.011635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10. 29. 29.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [16.  1.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10
  0 11  6  1 11  6  0  0  6] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 187.68411254882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[118.128555]
 [111.53679 ]
 [119.09447 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10. 29. 29.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [16.  1.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10
  0 11  6  1 11  6  0  0  6] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.01163482666016






Player: 1 
cards in hand: [16.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10
  0 11  6  1 11  6  0  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  5.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [6. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0
 11  6  1 11  6  0  0  6  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  4.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [6. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0
 11  6  1 11  6  0  0  6  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  4.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [6. 8. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0
 11  6  1 11  6  0  0  6  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[149.8222 ]
 [157.22333]
 [157.22333]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  9.] 
adversary cards in hand: [11.  1.  6.  0. 16.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0
 11  6  1 11  6  0  0  6  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.09446716308594



action possibilites: [-1] 
expected returns: [[124.20407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  1.  6.  0. 16.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0
 11  6  1 11  6  0  0  6  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 161.06463623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[123.96503]
 [137.56186]
 [132.64557]
 [101.77933]
 [135.91046]
 [132.3465 ]
 [128.6985 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  1.  6.  0. 16.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0
 11  6  1 11  6  0  0  6  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.20407104492188



buy possibilites: [-1] 
expected returns: [[122.99483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  1.  6.  0. 16.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0
 11  6  1 11  6  0  0  6  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 137.56185913085938






Player: 1 
cards in hand: [11.  1.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  6.  0. 16.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0
 11  6  1 11  6  0  0  6  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [29. 29. 11. 10. 29.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.  1. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1] -> size -> 35 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  6.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [29. 29. 11. 10. 29.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.  1. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1] -> size -> 35 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  6.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [29. 29. 11. 10. 29.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.  1. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1] -> size -> 35 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  6.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [29. 29. 11. 10. 29.] 
adversary cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.  1. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1] -> size -> 35 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29. 29. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 10. 29.] 
expected returns: [[ 94.51558 ]
 [104.885544]
 [104.885544]
 [102.2251  ]
 [ 95.57399 ]
 [104.885544]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 10. 29.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.  1. 11.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11. 16.  6.  0. 11.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.99482727050781



action possibilites: [-1. 11. 10. 29.  8.] 
expected returns: [[33.641563]
 [38.131668]
 [20.303633]
 [43.616333]
 [26.906248]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  8.] 
cards in discard: [ 8. 25.  3.  0. 11.  3.  0.  3. 15.  0. 11.  0. 10.  8. 10. 25. 10. 10.
  0. 10. 29. 29. 15.  1. 11.  0.  0.  0. 11. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11. 16.  6.  0. 11.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 101.35646057128906



action possibilites: [-1. 11. 10.] 
expected returns: [[126.43198]
 [135.27217]
 [125.73749]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11. 16.  6.  0. 11.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.199716567993164



action possibilites: [-1] 
expected returns: [[64.58766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 8. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11. 16.  6.  0. 11.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 319 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 140.85414123535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[46.395706]
 [61.316284]
 [54.73664 ]
 [32.575134]
 [62.306686]
 [55.694954]
 [65.884186]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 8. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11. 16.  6.  0. 11.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.58766174316406






Player: 1 
cards in hand: [11. 16.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  6.  0. 11.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15] -> size -> 36 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0. 11.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15] -> size -> 36 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0. 11.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15] -> size -> 36 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0. 11.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15] -> size -> 36 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[73.3723 ]
 [69.21001]
 [69.21001]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  6.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.88416290283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.778275]
 [69.85719 ]
 [49.591377]
 [74.55464 ]
 [73.6486  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 28. 30.  8.  3.  7.  0.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  6.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.37232971191406



buy possibilites: [-1] 
expected returns: [[129.1933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  6.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 201 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 74.5546646118164






Player: 1 
cards in hand: [ 6. 10.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  0.  8.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11. 10. 29. 29.  8.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 37 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0.  8.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11. 10. 29. 29.  8.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 37 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0.  8.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11. 10. 29. 29.  8.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 37 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 10. 29. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 29.  8.] 
expected returns: [[153.43782]
 [162.38307]
 [146.6157 ]
 [163.7949 ]
 [163.7949 ]
 [152.16411]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29. 29.  8.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 129.19329833984375



action possibilites: [-1. 10. 29.  8. 11.] 
expected returns: [[199.93515]
 [196.4232 ]
 [213.8408 ]
 [203.4703 ]
 [210.91068]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  8. 11.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 153.39002990722656



action possibilites: [-1. 10.  8.] 
expected returns: [[201.44202]
 [212.08719]
 [213.39632]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  1.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 29 10 11  8 29 10 11 25 10
 29 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 205.3843231201172



action possibilites: [-1] 
expected returns: [[186.31113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 215.8651123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[197.25122]
 [196.78033]
 [192.09033]
 [203.76418]
 [196.83344]
 [194.60406]
 [201.95975]
 [184.06764]
 [190.08838]
 [185.73273]
 [187.79095]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 26. 30. 28. 30.  8.  3.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1
Learning step: 0
desired expected reward: 186.31112670898438



buy possibilites: [-1] 
expected returns: [[144.1272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.   60.    0.    0.    0.    0.  -20.
    0. -300.    0.    0.] 
sum of rewards: -85.0 

action type: buy - action 6.0
Learning step: 0
desired expected reward: 203.7642059326172






Player: 1 
cards in hand: [ 6. 11.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0.  8.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11
  6  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6] -> size -> 37 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6] -> size -> 37 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6] -> size -> 37 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6] -> size -> 37 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[22.82425 ]
 [17.629402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.  0.  8.  6. 11.  3.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.127197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.601625]
 [23.385609]
 [20.702883]
 [16.97943 ]
 [21.424845]
 [23.62435 ]
 [33.60721 ]
 [14.948944]
 [20.944551]
 [21.760849]
 [25.07529 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.  0.  8.  6. 11.  3.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.82424545288086



buy possibilites: [-1] 
expected returns: [[120.8807]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.  0.  8.  6. 11.  3.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0 -30   0   0 128   0] 
sum of rewards: 273 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 33.607208251953125






Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.  0.  8.  6. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10. 11.  3. 29.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29] -> size -> 38 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.  0.  8.  6. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10. 11.  3. 29.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29] -> size -> 38 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 6.  8.  8. 16.  1.  0.  0.  0.  0. 16. 11.  1.  6.  1.  0. 11. 16.  6.
  0. 11.  0.  6. 10.  6.  0.  8.  0.  8.  6. 11.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [15. 10. 11.  3. 29.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29] -> size -> 38 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [15. 10. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 29.] 
expected returns: [[27.69095 ]
 [36.45955 ]
 [40.06202 ]
 [34.443344]
 [34.43766 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.  3. 29.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.88069915771484



action possibilites: [-1. 15. 11. 29.] 
expected returns: [[30.655756]
 [35.477272]
 [39.27234 ]
 [41.90152 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3. 29.  3.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 40.06201934814453



action possibilites: [-1. 15. 11.] 
expected returns: [[44.753853]
 [51.12667 ]
 [49.35437 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 11.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29] -> size -> 38 
action values: 2 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 46.26853942871094



action possibilites: [-1. 11.] 
expected returns: [[82.06044 ]
 [88.908905]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 51.12664794921875



action possibilites: [-1] 
expected returns: [[80.87555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29. 15. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 279 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.25355529785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.991905]
 [31.283052]
 [80.87557 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29. 15. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.87554931640625






Player: 1 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [25.  8. 25.  0. 15.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0. 11. 15. 10. 29. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  2.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [25.  8. 25.  0. 15.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0. 11. 15. 10. 29. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  1.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [25.  8. 25.  0. 15.] 
adversary cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0. 11. 15. 10. 29. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25.  8. 25.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 25. 15.] 
expected returns: [[15.118933]
 [26.68709 ]
 [15.605452]
 [26.68709 ]
 [12.468151]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 25.  0. 15.] 
cards in discard: [ 8. 15. 29. 29. 11. 10.  0.  8. 10.  0. 10.  0.  3. 11. 11.  6. 29. 29.
  8.  1. 29. 10.  0.  0.  0.  0. 11. 15. 10. 29. 15. 11.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  2.  7.  0.  1.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [16. 11.  0.  0. 11.] 
adversary cards in discard: [8. 0. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8] -> size -> 40 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.87554931640625



action possibilites: [-1] 
expected returns: [[93.91776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0. 15. 29.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  1.  7.  0.  1.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [16. 11.  0.  0. 11.] 
adversary cards in discard: [8. 0. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6] -> size -> 41 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.687070846557617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[74.17824 ]
 [81.95793 ]
 [62.08098 ]
 [86.31549 ]
 [96.890915]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0. 15. 29.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 28. 30.  8.  1.  7.  0.  1.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [16. 11.  0.  0. 11.] 
adversary cards in discard: [8. 0. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6] -> size -> 41 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.91776275634766






Player: 1 
cards in hand: [16. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  0. 11.] 
cards in discard: [8. 0. 0. 6. 0. 3. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  1.  7.  0.  1.  8.  4. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  8.  1.  3. 29.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 28. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  8.  1.  3. 29.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 28. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  8.  1.  3. 29.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  8.  1.  3. 29.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[94.42778 ]
 [94.57063 ]
 [99.191124]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  3. 29.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  6.  3.  1. 10.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3] -> size -> 43 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.89092254638672



action possibilites: [-1.  8.] 
expected returns: [[88.89775]
 [93.91611]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29
 10 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 27. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  6.  3.  1. 10.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3] -> size -> 43 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 94.67752838134766



action possibilites: [-1] 
expected returns: [[74.6614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 27. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  6.  3.  1. 10.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 94.79866027832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[73.6745  ]
 [78.59115 ]
 [73.122505]
 [66.89552 ]
 [77.90604 ]
 [72.49709 ]
 [77.44136 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 27. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  6.  3.  1. 10.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.6613998413086



buy possibilites: [-1] 
expected returns: [[68.169014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  6.  3.  1. 10.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 199 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 78.59115600585938






Player: 1 
cards in hand: [ 8.  6.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3.  1. 10.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11. 29.  0.  0. 11.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1] -> size -> 39 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  3.  1. 10.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 27. 30.  8.  1.  7.  0.  1.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11. 29.  0.  0. 11.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1] -> size -> 39 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  3.  1. 10.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 30.  8.  1.  7.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11. 29.  0.  0. 11.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1] -> size -> 39 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[143.1966 ]
 [145.83176]
 [146.40327]
 [145.83176]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0. 11.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 30.  8.  1.  7.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11.  8.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.16901397705078



action possibilites: [-1. 11. 11.] 
expected returns: [[ 96.26726 ]
 [102.689316]
 [102.689316]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 27. 30.  8.  1.  7.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11.  8.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 144.8190460205078



action possibilites: [-1] 
expected returns: [[122.99429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 27. 30.  8.  1.  6.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11.  8.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 4
Learning step: 0
desired expected reward: 123.63107299804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[117.82855]
 [114.57019]
 [115.04764]
 [125.87036]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 27. 30.  8.  1.  6.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11.  8.  0. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.99429321289062






Player: 1 
cards in hand: [11.  8.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 11.  6.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 30.  8.  1.  6.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8. 15. 11. 15. 29.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 40 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  6.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8. 15. 11. 15. 29.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 40 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  6.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8. 15. 11. 15. 29.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 40 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  6.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8. 15. 11. 15. 29.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 40 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 11. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11. 15. 29.] 
expected returns: [[130.84201]
 [144.44221]
 [138.17255]
 [141.1765 ]
 [138.17255]
 [142.05542]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 11. 15. 29.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 29 10 11  8 29 10 11 25 10 29 10
 11 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8. 16. 10.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0] -> size -> 46 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.87037658691406



action possibilites: [-1] 
expected returns: [[34.8852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8. 16. 10.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0] -> size -> 46 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 147.32266235351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.594648]
 [-5.496995]
 [33.59037 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 15.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8. 16. 10.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0] -> size -> 46 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.88520050048828






Player: 1 
cards in hand: [ 8. 16. 10.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 10.  6.  1.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  1  0  6 16  0  0  6  8 11  8  6 10  0 11  6
  1 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  3. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 29. 29. 15.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  6.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1
 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 29. 29. 15.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  6.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1
 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 29. 29. 15.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 15.] 
expected returns: [[78.27389 ]
 [86.46314 ]
 [88.07757 ]
 [88.07757 ]
 [82.203545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 29. 15.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1
 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 46 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.590362548828125



action possibilites: [-1. 10. 15.] 
expected returns: [[47.401497]
 [47.69091 ]
 [47.849182]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1
 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 46 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 91.96687316894531



action possibilites: [-1] 
expected returns: [[127.28296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1
 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 46 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 47.84917449951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.53398]
 [ 71.94692]
 [128.07999]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.] 
adversary owned cards: [ 0  0 16  0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1
 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 46 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.282958984375






Player: 1 
cards in hand: [ 8.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 16.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1
 11  6  0  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [10. 10. 10.  3.  8.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0. 29. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [10. 10. 10.  3.  8.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0. 29. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [10. 10. 10.  3.  8.] 
adversary cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0. 29. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.  8.] 
expected returns: [[ 91.68195]
 [ 99.63996]
 [ 99.63996]
 [ 99.63996]
 [103.74097]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3.  8.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0. 29. 15.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 10 11  8 29 10 11 25 10 29 10 11
 11 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.  8.  0.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.0799560546875



action possibilites: [-1] 
expected returns: [[32.418907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0. 29. 15.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.  8.  0.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 103.97027587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.008707]
 [18.661955]
 [32.41893 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.] 
cards in discard: [25.  8. 25.  0. 15. 29.  0.  1.  1. 29.  8.  0.  0.  0. 11. 16. 29. 11.
  0. 11.  8. 15. 11. 15. 29.  0. 29. 15.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.  8.  0.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 43 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.418907165527344






Player: 1 
cards in hand: [0. 6. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 38 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 25. 30. 27. 30.  8.  1.  5.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 38 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 29.  3. 11. 16.  0.  0. 11.  8.  8.  6.  3.
  1. 10. 16.  0. 11.  8.  0. 11.  6. 29. 16.  8. 10.  6.  8.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 38 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[77.507   ]
 [61.325775]
 [78.26878 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.418907165527344



action possibilites: [-1] 
expected returns: [[77.7139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 66.43164825439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[62.289474]
 [67.9707  ]
 [50.68277 ]
 [79.00193 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16] -> size -> 44 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.71389770507812






Player: 1 
cards in hand: [11.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 10.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [10.  8. 29. 29. 29.] 
adversary cards in discard: [15. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6. 10.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [10.  8. 29. 29. 29.] 
adversary cards in discard: [15. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6. 10.  0.] 
cards in discard: [0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [10.  8. 29. 29. 29.] 
adversary cards in discard: [15. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  8. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29. 29. 29.] 
expected returns: [[ 96.047066]
 [ 81.770744]
 [ 87.99833 ]
 [106.09636 ]
 [106.09636 ]
 [106.09636 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 29. 29.] 
cards in discard: [15. 11.  0.  6.  0. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 6.  6.  0. 16. 10.] 
adversary cards in discard: [ 0. 11.  0.  6. 10.  0.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0] -> size -> 45 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.00190734863281



action possibilites: [-1. 29. 29. 11.] 
expected returns: [[25.847525]
 [36.002594]
 [36.002594]
 [32.765472]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.] 
cards in discard: [15. 11.  0.  6.  0. 10. 10.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 6.  6.  0. 16. 10.] 
adversary cards in discard: [ 0. 11.  0.  6. 10.  0.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0] -> size -> 45 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 86.49876403808594



action possibilites: [-1.  8.] 
expected returns: [[26.508944]
 [25.454   ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15. 11.  0.  6.  0. 10. 10.  8. 29. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 6.  6.  0. 16. 10.] 
adversary cards in discard: [ 0. 11.  0.  6. 10.  0.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0] -> size -> 45 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.49420166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ -2.595532]
 [ 17.159742]
 [-27.499636]
 [ 26.959032]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [15. 11.  0.  6.  0. 10. 10.  8. 29. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
action values: 1 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 6.  6.  0. 16. 10.] 
adversary cards in discard: [ 0. 11.  0.  6. 10.  0.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0] -> size -> 45 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.508947372436523






Player: 1 
cards in hand: [ 6.  6.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 16. 10.] 
cards in discard: [ 0. 11.  0.  6. 10.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 25.  3. 11. 15.] 
adversary cards in discard: [15. 11.  0.  6.  0. 10. 10.  8. 29. 11. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 16. 10.] 
cards in discard: [ 0. 11.  0.  6. 10.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 25.  3. 11. 15.] 
adversary cards in discard: [15. 11.  0.  6.  0. 10. 10.  8. 29. 11. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 16. 10.] 
cards in discard: [ 0. 11.  0.  6. 10.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 25.  3. 11. 15.] 
adversary cards in discard: [15. 11.  0.  6.  0. 10. 10.  8. 29. 11. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 15.] 
expected returns: [[120.48273]
 [143.15146]
 [127.29166]
 [129.36443]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 11. 15.] 
cards in discard: [15. 11.  0.  6.  0. 10. 10.  8. 29. 11. 29. 29.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 27. 30.  8.  1.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  6. 10.  0.  0.  6.  6.  0. 16. 10.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0  0] -> size -> 46 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.959054946899414



Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 2 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 1 

Remodel: 0 
Workshop: 5 
Chapel: 4 
Witch: 2 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  3. 11. 15. 29.  0.] 
cards in discard: [15. 11.  0.  6.  0. 10. 10.  8. 29. 11. 29. 29.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8 25 29 11  8 29 10 11 25 10 29 10 11 11
 10 29  8 15  0 15  1 15  8  6 29 15  1 16 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 27. 30.  8.  0.  4.  0.  0.  8.  2. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  6. 10.  0.  0.  6.  6.  0. 16. 10.  6.] 
adversary owned cards: [ 0 10 16 11  3  3  0  6 16  0  0  6  8 11  8  6 10  0 11  6  1 11  6  0
  0  6  8  8  0  0  1  0  0  0 10  8  6 29  3  8 16  0 29 16  0  0  6] -> size -> 47 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[     -5 3000000       0     150       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000165 

action type: take_action - action 25.0
Learning step: 120000.8671875
desired expected reward: 120144.015625



