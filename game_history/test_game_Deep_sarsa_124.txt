 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[39.722893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0       20        0
        0        0        0        0        0     -300        0        0] 
sum of rewards: -3000375 

action type: buy - action 6.0
Learning step: -300037.90625
desired expected reward: -300033.96875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 40.06756 ]
 [ 73.356766]
 [ 54.57839 ]
 [ 20.40756 ]
 [ 67.997734]
 [ 74.00649 ]
 [ 57.167583]
 [119.45538 ]
 [ 31.737007]
 [ 41.554943]
 [ 60.4403  ]
 [ 38.20836 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.3562126159668



buy possibilites: [-1] 
expected returns: [[14.671047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 119.45536804199219






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.415016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.67104721069336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.370707 ]
 [51.571705 ]
 [37.5532   ]
 [10.5648775]
 [53.244987 ]
 [39.128532 ]
 [27.396364 ]
 [25.09026  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.4835147857666



buy possibilites: [-1] 
expected returns: [[7.8193426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 53.2449836730957






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 8.824345]
 [22.638927]
 [39.523823]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.819342613220215



action possibilites: [-1. 11.] 
expected returns: [[33.285557]
 [57.741123]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.98781204223633



action possibilites: [-1] 
expected returns: [[28.731537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 73.2876968383789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[36.80651 ]
 [59.91037 ]
 [46.764038]
 [17.90504 ]
 [59.181324]
 [49.101578]
 [36.06284 ]
 [30.802189]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.731536865234375



buy possibilites: [-1] 
expected returns: [[29.633068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 59.910362243652344






Player: 1 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1. 29. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1. 29. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1. 29. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.1563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  1. 29. 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.633068084716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.025894]
 [52.52259 ]
 [39.78541 ]
 [13.049189]
 [48.853584]
 [53.162342]
 [41.437702]
 [84.30746 ]
 [21.973948]
 [29.762856]
 [43.71634 ]
 [26.284754]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  1. 29. 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.361356735229492



buy possibilites: [-1] 
expected returns: [[18.477726]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  1. 29. 11.  0.  0.  3.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 3.  0.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 84.30743408203125






Player: 1 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 3.  0.  3. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 3.  0.  3. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 3.  0.  3. 29.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  1.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-4.870925]
 [25.63875 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.477725982666016



action possibilites: [-1.] 
expected returns: [[36.001755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 23.987850189208984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 47.846237]
 [ 75.07602 ]
 [ 35.426178]
 [ 58.860657]
 [ 40.783184]
 [ 29.064812]
 [ 71.18759 ]
 [ 74.99577 ]
 [ 61.246178]
 [125.53867 ]
 [110.179634]
 [ 39.320557]
 [ 73.71793 ]
 [ 47.737053]
 [ 46.851807]
 [ 63.700462]
 [ 42.67639 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.00175476074219



buy possibilites: [-1] 
expected returns: [[14.297956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 47.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 125.53868865966797






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [25. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [25. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 2.8185108]
 [33.60998  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [25. 29.  1.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  3. 29.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.297956466674805



action possibilites: [-1.] 
expected returns: [[29.149822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25. 29.  1.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  3. 29.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.26051330566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 43.149105]
 [ 69.269325]
 [ 52.935753]
 [ 36.621433]
 [ 25.90596 ]
 [ 66.733734]
 [ 67.01475 ]
 [ 55.816643]
 [118.27679 ]
 [106.14251 ]
 [ 34.537308]
 [ 68.767334]
 [ 41.790813]
 [ 42.575706]
 [ 57.350704]
 [ 35.49464 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25. 29.  1.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  3. 29.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.149822235107422



buy possibilites: [-1] 
expected returns: [[48.928238]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25. 29.  1.  0.  3.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  3. 29.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 118.27680206298828






Player: 1 
cards in hand: [ 8.  3.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 29.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3. 29.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3. 29.  0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[11.172802]
 [13.477608]
 [30.03263 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.92823791503906



action possibilites: [-1] 
expected returns: [[12.624496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  3.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.945274353027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.380722]
 [44.424526]
 [32.22465 ]
 [ 9.222979]
 [43.02971 ]
 [34.518116]
 [23.449474]
 [18.456106]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  3.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.624496459960938



buy possibilites: [-1] 
expected returns: [[35.292618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  3.] 
cards in discard: [10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 44.42453384399414






Player: 1 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  3.] 
adversary cards in discard: [10.  1. 11.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  3.] 
adversary cards in discard: [10.  1. 11.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  3.] 
adversary cards in discard: [10.  1. 11.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[13.02961 ]
 [52.535027]
 [58.96382 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0.  3.] 
cards in discard: [10.  1. 11.  1.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.29261779785156



action possibilites: [-1] 
expected returns: [[23.668606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  3.  0.] 
cards in discard: [10.  1. 11.  1.  0. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 52.627193450927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.586258]
 [42.17696 ]
 [34.600666]
 [19.068552]
 [41.265953]
 [36.102924]
 [28.872002]
 [25.358765]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  3.  0.] 
cards in discard: [10.  1. 11.  1.  0. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 29. 30.  8.  9. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.66860580444336



buy possibilites: [-1] 
expected returns: [[34.503254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  3.  0.] 
cards in discard: [10.  1. 11.  1.  0. 10.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 29. 30.  8.  9. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 42.17698669433594






Player: 1 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [1. 0. 0. 3. 1. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 29. 30.  8.  9. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [10.  1. 11.  1.  0. 10.  3.  1. 25. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 3. 1. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 29. 30.  8.  9. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [10.  1. 11.  1.  0. 10.  3.  1. 25. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 3. 1. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 25. 30. 29. 30.  8.  9. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [10.  1. 11.  1.  0. 10.  3.  1. 25. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 3. 1. 0. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 25. 30. 29. 30.  8.  9. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [10.  1. 11.  1.  0. 10.  3.  1. 25. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-10.858234]
 [ 29.254093]
 [ 22.539352]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0. 29.] 
cards in discard: [10.  1. 11.  1.  0. 10.  3.  1. 25. 29.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.50325393676758



action possibilites: [-1] 
expected returns: [[1.861253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 11.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  8. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.21544647216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.823795 ]
 [38.573853 ]
 [25.443974 ]
 [ 9.287213 ]
 [-1.6854372]
 [36.382607 ]
 [37.542053 ]
 [27.847143 ]
 [75.976234 ]
 [66.17506  ]
 [ 7.680979 ]
 [37.969967 ]
 [15.296865 ]
 [15.0701275]
 [29.422726 ]
 [10.136311 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 11.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 30.  8.  8. 10.  9.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.861253023147583



buy possibilites: [-1] 
expected returns: [[8.228107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 11.  1.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  8. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 75.97623443603516






Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  8. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 25.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0. 29. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  8. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 25.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0. 29. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 29. 30.  8.  8. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 25.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0. 29. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25] -> size -> 21 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[18.997707]
 [66.37426 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 25.  3.] 
cards in discard: [25. 25.  0.  0.  0. 29. 11.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  8. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [6. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.228107452392578



action possibilites: [-1] 
expected returns: [[41.444363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3.  1. 10.] 
cards in discard: [25. 25.  0.  0.  0. 29. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  7. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [6. 8. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 59.230690002441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.233025]
 [60.03888 ]
 [48.216583]
 [28.151201]
 [18.252768]
 [54.929283]
 [62.71576 ]
 [49.205406]
 [96.797935]
 [85.62016 ]
 [28.528229]
 [57.892155]
 [37.347107]
 [33.49746 ]
 [52.187202]
 [35.244625]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3.  1. 10.] 
cards in discard: [25. 25.  0.  0.  0. 29. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 30.  8.  7. 10.  9.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [6. 8. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.44436264038086



buy possibilites: [-1] 
expected returns: [[13.607836]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3.  1. 10.] 
cards in discard: [25. 25.  0.  0.  0. 29. 11.  1. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  7. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [6. 8. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 96.79793548583984






Player: 1 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [6. 8. 0. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  7. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0. 29. 11.  1. 25. 25.  0.  1.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [6. 8. 0. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 30. 29. 30.  8.  7. 10.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0. 29. 11.  1. 25. 25.  0.  1.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 6.  8.  0.  0.  3.  6. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0. 29. 11.  1. 25. 25.  0.  1.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 2.2192962]
 [27.322136 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [25. 25.  0.  0.  0. 29. 11.  1. 25. 25.  0.  1.  3.  3.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  6. 16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.60783576965332



action possibilites: [-1. 10.] 
expected returns: [[53.100372]
 [54.094955]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [25. 25.  0.  0.  0. 29. 11.  1. 25. 25.  0.  1.  3.  3.  1. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  6. 16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.351905822753906



action possibilites: [-1. 11.] 
expected returns: [[39.325294]
 [63.462677]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25] -> size -> 22 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  6. 16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 54.094970703125



action possibilites: [-1.] 
expected returns: [[27.295792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  6. 16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 75.77384948730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[37.623974]
 [64.21683 ]
 [51.058784]
 [18.9848  ]
 [59.422535]
 [65.83624 ]
 [52.57247 ]
 [95.68476 ]
 [29.915108]
 [39.652416]
 [55.309772]
 [37.024883]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  6. 16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.295791625976562



buy possibilites: [-1] 
expected returns: [[81.12378]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  3.  6. 16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 95.68476104736328






Player: 1 
cards in hand: [0. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [ 6.  8.  0.  0.  3.  6. 16.  0.  0.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 25. 25.] 
adversary cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [ 6.  8.  0.  0.  3.  6. 16.  0.  0.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 25. 25.] 
adversary cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  1. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[18.392872]
 [49.170498]
 [49.170498]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 25. 25.] 
cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  7.  9.  9.  9.  6.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.123779296875



action possibilites: [-1] 
expected returns: [[44.615288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 25.  3.  3.] 
cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  6.  9.  9.  9.  6.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 49.39140319824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[41.74505 ]
 [62.009315]
 [53.942947]
 [35.005035]
 [26.966154]
 [57.17503 ]
 [66.72221 ]
 [53.672176]
 [90.91759 ]
 [81.17731 ]
 [36.19447 ]
 [59.923553]
 [46.98482 ]
 [39.60586 ]
 [56.373318]
 [51.400906]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 25.  3.  3.] 
cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 30.  8.  6.  9.  9.  9.  6.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.61528778076172



buy possibilites: [-1] 
expected returns: [[37.228317]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 25.  3.  3.] 
cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  6.  9.  9.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 90.91759490966797






Player: 1 
cards in hand: [ 0.  0.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 29.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  6.  9.  9.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0. 29. 10. 25.] 
adversary cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25. 25.  0.  1.  1. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25] -> size -> 25 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 30.  8.  6.  9.  9.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0. 29. 10. 25.] 
adversary cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25. 25.  0.  1.  1. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 30. 29. 30.  8.  6.  9.  9.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0. 29. 10. 25.] 
adversary cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25. 25.  0.  1.  1. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [6. 4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 29.  8.  6.  9.  9.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0. 29. 10. 25.] 
adversary cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25. 25.  0.  1.  1. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [25.  0. 29. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 25.] 
expected returns: [[22.484917]
 [63.844307]
 [55.534805]
 [22.53144 ]
 [63.844307]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 10. 25.] 
cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25. 25.  0.  1.  1. 25.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  6.  9.  9.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.22831726074219



action possibilites: [-1] 
expected returns: [[28.451805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 25.  0.  0.] 
cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25. 25.  0.  1.  1. 25.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  5.  9.  9.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 63.84430694580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.671322]
 [54.874687]
 [40.69735 ]
 [13.37454 ]
 [58.073097]
 [42.491894]
 [30.868214]
 [28.180983]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10. 25.  0.  0.] 
cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25. 25.  0.  1.  1. 25.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  5.  9.  9.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.451805114746094



buy possibilites: [-1] 
expected returns: [[28.611485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10. 25.  0.  0.] 
cards in discard: [10. 29. 29. 10. 11.  0.  0.  0.  3. 25. 25.  0.  1.  1. 25.  3.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  5.  9.  8.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 58.073089599609375






Player: 1 
cards in hand: [3. 8. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 6. 0.] 
cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  5.  9.  8.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  5.  9.  8.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  5.  9.  8.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29. 25.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[-9.146753]
 [43.291367]
 [51.923096]
 [51.923096]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  5.  9.  8.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.61148452758789



action possibilites: [-1] 
expected returns: [[47.094597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  4.  9.  8.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.581298828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[52.397564]
 [63.603592]
 [57.49292 ]
 [48.20012 ]
 [41.641598]
 [62.8619  ]
 [62.6222  ]
 [58.808918]
 [86.85752 ]
 [80.81366 ]
 [47.74929 ]
 [63.508667]
 [52.604176]
 [51.638996]
 [59.301205]
 [49.346584]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 29.  8.  4.  9.  8.  9.  5.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.09459686279297



buy possibilites: [-1] 
expected returns: [[37.534195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  1.  0.  0.] 
cards in discard: [25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  4.  9.  8.  9.  4.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 86.85750579833984






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.  8.  6.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  4.  9.  8.  9.  4.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 29.  3.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25] -> size -> 27 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.  8.  6.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 29. 29.  8.  4.  9.  8.  9.  4.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 29.  3.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25] -> size -> 27 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  4. 29.  0.  0.  1.  3.  0.  6.  8.  6.  6.  6. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  4.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 29.  3.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25] -> size -> 27 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[139.76874]
 [196.49489]
 [181.04352]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 29.  3.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  4.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  6. 16.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.53419494628906



action possibilites: [-1] 
expected returns: [[95.96805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0. 10.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  3.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  6. 16.  1.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 196.92489624023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 90.074875]
 [103.83784 ]
 [ 73.38444 ]
 [102.96523 ]
 [ 98.41369 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  0. 10.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 29. 29.  8.  3.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  6. 16.  1.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.96804809570312



buy possibilites: [-1] 
expected returns: [[63.630737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  0. 10.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  3.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  6. 16.  1.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 103.83780670166016






Player: 1 
cards in hand: [ 1.  6. 16.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 16.  1.  3.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  3.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25. 10.  0. 10.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3] -> size -> 28 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 16.  1.  3.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 28. 29.  8.  3.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25. 10.  0. 10.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3] -> size -> 28 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 16.  1.  3.] 
cards in discard: [6. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 29.  8.  3.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25. 10.  0. 10.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3] -> size -> 28 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25. 25. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 10. 10.] 
expected returns: [[39.366966]
 [70.60868 ]
 [70.60868 ]
 [38.045395]
 [38.045395]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 10.  0. 10.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8.  3.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.6307373046875



action possibilites: [-1] 
expected returns: [[115.38407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 10.  1.  1.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.60869598388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[116.90025 ]
 [145.03471 ]
 [130.40828 ]
 [107.42513 ]
 [ 93.1236  ]
 [141.49982 ]
 [145.61295 ]
 [132.74017 ]
 [184.25633 ]
 [173.31429 ]
 [106.75821 ]
 [143.78304 ]
 [118.22325 ]
 [115.04737 ]
 [134.98494 ]
 [112.457085]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  0. 10.  1.  1.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  4.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.38407135009766



buy possibilites: [-1] 
expected returns: [[61.825706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  0. 10.  1.  1.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 184.25634765625






Player: 1 
cards in hand: [29.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  0.  0.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  0. 29.  3.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10. 25. 25.
 25. 10.  0. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25] -> size -> 29 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  0.  0.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  0. 29.  3.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10. 25. 25.
 25. 10.  0. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25] -> size -> 29 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  0.  0.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 11.  0. 29.  3.] 
adversary cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10. 25. 25.
 25. 10.  0. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25] -> size -> 29 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11. 11.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[30.46875 ]
 [46.310173]
 [46.310173]
 [60.363754]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 29.  3.] 
cards in discard: [25. 25. 29.  0. 25.  1.  0.  0.  3. 25.  0.  3. 29.  3.  0. 10. 25. 25.
 25. 10.  0. 10.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 4. 0. 6.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10] -> size -> 27 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.825706481933594



action possibilites: [-1. 11. 11.] 
expected returns: [[42.53926 ]
 [53.829445]
 [53.829445]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 4. 0. 6.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10] -> size -> 27 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.36376953125



action possibilites: [-1] 
expected returns: [[-56.02637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  1.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 6. 4. 0. 6.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10] -> size -> 27 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 59.36467742919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-69.99716 ]
 [-40.756927]
 [-58.539894]
 [-75.61934 ]
 [-47.789913]
 [-35.8392  ]
 [-56.879417]
 [  9.858173]
 [-73.45805 ]
 [-67.25181 ]
 [-52.639465]
 [-64.1298  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  1.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 6. 4. 0. 6.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10] -> size -> 27 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: -56.026371002197266



buy possibilites: [-1] 
expected returns: [[43.011364]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  1.] 
cards in discard: [10. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 6. 4. 0. 6.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10] -> size -> 27 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 343 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 9.8580904006958






Player: 1 
cards in hand: [0. 6. 4. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 4. 0. 6.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 4. 0. 6.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 24. 30. 28. 29.  8.  2.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 4. 0. 6.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 27. 29.  8.  2.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [25. 25. 25. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 29.] 
expected returns: [[-10.232708]
 [ 78.25294 ]
 [ 78.25294 ]
 [ 78.25294 ]
 [ 61.05623 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25. 29.  3.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 27. 29.  8.  2.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  8.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.  3.  0.  6.  4.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10  3] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.0113639831543



action possibilites: [-1] 
expected returns: [[50.992184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  3.  0. 10.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 27. 29.  8.  1.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  8.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.  3.  0.  6.  4.
  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10  3  6] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.25293731689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.982666]
 [33.979702]
 [51.048534]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 29.  3.  0. 10.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 24. 30. 27. 29.  8.  1.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  8.] 
adversary cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.  3.  0.  6.  4.
  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10  3  6] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.992183685302734






Player: 1 
cards in hand: [ 0. 29.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  6.  8.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.  3.  0.  6.  4.
  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  8  0  1  6  0  6  6 16  6  4  6  6 29  6
  1  6 10  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 27. 29.  8.  1.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.  3.  0.  6.  4.
  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 27. 29.  8.  1.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.  3.  0.  6.  4.
  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 24. 30. 27. 29.  8.  1.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  1.  1.  6. 16.  1.  3.  6. 10. 29.  0.  6.  0.  0.  3.  0.  6.  4.
  0.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 29.  8.  1.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[57.033974]
 [59.23493 ]
 [94.32566 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 25.  0.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 29.  8.  1.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.04850769042969



action possibilites: [-1] 
expected returns: [[119.51121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3. 10.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 29.  8.  0.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  0.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.32569122314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[129.23271]
 [143.25677]
 [144.71976]
 [124.35003]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  3. 10.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 30. 27. 29.  8.  0.  9.  8.  9.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  0.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.5112075805664



buy possibilites: [-1] 
expected returns: [[131.90253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  3. 10.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 29.  8.  0.  9.  8.  8.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  0.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 144.71974182128906






Player: 1 
cards in hand: [16.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  6.  3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 29.  8.  0.  9.  8.  8.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0. 25.  1. 25.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.  8. 25.  3.
 10.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8] -> size -> 32 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  6.  3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 30. 27. 29.  8.  0.  9.  8.  8.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0. 25.  1. 25.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.  8. 25.  3.
 10.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8] -> size -> 32 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  6.  3.] 
cards in discard: [6. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0. 25.  1. 25.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.  8. 25.  3.
 10.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8] -> size -> 32 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25.  0. 25.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[10.901691]
 [43.486877]
 [43.486877]
 [43.486877]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  1. 25.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.  8. 25.  3.
 10.  0.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.90252685546875



action possibilites: [-1] 
expected returns: [[37.675682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1. 25.  0.  0.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.  8. 25.  3.
 10.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.48688507080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[31.325645]
 [48.20535 ]
 [39.892212]
 [27.251667]
 [45.500244]
 [49.046436]
 [40.937447]
 [71.30502 ]
 [64.29394 ]
 [27.475723]
 [47.143906]
 [32.647293]
 [29.892185]
 [42.5811  ]
 [32.507946]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1. 25.  0.  0.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.  8. 25.  3.
 10.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  3.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.675682067871094



buy possibilites: [-1] 
expected returns: [[74.877365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1. 25.  0.  0.] 
cards in discard: [10. 29. 29. 11. 11.  0.  3.  1. 25. 25. 25. 29.  3.  0. 10.  8. 25.  3.
 10.  0.  0.  3. 10. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 71.30501556396484






Player: 1 
cards in hand: [6. 6. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 1. 6.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 25. 10. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25] -> size -> 33 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 1. 6.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 25. 10. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25] -> size -> 33 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 10. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10. 29.] 
expected returns: [[68.74886]
 [73.0709 ]
 [98.66323]
 [66.46939]
 [92.32424]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 10. 29.  1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.87736511230469



action possibilites: [-1] 
expected returns: [[28.60202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29.  1. 25.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 98.66326141357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[27.089212]
 [35.47277 ]
 [36.01651 ]
 [30.039017]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29.  1. 25.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  8.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.602020263671875



buy possibilites: [-1] 
expected returns: [[94.19542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29.  1. 25.  3.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 36.016510009765625






Player: 1 
cards in hand: [6. 3. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0. 6.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3. 29. 10.  0.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 6.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3. 29. 10.  0.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [25.  3. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[ 66.51411]
 [156.69934]
 [141.24005]
 [ 73.01775]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29. 10.  0.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.19541931152344



action possibilites: [-1] 
expected returns: [[143.14615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  0. 11. 10.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 156.6993408203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[142.05739]
 [145.22067]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 10.  0. 11. 10.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 143.14614868164062






Player: 1 
cards in hand: [0. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  1. 25.  1.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 24. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  1. 25.  1.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  1. 25.  1.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 93.85403]
 [126.96618]
 [136.06851]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1. 25.  1.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  4. 10.  6.  3.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.  1.
  0.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 145.2206573486328



action possibilites: [-1] 
expected returns: [[160.96404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  1.  0.  0.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  4. 10.  6.  3.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.  1.
  0.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.06851196289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[163.18167]
 [183.49966]
 [151.60118]
 [172.31479]
 [156.81516]
 [181.35153]
 [182.93333]
 [174.31581]
 [209.24873]
 [202.28716]
 [155.20132]
 [182.83661]
 [162.73532]
 [162.40366]
 [175.84116]
 [157.59407]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.  1.  0.  0.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  2.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  4. 10.  6.  3.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.  1.
  0.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.9640350341797



buy possibilites: [-1] 
expected returns: [[122.23196]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.  1.  0.  0.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  4. 10.  6.  3.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.  1.
  0.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 227.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 209.2487030029297






Player: 1 
cards in hand: [29.  4. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  4. 10.  6.  3.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.  1.
  0.  3.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0. 11.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25] -> size -> 35 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  4.  6.  3.  0.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.  1.
  0.  3.  0.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0. 11.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25] -> size -> 35 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  4.  6.  3.  0.] 
cards in discard: [ 6.  3. 16.  0.  0.  6.  3.  6.  6.  0.  1.  6.  6.  3.  8.  0.  6.  1.
  0.  3.  0.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0. 11.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25] -> size -> 35 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [25. 25. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 11.] 
expected returns: [[32.381275]
 [73.172874]
 [73.172874]
 [62.55307 ]
 [51.956257]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  0. 11.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.2319564819336



action possibilites: [-1] 
expected returns: [[25.836512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0. 11. 10.  0.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.1728744506836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[23.94801 ]
 [30.960072]
 [31.648293]
 [23.945679]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0. 11. 10.  0.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  7.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.836511611938477



buy possibilites: [-1] 
expected returns: [[29.152714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0. 11. 10.  0.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  6.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 31.648265838623047






Player: 1 
cards in hand: [10. 29.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  6.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25.  0.  0.  3.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.  8. 25. 25. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8] -> size -> 36 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  1.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  6.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25.  0.  0.  3.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.  8. 25. 25. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8] -> size -> 36 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  1.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  6.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25.  0.  0.  3.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.  8. 25. 25. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8] -> size -> 36 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  1.  6.] 
cards in discard: [8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25.  0.  0.  3.] 
adversary cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.  8. 25. 25. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8] -> size -> 36 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [25. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-3.051026]
 [32.1408  ]
 [32.1408  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  0.  3.] 
cards in discard: [ 8. 25.  8. 10. 29.  1. 25.  3. 25.  3. 29. 10.  0. 11. 10. 25. 25.  3.
 29.  1.  1.  0.  0.  8. 25. 25. 29.  0. 11. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 1. 1. 8.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.152713775634766



action possibilites: [-1] 
expected returns: [[75.82468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3. 10. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 1. 1. 8.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.14076232910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[69.88017 ]
 [79.34276 ]
 [78.624504]
 [75.34585 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  3. 10. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 30. 26. 29.  8.  0.  9.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 1. 1. 8.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.82467651367188



buy possibilites: [-1] 
expected returns: [[142.85423]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  3. 10. 25.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  9.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 1. 1. 8.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8] -> size -> 31 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 191 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 79.3427505493164






Player: 1 
cards in hand: [3. 6. 1. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 1. 8.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  9.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  0. 29.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8  3] -> size -> 37 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 1. 8.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 23. 30. 25. 29.  8.  0.  9.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  0. 29.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8  3] -> size -> 37 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 1. 8.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  0. 29.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8  3] -> size -> 37 
adversary victory points: 5
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[ 55.548023]
 [ 77.44518 ]
 [113.14698 ]
 [113.14698 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0. 29.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.85423278808594



action possibilites: [-1.  8.] 
expected returns: [[111.56426]
 [130.6286 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  1 29 25 25 10  1  1 25 25 10 29
 25 11 25  3 25 10 29  8 25  8 25  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 89.16996002197266



action possibilites: [-1] 
expected returns: [[132.6792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 144.1778564453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[131.66763]
 [160.04115]
 [147.32693]
 [163.42416]
 [148.12476]
 [135.41818]
 [133.8766 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  8.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.67919921875



buy possibilites: [-1] 
expected returns: [[77.3118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 163.42416381835938






Player: 1 
cards in hand: [6. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29. 11.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11] -> size -> 37 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 25. 25. 29. 11.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11] -> size -> 37 
adversary victory points: 5
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [25. 25. 25. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 29. 11.] 
expected returns: [[32.258904]
 [75.850876]
 [75.850876]
 [75.850876]
 [63.383842]
 [53.15716 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25. 29. 11.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 4. 0. 6. 0.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.31179809570312



action possibilites: [-1] 
expected returns: [[6.6481276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29. 11. 29.  8.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 4. 0. 6. 0.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 75.85088348388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[8.286046]
 [8.060574]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 29. 11. 29.  8.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 4. 0. 6. 0.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.648127555847168



buy possibilites: [-1] 
expected returns: [[-35.443485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 29. 11. 29.  8.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 4. 0. 6. 0.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -30   0   0   0   0] 
sum of rewards: 165 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 8.286100387573242






Player: 1 
cards in hand: [0. 4. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 6. 0.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 25. 25. 10.  1.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0] -> size -> 38 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 6. 0.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 25. 25. 10.  1.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0] -> size -> 38 
adversary victory points: 5
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11. 25. 25. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25. 10.] 
expected returns: [[ 1.4354937 ]
 [14.45878   ]
 [30.116627  ]
 [30.116627  ]
 [-0.14903712]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25. 10.  1.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1.  0. 16.  3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.
  0.  4.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -35.443485260009766



action possibilites: [-1] 
expected returns: [[30.121574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10.  1.  3.  0.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1.  0. 16.  3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.
  0.  4.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.116641998291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[16.866879]
 [38.396374]
 [29.91491 ]
 [42.661255]
 [29.52425 ]
 [21.623844]
 [23.619259]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25. 10.  1.  3.  0.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  7.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1.  0. 16.  3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.
  0.  4.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.12157440185547



buy possibilites: [-1] 
expected returns: [[4.7816496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25. 10.  1.  3.  0.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  6.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1.  0. 16.  3.] 
adversary cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.
  0.  4.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 42.661231994628906






Player: 1 
cards in hand: [ 6.  1.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0. 16.  3.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.
  0.  4.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  6.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 10.  1. 25.  3.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8. 11. 25. 11. 25. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11] -> size -> 39 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 16.  3.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.
  0.  4.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 25. 29.  8.  0.  8.  6.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 10.  1. 25.  3.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8. 11. 25. 11. 25. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11] -> size -> 39 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 16.  3.] 
cards in discard: [ 8. 10. 29.  3.  0.  1.  6. 16.  3.  6.  1.  1.  8.  6.  6.  0.  3.  3.
  0.  4.  0.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  6.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 10.  1. 25.  3.] 
adversary cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8. 11. 25. 11. 25. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11] -> size -> 39 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  1. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 25.] 
expected returns: [[-46.07824 ]
 [-47.232887]
 [-47.669113]
 [-36.577965]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1. 25.  3.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8. 11. 25. 11. 25. 10.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  6.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.781649589538574



action possibilites: [-1] 
expected returns: [[-36.802177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.  3.  0. 10.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8. 11. 25. 11. 25. 10.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  6.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -36.57796859741211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-47.496517]
 [-30.143345]
 [-34.35433 ]
 [-23.776054]
 [-35.696384]
 [-40.971035]
 [-36.8022  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1.  3.  0. 10.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8. 11. 25. 11. 25. 10.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  6.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -36.80217742919922



buy possibilites: [-1] 
expected returns: [[-4.0516644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1.  3.  0. 10.] 
cards in discard: [ 3. 25. 25.  0.  0.  3. 10. 25. 29. 11. 29.  8.  0.  0.  0. 25. 25. 25.
 29. 11. 29.  8. 11. 25. 11. 25. 10.  1.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -23.77604866027832






Player: 1 
cards in hand: [6. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11] -> size -> 40 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11] -> size -> 40 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[ 54.304153]
 [101.33248 ]
 [ 68.328926]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  0.] 
adversary cards in discard: [6. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.051664352416992



action possibilites: [-1. 25.] 
expected returns: [[ 93.858475]
 [140.62775 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.] 
cards in discard: [8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  0.] 
adversary cards in discard: [6. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 78.2933578491211



action possibilites: [-1] 
expected returns: [[159.52379]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  0.] 
adversary cards in discard: [6. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.62771606445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[154.79376]
 [181.36343]
 [167.95882]
 [177.32455]
 [182.78644]
 [169.59894]
 [209.97241]
 [145.5163 ]
 [156.06598]
 [172.1501 ]
 [156.53085]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  0.] 
adversary cards in discard: [6. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.52378845214844



buy possibilites: [-1] 
expected returns: [[96.65632]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [ 8. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  0.] 
adversary cards in discard: [6. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -60   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 209.97238159179688






Player: 1 
cards in hand: [16.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  6.  0.] 
cards in discard: [6. 6. 0. 6. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10
  3  6  0  6  3  1  8 16  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  5.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 10. 25. 11.  8.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [6. 6. 0. 6. 6. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 10. 25. 11.  8.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [6. 6. 0. 6. 6. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 10. 25. 11.  8.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [25. 10. 25. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25. 11.  8.] 
expected returns: [[ 82.48192]
 [133.27728]
 [ 85.02607]
 [133.27728]
 [106.32464]
 [ 94.30201]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 25. 11.  8.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  1.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.65631866455078



action possibilites: [-1] 
expected returns: [[85.16637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 11.  8.  3.  8.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  1.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.27731323242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[81.06503]
 [83.82144]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25. 11.  8.  3.  8.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  1.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.16636657714844






Player: 1 
cards in hand: [10.  1.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.  1.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 1. 1.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1. 1.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  1.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1. 1.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[65.74992]
 [97.43604]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  3.  0.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  6.  3.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8 25] -> size -> 34 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.82142639160156



action possibilites: [-1] 
expected returns: [[126.34397]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 25. 25.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  6.  3.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8 25] -> size -> 34 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 97.4360122680664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[110.01917]
 [128.00784]
 [126.6802 ]
 [122.91647]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 25. 25.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 23. 30. 24. 29.  8.  0.  8.  5.  4.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  6.  3.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8 25] -> size -> 34 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.3439712524414



buy possibilites: [-1] 
expected returns: [[81.226105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 25. 25.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 23. 29.  8.  0.  8.  5.  4.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  6.  3.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8 25] -> size -> 34 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 141 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 128.00784301757812






Player: 1 
cards in hand: [ 3. 16.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  6.  3.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6  6 16  6  4  6  6 29  6  1  6 10  3
  6  0  6  3  1  8 16  3  8 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 23. 29.  8.  0.  8.  5.  4.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 25.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3] -> size -> 42 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 23. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 25.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3] -> size -> 42 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 30. 23. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 25.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3] -> size -> 42 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 25.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3] -> size -> 42 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[37.902905]
 [54.03706 ]
 [54.03706 ]
 [68.410194]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 25.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 29.  6.  0.  8.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8  0] -> size -> 35 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.22610473632812



action possibilites: [-1] 
expected returns: [[79.31635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 29. 29.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 29.  6.  0.  8.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8  0] -> size -> 35 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 68.41020202636719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[66.0206 ]
 [81.64646]
 [79.87017]
 [79.31635]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0. 29. 29.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 23. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 29.  6.  0.  8.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8  0] -> size -> 35 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.31635284423828



buy possibilites: [-1] 
expected returns: [[18.05478]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0. 29. 29.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 29.  6.  0.  8.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8  0] -> size -> 35 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 81.64645385742188






Player: 1 
cards in hand: [ 1. 29.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  6.  0.  8.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1. 11. 25. 10.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6
  0  6  3  1  8 16  3  8 25  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1. 11. 25. 10.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1. 11. 25. 10.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1. 11. 25. 10.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1. 11. 25. 10.] 
adversary cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  1. 11. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 10.] 
expected returns: [[-37.86375 ]
 [-49.49078 ]
 [-33.978287]
 [-27.237791]
 [-49.49078 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 11. 25. 10.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.  0. 29.  8.] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.054779052734375



action possibilites: [-1] 
expected returns: [[55.435436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 11. 10.  0.  1.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.  0. 29.  8.] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -27.237754821777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[29.099644]
 [62.603767]
 [55.311115]
 [16.652573]
 [47.413883]
 [75.48371 ]
 [51.57486 ]
 [84.691956]
 [25.575806]
 [55.364655]
 [44.31484 ]
 [22.64351 ]
 [58.857777]
 [55.43544 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 11. 10.  0.  1.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.  0. 29.  8.] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.4354362487793



buy possibilites: [-1] 
expected returns: [[59.606518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 11. 10.  0.  1.] 
cards in discard: [ 8. 29. 29. 25.  0.  0.  3.  0. 10. 25. 10. 25. 11.  8.  3.  8.  3. 25.
  0.  3.  3.  0. 25. 25.  3. 25.  0. 11. 11.  0. 29. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.  0. 29.  8.] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   0. 180.   0.   0.  20.   0.   0.   0.   0. -90.   0.   0.
  32.   0.] 
sum of rewards: 137.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 84.69196319580078






Player: 1 
cards in hand: [3. 3. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 6. 0.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.  0. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 6. 0.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.  0. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 6. 0.] 
cards in discard: [ 6.  6.  0.  6.  6.  8. 16.  3.  6.  0. 25. 10.  1.  3.  0.  1.  1.  8.
  0. 16.  3.  6.  3.  1.  6.  0. 29.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  3. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11. 25.] 
expected returns: [[ 67.86039 ]
 [ 79.15632 ]
 [108.15699 ]
 [ 90.16893 ]
 [117.275085]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 11. 25.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.60651779174805



action possibilites: [-1] 
expected returns: [[152.54175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 11. 11. 25.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.27508544921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[145.6997 ]
 [151.12822]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3. 11. 11. 25.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.541748046875






Player: 1 
cards in hand: [0. 6. 6. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 4.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 10. 25.  3.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 4.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  3.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 10. 25.  3.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 4.] 
cards in discard: [8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 10. 25.  3.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10. 11. 10. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 25.] 
expected returns: [[ 70.677605]
 [ 69.98571 ]
 [ 90.42713 ]
 [ 69.98571 ]
 [109.65968 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 25.  3.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 6.] 
adversary cards in discard: [8. 0. 6. 6. 0. 4.] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.1282196044922



action possibilites: [-1] 
expected returns: [[92.62508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  3.  3. 25.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 6.] 
adversary cards in discard: [8. 0. 6. 6. 0. 4.] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 109.65972137451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[93.32875 ]
 [92.753006]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  3.  3. 25.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 6.] 
adversary cards in discard: [8. 0. 6. 6. 0. 4.] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.62507629394531



buy possibilites: [-1] 
expected returns: [[101.073685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  3.  3. 25.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 6.] 
adversary cards in discard: [8. 0. 6. 6. 0. 4.] 
adversary owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -100    0    0
    0    0] 
sum of rewards: 95 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 93.32874298095703






Player: 1 
cards in hand: [8. 8. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 6.] 
cards in discard: [8. 0. 6. 6. 0. 4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  8  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6
  3  1  8 16  3  8 25  8  0  0  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  1.  0. 25.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0] -> size -> 45 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [8. 0. 6. 6. 0. 4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1
  8 16  3  8 25  8  0  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  1.  0. 25.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0] -> size -> 45 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [8. 0. 6. 6. 0. 4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1
  8 16  3  8 25  8  0  0  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  1.  0. 25.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0] -> size -> 45 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[118.013565]
 [146.78658 ]
 [162.45732 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  0. 25.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  1.  3.  0.] 
adversary cards in discard: [8. 0. 6. 6. 0. 4. 8. 0. 6.] 
adversary owned cards: [ 0  3  1  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1
  8 16  3  8 25  8  0  0  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.07368469238281



action possibilites: [-1] 
expected returns: [[82.408356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  0.  3. 25.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  1.  3.  0.] 
adversary cards in discard: [8. 0. 6. 6. 0. 4. 8. 0. 6.] 
adversary owned cards: [ 0  3  1  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1
  8 16  3  8 25  8  0  0  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 162.4573211669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[68.146614]
 [84.073006]
 [81.65976 ]
 [93.477554]
 [78.86759 ]
 [76.40561 ]
 [82.88994 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.  0.  3. 25.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  5.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  1.  3.  0.] 
adversary cards in discard: [8. 0. 6. 6. 0. 4. 8. 0. 6.] 
adversary owned cards: [ 0  3  1  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1
  8 16  3  8 25  8  0  0  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.40835571289062



buy possibilites: [-1] 
expected returns: [[38.807106]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.  0.  3. 25.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  1.  3.  0.] 
adversary cards in discard: [8. 0. 6. 6. 0. 4. 8. 0. 6.] 
adversary owned cards: [ 0  3  1  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1
  8 16  3  8 25  8  0  0  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -110    0    0
   54    0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 93.47754669189453






Player: 1 
cards in hand: [16.  3.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  1.  3.  0.] 
cards in discard: [8. 0. 6. 6. 0. 4. 8. 0. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1
  8 16  3  8 25  8  0  0  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11] -> size -> 46 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  2. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11] -> size -> 46 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  2. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11] -> size -> 46 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  2. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11] -> size -> 46 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[24.67855 ]
 [42.738106]
 [64.34101 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  0.  0.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  2. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25.  1.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.807106018066406



action possibilites: [-1] 
expected returns: [[28.256004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.  3.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  2. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25.  1.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 64.34101104736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.498999]
 [44.717278]
 [34.127693]
 [35.599674]
 [52.388878]
 [32.923656]
 [68.98641 ]
 [11.528832]
 [24.296993]
 [38.28696 ]
 [28.25602 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.  3.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  2. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25.  1.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.256004333496094



buy possibilites: [-1] 
expected returns: [[74.99115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.  3.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25.  1.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0] -> size -> 35 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -120    0    0
  128    0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 68.98640441894531






Player: 1 
cards in hand: [25.  1.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  6.  0.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25.  8.  3.  1. 10.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0. 1. 8.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25.  8.  3.  1. 10.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 1. 8.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 23. 30. 22. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25.  8.  3.  1. 10.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 1. 8.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25.  8.  3.  1. 10.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [25.  8.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10.] 
expected returns: [[-18.26105  ]
 [  3.3279984]
 [-27.629011 ]
 [-29.23542  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  3.  1. 10.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  1.  3.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.99114990234375



action possibilites: [-1] 
expected returns: [[-44.045853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  1. 10. 29.  0.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  1.  3.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 3.3279383182525635





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-50.82119 ]
 [-49.3537  ]
 [-47.847458]
 [-46.28855 ]
 [-49.148262]
 [-47.642014]
 [-44.045868]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  1. 10. 29.  0.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  1.  3.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -44.04585266113281






Player: 1 
cards in hand: [ 0.  6. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  1.  3.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  0. 29. 29.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3. 25.  8.  3.  1. 10.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 3. 6.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  0. 29. 29.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3. 25.  8.  3.  1. 10.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 3. 6.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  0. 29. 29.] 
adversary cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3. 25.  8.  3.  1. 10.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [10. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 29.] 
expected returns: [[-36.112247]
 [-46.253746]
 [-27.390244]
 [-27.390244]
 [-27.390244]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 29. 29.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3. 25.  8.  3.  1. 10.
 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3.  3.  6. 29.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8. 10.  0.  6.  1.  3.  6.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -44.04585266113281



action possibilites: [-1. 10. 29. 11.] 
expected returns: [[ -97.927925]
 [-104.08055 ]
 [ -93.189095]
 [ -92.60197 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3. 25.  8.  3.  1. 10.
 29.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3.  3.  6. 29.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8. 10.  0.  6.  1.  3.  6.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -39.426673889160156



action possibilites: [-1] 
expected returns: [[-14.135981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3. 25.  8.  3.  1. 10.
 29.  0.  0. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  6. 29.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8. 10.  0.  6.  1.  3.  6.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  180    0    0   40    0    0    0    0 -130    0    0
   64    0] 
sum of rewards: 149 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -90.67127227783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-19.747217]
 [-14.135981]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.] 
cards in discard: [25.  8. 29.  3. 11. 11. 25.  0. 25. 10. 11. 10.  3.  3. 25. 11. 25.  3.
 29.  1.  0.  3. 25. 29. 25.  0. 11.  0.  0.  0.  3. 25.  8.  3.  1. 10.
 29.  0.  0. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  6. 29.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8. 10.  0.  6.  1.  3.  6.] 
adversary owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.135980606079102






Player: 1 
cards in hand: [ 8.  3.  3.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  6. 29.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8. 10.  0.  6.  1.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 16.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8. 10.  0.  6.  1.  3.  6.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  0  1  0  6 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8
 16  3  8 25  8  0  0  0  8 10  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  2.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8. 10.  0.  6.  1.  3.  6.  3.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  3  3  0  1  0 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8 16
  3  8 25  8  0  0  0  8 10  0  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  1.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8.  0.  6.  6.  0.  4.  8.  0.  6. 10.  0. 16.  3.  3.  0.  3. 25.  1.
  0.  6.  0.  1.  8. 10.  0.  6.  1.  3.  6.  3.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  3  3  0  1  0 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8 16
  3  8 25  8  0  0  0  8 10  0  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  1.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 25.] 
expected returns: [[103.58343]
 [157.09818]
 [116.94181]
 [157.09818]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  8. 25.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  1.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  4.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0  1  0 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8 16
  3  8 25  8  0  0  0  8 10  0  3  8] -> size -> 36 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -14.135980606079102



action possibilites: [-1] 
expected returns: [[148.98477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 25.  1. 11.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  1.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  4.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0  1  0 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8 16
  3  8 25  8  0  0  0  8 10  0  3  8] -> size -> 36 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 157.09815979003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[141.28094]
 [159.20312]
 [153.84923]
 [154.29622]
 [162.87952]
 [153.34207]
 [169.55296]
 [139.86453]
 [148.2648 ]
 [155.89835]
 [150.59622]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 25.  1. 11.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  1.  0.  1. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  4.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0  1  0 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8 16
  3  8 25  8  0  0  0  8 10  0  3  8] -> size -> 36 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.98477172851562



Player 0 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 3 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 3 
Witch: 9 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  0.  8. 25.  1. 11.] 
cards in discard: [29.] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 25 25 10  1  1 25 25 10 29 25
 11 25  3 25 10 29  8 25  8 25  8  3 11  0 11 11 29  3  3 29  0 11 29 15
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 29.  8.  0.  8.  4.  1.  0.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  4.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0  1  0 16  6  4  6  6 29  6  1  6 10  3  6  0  6  3  1  8 16
  3  8 25  8  0  0  0  8 10  0  3  8] -> size -> 36 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[     -5 3000000       0     150       0       0      20       0       0
       0       0    -140       0       0      64       0] 
sum of rewards: 3000089 

action type: buy - action 29.0
Learning step: 299991.96875
desired expected reward: 300161.53125



