 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.598854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -390        0        0       40        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000355 

action type: buy - action 0.0
Learning step: -120010.828125
desired expected reward: -120095.1015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[13.474606 ]
 [23.614069 ]
 [19.482094 ]
 [-1.5518548]
 [27.526945 ]
 [21.518148 ]
 [17.386171 ]
 [18.354198 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.7493896484375



buy possibilites: [-1] 
expected returns: [[18.67603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.526945114135742






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.176641]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.676029205322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[15.793087 ]
 [25.953186 ]
 [21.813145 ]
 [ 0.7096453]
 [23.97803  ]
 [29.544352 ]
 [23.855284 ]
 [30.797888 ]
 [ 8.744783 ]
 [19.713015 ]
 [18.907118 ]
 [20.667128 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.716245651245117



buy possibilites: [-1] 
expected returns: [[23.052267]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.797887802124023






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.937822]
 [28.609991]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.05226707458496



action possibilites: [-1] 
expected returns: [[29.466684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 30.976945877075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.044209]
 [30.500288]
 [11.773993]
 [32.2039  ]
 [30.140692]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.466684341430664



buy possibilites: [-1] 
expected returns: [[15.775953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.20390319824219






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[28.9578  ]
 [37.898117]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.77595329284668



action possibilites: [-1.] 
expected returns: [[27.003618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.445556640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.558077]
 [31.42988 ]
 [28.237055]
 [15.110918]
 [11.939032]
 [29.856146]
 [34.656425]
 [29.723734]
 [45.19118 ]
 [35.82059 ]
 [18.083748]
 [26.087946]
 [26.530909]
 [18.216143]
 [25.955544]
 [27.048357]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  8. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.003618240356445



buy possibilites: [-1] 
expected returns: [[21.935844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  8. 11.  3.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 45.19116973876953






Player: 1 
cards in hand: [14.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [11.  0.  3.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[25.578894]
 [34.112953]
 [23.193449]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.93584442138672



action possibilites: [-1. 10. 11.] 
expected returns: [[15.097815]
 [13.970274]
 [21.591314]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.627050399780273



action possibilites: [-1] 
expected returns: [[28.3285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.58194351196289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.525772]
 [30.309866]
 [13.986277]
 [31.77749 ]
 [30.110785]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.328500747680664



buy possibilites: [-1] 
expected returns: [[28.073793]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 31.77748680114746






Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  8.] 
adversary cards in discard: [10.  8. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  8.] 
adversary cards in discard: [10.  8. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  8.] 
adversary cards in discard: [10.  8. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[47.860878]
 [67.61086 ]
 [50.29383 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  8.] 
cards in discard: [10.  8. 29. 11.  3. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.073793411254883



action possibilites: [-1] 
expected returns: [[61.01291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3. 0.] 
cards in discard: [10.  8. 29. 11.  3. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 66.70130157470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[52.72062 ]
 [65.91069 ]
 [60.81862 ]
 [36.379112]
 [63.316605]
 [71.57775 ]
 [63.468163]
 [73.59943 ]
 [45.233616]
 [58.378857]
 [57.90041 ]
 [64.507034]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3. 0.] 
cards in discard: [10.  8. 29. 11.  3. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.012908935546875



buy possibilites: [-1] 
expected returns: [[71.91458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3. 0.] 
cards in discard: [10.  8. 29. 11.  3. 10.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.59942626953125






Player: 1 
cards in hand: [ 0.  0. 14.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0. 11.] 
cards in discard: [8. 0. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8 29] -> size -> 18 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [8. 0. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8 29] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [8. 0. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8 29] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [8. 0. 0. 3. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[22.099829]
 [23.655405]
 [20.87144 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  8 25 10  8 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 323   0] 
sum of rewards: 348 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 37.88255310058594



action possibilites: [-1] 
expected returns: [[18.895086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 10  8 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 23.28489112854004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.666382 ]
 [ 4.6092267]
 [20.833483 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 10  8 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.89508628845215






Player: 1 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  8.] 
adversary cards in discard: [11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 10  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  8.] 
adversary cards in discard: [11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 10  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  8.] 
adversary cards in discard: [11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 10  8 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[26.835527]
 [33.965088]
 [27.88856 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  8.] 
cards in discard: [11.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 10  8 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.833494186401367



action possibilites: [-1.  8.] 
expected returns: [[17.58719 ]
 [18.992592]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [11.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 25 10  8 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.320411682128906



action possibilites: [-1] 
expected returns: [[26.03694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 19.147756576538086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.791311 ]
 [31.221815 ]
 [27.382912 ]
 [ 7.9195514]
 [29.35314  ]
 [34.888218 ]
 [29.24964  ]
 [36.159744 ]
 [15.330845 ]
 [25.423223 ]
 [24.726421 ]
 [26.478975 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.03693962097168



buy possibilites: [-1] 
expected returns: [[38.373695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  8.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.15974044799805






Player: 1 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [11. 14.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  3. 10.] 
adversary cards in discard: [11.  0.  8.  0. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [11. 14.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  3. 10.] 
adversary cards in discard: [11.  0.  8.  0. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29] -> size -> 17 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [11. 14.  3.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  6.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  3. 10.] 
adversary cards in discard: [11.  0.  8.  0. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29] -> size -> 17 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[34.19449 ]
 [47.58098 ]
 [31.590796]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  3. 10.] 
cards in discard: [11.  0.  8.  0. 29. 29.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  6.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 3.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.  8.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.373695373535156



action possibilites: [-1] 
expected returns: [[51.551086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10. 29.  0.] 
cards in discard: [11.  0.  8.  0. 29. 29.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  6.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 3.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.  8.  3.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 47.0419921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.253117]
 [52.07878 ]
 [35.564224]
 [53.723778]
 [52.889835]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10. 29.  0.] 
cards in discard: [11.  0.  8.  0. 29. 29.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  6.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 3.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.  8.  3.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.55108642578125



buy possibilites: [-1] 
expected returns: [[38.595795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10. 29.  0.] 
cards in discard: [11.  0.  8.  0. 29. 29.  8.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 3.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.  8.  3.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 53.72378158569336






Player: 1 
cards in hand: [0. 6. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 3.] 
cards in discard: [11. 14.  3.  0.  0.  0.  8.  3.  0.  0.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29  8] -> size -> 18 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 3.] 
cards in discard: [11. 14.  3.  0.  0.  0.  8.  3.  0.  0.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29  8] -> size -> 18 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[17.090662]
 [23.764996]
 [23.764996]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.595794677734375



action possibilites: [-1. 29.  8.] 
expected returns: [[53.40377 ]
 [60.421364]
 [54.38329 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.477434158325195



action possibilites: [-1.  8.] 
expected returns: [[43.247276]
 [43.927727]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29  8 25 10  8 29 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.421363830566406



action possibilites: [-1] 
expected returns: [[9.026722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 50.257598876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 6.1505647]
 [13.585556 ]
 [10.726994 ]
 [-4.180929 ]
 [16.618013 ]
 [11.961117 ]
 [ 9.107933 ]
 [11.417152 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.026721954345703



buy possibilites: [-1] 
expected returns: [[33.859756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 16.618009567260742






Player: 1 
cards in hand: [8. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  8.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11] -> size -> 16 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  8.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11] -> size -> 16 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  8.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11] -> size -> 16 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[30.30905 ]
 [37.378796]
 [36.46329 ]
 [32.2957  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  8.  0.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.85975646972656



action possibilites: [-1. 11.  8.] 
expected returns: [[34.345436]
 [39.67458 ]
 [35.663666]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  0.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.54773712158203



action possibilites: [-1] 
expected returns: [[37.505104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [11. 29. 29.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.423912048339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.26214 ]
 [40.674255]
 [38.14277 ]
 [25.397287]
 [39.347298]
 [43.095985]
 [39.214386]
 [43.937263]
 [30.110128]
 [36.683075]
 [36.31955 ]
 [37.492065]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [11. 29. 29.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.505104064941406



buy possibilites: [-1] 
expected returns: [[72.818855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [11. 29. 29.  8.  0. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.93727111816406






Player: 1 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [8. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 25. 10.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 10. 29. 29. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29] -> size -> 18 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [8. 6. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 25. 10.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 10. 29. 29. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29] -> size -> 18 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [8. 6. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 25. 10.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 10. 29. 29. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29] -> size -> 18 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8.  6.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8. 25. 10.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 10. 29. 29. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29] -> size -> 18 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.] 
expected returns: [[113.44475]
 [113.04053]
 [131.97234]
 [108.97087]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25. 10.  0.] 
cards in discard: [11. 29. 29.  8.  0. 10. 29. 29. 11.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  5.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [ 8.  6.  0. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.81885528564453



action possibilites: [-1] 
expected returns: [[51.622887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  5.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [ 8.  6.  0. 10. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.73655700683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[46.33556 ]
 [50.356617]
 [38.248875]
 [51.710503]
 [50.557148]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  5.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [ 8.  6.  0. 10. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.622886657714844



buy possibilites: [-1] 
expected returns: [[45.753555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0. 29. 11.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  4.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  6.  3.] 
adversary cards in discard: [ 8.  6.  0. 10. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 51.71049499511719






Player: 1 
cards in hand: [ 3.  0. 14.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  6.  3.] 
cards in discard: [ 8.  6.  0. 10. 11.  0.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  4.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  0.] 
adversary cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8] -> size -> 19 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3.] 
cards in discard: [ 8.  6.  0. 10. 11.  0.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  4.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.] 
adversary cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8] -> size -> 19 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3.] 
cards in discard: [ 8.  6.  0. 10. 11.  0.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  4.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.] 
adversary cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8] -> size -> 19 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3.] 
cards in discard: [ 8.  6.  0. 10. 11.  0.  0.  3.  0.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.] 
adversary cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8] -> size -> 19 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[ 5.9707856]
 [11.112865 ]
 [ 6.7994895]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.] 
cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8] -> size -> 19 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 424   0] 
sum of rewards: 419 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 77.62667846679688



action possibilites: [-1] 
expected returns: [[102.83859]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8] -> size -> 19 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 12.25078010559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 93.631905]
 [ 79.63078 ]
 [101.326645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8] -> size -> 19 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.83859252929688






Player: 1 
cards in hand: [11.  0.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29. 10.  8. 29. 29.] 
adversary cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29. 10.  8. 29. 29.] 
adversary cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29. 10.  8. 29. 29.] 
adversary cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29. 10.  8. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8. 29. 29.] 
expected returns: [[45.650036]
 [51.609077]
 [42.99385 ]
 [45.943844]
 [51.609077]
 [51.609077]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  8. 29. 29.] 
cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0. 10. 11.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.32662963867188



action possibilites: [-1. 10.  8. 29. 29.] 
expected returns: [[78.30134]
 [77.24509]
 [79.41619]
 [83.48517]
 [83.48517]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 29.  0.] 
cards in discard: [ 8. 25.  0.  8. 10.  0. 29. 11.  0.  0. 10. 11.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.06309509277344



action possibilites: [-1. 10.  8. 29.] 
expected returns: [[42.597572]
 [40.168083]
 [42.26507 ]
 [46.67421 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 83.48516082763672



action possibilites: [-1. 10.  8.  8.] 
expected returns: [[33.297718]
 [30.047338]
 [33.231598]
 [33.231598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.674217224121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.497957]
 [35.95098 ]
 [32.68418 ]
 [19.344849]
 [16.116594]
 [34.212917]
 [39.470936]
 [34.215702]
 [49.702785]
 [40.724915]
 [22.594126]
 [30.648401]
 [30.948889]
 [22.590273]
 [30.651194]
 [34.100437]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.29770278930664



buy possibilites: [-1] 
expected returns: [[62.44751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.  8.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 49.702762603759766






Player: 1 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 3. 11.  0.  8.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [25. 29.  8. 11.  0.] 
adversary cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 3. 11.  0.  8.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [25. 29.  8. 11.  0.] 
adversary cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 3. 11.  0.  8.  0. 11. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25. 29.  8. 11.  0.] 
adversary cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [25. 29.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8. 11.] 
expected returns: [[103.9665 ]
 [114.85417]
 [108.83418]
 [104.43492]
 [108.01613]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  8. 11.  0.] 
cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  3. 14.  3.  8.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11. 14.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.447509765625



action possibilites: [-1] 
expected returns: [[55.562996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11.  0. 11.  8.] 
cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  3. 14.  3.  8.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11. 14.  0.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 110.94902038574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.612755]
 [37.3332  ]
 [55.1783  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 11.  0. 11.  8.] 
cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  3. 14.  3.  8.] 
adversary cards in discard: [ 3. 11.  0.  8.  0. 11. 14.  0.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.56299591064453






Player: 1 
cards in hand: [ 6.  3. 14.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14.  3.  8.] 
cards in discard: [ 3. 11.  0.  8.  0. 11. 14.  0.  0.  0.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8. 25. 29.  8. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.  3.  8.] 
cards in discard: [ 3. 11.  0.  8.  0. 11. 14.  0.  0.  0.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8. 25. 29.  8. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.  3.  8.] 
cards in discard: [ 3. 11.  0.  8.  0. 11. 14.  0.  0.  0.  6.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 10.] 
adversary cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8. 25. 29.  8. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[60.34816]
 [59.26552]
 [59.26552]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 10.] 
cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8. 25. 29.  8. 11.  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.17829895019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[53.749077]
 [59.5465  ]
 [57.24678 ]
 [45.3247  ]
 [61.806694]
 [58.30898 ]
 [56.00924 ]
 [57.091896]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 10.] 
cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8. 25. 29.  8. 11.  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.34815979003906



buy possibilites: [-1] 
expected returns: [[17.389107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 10.] 
cards in discard: [25. 29. 29. 29. 10.  8.  0.  0.  8. 25. 29.  8. 11.  0. 11.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 61.806678771972656






Player: 1 
cards in hand: [ 0.  6.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 11  8  6  3 11  8  6  0 10  6  8  3 14  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11] -> size -> 22 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11] -> size -> 22 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11] -> size -> 22 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  0. 10. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.  8.] 
expected returns: [[43.4662  ]
 [47.57292 ]
 [39.95681 ]
 [48.689777]
 [42.8186  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14. 14.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.38910675048828



action possibilites: [-1. 11. 10.  8. 11.] 
expected returns: [[30.71424 ]
 [35.18026 ]
 [28.17179 ]
 [30.825212]
 [35.18026 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  8. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14. 14.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.76168441772461



action possibilites: [-1] 
expected returns: [[27.174784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14. 14.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.99494934082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.36421 ]
 [27.749115]
 [17.281725]
 [28.497168]
 [28.548151]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14. 14.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.17478370666504






Player: 1 
cards in hand: [ 0.  0.  0. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14. 14.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0. 25.  8. 29.] 
adversary cards in discard: [10. 29. 11.  0. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14. 14.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0. 25.  8. 29.] 
adversary cards in discard: [10. 29. 11.  0. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11.  0. 25.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8. 29.] 
expected returns: [[85.76908 ]
 [88.203575]
 [96.063736]
 [83.908356]
 [89.236565]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.  8. 29.] 
cards in discard: [10. 29. 11.  0. 10.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  8.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 14. 14.] 
adversary owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.548139572143555



action possibilites: [-1] 
expected returns: [[30.083849]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 29. 10. 10.] 
cards in discard: [10. 29. 11.  0. 10.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  8.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.17366790771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.531425]
 [14.302801]
 [29.779745]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 29. 10. 10.] 
cards in discard: [10. 29. 11.  0. 10.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  8.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.08384895324707






Player: 1 
cards in hand: [ 3.  0.  3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  8.] 
cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0.  8.  8. 29.] 
adversary cards in discard: [10. 29. 11.  0. 10.  8. 11. 25. 11.  0.  8. 29. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0.  8.  8. 29.] 
adversary cards in discard: [10. 29. 11.  0. 10.  8. 11. 25. 11.  0.  8. 29. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.] 
cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0.  8.  8. 29.] 
adversary cards in discard: [10. 29. 11.  0. 10.  8. 11. 25. 11.  0.  8. 29. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25.  0.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8. 29.] 
expected returns: [[20.40779 ]
 [30.42737 ]
 [20.314993]
 [20.314993]
 [24.55257 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8.  8. 29.] 
cards in discard: [10. 29. 11.  0. 10.  8. 11. 25. 11.  0.  8. 29. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.  8.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6] -> size -> 20 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.779733657836914



action possibilites: [-1] 
expected returns: [[24.573975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 29.  0.  0.] 
cards in discard: [10. 29. 11.  0. 10.  8. 11. 25. 11.  0.  8. 29. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.  8.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6] -> size -> 21 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.947126388549805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.304165]
 [30.558546]
 [28.494974]
 [17.943745]
 [32.595154]
 [29.404348]
 [27.340775]
 [28.359274]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 29.  0.  0.] 
cards in discard: [10. 29. 11.  0. 10.  8. 11. 25. 11.  0.  8. 29. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  5.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.  8.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6] -> size -> 21 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.573974609375



buy possibilites: [-1] 
expected returns: [[61.35913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 29.  0.  0.] 
cards in discard: [10. 29. 11.  0. 10.  8. 11. 25. 11.  0.  8. 29. 10. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  4.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.  8.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6] -> size -> 21 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 32.595157623291016






Player: 1 
cards in hand: [6. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 3. 6.] 
cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.  8.  3.  3. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  4.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11] -> size -> 24 
adversary victory points: 0
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 3. 6.] 
cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.  8.  3.  3. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  4.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11] -> size -> 24 
adversary victory points: 0
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 3. 6.] 
cards in discard: [ 8.  0.  0.  0.  0. 14. 14.  6.  8.  3.  3. 11.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  4. 10.  4.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11] -> size -> 24 
adversary victory points: 0
player victory points: -2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[28.728148]
 [33.00606 ]
 [33.00606 ]
 [33.948997]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  4. 10.  4.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0] -> size -> 22 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.359130859375



action possibilites: [-1. 11. 11. 25.] 
expected returns: [[27.615847]
 [30.079866]
 [30.079866]
 [35.36326 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  4. 10.  4.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0] -> size -> 22 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.20501708984375



action possibilites: [-1] 
expected returns: [[15.985636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  3. 10.  4.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  6. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.363258361816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.512281 ]
 [19.149067 ]
 [17.442194 ]
 [ 8.165384 ]
 [18.093895 ]
 [20.974495 ]
 [18.031488 ]
 [21.607342 ]
 [11.6728325]
 [16.328184 ]
 [16.306051 ]
 [17.96422  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 28. 30.  8.  3. 10.  4.  3.  8.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  6. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.985635757446289



buy possibilites: [-1] 
expected returns: [[16.291546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  0.  8.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  6. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 21.607332229614258






Player: 1 
cards in hand: [ 0.  8.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  6. 11.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 11. 10.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29] -> size -> 25 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  6. 11.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 11. 10.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29] -> size -> 25 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  6. 11.] 
cards in discard: [6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 11. 10.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29] -> size -> 25 
adversary victory points: 0
player victory points: -2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 10.] 
expected returns: [[-3.0137677]
 [-2.60601  ]
 [-2.60601  ]
 [ 1.5970235]
 [-5.1673093]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 11. 10.] 
cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  4. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.291545867919922



action possibilites: [-1] 
expected returns: [[-11.240465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 4.193540096282959





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.114033]
 [-19.20215 ]
 [-11.533244]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3] -> size -> 24 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.24046516418457






Player: 1 
cards in hand: [0. 8. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 6.] 
cards in discard: [ 6.  3.  0.  8.  0.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 29. 29. 25. 10.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8. 10. 11.  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
adversary victory points: 0
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 6. 6.] 
cards in discard: [ 6.  3.  0.  8.  0.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 29. 29. 25. 10.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8. 10. 11.  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
adversary victory points: 0
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 6. 6.] 
cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 29. 29. 25. 10.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8. 10. 11.  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
adversary victory points: 0
player victory points: -2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 29. 29. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 25. 10.] 
expected returns: [[11.782816]
 [14.989138]
 [15.87661 ]
 [15.87661 ]
 [21.992384]
 [ 8.994297]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29. 25. 10.] 
cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8. 10. 11.  0.  8.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  8. 14.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -11.53325366973877



action possibilites: [-1] 
expected returns: [[11.824322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29. 10. 29.  0.] 
cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8. 10. 11.  0.  8.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  8. 14.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3
  0  6] -> size -> 26 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 21.99238395690918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 3.36031 ]
 [-6.598187]
 [10.650892]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 29. 10. 29.  0.] 
cards in discard: [29. 29. 25.  0. 11. 11.  0.  0.  8. 10. 11.  0.  8.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  8. 14.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3
  0  6] -> size -> 26 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.824321746826172






Player: 1 
cards in hand: [ 0. 14.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  8. 14.] 
cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [25. 10. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
adversary victory points: 0
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [25. 10. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [25. 10. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25. 10. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.  8.] 
expected returns: [[14.725994]
 [24.122553]
 [12.592043]
 [12.592043]
 [14.482594]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.  8.  0. 14.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6] -> size -> 24 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.650907516479492



action possibilites: [-1] 
expected returns: [[-8.816252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.  8.  0. 14.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 21.106924057006836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-12.595524]
 [ -9.4158  ]
 [-19.864618]
 [ -8.579744]
 [ -9.37978 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  3.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.  8.  0. 14.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.816251754760742



buy possibilites: [-1] 
expected returns: [[22.460363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.  0.  0. 10.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.  8.  0. 14.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -8.579740524291992






Player: 1 
cards in hand: [3. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3. 0.] 
cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.  8.  0. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29. 11. 10.  8.] 
adversary cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8] -> size -> 27 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 0.] 
cards in discard: [ 6.  3.  0.  8.  0.  6. 11.  0.  0.  8.  6.  6.  6.  6.  8.  0. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29. 11. 10.  8.] 
adversary cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8] -> size -> 27 
adversary victory points: 0
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29. 29. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 10.  8.] 
expected returns: [[ 9.516056]
 [16.15988 ]
 [16.15988 ]
 [15.339575]
 [ 9.017454]
 [11.548548]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 10.  8.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.460363388061523



action possibilites: [-1. 29. 11. 10.  8. 29.] 
expected returns: [[ 1.3896866]
 [ 6.6723533]
 [ 5.7062716]
 [-1.111223 ]
 [ 1.4485455]
 [ 6.6723533]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  8. 29.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.159866333007812



action possibilites: [-1. 11. 10.  8. 29. 11.] 
expected returns: [[ 8.042711 ]
 [13.081415 ]
 [ 5.8171144]
 [ 8.618483 ]
 [14.097412 ]
 [13.081415 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 29. 11.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 6.67235803604126



action possibilites: [-1. 11. 10.  8. 11.] 
expected returns: [[-1.1141405]
 [ 3.899961 ]
 [-3.3428764]
 [-0.5591998]
 [ 3.899961 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 11.  0.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.097417831420898



action possibilites: [-1] 
expected returns: [[-0.61450577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  0.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 6.701326847076416





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -2.6171753 ]
 [  2.6392622 ]
 [  0.53506756]
 [-10.295635  ]
 [  1.5173368 ]
 [  4.533358  ]
 [  1.3811116 ]
 [  5.184379  ]
 [ -6.310761  ]
 [ -0.7230785 ]
 [ -1.0543218 ]
 [ -0.7727339 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  0.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  5.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.6145057678222656



buy possibilites: [-1] 
expected returns: [[3.8409066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  0.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  4.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 5.184390544891357






Player: 1 
cards in hand: [ 6. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  4.  8. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0. 29.] 
adversary cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
adversary victory points: 0
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.] 
cards in discard: [14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0. 29.] 
adversary cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.] 
cards in discard: [14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0. 29.] 
adversary cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.] 
cards in discard: [14.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0. 29.] 
adversary cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 10. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 29.] 
expected returns: [[ 0.201087  ]
 [ 3.7336001 ]
 [-0.86153126]
 [ 3.7336001 ]
 [ 4.3419633 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0. 29.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 14.  6.  6.  8.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0] -> size -> 27 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.8409066200256348



action possibilites: [-1. 11. 10. 11. 25.] 
expected returns: [[ 1.369667 ]
 [ 5.4397206]
 [ 0.8786578]
 [ 5.4397206]
 [10.738033 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0. 25.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 27. 30.  8.  1. 10.  4.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 14.  6.  6.  8.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0] -> size -> 27 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.341969013214111



action possibilites: [-1] 
expected returns: [[-6.7092376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0.  8.  0.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  4.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 14.  6.  6.  8.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.738037109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-8.215502 ]
 [-4.3435297]
 [-5.8102922]
 [-2.9681072]
 [-5.3747272]
 [-6.8403635]
 [-6.1420074]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  0.  8.  0.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  4.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 14.  6.  6.  8.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.709237575531006



buy possibilites: [-1] 
expected returns: [[15.365961]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  0.  8.  0.] 
cards in discard: [ 8. 25. 10. 10.  8.  0.  0. 10. 10. 29. 29. 29. 29. 11. 10.  8. 11.  0.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 14.  6.  6.  8.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -2.968116283416748






Player: 1 
cards in hand: [ 8. 14.  6.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  6.  6.  8.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
adversary victory points: 0
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 8.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10.  8.] 
adversary cards in discard: [29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 8.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10.  8.] 
adversary cards in discard: [29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
adversary victory points: 0
player victory points: -5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[6.219376 ]
 [4.4856286]
 [4.4856286]
 [5.892363 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.] 
cards in discard: [29.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0 893   0] 
sum of rewards: 1038 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -1.4567902088165283





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[3.0350475]
 [6.313948 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.] 
cards in discard: [29.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.232153415679932



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 6.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [10. 29. 29. 11. 25.] 
adversary cards in discard: [29.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 6.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [10. 29. 29. 11. 25.] 
adversary cards in discard: [29.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
adversary victory points: 0
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 6.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [10. 29. 29. 11. 25.] 
adversary cards in discard: [29.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
adversary victory points: 0
player victory points: -5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10. 29. 29. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 11. 25.] 
expected returns: [[ 3.9494061 ]
 [ 0.96212006]
 [ 7.0816636 ]
 [ 7.0816636 ]
 [ 6.3470874 ]
 [12.57486   ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29. 11. 25.] 
cards in discard: [29.  0. 10. 10.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 6. 3. 6. 3.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 6.313953876495361



action possibilites: [-1] 
expected returns: [[-3.6974125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29. 11.  0.  8.] 
cards in discard: [29.  0. 10. 10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 6. 3. 6. 3.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.574848175048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.5547743]
 [-3.5279922]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 29. 11.  0.  8.] 
cards in discard: [29.  0. 10. 10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [0. 6. 3. 6. 3.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.6974124908447266






Player: 1 
cards in hand: [0. 6. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 3.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  0.] 
adversary cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 3.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  0.] 
adversary cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
adversary victory points: 0
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ -9.310001 ]
 [ -5.0650263]
 [-12.007078 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10.  0.] 
cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.  0.  6.  3.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.528000831604004



action possibilites: [-1. 10.] 
expected returns: [[5.4765687]
 [2.69974  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.  0.  6.  3.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.468315124511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 1.718637 ]
 [ 8.250593 ]
 [ 5.8369536]
 [ 6.836246 ]
 [10.898201 ]
 [ 6.7798896]
 [11.838287 ]
 [-1.3086665]
 [ 4.3662524]
 [ 4.307053 ]
 [ 7.1430774]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  4.  7. 10.  2. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.  0.  6.  3.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 5.476566791534424



buy possibilites: [-1] 
expected returns: [[16.963114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.  0.  6.  3.  6.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 11.838294982910156






Player: 1 
cards in hand: [3. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.  0.  6.  3.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [25.  8. 11. 11. 29.] 
adversary cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.  0.  6.  3.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  2.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [25.  8. 11. 11. 29.] 
adversary cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
adversary victory points: 0
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [14.  0. 11.  6.  0.  0. 11.  6. 14.  8.  6.  6.  8.  0.  8.  0.  0.  6.
  6.  0.  6.  3.  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [25.  8. 11. 11. 29.] 
adversary cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
adversary victory points: 0
player victory points: -5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [25.  8. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11. 11. 29.] 
expected returns: [[-22.728838]
 [-11.186542]
 [-20.57749 ]
 [-17.425245]
 [-17.425245]
 [-16.77422 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 11. 11. 29.] 
cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  6. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0  8] -> size -> 30 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.96311378479004



action possibilites: [-1] 
expected returns: [[66.34874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11. 29.  0. 10.] 
cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  6. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0  8] -> size -> 30 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -11.186553955078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[60.941803]
 [67.02194 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 11. 29.  0. 10.] 
cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  6. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0  8] -> size -> 30 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.34873962402344






Player: 1 
cards in hand: [ 8.  6. 14.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 14.  6.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  6  0  6  8  3 14  6  0  6  6  0  6  3  0  6
  6 14  0  6  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  8. 29. 10.] 
adversary cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0. 25.  8. 11. 11. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
adversary victory points: 0
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  8. 29. 10.] 
adversary cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0. 25.  8. 11. 11. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  8. 29. 10.] 
adversary cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0. 25.  8. 11. 11. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 11.  8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 29. 10.] 
expected returns: [[-7.3016844]
 [-4.686703 ]
 [-4.686703 ]
 [-8.009815 ]
 [-3.9462538]
 [-9.831904 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8. 29. 10.] 
cards in discard: [29.  0. 10. 10.  8. 25. 10. 29. 29. 11.  0.  8.  8. 29. 29.  0.  0. 10.
  0. 25.  8. 11. 11. 29.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  8.  3. 14.  3.] 
adversary cards in discard: [ 8. 14.  6.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 67.02192687988281



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[ -9.414024 ]
 [ -7.4438944]
 [ -7.4438944]
 [-11.197773 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  0.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  8.  3. 14.  3.] 
adversary cards in discard: [ 8. 14.  6.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -6.746931552886963



action possibilites: [-1] 
expected returns: [[-14.325487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [ 8. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 14.  3.] 
adversary cards in discard: [ 8. 14.  6.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -5.854752540588379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-17.95167 ]
 [-15.57691 ]
 [-15.264168]
 [-14.762272]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.] 
cards in discard: [ 8. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 14.  3.] 
adversary cards in discard: [ 8. 14.  6.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.32548713684082






Player: 1 
cards in hand: [ 8.  8.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 14.  3.] 
cards in discard: [ 8. 14.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29. 11. 11. 29.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 3.] 
cards in discard: [ 8. 14.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11. 29.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 3.] 
cards in discard: [ 8. 14.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  1.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11. 29.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 3.] 
cards in discard: [ 8. 14.  6.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11. 29.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[ 4.5578694]
 [-1.5111582]
 [ 6.3062444]
 [ 7.5478606]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8] -> size -> 30 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  120    0    0    0    0    0    0    0    0    0    0
 1013    0] 
sum of rewards: 1128 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 44.06547927856445



action possibilites: [-1. 29.] 
expected returns: [[-6.0510283]
 [-1.2199173]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8] -> size -> 30 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.875122547149658



action possibilites: [-1.] 
expected returns: [[12.921545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8] -> size -> 30 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -9.687904357910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 6.9196763]
 [11.28277  ]
 [13.19895  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8] -> size -> 30 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.921545028686523






Player: 1 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  8.  8.  8. 25.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  3.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  8.  8.  8. 25.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  8.  8.  8. 25.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.  8. 25.] 
expected returns: [[ 2.3848715]
 [ 1.9458632]
 [ 1.9458632]
 [ 1.9458632]
 [ 1.9458632]
 [10.15514  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8.  8. 25.] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 6.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11] -> size -> 31 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 13.198953628540039



action possibilites: [-1] 
expected returns: [[57.12551]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 8. 0. 0.] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 6.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11] -> size -> 31 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.155136108398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[53.10617 ]
 [56.596954]
 [57.793694]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 8. 0. 0.] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 6.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11] -> size -> 31 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.125511169433594






Player: 1 
cards in hand: [6. 8. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 6.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29. 25.  8.  8.  8.
  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 6.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29. 25.  8.  8.  8.
  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 6.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10. 25.] 
adversary cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29. 25.  8.  8.  8.
  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25.] 
expected returns: [[22.088106]
 [24.452114]
 [18.835682]
 [29.796476]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10. 25.] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29. 25.  8.  8.  8.
  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  6. 11.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0] -> size -> 32 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.79368591308594



action possibilites: [-1] 
expected returns: [[30.024263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10. 11. 10.] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29. 25.  8.  8.  8.
  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  6. 11.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0] -> size -> 32 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.796472549438477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[24.238377]
 [27.862291]
 [30.16405 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10. 11. 10.] 
cards in discard: [ 8. 15. 29. 11. 11. 10.  0. 11. 29. 10. 11.  0. 29. 29. 25.  8.  8.  8.
  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  6. 11.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0] -> size -> 32 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.024263381958008






Player: 1 
cards in hand: [ 6.  6.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  6. 11.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  6. 11.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  6. 11.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 10.] 
expected returns: [[7.040177 ]
 [8.794863 ]
 [8.794863 ]
 [4.3083787]
 [4.3083787]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 10. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.  0.  6.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.16402244567871



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[ 8.52178 ]
 [ 6.728764]
 [ 6.728764]
 [10.882111]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.] 
cards in discard: [ 0. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.  0.  6.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.496357440948486



action possibilites: [-1. 10.] 
expected returns: [[-16.93967 ]
 [-18.362228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0. 29. 10. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.  0.  6.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 5.2877278327941895





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-19.990091]
 [-17.588362]
 [-17.143795]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0. 29. 10. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.  0.  6.  6.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.939664840698242






Player: 1 
cards in hand: [ 0. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  0.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.  0.  6.  6.  0.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8.  0.  8. 11.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  0.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.  0.  6.  6.  0.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8.  0.  8. 11.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  0.] 
cards in discard: [ 8. 14.  6.  0.  8. 14.  8.  8.  3.  3. 11.  0.  0.  0.  3.  6.  0.  6.
  8.  3.  0.  6.  0.  6.  6.  0.  6. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8.  0.  8. 11.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [25.  8.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8. 11.] 
expected returns: [[ 2.0120416]
 [14.900421 ]
 [ 1.2795048]
 [ 1.2795048]
 [ 6.042627 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.  8. 11.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -17.14379119873047



action possibilites: [-1] 
expected returns: [[-4.44848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 11. 11. 11.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.90042495727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.296837 ]
 [-5.2203593]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 11. 11. 11.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.448480129241943






Player: 1 
cards in hand: [ 3. 11.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  8. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 10. 11.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 11.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 10. 11.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  8. 11.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 10. 11.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 11.] 
expected returns: [[ 5.75689  ]
 [10.733967 ]
 [ 6.552688 ]
 [ 4.4153714]
 [ 9.980888 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 10. 11.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3] -> size -> 35 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -5.220359802246094



action possibilites: [-1.  8. 10. 29.] 
expected returns: [[ 7.611443 ]
 [ 7.6262174]
 [ 5.8060765]
 [11.413317 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3] -> size -> 35 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 12.118209838867188



action possibilites: [-1.  8.] 
expected returns: [[35.003017]
 [33.18281 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3] -> size -> 35 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.778070449829102





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[29.292578]
 [32.819714]
 [35.22194 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3] -> size -> 35 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.00300216674805






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 10.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.  8. 10.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 10.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.  8. 10.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 10.] 
adversary cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.  8. 10.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[43.639412]
 [51.311405]
 [46.174652]
 [40.09475 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29. 10.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.  8. 10.
 29. 29.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0] -> size -> 36 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.22193145751953



action possibilites: [-1] 
expected returns: [[20.577621]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10. 10. 11.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.  8. 10.
 29. 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0] -> size -> 36 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 51.311405181884766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[16.770842]
 [19.63555 ]
 [20.690914]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 10. 10. 11.] 
cards in discard: [ 0. 29. 10. 10. 29. 29. 10. 25.  8.  0.  8. 11. 11. 11.  0. 11.  8. 10.
 29. 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0] -> size -> 36 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.577621459960938






Player: 1 
cards in hand: [0. 6. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29. 15. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29. 15. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29. 15. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [29. 15. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29.  8.] 
expected returns: [[-6.816289]
 [-4.941691]
 [-8.97807 ]
 [-4.941691]
 [-7.926525]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.69091796875



action possibilites: [-1. 15. 10.] 
expected returns: [[-3.2404964]
 [-4.9026065]
 [-5.0242457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.] 
cards in discard: [29.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -4.237544536590576





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-6.717    ]
 [-4.334304 ]
 [-3.4975996]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.] 
cards in discard: [29.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -3.2404861450195312






Player: 1 
cards in hand: [8. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10.  8.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 26. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10.  8.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 25. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10.  8.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
adversary victory points: 0
player victory points: -2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[-8.676901 ]
 [-1.8006859]
 [-8.047478 ]
 [-5.7131567]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10.  8.] 
cards in discard: [29.  8. 29. 15.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 25. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.497593641281128



action possibilites: [-1.  8. 11.] 
expected returns: [[-5.5167437]
 [-4.5377054]
 [-1.376539 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 25. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.495788097381592



action possibilites: [-1] 
expected returns: [[-13.72303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -3.276752233505249





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-15.913513 ]
 [-12.7612705]
 [-14.069075 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 25. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.723030090332031



buy possibilites: [-1] 
expected returns: [[-10.857202]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  0.  0.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 141 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -12.761268615722656






Player: 1 
cards in hand: [ 6.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  0.  0.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29. 10. 11. 10. 29.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3] -> size -> 34 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  0.  0.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29. 10. 11. 10. 29.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3] -> size -> 34 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [29. 10. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 10. 29.] 
expected returns: [[2.4448524 ]
 [5.8790135 ]
 [0.58069706]
 [5.237106  ]
 [0.58069706]
 [5.8790135 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 10. 29.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  8.  8.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.  6.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.85720157623291



action possibilites: [-1. 10. 29.] 
expected returns: [[27.75783 ]
 [24.260265]
 [30.817297]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  8.  8.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.  6.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.386115550994873



action possibilites: [-1.] 
expected returns: [[6.6881127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  8.  8.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.  6.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.538583755493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 5.347708 ]
 [ 8.986757 ]
 [ 7.4628778]
 [10.618769 ]
 [ 6.454249 ]
 [ 7.0752625]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  2.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  8.  8.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.  6.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.688112735748291



buy possibilites: [-1] 
expected returns: [[21.190351]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 11.  3.  8.  8.] 
adversary cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.  6.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 10.61876106262207






Player: 1 
cards in hand: [ 6. 11.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  8.  8.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.  6.  0. 14.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  8  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6
 14  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 25. 10. 25. 11.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.  6.  0. 14.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 25. 10. 25. 11.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.] 
cards in discard: [ 3. 11.  3.  8.  8. 11.  0.  0.  0.  0.  0.  3.  0.  0.  6.  3.  6.  6.
  3.  8.  0.  0.  0.  6.  6.  0. 14.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 25. 10. 25. 11.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [10. 25. 10. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 25. 11.] 
expected returns: [[4.255442  ]
 [0.28947735]
 [9.191811  ]
 [0.28947735]
 [9.191811  ]
 [4.5860133 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 10. 25. 11.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.190351486206055



action possibilites: [-1] 
expected returns: [[11.535942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25. 11.  8. 29.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.191810607910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 8.419138]
 [11.67684 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 25. 11.  8. 29.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.535942077636719






Player: 1 
cards in hand: [ 6.  0.  6. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 14.  6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [11.  0.  8. 29.  8.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0. 25. 10. 10. 25. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0. 25. 10. 10. 25. 11.  8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0. 25. 10. 10. 25. 11.  8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[58.333458]
 [58.22669 ]
 [54.698273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0. 25. 10. 10. 25. 11.  8. 29. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [14.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 6.010252475738525





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[50.978302]
 [58.46459 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.] 
cards in discard: [29.  8. 29. 15.  0. 10.  0. 10.  1.  3. 29. 11.  0.  8. 11. 10. 10. 11.
 11. 29. 29.  0. 25. 10. 10. 25. 11.  8. 29. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [14.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.333457946777344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [14.  6.  0.  6.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [14.  6.  0.  6.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [14.  6.  0.  6.  6.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[-12.404806]
 [-14.171782]
 [-14.171782]
 [-10.030893]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.464576721191406



action possibilites: [-1. 10. 10. 15.] 
expected returns: [[-21.720541]
 [-22.774841]
 [-22.774841]
 [-22.871273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.] 
cards in discard: [0. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.963567733764648





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-23.944979]
 [-21.685816]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.] 
cards in discard: [0. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -21.720539093017578






Player: 1 
cards in hand: [ 3. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.  0.] 
cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29. 10. 29. 11.  0.] 
adversary cards in discard: [ 0.  0. 29. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.  0.] 
cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [29. 10. 29. 11.  0.] 
adversary cards in discard: [ 0.  0. 29. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [29. 10. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 11.] 
expected returns: [[-7.440836 ]
 [-2.583168 ]
 [-9.177401 ]
 [-2.583168 ]
 [-3.4044604]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29. 11.  0.] 
cards in discard: [ 0.  0. 29. 10. 10. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -21.685815811157227



action possibilites: [-1. 10. 29. 29.] 
expected returns: [[-2.7619505]
 [-3.119769 ]
 [ 3.5502148]
 [ 3.5502148]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29.] 
cards in discard: [ 0.  0. 29. 10. 10. 15. 11.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.761192321777344



action possibilites: [-1. 29.] 
expected returns: [[-0.26802254]
 [ 5.8211074 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 0.  0. 29. 10. 10. 15. 11.  0. 10.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 0.6012177467346191



action possibilites: [-1.] 
expected returns: [[-0.97420335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0. 29. 10. 10. 15. 11.  0. 10.  8.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -2.2491989135742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-3.7823195 ]
 [ 1.7664285 ]
 [-0.37760544]
 [ 3.8895926 ]
 [-1.6591482 ]
 [-0.60493803]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0. 29. 10. 10. 15. 11.  0. 10.  8.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11] -> size -> 35 
action values: 1 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  1.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.97420334815979



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 5 
Witch: 2 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [] 
cards in discard: [ 0.  0. 29. 10. 10. 15. 11.  0. 10.  8.  8. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0 11 29  8 25 10  8 29 29  8 11 10 29  8 10 25 11 10 11
 29 10  8 10 29 11 29 15  1  3 11 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 24. 30.  8.  0. 10.  0.  0.  8.  3.  7. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [14.  6.  0.  6.  6.  0.  0.  6.  0.  0.  0.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11  3 11  8  0  6  8  3 14  6  0  6  6  0  6  3  0  6  6 14
  0  6  0  8  8 11  0  0  0  3  0  0  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      60       0       0
       0       0     -10       0       0      27       0] 
sum of rewards: 3000162 

action type: buy - action 11.0
Learning step: 120006.3203125
desired expected reward: 120010.2109375



