 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[47.16672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -290    0    0
   27    0] 
sum of rewards: -248 

action type: buy - action 11.0
Learning step: -32.67771911621094
desired expected reward: 46.09947967529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 46.368114]
 [ 79.89475 ]
 [ 67.674126]
 [ 29.110825]
 [ 65.86385 ]
 [ 88.04504 ]
 [ 64.86729 ]
 [109.25562 ]
 [ 42.753384]
 [ 53.109097]
 [ 74.862686]
 [ 45.604736]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.615623474121094



buy possibilites: [-1] 
expected returns: [[24.75353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.255615234375






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[39.4719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.753530502319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.093933]
 [59.88086 ]
 [51.906345]
 [22.17782 ]
 [67.00454 ]
 [49.670937]
 [42.829636]
 [38.75626 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.03874969482422



buy possibilites: [-1] 
expected returns: [[16.741796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 67.00454711914062






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.180355]
 [43.204712]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.741796493530273



action possibilites: [-1] 
expected returns: [[18.087318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 51.094879150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.918953 ]
 [38.361946 ]
 [30.980057 ]
 [ 6.4616055]
 [43.89705  ]
 [28.957188 ]
 [22.365284 ]
 [18.561005 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.087318420410156



buy possibilites: [-1] 
expected returns: [[19.728144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 43.89704895019531






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[51.979996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.7281436920166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 50.906693]
 [ 83.63042 ]
 [ 72.69436 ]
 [ 31.068436]
 [ 69.98016 ]
 [ 92.21832 ]
 [ 69.750534]
 [112.01504 ]
 [ 46.89852 ]
 [ 58.91482 ]
 [ 79.52188 ]
 [ 51.445446]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 47.29283142089844



buy possibilites: [-1] 
expected returns: [[30.76926]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.01505279541016






Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  8. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[18.984608]
 [48.14882 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  8. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.76926040649414



action possibilites: [-1.] 
expected returns: [[34.030476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  8. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.30875778198242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[39.129562]
 [63.159073]
 [54.234055]
 [24.450905]
 [52.63313 ]
 [69.58896 ]
 [52.18725 ]
 [86.405594]
 [36.466618]
 [44.207695]
 [59.330498]
 [39.134365]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  8. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.03047561645508



buy possibilites: [-1] 
expected returns: [[17.695915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 86.40559387207031






Player: 1 
cards in hand: [ 0.  3. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 23.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23] -> size -> 14 
action values: 1 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23] -> size -> 14 
action values: 0 
buys: 2 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[ 8.459572]
 [34.355247]
 [ 9.594788]
 [26.386316]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 10. 11.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 23.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.69591522216797



action possibilites: [-1. 10. 11.] 
expected returns: [[41.5132  ]
 [47.760956]
 [72.606964]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 23.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.34294891357422



action possibilites: [-1] 
expected returns: [[35.231953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 23.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 81.99295043945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.389088]
 [54.41569 ]
 [49.183403]
 [28.466019]
 [58.391853]
 [47.90664 ]
 [43.18062 ]
 [39.57277 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 23.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.23195266723633



buy possibilites: [-1] 
expected returns: [[20.546684]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 23.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 58.39185333251953






Player: 1 
cards in hand: [ 0.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [ 0.  3. 23.  0.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [29. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [ 0.  3. 23.  0.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [29. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [ 0.  3. 23.  0.  3.  0.  3.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  7. 10. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [29. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[18.386456]
 [43.154373]
 [35.354393]
 [35.354393]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  7. 10. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.54668426513672



action possibilites: [-1. 11. 11.] 
expected returns: [[43.90495]
 [65.82608]
 [65.82608]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  7. 10. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.945281982421875



action possibilites: [-1] 
expected returns: [[32.538338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  7. 10. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 72.98113250732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.18729 ]
 [65.5627  ]
 [57.158955]
 [29.595036]
 [70.392624]
 [55.45392 ]
 [47.192356]
 [40.394558]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  7. 10. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.53833770751953



buy possibilites: [-1] 
expected returns: [[34.871025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 70.39262390136719






Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [29. 11.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [29. 11.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [29. 11.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[30.224884]
 [56.274216]
 [48.224823]
 [31.269539]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 10.  0.] 
cards in discard: [10. 11. 29. 11. 11.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.87102508544922



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[12.421747]
 [29.79628 ]
 [14.871632]
 [39.59208 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0. 29.] 
cards in discard: [10. 11. 29. 11. 11.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 52.20754623413086



action possibilites: [-1. 11. 10.] 
expected returns: [[47.783478]
 [79.52312 ]
 [53.62522 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 11.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.592079162597656



action possibilites: [-1] 
expected returns: [[23.399261]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 11.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.10568237304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.852657]
 [38.41053 ]
 [34.19788 ]
 [21.619923]
 [17.661793]
 [31.9814  ]
 [42.999313]
 [32.61637 ]
 [56.1827  ]
 [50.238373]
 [23.5872  ]
 [36.558975]
 [28.42212 ]
 [23.827253]
 [37.23927 ]
 [27.142418]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 11.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.399261474609375



buy possibilites: [-1] 
expected returns: [[25.064003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 11.  0.  0.  3. 10. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 56.18268585205078






Player: 1 
cards in hand: [16. 16.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  3.  0.  3.] 
cards in discard: [29.  0.  0.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6. 10.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11. 11.  0.  0.  3. 10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.] 
cards in discard: [29.  0.  0.  0.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11. 11.  0.  0.  3. 10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.] 
cards in discard: [29.  0.  0.  0.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11. 11.  0.  0.  3. 10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.] 
cards in discard: [29.  0.  0.  0.  0.  1.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11. 11.  0.  0.  3. 10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[34.130486]
 [35.04135 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  0.] 
cards in discard: [10. 11. 29. 11. 11.  0.  0.  3. 10. 25. 29. 29. 11.  0. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  0.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.  8.  0. 16. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.064002990722656



action possibilites: [-1.] 
expected returns: [[59.425793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  0.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.  8.  0. 16. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 34.91572570800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[68.58988]
 [82.98267]
 [54.19582]
 [81.20723]
 [66.00504]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  0.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.  8.  0. 16. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 59.4257926940918



buy possibilites: [-1] 
expected returns: [[125.907135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  0.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.  8.  0. 16. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 82.9826889038086






Player: 1 
cards in hand: [23.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.  0.  0.] 
cards in discard: [29.  0.  0.  0.  0.  1.  8.  0. 16. 16.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  1.  8.  0. 16. 16.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  1.  8.  0. 16. 16.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0] -> size -> 19 
action values: 0 
buys: 2 
player value: 5 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  1.  8.  0. 16. 16.  3.  3. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6.  9. 10.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 78.910965]
 [126.3938  ]
 [ 81.13043 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0.  0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6.  9. 10.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.90713500976562



action possibilites: [-1. 10. 11.] 
expected returns: [[ 74.64064]
 [ 76.37529]
 [100.15082]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  6.  9. 10.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 115.3609619140625



action possibilites: [-1] 
expected returns: [[44.565464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  5.  9. 10.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 110.17459106445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[33.557354]
 [51.249687]
 [47.254948]
 [22.670305]
 [42.191845]
 [59.660557]
 [44.531147]
 [67.27367 ]
 [33.35396 ]
 [40.89406 ]
 [51.23121 ]
 [45.59554 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  6. 10.  9.  5.  9. 10.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.56546401977539



buy possibilites: [-1] 
expected returns: [[97.57979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 67.273681640625






Player: 1 
cards in hand: [23.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0. 10. 29. 11. 11.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29] -> size -> 25 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0. 10. 29. 11. 11.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29] -> size -> 25 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 11.] 
expected returns: [[67.09195]
 [64.49315]
 [86.18674]
 [81.53679]
 [81.53679]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11. 11.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 22.] 
adversary cards in discard: [23.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.57978820800781



action possibilites: [-1. 10. 11. 11. 25.] 
expected returns: [[75.12626]
 [69.7098 ]
 [81.33483]
 [81.33483]
 [95.92474]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 25.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 22.] 
adversary cards in discard: [23.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 86.186767578125



action possibilites: [-1] 
expected returns: [[46.02349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 10.  0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  6.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 22.] 
adversary cards in discard: [23.  8.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 95.92479705810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[36.853073]
 [61.319244]
 [54.787212]
 [21.083138]
 [69.464386]
 [51.982346]
 [45.541454]
 [45.26765 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11. 10.  0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  6.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 22.] 
adversary cards in discard: [23.  8.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.02349090576172



buy possibilites: [-1] 
expected returns: [[71.07571]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11. 10.  0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  3. 10. 29. 29. 11. 10.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 22.] 
adversary cards in discard: [23.  8.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 69.46439361572266






Player: 1 
cards in hand: [ 0.  3.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 22.] 
cards in discard: [23.  8.  0.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10.  0.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0. 0. 1.] 
cards in discard: [23.  8.  0.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10.  0.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0. 0. 1.] 
cards in discard: [23.  8.  0.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  9.  5.  9. 10.] 
adversary cards in hand: [10.  0.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0. 0. 1.] 
cards in discard: [23.  8.  0.  0.  3.  6. 23.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  8.  5.  9. 10.] 
adversary cards in hand: [10.  0.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[ 65.421715]
 [ 70.85034 ]
 [ 91.96298 ]
 [105.38927 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  8.  5.  9. 10.] 
adversary cards in hand: [ 0. 16.  0. 16. 29.] 
adversary cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.0757064819336



action possibilites: [-1. 10. 11.] 
expected returns: [[108.48663]
 [115.08836]
 [141.16371]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  8.  5.  9. 10.] 
adversary cards in hand: [ 0. 16.  0. 16. 29.] 
adversary cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 93.02294921875



action possibilites: [-1] 
expected returns: [[103.253174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [ 0. 16.  0. 16. 29.] 
adversary cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 150.3227996826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.9153  ]
 [132.03937 ]
 [124.116486]
 [ 88.49001 ]
 [140.56058 ]
 [121.18638 ]
 [113.24068 ]
 [110.53907 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  5.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [ 0. 16.  0. 16. 29.] 
adversary cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.253173828125



buy possibilites: [-1] 
expected returns: [[51.956596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [ 0. 16.  0. 16. 29.] 
adversary cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 140.56056213378906






Player: 1 
cards in hand: [ 0. 16.  0. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 16. 29.] 
cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 16.  3.] 
cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0. 16.  3.] 
cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0. 16.  3.] 
cards in discard: [23.  8.  0.  0.  3.  6. 23. 22.  0.  3.  0.  3.  0.  0.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[58.467438]
 [72.7178  ]
 [49.420498]
 [70.798645]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 10. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.95659637451172



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[47.17954]
 [43.91947]
 [65.63285]
 [65.63285]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  4.  9. 10.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 72.71780395507812



action possibilites: [-1] 
expected returns: [[141.28423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  3.  9. 10.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 70.46507263183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[135.80544]
 [144.73706]
 [128.06113]
 [143.05046]
 [142.03598]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  3.  9. 10.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.2842254638672



buy possibilites: [-1] 
expected returns: [[75.340866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  3.  9. 10.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3] -> size -> 23 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 81 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 144.73703002929688






Player: 1 
cards in hand: [ 6. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  3.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3] -> size -> 30 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  3.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3] -> size -> 30 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  3.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3] -> size -> 30 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[34.31243 ]
 [34.07944 ]
 [53.444992]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  3.  9. 10.] 
adversary cards in hand: [ 0. 16.  1.  3.  0.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.34086608886719



action possibilites: [-1] 
expected returns: [[54.04946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  2.  9. 10.] 
adversary cards in hand: [ 0. 16.  1.  3.  0.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 60.023704528808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.271564]
 [34.569344]
 [53.14686 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  2.  9. 10.] 
adversary cards in hand: [ 0. 16.  1.  3.  0.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.049461364746094






Player: 1 
cards in hand: [ 0. 16.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  3.  0.] 
cards in discard: [ 0.  6. 16.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  2.  9. 10.] 
adversary cards in hand: [10. 11.  0. 10. 25.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10. 11.
  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10] -> size -> 31 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  3.  0.] 
cards in discard: [ 0.  6. 16.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  2.  9. 10.] 
adversary cards in hand: [10. 11.  0. 10. 25.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10. 11.
  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10] -> size -> 31 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  3.  0.] 
cards in discard: [ 0.  6. 16.  3.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [10. 11.  0. 10. 25.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10. 11.
  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10] -> size -> 31 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 25.] 
expected returns: [[61.23619]
 [58.76222]
 [79.36258]
 [58.76222]
 [95.6278 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10. 25.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10. 11.
  0.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9.  8.  4.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [ 0.  0. 22. 23.  3.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 53.14686584472656



action possibilites: [-1] 
expected returns: [[92.824936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10. 11.
  0.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  4.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [ 0.  0. 22. 23.  3.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 95.6278076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 77.276436]
 [108.36466 ]
 [ 99.879845]
 [ 60.10704 ]
 [120.00466 ]
 [ 95.7587  ]
 [ 88.17265 ]
 [ 90.09941 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10. 11.
  0.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  4.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [ 0.  0. 22. 23.  3.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.82493591308594



buy possibilites: [-1] 
expected returns: [[68.74331]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.  3. 29. 11.  0.  3. 10. 11. 10. 11.
  0.  3. 10.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [ 0.  0. 22. 23.  3.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 120.00468444824219






Player: 1 
cards in hand: [ 0.  0. 22. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22. 23.  3.] 
cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [10.  0. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22. 23.  3.] 
cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [10.  0. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 29.] 
expected returns: [[102.213326]
 [ 94.2952  ]
 [129.10602 ]
 [135.37201 ]
 [135.37201 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  8.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.7433090209961



action possibilites: [-1. 10. 11. 29. 29.] 
expected returns: [[65.063095]
 [60.81353 ]
 [87.80138 ]
 [94.71296 ]
 [94.71296 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  8.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 135.30941772460938



action possibilites: [-1. 10. 11. 29. 10.] 
expected returns: [[ 64.71453 ]
 [ 64.329834]
 [ 92.540565]
 [101.79975 ]
 [ 64.329834]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  8.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 94.71296691894531



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[50.5437  ]
 [47.766556]
 [64.03423 ]
 [47.766556]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  1.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  8.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.79976654052734



action possibilites: [-1] 
expected returns: [[69.29984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  0.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  8.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.54078674316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[51.275223]
 [79.04679 ]
 [73.6403  ]
 [34.83559 ]
 [64.17463 ]
 [91.73028 ]
 [69.177574]
 [97.98065 ]
 [51.892593]
 [79.65854 ]
 [69.881226]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  5. 10.  8.  0.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  8.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.29984283447266



buy possibilites: [-1] 
expected returns: [[94.316635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  8.] 
adversary cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  60   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 97.98065948486328






Player: 1 
cards in hand: [ 3. 29.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  8.] 
cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 16 23  0  3 16 29  8  0 22  6 23  3  0
 10  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29] -> size -> 34 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29] -> size -> 34 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  6. 16.  3.  0.  0. 10.  0. 16.  1.  3.  0.  6.  0.  0. 22. 23.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9. 10.] 
adversary cards in hand: [29.  0.  3. 10. 11.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29] -> size -> 34 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[107.8383 ]
 [115.20269]
 [ 93.90666]
 [118.22704]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 10. 11.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.31663513183594



action possibilites: [-1] 
expected returns: [[61.784653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 118.35171508789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.933777]
 [39.0894  ]
 [62.735306]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.78465270996094






Player: 1 
cards in hand: [ 0.  0.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 23.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6] -> size -> 23 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6] -> size -> 23 
action values: 0 
buys: 2 
player value: 6 
card supply: [26. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
adversary victory points: 5
player victory points: 1 


buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 29. 30. 26. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[ 99.916046]
 [105.791565]
 [105.791565]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0. 16. 16.  0.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 62.7353515625



action possibilites: [-1. 10.] 
expected returns: [[80.1956  ]
 [84.575226]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0. 16. 16.  0.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 105.79158020019531



action possibilites: [-1. 11.] 
expected returns: [[65.28019]
 [87.16307]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15] -> size -> 35 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  9.] 
adversary cards in hand: [ 0. 16. 16.  0.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 84.57523345947266



action possibilites: [-1.] 
expected returns: [[43.155872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  8.] 
adversary cards in hand: [ 0. 16. 16.  0.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.8310317993164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[31.098484]
 [50.382484]
 [45.651638]
 [20.975481]
 [40.358696]
 [58.496315]
 [42.756233]
 [65.05289 ]
 [30.997524]
 [50.009613]
 [40.87691 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  4. 10.  8.  0.  9.  8.] 
adversary cards in hand: [ 0. 16. 16.  0.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 43.1558723449707



buy possibilites: [-1] 
expected returns: [[49.720192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  8.  0.  9.  8.] 
adversary cards in hand: [ 0. 16. 16.  0.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -20   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 65.05290222167969






Player: 1 
cards in hand: [ 0. 16. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16.  0.  6.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 16 23  0  3 16  8  0 22  6 23  3  0 10  6  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  8.  0.  9.  8.] 
adversary cards in hand: [11.  3. 10. 11. 10.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29] -> size -> 37 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  8.] 
adversary cards in hand: [11.  3. 10. 11. 10.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29] -> size -> 37 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  8.] 
adversary cards in hand: [11.  3. 10. 11. 10.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29] -> size -> 37 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  8.] 
adversary cards in hand: [11.  3. 10. 11. 10.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29] -> size -> 37 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  3. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[72.88216]
 [86.62017]
 [62.43786]
 [86.62017]
 [62.43786]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 11. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  8.] 
adversary cards in hand: [ 0. 23.  1.  0.  3.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.720191955566406



action possibilites: [-1] 
expected returns: [[29.990978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [ 0. 23.  1.  0.  3.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 88.67158508300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.85346  ]
 [13.9240265]
 [31.074032 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [ 0. 23.  1.  0.  3.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.990978240966797






Player: 1 
cards in hand: [ 0. 23.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  1.  0.  3.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [11. 25.  3.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0. 15. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  1.  0.  3.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 25. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [11. 25.  3.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0. 15. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  1.  0.  3.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [11. 25.  3.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0. 15. 11.  3. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 25.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[46.328796]
 [66.58609 ]
 [83.303314]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3.  3.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0. 15. 11.  3. 10. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  8.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [10.  8.  3.  3.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.  3.  0. 23.  1.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0  3] -> size -> 27 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.074016571044922



action possibilites: [-1] 
expected returns: [[66.93828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0. 11. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0. 15. 11.  3. 10. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [10.  8.  3.  3.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.  3.  0. 23.  1.
  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0  3  6] -> size -> 28 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.30330657958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.502922]
 [37.99771 ]
 [66.93827 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0. 11. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11. 10.  0. 10.  3. 15. 11. 29.  0.  3. 10. 15. 29.
 10. 10. 11.  0.  0.  0.  0. 15. 11.  3. 10. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [10.  8.  3.  3.  6.] 
adversary cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.  3.  0. 23.  1.
  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0  3  6] -> size -> 28 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.93827819824219






Player: 1 
cards in hand: [10.  8.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  3.  6.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.  3.  0. 23.  1.
  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22  6 23  3  0 10  6  0  3
 23  0  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [10. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.  3.  0. 23.  1.
  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [10. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.  3.  0. 23.  1.
  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [10. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  3. 23.  0.  0.  0.  0.  0. 23.  0. 16.  0.  0.  6.  3.  0. 23.  1.
  0.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [10. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[ 83.22981]
 [ 75.23973]
 [102.13982]
 [102.13982]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 66.93827819824219



action possibilites: [-1] 
expected returns: [[83.17765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 107.632568359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.049194]
 [91.414635]
 [56.57238 ]
 [87.3639  ]
 [82.349075]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 24. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.17765045166016



buy possibilites: [-1] 
expected returns: [[151.81578]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [15.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 91.4146499633789






Player: 1 
cards in hand: [ 0.  0.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  6.] 
adversary cards in hand: [11. 10.  0.  0. 29.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 23. 30.  8.  7.  8.  3.  9.  9.  3. 10.  7.  0.  9.  6.] 
adversary cards in hand: [11. 10.  0.  0. 29.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 22.] 
cards in discard: [14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  6.] 
adversary cards in hand: [11. 10.  0.  0. 29.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[45.536705]
 [69.29607 ]
 [44.72077 ]
 [79.53229 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 29.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  6.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14] -> size -> 28 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 151.81578063964844



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[64.574615]
 [81.918365]
 [64.56076 ]
 [64.56076 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 23. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  6.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14] -> size -> 28 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.345008850097656



action possibilites: [-1] 
expected returns: [[15.998413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 23. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14] -> size -> 28 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.90585327148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 7.788672 ]
 [17.984167 ]
 [ 1.1253004]
 [15.62899  ]
 [16.504875 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14] -> size -> 28 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.9984130859375



buy possibilites: [-1] 
expected returns: [[133.33533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14] -> size -> 28 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 101 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 17.984172821044922






Player: 1 
cards in hand: [3. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [14.  0.  0.  0.  0. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [14.  0.  0.  0.  0. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 22. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[80.25499]
 [70.97387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  0.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [23.  0.  0.  3. 23.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1] -> size -> 29 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.3353271484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.66166 ]
 [50.757393]
 [83.57133 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  0.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [23.  0.  0.  3. 23.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1] -> size -> 29 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.2550277709961



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [23.  0.  0.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.  3. 23.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [15. 10. 15. 29. 10.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.  3. 23.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 22. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [15. 10. 15. 29. 10.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.  3. 23.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [15. 10. 15. 29. 10.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [15. 10. 15. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15. 29. 10.] 
expected returns: [[ 88.99569 ]
 [ 89.65775 ]
 [ 73.831696]
 [ 89.65775 ]
 [104.26887 ]
 [ 73.831696]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15. 29. 10.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.57137298583984



action possibilites: [-1. 15. 15. 10. 10.] 
expected returns: [[20.014074]
 [28.175125]
 [28.175125]
 [17.96762 ]
 [17.96762 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 10.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 86.15377044677734



action possibilites: [-1] 
expected returns: [[49.782085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 28.175113677978516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.330444]
 [33.144302]
 [48.914757]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.78208541870117






Player: 1 
cards in hand: [6. 6. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 3.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [10. 11. 15. 29. 25.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 3.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [10. 11. 15. 29. 25.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 11. 15. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 29. 25.] 
expected returns: [[42.860252]
 [41.756332]
 [51.58735 ]
 [47.229683]
 [55.338974]
 [60.01616 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 29. 25.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  7.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [23.  0.  0. 16.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.
  6.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.914756774902344



action possibilites: [-1] 
expected returns: [[78.75255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 29.  3. 11.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  6.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [23.  0.  0. 16.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.
  6.  6.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6] -> size -> 31 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.01615905761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.65767 ]
 [44.374165]
 [78.75252 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15. 29.  3. 11.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  6.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [23.  0.  0. 16.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.
  6.  6.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6] -> size -> 31 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.75254821777344






Player: 1 
cards in hand: [23.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0. 16.  3.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.
  6.  6.  0.  8.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  6.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [11. 10. 29. 29.  0.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.
  6.  6.  0.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  6.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [11. 10. 29. 29.  0.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.
  6.  6.  0.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6] -> size -> 31 
action values: 0 
buys: 2 
player value: 4 
card supply: [23. 28. 30. 21. 30.  8.  6.  8.  3.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [11. 10. 29. 29.  0.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.
  6.  6.  0.  8.  3.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [11. 10. 29. 29.  0.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [14.  0.  0.  0.  0. 22.  1.  3.  0.  3.  0.  1.  3. 23.  0.  0.  3. 23.
  6.  6.  0.  8.  3.  6. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 21. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [11. 10. 29. 29.  0.] 
adversary cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11. 10. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 29.] 
expected returns: [[ 6.06848 ]
 [23.820404]
 [-6.980848]
 [31.594727]
 [31.594727]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29. 29.  0.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [14.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.75254821777344



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[-32.477337]
 [-13.622219]
 [-35.095154]
 [-13.622219]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 21. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  5.] 
adversary cards in hand: [14.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.2836194038391113



action possibilites: [-1] 
expected returns: [[51.800568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 21. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  4.] 
adversary cards in hand: [14.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.681591033935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[38.508945]
 [55.402763]
 [25.886902]
 [52.218994]
 [51.800552]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 21. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  4.] 
adversary cards in hand: [14.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.800567626953125



buy possibilites: [-1] 
expected returns: [[70.024635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [15.  3. 11. 10. 11.  0.  0.  0. 15.  3. 29. 11. 10.  0. 10.  3.  3.  3.
 10.  0. 10. 29. 15. 15. 10. 10. 25. 10. 11. 15. 29.  3. 11. 29. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  4.] 
adversary cards in hand: [14.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 111 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 55.40278244018555






Player: 1 
cards in hand: [14.  0.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  4.] 
adversary cards in hand: [ 3. 11.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  4.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  4.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.005363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [11. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [ 0. 23.  1.  6. 22.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15] -> size -> 34 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  150    0    0    0    0    0    0    0  -90    0    0
 1314    0] 
sum of rewards: 1369 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 125.52474975585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.91289 ]
 [24.677702]
 [58.091537]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [ 0. 23.  1.  6. 22.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15] -> size -> 34 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.00536346435547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 23.  1.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  1.  6. 22.] 
cards in discard: [15. 14.  0.  8.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [29.  0. 10. 15. 10.] 
adversary cards in discard: [11. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  1.  6.  0.  6.  1.] 
cards in discard: [15. 14.  0.  8.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [29.  0. 10. 15. 10.] 
adversary cards in discard: [11. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  1.  6.  0.  6.  1.] 
cards in discard: [15. 14.  0.  8.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  9.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [29.  0. 10. 15. 10.] 
adversary cards in discard: [11. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  1.  6.  0.  6.  1.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [29.  0. 10. 15. 10.] 
adversary cards in discard: [11. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29.  0. 10. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15. 10.] 
expected returns: [[41.660233]
 [64.74876 ]
 [38.63449 ]
 [49.68946 ]
 [38.63449 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 15. 10.] 
cards in discard: [11. 29.  3.  3.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.09154510498047



action possibilites: [-1. 10. 10. 15.] 
expected returns: [[25.956696]
 [24.11132 ]
 [24.11132 ]
 [32.911705]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 15.] 
cards in discard: [11. 29.  3.  3.  0. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10
 29 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 49.73126983642578



action possibilites: [-1] 
expected returns: [[126.391174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [11. 29.  3.  3.  0. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 32.91172409057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[112.606384]
 [137.6496  ]
 [132.2741  ]
 [ 96.76086 ]
 [124.68854 ]
 [148.2486  ]
 [128.50098 ]
 [155.17488 ]
 [112.45786 ]
 [137.64551 ]
 [126.70776 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [11. 29.  3.  3.  0. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  3.  9.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.39117431640625



buy possibilites: [-1] 
expected returns: [[66.57227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  2.  9.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -90   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 155.17486572265625






Player: 1 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  2.  9.  7.  0.  9.  3.] 
adversary cards in hand: [25. 11.  0. 11. 10.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  2.  8.  7.  0.  9.  3.] 
adversary cards in hand: [25. 11.  0. 11. 10.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  2.  8.  7.  0.  9.  3.] 
adversary cards in hand: [25. 11.  0. 11. 10.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [25. 11.  0. 11. 10.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
adversary victory points: 8
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [25. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11. 10.] 
expected returns: [[133.91113 ]
 [156.88164 ]
 [145.29927 ]
 [145.29927 ]
 [122.115036]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 11. 10.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  6.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14] -> size -> 37 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.57227325439453



action possibilites: [-1] 
expected returns: [[129.31319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.  0. 29.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6] -> size -> 38 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 156.88165283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.08589]
 [120.42685]
 [ 85.54994]
 [115.21298]
 [128.24362]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 10.  0. 29.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 20. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6] -> size -> 38 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.3131866455078






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 20. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 20. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
adversary victory points: 8
player victory points: 2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[35.95637 ]
 [34.792477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [23.  6.  3. 23.  3.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0] -> size -> 39 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.24368286132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.28992  ]
 [40.19309  ]
 [ 2.6239839]
 [35.976707 ]
 [28.83617  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 20. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [23.  6.  3. 23.  3.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0] -> size -> 39 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.95642852783203



buy possibilites: [-1] 
expected returns: [[21.98399]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 19. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [23.  6.  3. 23.  3.] 
adversary cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0] -> size -> 39 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0    0    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 40.193153381347656






Player: 1 
cards in hand: [23.  6.  3. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  3. 23.  3.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 19. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [29. 10. 29. 10. 29.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 23.  3.  3.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0] -> size -> 39 
action values: 1 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 19. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [29. 10. 29. 10. 29.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0] -> size -> 39 
action values: 1 
buys: 2 
player value: 2 
card supply: [21. 28. 30. 19. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [29. 10. 29. 10. 29.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0] -> size -> 39 
action values: 0 
buys: 3 
player value: 3 
card supply: [21. 28. 30. 19. 30.  8.  5.  8.  2.  8.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [29. 10. 29. 10. 29.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8] -> size -> 40 
action values: 0 
buys: 2 
player value: 1 
card supply: [21. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [29. 10. 29. 10. 29.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [29. 10. 29. 10. 29.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [15. 14.  0.  8.  3.  0.  8. 22.  0. 23.  1.  6.  0.  6.  1. 14. 14. 11.
  0.  0.  0.  0.  6.  0.  0.  0.  0.  3.  3.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [29. 10. 29. 10. 29.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29. 10. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 10. 29.] 
expected returns: [[29.045033]
 [34.359478]
 [20.322767]
 [34.359478]
 [20.322767]
 [34.359478]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29. 10. 29.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  1.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0] -> size -> 42 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.983989715576172



action possibilites: [-1. 10. 29. 10. 29.] 
expected returns: [[-16.962872]
 [-28.000475]
 [ -9.809105]
 [-28.000475]
 [ -9.809105]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 29.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  1.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0] -> size -> 42 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.795913696289062



action possibilites: [-1. 10. 29. 10.] 
expected returns: [[44.43882 ]
 [26.051996]
 [43.758236]
 [26.051996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  1.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0] -> size -> 42 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -20.970924377441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 9.189571]
 [32.013325]
 [-3.542939]
 [26.16687 ]
 [44.438812]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 10.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
action values: 1 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 0.  1.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0] -> size -> 42 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.4388427734375






Player: 1 
cards in hand: [ 0.  1.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 0. 10.  3. 11.  3.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 28. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 0. 10.  3. 11.  3.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 16.] 
cards in discard: [1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 0. 10.  3. 11.  3.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-59.77826 ]
 [-62.631775]
 [-59.009712]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.  3.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  3.] 
adversary cards in hand: [ 3.  8.  0.  3. 22.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1] -> size -> 43 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.4388427734375



action possibilites: [-1] 
expected returns: [[-46.412086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  2.] 
adversary cards in hand: [ 3.  8.  0.  3. 22.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1] -> size -> 43 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -110    0    0
   64    0] 
sum of rewards: 179 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -58.62994384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-53.827263]
 [-54.45345 ]
 [-46.412094]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  2.] 
adversary cards in hand: [ 3.  8.  0.  3. 22.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1] -> size -> 43 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -46.412086486816406






Player: 1 
cards in hand: [ 3.  8.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3. 22.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  2.] 
adversary cards in hand: [10. 11. 15. 11. 15.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15. 11.  0. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15] -> size -> 46 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3.  0. 14.  0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  2.] 
adversary cards in hand: [10. 11. 15. 11. 15.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15. 11.  0. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15] -> size -> 46 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  3.  0. 14.  0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  2.] 
adversary cards in hand: [10. 11. 15. 11. 15.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15. 11.  0. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15] -> size -> 46 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  3.  0. 14.  0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  2.] 
adversary cards in hand: [10. 11. 15. 11. 15.] 
adversary cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15. 11.  0. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15] -> size -> 46 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 11. 15. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 11. 15.] 
expected returns: [[ -5.6004405]
 [-15.1656475]
 [  7.5406384]
 [ -2.6653523]
 [  7.5406384]
 [ -2.6653523]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 11. 15.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15. 11.  0. 10.  3.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  2.] 
adversary cards in hand: [ 0. 23. 23.  0.  8.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1] -> size -> 44 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -46.412086486816406



action possibilites: [-1] 
expected returns: [[-30.533802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11. 15.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15. 11.  0. 10.  3.
  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  1.] 
adversary cards in hand: [ 0. 23. 23.  0.  8.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1] -> size -> 44 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -120    0    0
   64    0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 10.335433959960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-43.209846]
 [-48.60969 ]
 [-30.533794]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 11. 15.] 
cards in discard: [11. 29.  3.  3.  0. 15. 29. 29. 15. 10. 10. 25. 11.  0. 11. 10.  0. 29.
  3.  3. 10.  3.  0.  0.  3. 10. 29. 29. 10. 29. 10. 15. 11.  0. 10.  3.
  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  1.] 
adversary cards in hand: [ 0. 23. 23.  0.  8.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1] -> size -> 44 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -30.533802032470703






Player: 1 
cards in hand: [ 0. 23. 23.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 23.  0.  8.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  1.] 
adversary cards in hand: [11. 15. 15.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15] -> size -> 47 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1. 23.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  8. 15.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  1.] 
adversary cards in hand: [11. 15. 15.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15] -> size -> 47 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  8. 15.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1] -> size -> 44 
action values: 0 
buys: 2 
player value: 3 
card supply: [19. 26. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  1.] 
adversary cards in hand: [11. 15. 15.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15] -> size -> 47 
adversary victory points: 9
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  8. 15.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  1.] 
adversary cards in hand: [11. 15. 15.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15] -> size -> 47 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11. 15. 15.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15. 11.] 
expected returns: [[75.37442]
 [88.15013]
 [80.84268]
 [80.84268]
 [88.15013]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15.  3. 11.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  1.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1] -> size -> 45 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -30.533802032470703



action possibilites: [-1] 
expected returns: [[93.77043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 11.] 
cards in discard: [15.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1] -> size -> 45 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -130    0    0
   64    0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.27903747558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[79.46733 ]
 [65.77162 ]
 [94.370224]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3. 11.] 
cards in discard: [15.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1] -> size -> 45 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.77043151855469






Player: 1 
cards in hand: [ 6.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 14.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11. 10.  3.  0. 10.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15] -> size -> 48 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11.  3. 10.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15] -> size -> 48 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11.  3. 10.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15] -> size -> 48 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 5 
card supply: [18. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11.  3. 10.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15] -> size -> 48 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 88.817345]
 [107.4872  ]
 [ 83.50948 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0] -> size -> 46 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0    0    0    0    0    0 -130    0    0
 1514    0] 
sum of rewards: 1589 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 191.80111694335938



action possibilites: [-1] 
expected returns: [[119.83894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0] -> size -> 46 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 96.53638458251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[104.9445 ]
 [ 91.47505]
 [119.67642]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 24. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0] -> size -> 46 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.83894348144531






Player: 1 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11. 29. 11. 10.  3.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1] -> size -> 49 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 24. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11. 29. 11. 10.  3.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1] -> size -> 49 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 24. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11. 29. 11. 10.  3.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1] -> size -> 49 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 29. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 10.] 
expected returns: [[131.5097 ]
 [137.92099]
 [132.314  ]
 [137.92099]
 [112.24669]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 11. 10.  3.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 6.  0. 23.  0.  3.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0] -> size -> 47 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.67642974853516



action possibilites: [-1] 
expected returns: [[175.10886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  3.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 6.  0. 23.  0.  3.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0] -> size -> 47 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: 102 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 119.22158813476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[141.65205]
 [119.02393]
 [175.67639]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 10.  3.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 6.  0. 23.  0.  3.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0] -> size -> 47 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 175.10885620117188






Player: 1 
cards in hand: [ 6.  0. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 23.  0.  3.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [25. 15.  3.  0.  0.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 23.  0.  3.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [25. 15.  3.  0.  0.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [25. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[ 74.584564]
 [104.70381 ]
 [ 82.235756]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  3.  0.  0.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 19. 30.  8.  5.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [0. 6. 8. 3. 6.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.  6.
  0. 23.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0] -> size -> 47 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 175.67637634277344



action possibilites: [-1] 
expected returns: [[1.7784104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0. 10. 10.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [0. 6. 8. 3. 6.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.  6.
  0. 23.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6] -> size -> 48 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.70381164550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-24.83674  ]
 [  1.5910149]
 [-38.94847  ]
 [ -4.0179243]
 [  1.7783861]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0. 10. 10.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [0. 6. 8. 3. 6.] 
adversary cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.  6.
  0. 23.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6] -> size -> 48 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.7784104347229004






Player: 1 
cards in hand: [0. 6. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3. 6.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.  6.
  0. 23.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [15. 10. 29.  3. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3. 6.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.  6.
  0. 23.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [15. 10. 29.  3. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3. 6.] 
cards in discard: [ 1.  0.  1.  0.  0. 16.  1. 22. 14.  3.  8.  0.  3.  0. 14.  0.  1. 23.
  0. 23.  0.  8. 15.  0. 14.  6.  0.  0.  0.  0.  3. 11.  0.  0.  0.  6.
  0. 23.  0.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [15. 10. 29.  3. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [15. 10. 29.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 29. 15.] 
expected returns: [[72.32299]
 [70.61028]
 [64.41583]
 [77.48621]
 [70.61028]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 29.  3. 15.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0] -> size -> 49 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.7784104347229004



action possibilites: [-1. 15.] 
expected returns: [[29.921932]
 [29.659248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0] -> size -> 49 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 69.0689697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.08144 ]
 [ 5.38814 ]
 [29.921932]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0] -> size -> 49 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.921966552734375






Player: 1 
cards in hand: [0. 6. 6. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 29. 10. 29. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  7.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 29. 10. 29. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [8.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 29. 10. 29. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [10. 29. 10. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 29. 15.] 
expected returns: [[-28.648293]
 [-42.012993]
 [ -8.957272]
 [-42.012993]
 [ -8.957272]
 [-29.88244 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 29. 15.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  3. 23.  0.] 
adversary cards in discard: [8. 0. 6. 6. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8] -> size -> 50 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.921966552734375



action possibilites: [-1. 10. 10. 15.] 
expected returns: [[-68.58457]
 [-70.48869]
 [-70.48869]
 [-69.28479]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  3. 23.  0.] 
adversary cards in discard: [8. 0. 6. 6. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8] -> size -> 50 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -33.08637237548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-71.16423]
 [-71.01405]
 [-68.58457]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  3. 23.  0.] 
adversary cards in discard: [8. 0. 6. 6. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8] -> size -> 50 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -68.58456420898438






Player: 1 
cards in hand: [ 0.  1.  3. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 23.  0.] 
cards in discard: [8. 0. 6. 6. 1. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [29.  3. 29. 10. 29.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 23.  0.] 
cards in discard: [8. 0. 6. 6. 1. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 23. 30. 19. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [29.  3. 29. 10. 29.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 23.  0.] 
cards in discard: [8. 0. 6. 6. 1. 3. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [29.  3. 29. 10. 29.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [29.  3. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 29.] 
expected returns: [[76.05931]
 [88.35075]
 [88.35075]
 [64.72715]
 [88.35075]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 10. 29.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8  3] -> size -> 51 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -68.58456420898438



action possibilites: [-1. 29. 15.] 
expected returns: [[-11.398676  ]
 [  0.05036592]
 [-13.085011  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 15.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8  3] -> size -> 51 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 73.94393920898438



action possibilites: [-1.] 
expected returns: [[-21.560413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8  3] -> size -> 51 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.112815856933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-47.99739 ]
 [-32.232338]
 [-55.47455 ]
 [-36.558258]
 [-21.560404]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8  3] -> size -> 51 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -21.560413360595703






Player: 1 
cards in hand: [1. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 8. 0.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0
  3  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6
  0  8  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11. 11.  0.  0. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.  3. 15. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11. 11.  0.  0. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.  3. 15. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11. 11.  0.  0. 15.] 
adversary cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.  3. 15. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[58.57101]
 [68.14249]
 [68.14249]
 [59.39121]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0. 15.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.  3. 15. 29. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11.  6.  0. 23.  8.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3] -> size -> 50 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -21.560413360595703



action possibilites: [-1] 
expected returns: [[76.72986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 15.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.  3. 15. 29. 29.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11.  6.  0. 23.  8.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3] -> size -> 50 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 57.27582550048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[52.36188 ]
 [75.95206 ]
 [36.499283]
 [70.879875]
 [76.72983 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 15.] 
cards in discard: [15. 11. 15. 15.  3. 11.  0. 10.  1. 11.  3. 10.  1. 11. 29. 11. 10.  3.
 25. 15.  3.  0.  0. 10. 10. 15. 10. 29.  3. 15.  3. 29.  0. 29. 10. 10.
 15. 29. 10.  3. 15. 29. 29.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 22. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [11.  6.  0. 23.  8.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3] -> size -> 50 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.7298583984375






Player: 1 
cards in hand: [11.  6.  0. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 23.  8.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1] -> size -> 51 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 23.  8.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 22. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1] -> size -> 51 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 23.  8.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1] -> size -> 51 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [10. 11. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[110.51529 ]
 [107.11224 ]
 [123.813095]
 [116.63574 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 0.  0. 14.  3.  1.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0] -> size -> 51 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.7298583984375



action possibilites: [-1] 
expected returns: [[105.459564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  3.] 
cards in discard: [1.] 
cards in deck: 46 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 0.  0. 14.  3.  1.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0] -> size -> 51 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: 82 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 116.21177673339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 95.278275]
 [ 85.69093 ]
 [105.65707 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  3.] 
cards in discard: [1.] 
cards in deck: 46 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [ 0.  0. 14.  3.  1.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0] -> size -> 51 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.45956420898438






Player: 1 
cards in hand: [ 0.  0. 14.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  1.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 15. 15.  3.  0.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 15. 15.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  7.  0.  9.  0.] 
adversary cards in hand: [10. 15. 15.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [10. 15. 15.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
expected returns: [[77.79825]
 [71.83424]
 [83.00296]
 [83.00296]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [14. 23.  3.  1. 15.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23] -> size -> 52 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0    0    0    0    0    0 -170    0    0
 1506    0] 
sum of rewards: 1541 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 183.03614807128906



action possibilites: [-1] 
expected returns: [[141.26115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [14. 23.  3.  1. 15.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23] -> size -> 52 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 83.00299072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.016815]
 [109.774994]
 [144.50127 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [14. 23.  3.  1. 15.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23] -> size -> 52 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.2611541748047






Player: 1 
cards in hand: [14. 23.  3.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 23.  3.  1. 15.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [ 1. 10. 10. 15. 10.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 23.  3.  1.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [ 1. 10. 10. 15. 10.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 23.  3.  1.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [ 1. 10. 10. 15. 10.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 23.  3.  1.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [ 1. 10. 10. 15. 10.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 1. 10. 10. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15. 10.] 
expected returns: [[147.67091]
 [143.26437]
 [143.26437]
 [154.68527]
 [143.26437]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10. 15. 10.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0] -> size -> 53 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 144.5012664794922



action possibilites: [-1] 
expected returns: [[77.42398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10. 10.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0] -> size -> 53 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 154.6852264404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.016403]
 [72.23986 ]
 [49.197865]
 [68.91711 ]
 [79.598526]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10. 10.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0] -> size -> 53 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.42398071289062






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 21. 30. 18. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 21. 30. 17. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
adversary victory points: 9
player victory points: 3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[82.89807]
 [85.97962]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.  0.  0.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 17. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.  3.  0.
  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0  3] -> size -> 54 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.5985336303711



action possibilites: [-1. 10.] 
expected returns: [[121.00163]
 [106.41774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 21. 30. 17. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.  3.  0.
  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0  3] -> size -> 54 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 74.71312713623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 94.31517 ]
 [108.973755]
 [109.86169 ]
 [ 86.73109 ]
 [122.16706 ]
 [105.63262 ]
 [121.00164 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 21. 30. 17. 30.  8.  4.  8.  2.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.  3.  0.
  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0  3] -> size -> 54 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 121.00167083740234



buy possibilites: [-1] 
expected returns: [[65.76348]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.  0.  0.
 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1 11] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 17. 30.  8.  4.  8.  1.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.  3.  0.
  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0  3] -> size -> 54 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -180    0    0
   54    0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 122.16708374023438






Player: 1 
cards in hand: [0. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.  3.  0.
  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 17. 30.  8.  4.  8.  1.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [15. 10. 15.  1. 15.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.  0.  0.
 11. 29.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1 11] -> size -> 53 
adversary victory points: 9
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.  3.  0.
  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0  3] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 21. 30. 17. 30.  8.  4.  8.  1.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [15. 10. 15.  1. 15.] 
adversary cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.  0.  0.
 11. 29.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1 11] -> size -> 53 
adversary victory points: 9
player victory points: 3 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 1 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 10. 15.  1. 15.] 
cards in discard: [ 1. 11. 10. 15.  0.  3.  3.  0. 15. 10. 15. 15.  1. 10. 10. 10.  0.  0.
 11. 29.  3.  1. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 11 10 11 10 25  3 10 29
 11 10 11 10  3 10 11 10 29 15 15 29 15 15  3 15  3 15  3 29  3 15 15 15
  1  1  1  1 11] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 17. 30.  8.  4.  8.  0.  6.  9.  2.  7.  6.  0.  9.  0.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  6.  6.  1.  3.  3.  0.  1.  3. 23.  0.  8.  1.  6.  0.  0. 11.
  6.  0. 23.  8. 23. 14.  0.  0.  3.  1.  0. 15. 14. 23.  3.  1.  3.  0.
  3.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0 23  0  3 16  8  0 22 23  3  0  6  0  3 23  0  3
  6  0 14  1  3  6 11  0 15  8 14 14  6  0  8  0  0  1  1  1  0  0  6  0
  8  3  0 23  0  3 11] -> size -> 55 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000175 

action type: buy - action -1
Learning step: 300010.9375
desired expected reward: 300076.6875



