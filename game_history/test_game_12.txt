 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.605537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0        0        0        0        8        0] 
sum of rewards: -3000027 

action type: buy - action 8.0
Learning step: -120000.7109375
desired expected reward: -120009.9375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.121498 ]
 [11.6093235]
 [11.010852 ]
 [ 9.554747 ]
 [11.193755 ]
 [10.290568 ]
 [ 9.777518 ]
 [ 9.509538 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.650664329528809



buy possibilites: [-1] 
expected returns: [[13.326927]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 11.60932445526123






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.888144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.326927185058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[11.84437 ]
 [13.497935]
 [12.826748]
 [11.174501]
 [13.454136]
 [13.059627]
 [12.057399]
 [15.330217]
 [11.538675]
 [11.48175 ]
 [13.1552  ]
 [11.109611]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.420190811157227



buy possibilites: [-1] 
expected returns: [[6.0002117]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 15.330217361450195






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.05349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.000211715698242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[10.947356]
 [12.683069]
 [11.95472 ]
 [10.737818]
 [10.141731]
 [12.62919 ]
 [12.260752]
 [11.219945]
 [14.702332]
 [14.589849]
 [10.539688]
 [13.374049]
 [10.596359]
 [11.656682]
 [12.250109]
 [10.032418]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.773624420166016



buy possibilites: [-1] 
expected returns: [[7.1200733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 14.70233154296875






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  0.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [25.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  0.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [25.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  0.  3. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [25.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-0.23083305]
 [ 2.8827868 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [25.  0.  0.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.120073318481445



action possibilites: [-1.] 
expected returns: [[16.870424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25.  0.  0.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 2.7735891342163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.498045]
 [21.17134 ]
 [20.493399]
 [18.82065 ]
 [21.126951]
 [20.729872]
 [19.714605]
 [23.017685]
 [19.18927 ]
 [19.13275 ]
 [20.825207]
 [18.755554]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25.  0.  0.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.870424270629883



buy possibilites: [-1] 
expected returns: [[16.728561]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25.  0.  0.  3.  1.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.017688751220703






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[13.985233]
 [18.928642]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.728561401367188



action possibilites: [-1] 
expected returns: [[8.449491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.34328842163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[10.848324]
 [12.37602 ]
 [11.751951]
 [10.706648]
 [10.220724]
 [12.333775]
 [11.96627 ]
 [11.042839]
 [14.221212]
 [14.160162]
 [10.558951]
 [13.079632]
 [10.511614]
 [11.53754 ]
 [12.044813]
 [10.155988]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.449490547180176



buy possibilites: [-1] 
expected returns: [[2.9653325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 14.221212387084961






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [10.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  0.] 
cards in discard: [8. 3. 0. 0. 1. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 1. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 1. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 1.  0. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[14.383076]
 [18.071518]
 [18.071518]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  3. 29.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.965332508087158



action possibilites: [-1. 29.] 
expected returns: [[26.048946]
 [30.089516]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 29.  3.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 17.38327980041504



action possibilites: [-1.] 
expected returns: [[31.672134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.08951187133789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.28491 ]
 [35.883114]
 [33.76124 ]
 [35.238785]
 [34.16476 ]
 [33.667213]
 [35.845104]
 [35.43562 ]
 [34.465607]
 [37.858753]
 [37.78884 ]
 [34.015133]
 [36.617645]
 [33.912025]
 [35.043304]
 [35.572178]
 [33.614487]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.672134399414062



buy possibilites: [-1] 
expected returns: [[27.65812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 37.85875701904297






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 25.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 25.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 25.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 25.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 25. 25.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[-0.48173058]
 [ 3.0740838 ]
 [ 3.0740838 ]
 [ 3.0740838 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  3. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 1. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.658119201660156



action possibilites: [-1] 
expected returns: [[-3.330317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 1. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.524855375289917





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.9628408 ]
 [ 0.46520758]
 [-0.12958765]
 [-1.5399711 ]
 [ 0.43135858]
 [ 0.04487538]
 [-0.80741036]
 [ 2.0505242 ]
 [-1.2268251 ]
 [-1.3141685 ]
 [ 0.16517234]
 [-1.6021836 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 1. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.3303170204162598



buy possibilites: [-1] 
expected returns: [[6.7924232]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3. 25.  0.  1.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 1. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 2.050525665283203






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 1. 0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [29. 25.  0. 25.  3. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1. 0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [29. 25.  0. 25.  3. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1. 0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [29. 25.  0. 25.  3. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[6.5788097]
 [9.861357 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [29. 25.  0. 25.  3. 25.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.792423248291016



action possibilites: [-1.] 
expected returns: [[14.807146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29. 25.  0. 25.  3. 25.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.517581939697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.547956]
 [17.885363]
 [17.327873]
 [16.465097]
 [16.039534]
 [17.854548]
 [17.47455 ]
 [16.680395]
 [19.398481]
 [19.38104 ]
 [16.325562]
 [18.486206]
 [16.209894]
 [17.180391]
 [17.624996]
 [15.992985]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29. 25.  0. 25.  3. 25.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.807146072387695



buy possibilites: [-1] 
expected returns: [[12.122656]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29. 25.  0. 25.  3. 25.  0.  1. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 19.398479461669922






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  6.  7.  8. 10.  9. 10. 10.] 
adversary cards in hand: [25.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  1. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-8.763959 ]
 [-5.7362766]
 [-5.754876 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10. 10.  9.  6.  7.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.122655868530273



action possibilites: [-1] 
expected returns: [[-0.4048289]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10. 10.  9.  6.  7.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -6.185460090637207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 0.4454279 ]
 [ 1.7077103 ]
 [ 1.1691437 ]
 [-0.06093097]
 [ 1.6787255 ]
 [ 1.310523  ]
 [ 0.56916547]
 [ 3.115035  ]
 [ 0.21290946]
 [ 0.11560822]
 [ 1.4409728 ]
 [-0.11859822]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  7. 10. 10.  9.  6.  7.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.40482890605926514



buy possibilites: [-1] 
expected returns: [[2.938828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  0. 29.  0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10. 10.  9.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 3.1150331497192383






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [14.  1.  3.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10. 10.  9.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 29.  3.] 
adversary cards in discard: [29. 25.  1. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [14.  1.  3.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  7. 10. 10.  9.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 29.  3.] 
adversary cards in discard: [29. 25.  1. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [14.  1.  3.  3.  0.  0.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 29.  3.] 
adversary cards in discard: [29. 25.  1. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[11.065584]
 [14.281261]
 [14.266109]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29.  3.] 
cards in discard: [29. 25.  1. 29.  3.  0. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  6.  8.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.9388279914855957



action possibilites: [-1] 
expected returns: [[19.008593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 25.  0.] 
cards in discard: [29. 25.  1. 29.  3.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  6.  8.  0.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 13.732955932617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.228657]
 [21.615047]
 [21.034908]
 [19.686256]
 [21.193184]
 [20.370228]
 [19.879427]
 [19.63166 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3. 25.  0.] 
cards in discard: [29. 25.  1. 29.  3.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  6. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  6.  8.  0.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.00859260559082



buy possibilites: [-1] 
expected returns: [[21.74332]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3. 25.  0.] 
cards in discard: [29. 25.  1. 29.  3.  0. 29.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  6. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  6.  8.  0.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 21.61505126953125






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [14.  1.  3.  3.  0.  0.  6.  8.  0.  0.  3.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  6. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [14.  1.  3.  3.  0.  0.  6.  8.  0.  0.  3.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 28. 30.  8.  6. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [14.  1.  3.  3.  0.  0.  6.  8.  0.  0.  3.  3.  6.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  6. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1] -> size -> 20 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-8.156841 ]
 [-5.0846257]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  6. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.74332046508789



action possibilites: [-1] 
expected returns: [[1.2874799]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  8. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -5.3159074783325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[2.1721754]
 [2.8232098]
 [1.7546954]
 [2.2600403]
 [1.715699 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 26. 30. 28. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  8. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.2874798774719238



buy possibilites: [-1] 
expected returns: [[8.149914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 25. 29.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  8. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 2.823209762573242






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8. 14.  3.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1. 29.  0.  3. 25.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 3.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 26. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 3.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 26. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 3.] 
cards in discard: [ 6. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 7.3245735]
 [10.530523 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.] 
cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  3.  3.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 6.580920219421387



action possibilites: [-1.] 
expected returns: [[14.417313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  3.  3.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 10.171351432800293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.214693]
 [16.628244]
 [16.02791 ]
 [14.629898]
 [16.208908]
 [15.374693]
 [14.867929]
 [14.561249]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  3.  3.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.417312622070312



buy possibilites: [-1] 
expected returns: [[16.186924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  3.  3.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 16.62824249267578






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  3.  3.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1. 25.  0.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1] -> size -> 22 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1. 29.  0.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1] -> size -> 22 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 27. 30.  8.  5. 10. 10.  8.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1. 29.  0.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1] -> size -> 22 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 27. 30.  8.  5. 10. 10.  7.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1. 29.  0.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1] -> size -> 22 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[33.15718]
 [36.86612]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1. 29.  0.  3.  0. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 27. 30.  8.  5. 10. 10.  7.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  6. 10.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -7.183415412902832



action possibilites: [-1] 
expected returns: [[41.926052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1. 29.  0.  3.  0. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 27. 30.  8.  4. 10. 10.  7.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  6. 10.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.86610412597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.051277]
 [40.64907 ]
 [39.832535]
 [37.86826 ]
 [40.290874]
 [39.417515]
 [38.72833 ]
 [37.586597]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1. 29.  0.  3.  0. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 27. 30.  8.  4. 10. 10.  7.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  6. 10.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.92605209350586



buy possibilites: [-1] 
expected returns: [[26.956232]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [ 3. 25.  3.  3.  0.  0. 25. 29.  1. 25.  1. 29.  0.  3.  0. 29.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  4. 10. 10.  7.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  6. 10.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 40.64905548095703






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  6. 10.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  4. 10. 10.  7.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1] -> size -> 23 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  4. 10. 10.  7.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1] -> size -> 23 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 24. 30. 27. 30.  8.  4. 10. 10.  7.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1] -> size -> 23 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  4. 10. 10.  6.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1] -> size -> 23 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [25.  1.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-7.5466304]
 [-4.919057 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  4. 10. 10.  6.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.  8. 10.  3.  6.
  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.95623207092285



action possibilites: [-1] 
expected returns: [[-0.61361]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  3. 10. 10.  6.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.  8. 10.  3.  6.
  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -5.097723484039307





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[0.8834133 ]
 [2.0597997 ]
 [0.49650645]
 [1.5675046 ]
 [0.8206847 ]
 [0.44901657]
 [2.035452  ]
 [1.6782384 ]
 [0.98244   ]
 [3.3814692 ]
 [3.3775454 ]
 [0.6985471 ]
 [2.59412   ]
 [0.5674038 ]
 [1.4486628 ]
 [1.8382998 ]
 [0.41074777]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 24. 30. 27. 30.  8.  3. 10. 10.  6.  6.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.  8. 10.  3.  6.
  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.613610029220581



buy possibilites: [-1] 
expected returns: [[8.796209]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 0. 3.] 
cards in discard: [25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 24. 30. 27. 30.  8.  3. 10. 10.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.  8. 10.  3.  6.
  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 227.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 3.3814687728881836






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.  8. 10.  3.  6.
  0.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  3. 10. 10.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25] -> size -> 24 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.  8. 10.  3.  6.
  0.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 24. 30. 27. 30.  8.  3. 10. 10.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25] -> size -> 24 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6. 10. 14.  1.  3.  8.  3.  8. 14.  6.  0.  3.  3.  6.  8. 10.  3.  6.
  0.  6.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 24. 30. 27. 30.  8.  3. 10.  9.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25] -> size -> 24 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [ 0. 25. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[10.390226]
 [14.241581]
 [14.195471]
 [14.241581]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  0. 25.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  3. 10.  9.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.796209335327148



action possibilites: [-1] 
expected returns: [[15.7465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 25.  3.  0.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  8.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.241580963134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.882454]
 [18.385464]
 [17.753405]
 [16.256746]
 [17.956789]
 [17.063833]
 [16.528183]
 [16.184818]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 25.  3.  0.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 24. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  8.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.746500015258789



buy possibilites: [-1] 
expected returns: [[24.368317]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 25.  3.  0.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  8.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 18.385467529296875






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  8.  1.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29. 29.] 
adversary cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.] 
adversary cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.] 
adversary cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1.] 
cards in discard: [ 6. 23.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.] 
adversary cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
adversary victory points: 4
player victory points: -3 





Player: 0 
cards in hand: [ 3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[35.786415]
 [40.643913]
 [40.643913]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -6.974394798278809



action possibilites: [-1. 29.] 
expected returns: [[30.076614]
 [34.40203 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0. 25. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.64391326904297



action possibilites: [-1.] 
expected returns: [[30.922398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0. 25. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.402015686035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[30.518154]
 [32.136005]
 [29.75605 ]
 [31.30017 ]
 [30.066185]
 [29.279955]
 [32.065063]
 [31.779057]
 [30.898972]
 [34.084846]
 [33.829746]
 [29.725168]
 [32.39565 ]
 [30.192715]
 [30.745083]
 [31.36969 ]
 [28.959389]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0. 25. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  5.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.92239761352539



buy possibilites: [-1] 
expected returns: [[58.44986]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1.] 
cards in discard: [25. 25.  1.  0.  1.  3.  0.  3.  1. 25.  0. 29.  0. 25.  3.  0. 25. 29.
 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  4.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 307.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 34.08486557006836






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  4.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25] -> size -> 26 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  4.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25] -> size -> 26 
adversary victory points: 4
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 25. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[-10.354338]
 [ -8.797345]
 [ -8.801409]
 [ -8.801409]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  4.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10.  0.  6.  8.  6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.449859619140625



action possibilites: [-1. 25. 25.] 
expected returns: [[-10.352718 ]
 [ -7.9677925]
 [ -7.9677925]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 23. 30. 27. 30.  8.  2. 10.  9.  6.  4.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10.  0.  6.  8.  6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -8.797810554504395



action possibilites: [-1] 
expected returns: [[0.0638988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 23. 30. 27. 30.  8.  1. 10.  9.  6.  4.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10.  0.  6.  8.  6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -7.967792510986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[0.9218862 ]
 [2.0831947 ]
 [0.54069734]
 [1.5970016 ]
 [0.86223745]
 [0.49601984]
 [2.0594025 ]
 [1.703975  ]
 [1.0175881 ]
 [3.3867483 ]
 [3.3849359 ]
 [0.74172807]
 [2.6123252 ]
 [0.6080415 ]
 [1.4820042 ]
 [1.8663721 ]
 [0.45917535]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 23. 30. 27. 30.  8.  1. 10.  9.  6.  4.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10.  0.  6.  8.  6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.06389880180358887



buy possibilites: [-1] 
expected returns: [[3.623539]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  3.  0.  1.] 
cards in discard: [25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 23. 30. 27. 30.  8.  1. 10.  9.  6.  3.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10.  0.  6.  8.  6.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 307.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 3.3867483139038086






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10.  0.  6.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  8.  6.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 30. 27. 30.  8.  1. 10.  9.  6.  3.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  3. 25.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25] -> size -> 27 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  8.  6.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 23. 30. 27. 30.  8.  1. 10.  9.  6.  3.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  3. 25.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25] -> size -> 27 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  8.  6.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 23. 30. 27. 30.  8.  1. 10.  9.  6.  3.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  3. 25.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25] -> size -> 27 
adversary victory points: 4
player victory points: -4 





Player: 0 
cards in hand: [ 0.  1. 25.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[24.213686]
 [27.947803]
 [27.947803]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  3. 25.] 
cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 27. 30.  8.  1. 10.  9.  6.  3.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 1. 6. 0.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6  0] -> size -> 34 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.6235389709472656



action possibilites: [-1] 
expected returns: [[31.822144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 25.  0. 25.] 
cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 1. 6. 0.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.94780731201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.70092 ]
 [33.00429 ]
 [32.409214]
 [32.96894 ]
 [32.612114]
 [31.866734]
 [34.429768]
 [31.343224]
 [31.364529]
 [32.62612 ]
 [30.91631 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 25.  0. 25.] 
cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  6.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 1. 6. 0.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.8221435546875



buy possibilites: [-1] 
expected returns: [[37.831604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 25.  0. 25.] 
cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  5.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 8. 1. 6. 0.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 383 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 34.429771423339844






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 8. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1. 6. 0.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  3  8  6  3  6 14 14  6  8  6  1  6
 10  8  6  8  6 11  6 23  6  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  5.  8.  9.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3. 25.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29. 25.  0.  1.  3. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29] -> size -> 28 
adversary victory points: 4
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  5.  8.  9.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3. 25.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29. 25.  0.  1.  3. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29] -> size -> 28 
adversary victory points: 4
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  5.  8.  9.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3. 25.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29. 25.  0.  1.  3. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29] -> size -> 28 
adversary victory points: 4
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  5.  8.  9.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3. 25.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29. 25.  0.  1.  3. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29] -> size -> 28 
adversary victory points: 4
player victory points: -5 





Player: 0 
cards in hand: [29.  3.  1.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[41.88705 ]
 [45.866974]
 [46.03969 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3. 25.] 
cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29. 25.  0.  1.  3. 25.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  5.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 14.  0. 10. 11.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.83160400390625



action possibilites: [-1] 
expected returns: [[27.52839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3.  1. 29.] 
cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29. 25.  0.  1.  3. 25.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  5.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 14.  0. 10. 11.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.039676666259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.269924]
 [22.543205]
 [21.895435]
 [22.493176]
 [22.23699 ]
 [21.522928]
 [23.8926  ]
 [20.733265]
 [20.973114]
 [21.982529]
 [20.18426 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  3.  1. 29.] 
cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29. 25.  0.  1.  3. 25.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  5.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 14.  0. 10. 11.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.528390884399414



buy possibilites: [-1] 
expected returns: [[-10.354338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  3.  1. 29.] 
cards in discard: [25. 29. 25. 25.  0.  0.  3.  0.  1. 29. 25.  0.  1.  3. 25.  0. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 14.  0. 10. 11.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 413 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.892608642578125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0. 10. 11.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [29. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29] -> size -> 29 
adversary victory points: 4
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 10. 11.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [29. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29] -> size -> 29 
adversary victory points: 4
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-9.971187 ]
 [-7.3200493]
 [-7.3200493]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.  3. 14.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.354337692260742



action possibilites: [-1.] 
expected returns: [[3.3390522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.  3. 14.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.561568260192871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[4.4609847]
 [5.8705235]
 [3.9806933]
 [5.2722735]
 [4.346219 ]
 [5.8350706]
 [5.4524064]
 [4.6202126]
 [7.4758167]
 [7.438018 ]
 [4.187099 ]
 [6.4694977]
 [4.1149907]
 [5.0875154]
 [5.5625176]
 [3.8097372]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  3.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.  3. 14.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.339052200317383



buy possibilites: [-1] 
expected returns: [[15.759962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [29. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.  3. 14.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 347.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 7.47581672668457






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.  3. 14.  0. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 3.] 
adversary cards in discard: [29. 25. 29.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25] -> size -> 30 
adversary victory points: 4
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [ 6. 23. 14.  3.  0.  8.  1.  3.  0.  3.  3.  6.  6.  0. 10.  0.  6.  8.
  6.  6.  0.  8.  6.  6.  0.  3. 14.  0. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 3.] 
adversary cards in discard: [29. 25. 29.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25] -> size -> 30 
adversary victory points: 4
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[54.4563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 3.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.75996208190918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[54.34325 ]
 [55.89291 ]
 [55.21721 ]
 [55.8516  ]
 [55.446335]
 [54.538982]
 [57.59797 ]
 [53.9771  ]
 [53.965515]
 [55.497623]
 [53.51413 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 3.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  4.  8.  9.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.456298828125



buy possibilites: [-1] 
expected returns: [[52.418465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 3.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  3.  8.  9.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 393 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 57.59797286987305






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8  6  3  6 14 14  6  8  6  1  6 10
  8  6  8  6 11  6 23  6  0  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  3.  8.  9.  8. 10. 10.] 
adversary cards in hand: [25. 29.  3.  0. 25.] 
adversary cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29] -> size -> 31 
adversary victory points: 4
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  3.  8.  9.  8. 10. 10.] 
adversary cards in hand: [25. 29.  3.  0. 25.] 
adversary cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29] -> size -> 31 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  3.  8.  9.  8. 10. 10.] 
adversary cards in hand: [25. 29.  3.  0. 25.] 
adversary cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29] -> size -> 31 
adversary victory points: 4
player victory points: -4 





Player: 0 
cards in hand: [25. 29.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[58.680122]
 [62.791626]
 [62.660713]
 [62.791626]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  0. 25.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  3.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10. 14.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0] -> size -> 32 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.41846466064453



action possibilites: [-1] 
expected returns: [[17.752815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25.  0.  1.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  3.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10. 14.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0] -> size -> 32 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.79161834716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[13.458416]
 [14.734497]
 [14.140326]
 [14.694899]
 [14.37977 ]
 [13.653908]
 [16.117731]
 [13.054227]
 [13.151502]
 [14.319193]
 [12.600712]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 25.  0.  1.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  3.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10. 14.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0] -> size -> 32 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.75281524658203



buy possibilites: [-1] 
expected returns: [[12.508068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 25.  0.  1.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [10. 14.  0.  3.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0] -> size -> 32 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 383 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 16.117717742919922






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [10. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  3.  0.] 
cards in discard: [8. 6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 29.  1.] 
adversary cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29. 25. 29.  3.  0.
 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29] -> size -> 32 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  3.  0.] 
cards in discard: [8. 6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  6.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 29.  1.] 
adversary cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29. 25. 29.  3.  0.
 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29] -> size -> 32 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  3.  0.] 
cards in discard: [8. 6. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 29.  1.] 
adversary cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29. 25. 29.  3.  0.
 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29] -> size -> 32 
adversary victory points: 4
player victory points: -4 





Player: 0 
cards in hand: [ 0.  3. 25. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-10.354338]
 [ -8.80311 ]
 [ -8.799242]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 29.  1.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29. 25. 29.  3.  0.
 25.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 8. 8. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.508068084716797



action possibilites: [-1. 25. 25.] 
expected returns: [[-10.145496 ]
 [ -7.7125115]
 [ -7.7125115]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 25.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29. 25. 29.  3.  0.
 25.  0.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 8. 8. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.773706436157227



action possibilites: [-1] 
expected returns: [[-10.354338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 29. 25.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29. 25. 29.  3.  0.
 25.  0.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 8. 8. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -7.712512493133545





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-10.354338]
 [-10.146006]
 [-10.354338]
 [-10.354338]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25. 29. 25.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29. 25. 29.  3.  0.
 25.  0.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 23. 30. 27. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 8. 8. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.354337692260742



buy possibilites: [-1] 
expected returns: [[-10.354338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25. 29. 25.] 
cards in discard: [29. 25. 29.  1.  0.  0.  1. 29.  1.  0.  3.  0.  3. 29. 25. 29.  3.  0.
 25.  0.  1.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 26. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 8. 8. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 321 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -10.146005630493164






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [3. 8. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 8. 6.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  8  3  6 14 14  6  8  6  1  6 10  8  6  8
  6 11  6 23  6  0  6  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 26. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3] -> size -> 33 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 26. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3] -> size -> 33 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 23. 30. 26. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3] -> size -> 33 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3] -> size -> 33 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [ 0. 29. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 25.] 
expected returns: [[12.857312]
 [17.252003]
 [17.252003]
 [17.42192 ]
 [17.42192 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 25. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 23.  3.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.354337692260742



action possibilites: [-1] 
expected returns: [[7.144142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 25.  1.  1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 23.  3.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.42192840576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 8.333383 ]
 [ 9.753332 ]
 [ 9.126976 ]
 [ 8.17621  ]
 [ 9.713021 ]
 [ 9.345797 ]
 [ 8.520835 ]
 [11.384527 ]
 [11.320093 ]
 [ 8.014996 ]
 [10.296737 ]
 [ 7.99362  ]
 [ 8.895673 ]
 [ 9.385687 ]
 [ 7.6474495]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 25.  1.  1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  9.  5.  2.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 23.  3.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.144142150878906



buy possibilites: [-1] 
expected returns: [[13.659243]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 25.  1.  1.] 
cards in discard: [25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  9.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 23.  3.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 535 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 11.384527206420898






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  6. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 23.  3.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  9.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  3.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25] -> size -> 34 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  9.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  3.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25] -> size -> 34 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0] -> size -> 31 
action values: 0 
buys: 2 
player value: 3 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  9.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  3.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25] -> size -> 34 
adversary victory points: 5
player victory points: -4 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  3.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25] -> size -> 34 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [ 0. 25. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[10.812035 ]
 [13.983526 ]
 [13.9579525]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  0.  3.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.659242630004883



action possibilites: [-1] 
expected returns: [[8.571903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  3.  0.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 13.983528137207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[8.158075 ]
 [9.338431 ]
 [8.825603 ]
 [8.951457 ]
 [8.263303 ]
 [7.829359 ]
 [7.5927553]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  3.  0.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 23. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.571903228759766



buy possibilites: [-1] 
expected returns: [[6.5519123]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  3.  0.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 339 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 9.338433265686035






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [25.  1. 29.  1. 25.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1] -> size -> 35 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [25.  1. 29.  1. 25.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1] -> size -> 35 
adversary victory points: 5
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  1. 29.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-9.23155  ]
 [-6.7985654]
 [-6.788151 ]
 [-6.7985654]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29.  1. 25.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 14.  6. 11.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.
  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.551912307739258



action possibilites: [-1. 25. 25.] 
expected returns: [[-5.0154915]
 [-2.0804403]
 [-2.0804403]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 25.  0.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 14.  6. 11.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.
  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -7.869478225708008



action possibilites: [-1] 
expected returns: [[-6.5336776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0. 29.  3.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 14.  6. 11.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.
  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -2.080440044403076





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-6.1329603]
 [-5.1667356]
 [-5.5824103]
 [-5.1822376]
 [-5.517257 ]
 [-6.0793915]
 [-4.085407 ]
 [-6.2857337]
 [-6.4291425]
 [-5.3532543]
 [-6.5288053]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0. 29.  3.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  2.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 14.  6. 11.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.
  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.533677577972412



buy possibilites: [-1] 
expected returns: [[-6.4599724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0. 29.  3.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  1.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 14.  6. 11.] 
adversary cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.
  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -10   0   0 128   0] 
sum of rewards: 423 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -4.085406303405762






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 14.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14.  6. 11.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.
  6.  3.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  1.  8.  9.  8. 10. 10.] 
adversary cards in hand: [25.  0.  3. 29. 25.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.
 29. 25.  1. 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29] -> size -> 36 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14.  6.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.
  6.  3.  3.  0.  6. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [25.  0.  3. 29. 25.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.
 29. 25.  1. 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29] -> size -> 36 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  6.] 
cards in discard: [ 8.  6.  8. 10. 14.  0.  3.  0.  0.  8.  8. 11. 23.  6.  0.  6.  3.  0.
  6.  3.  3.  0.  6. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [25.  0.  3. 29. 25.] 
adversary cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.
 29. 25.  1. 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29] -> size -> 36 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [25.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-10.354338 ]
 [ -8.704798 ]
 [ -8.6969185]
 [ -8.704798 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 29. 25.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.
 29. 25.  1. 25.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.459972381591797



action possibilites: [-1. 25.] 
expected returns: [[-10.354338]
 [ -8.80311 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.
 29. 25.  1. 25.  0. 29.  3. 25.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.728620529174805



action possibilites: [-1] 
expected returns: [[-10.240804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.
 29. 25.  1. 25.  0. 29.  3. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -8.80311107635498





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-10.037979 ]
 [ -9.071755 ]
 [ -9.487431 ]
 [ -9.087258 ]
 [ -9.422277 ]
 [ -9.984413 ]
 [-10.190754 ]
 [-10.3270855]
 [ -9.258274 ]
 [-10.354339 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.
 29. 25.  1. 25.  0. 29.  3. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 22. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.240803718566895



buy possibilites: [-1] 
expected returns: [[-10.232655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0.] 
cards in discard: [25. 25.  0. 29. 29. 25.  1.  1.  1. 25.  0. 29.  0.  3.  3.  0.  1. 29.
 29. 25.  1. 25.  0. 29.  3. 25.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   40.    0.    0.    0.    0.  -20.
   0.    0.   13.5   0. ] 
sum of rewards: 298.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -9.071756362915039






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 10.  1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 29. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29  1] -> size -> 37 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 10.  1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  8.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 29. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29  1] -> size -> 37 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 10.  1.] 
cards in discard: [11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  7.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 29. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29  1] -> size -> 37 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [ 3.  1. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[92.68502 ]
 [98.312325]
 [98.63507 ]
 [98.312325]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29. 25. 29.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  7.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14. 29.] 
adversary cards in discard: [11.  8.  0.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29 11] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.232654571533203



action possibilites: [-1] 
expected returns: [[27.95031]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29. 29.  0.  1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  7.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14. 29.] 
adversary cards in discard: [11.  8.  0.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29 11] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 98.63506317138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.253899]
 [28.85272 ]
 [28.135927]
 [27.022839]
 [28.799831]
 [28.442238]
 [27.5153  ]
 [30.716572]
 [26.797766]
 [29.40783 ]
 [26.90992 ]
 [27.81802 ]
 [28.380606]
 [26.273354]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 29. 29.  0.  1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  7.  5.  1.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14. 29.] 
adversary cards in discard: [11.  8.  0.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29 11] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.95030975341797



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 7 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  1. 29. 29.  0.  1.] 
cards in discard: [25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 29 25 29  1  3  1  1 25
  1 25 25 29 29 25 29 29  3 25  1 29  1 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  7.  5.  0.  0.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14. 29.] 
adversary cards in discard: [11.  8.  0.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  3 14 14  6  8  6  1  6 10  8  6  8  6 11  6
 23  6  0  6  0  8  0 11 29 11] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[     -5 3000000       0     270       0       0      20       0       0
       0       0     -30       0       0     125       0] 
sum of rewards: 3000380 

action type: buy - action 25.0
Learning step: 120013.96875
desired expected reward: 120044.6875



