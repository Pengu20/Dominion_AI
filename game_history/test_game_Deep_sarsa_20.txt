 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.67231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000365 

action type: buy - action -1.0
Learning step: -299995.125
desired expected reward: -300408.8125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[72.65247 ]
 [76.537994]
 [74.47923 ]
 [71.10549 ]
 [73.40918 ]
 [78.47729 ]
 [76.63324 ]
 [81.789894]
 [74.99165 ]
 [74.57426 ]
 [78.90411 ]
 [71.10549 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.56474304199219



buy possibilites: [-1] 
expected returns: [[47.6449]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 81.78988647460938






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[71.951645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.644901275634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[72.82404 ]
 [76.792114]
 [74.69057 ]
 [71.20326 ]
 [78.75477 ]
 [76.88824 ]
 [74.78669 ]
 [71.20326 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.25856018066406



buy possibilites: [-1] 
expected returns: [[67.31451]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 78.75476837158203






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[54.43162 ]
 [61.750957]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.31450653076172



action possibilites: [-1] 
expected returns: [[38.482925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 63.43439865112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[40.382328]
 [41.983547]
 [38.989407]
 [43.851513]
 [38.989407]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.48292541503906



buy possibilites: [-1] 
expected returns: [[32.214733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 43.851505279541016






Player: 1 
cards in hand: [ 0.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 90.210754]
 [102.43912 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [10.  8. 11.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.2147331237793



action possibilites: [-1.] 
expected returns: [[118.86192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.2138900756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[123.51463 ]
 [128.02104 ]
 [125.63051 ]
 [124.01938 ]
 [121.6777  ]
 [124.450485]
 [130.24557 ]
 [128.12973 ]
 [133.57198 ]
 [134.07669 ]
 [126.24394 ]
 [127.071075]
 [125.7392  ]
 [122.829216]
 [130.75032 ]
 [121.6777  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.86192321777344



buy possibilites: [-1] 
expected returns: [[70.60129]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 11.  3.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 1.  0.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 134.0767059326172






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 1.  0.  0. 16.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 1.  0.  0. 16.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 1.  0.  0. 16.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.510986]
 [32.877304]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.60128784179688



action possibilites: [-1. 11.] 
expected returns: [[57.084568]
 [64.783646]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.644451141357422



action possibilites: [-1] 
expected returns: [[44.19609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.05683135986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[47.06657 ]
 [50.97277 ]
 [48.90502 ]
 [45.47203 ]
 [52.90701 ]
 [51.067616]
 [48.999863]
 [45.47203 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.19609069824219



buy possibilites: [-1] 
expected returns: [[41.22198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 52.90700149536133






Player: 1 
cards in hand: [ 3. 16.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  1.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[71.7018  ]
 [74.998856]
 [76.93259 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16. 10.  3. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.221981048583984



action possibilites: [-1] 
expected returns: [[40.80717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  8 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16. 10.  3. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 65.17079162597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.384415]
 [42.814953]
 [42.814953]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  8 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  8.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16. 10.  3. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.80717086791992



buy possibilites: [-1] 
expected returns: [[39.638283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  8 29 10 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16. 10.  3. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 44.38441848754883






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16. 10.  3. 16.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  8 29 10 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16. 10.  3. 16.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  8 29 10 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16. 10.  3. 16.  0.  0.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  8.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  8 29 10 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[ 9.100046]
 [13.071587]
 [16.689083]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  8 29 10 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  8.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.638282775878906



action possibilites: [-1.  8.] 
expected returns: [[41.090652]
 [46.09303 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  8 29 10 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  8.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.822494506835938



action possibilites: [-1] 
expected returns: [[8.031553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  8.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 38.71559143066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.675098 ]
 [13.138561 ]
 [11.8482895]
 [ 9.652517 ]
 [14.373226 ]
 [13.200033 ]
 [11.909761 ]
 [ 9.652517 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  8.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.031553268432617



buy possibilites: [-1] 
expected returns: [[2.7996888]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 14.373235702514648






Player: 1 
cards in hand: [16.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11. 10.] 
adversary cards in discard: [11. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11. 10.] 
adversary cards in discard: [11. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[23.716946]
 [30.102924]
 [30.102924]
 [26.752502]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11. 10.] 
cards in discard: [11. 29.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [16.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.7996888160705566



action possibilites: [-1] 
expected returns: [[-4.7760344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.] 
cards in discard: [11. 29.  8.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [16.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.408584594726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.4610677]
 [-2.5644715]
 [-2.5644715]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 10.] 
cards in discard: [11. 29.  8.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [16.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.776034355163574



buy possibilites: [-1] 
expected returns: [[20.13317]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 10.] 
cards in discard: [11. 29.  8.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [16.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -1.4610638618469238






Player: 1 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [16.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [16.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [16.  3.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 4.1216416]
 [ 8.853434 ]
 [10.8665695]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  1.] 
adversary cards in discard: [16.  3.  3.  0.  0.  3.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.133169174194336



action possibilites: [-1. 11. 11.] 
expected returns: [[4.583693]
 [9.381498]
 [9.381498]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  1.] 
adversary cards in discard: [16.  3.  3.  0.  0.  3.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.907026290893555



action possibilites: [-1] 
expected returns: [[15.414436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  1.] 
adversary cards in discard: [16.  3.  3.  0.  0.  3.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 10.774660110473633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.607624]
 [22.786392]
 [21.11065 ]
 [18.302275]
 [24.367392]
 [22.864367]
 [21.188623]
 [18.302275]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  7.  8. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  1.] 
adversary cards in discard: [16.  3.  3.  0.  0.  3.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.414436340332031



buy possibilites: [-1] 
expected returns: [[14.873291]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  8. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  1.] 
adversary cards in discard: [16.  3.  3.  0.  0.  3.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: -1 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 24.367395401000977






Player: 1 
cards in hand: [ 3.  0.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  1.] 
cards in discard: [16.  3.  3.  0.  0.  3.  0.  0. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  8. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8. 11.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  1.] 
cards in discard: [16.  3.  3.  0.  0.  3.  0.  0. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  8. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8. 11.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11] -> size -> 18 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[64.71316 ]
 [67.964874]
 [69.87659 ]
 [71.57971 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  0.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  8. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.873291015625



action possibilites: [-1] 
expected returns: [[19.744297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  8. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.40941619873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.043701]
 [28.360119]
 [25.897783]
 [29.889526]
 [25.897783]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  8. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.74429702758789



buy possibilites: [-1] 
expected returns: [[28.434937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 11. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  7. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 29.889522552490234






Player: 1 
cards in hand: [ 3.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  1  3 16  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  7. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 11. 10.  8. 11. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8] -> size -> 20 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  7. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 11. 10.  8. 11. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8] -> size -> 20 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  7. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 11. 10.  8. 11. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8] -> size -> 20 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 11. 10.  8. 11. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8] -> size -> 20 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-12.738335 ]
 [ -8.009958 ]
 [-11.1439705]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 11. 10.  8. 11. 10.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.4349365234375



action possibilites: [-1. 10. 10.] 
expected returns: [[ 9.056187]
 [11.073774]
 [11.073774]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -8.641950607299805



action possibilites: [-1. 10. 11.] 
expected returns: [[ 9.8549  ]
 [11.921215]
 [14.184431]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8] -> size -> 20 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 11.073776245117188



action possibilites: [-1. 10.] 
expected returns: [[12.346264]
 [14.524994]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  8. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: -8 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 15.45109748840332



action possibilites: [-1.] 
expected returns: [[6.661652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 11. 10.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10] -> size -> 21 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  8. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 14.524993896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[12.921354]
 [15.45323 ]
 [14.120838]
 [11.877367]
 [13.39753 ]
 [16.72294 ]
 [15.515633]
 [18.84559 ]
 [14.444397]
 [14.183235]
 [16.99155 ]
 [11.877367]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 11. 10.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  8. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.661652088165283



buy possibilites: [-1] 
expected returns: [[16.073324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 11. 10.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 18.84558868408203






Player: 1 
cards in hand: [ 0. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 29.  8. 10.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  6. 10.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 29.  8. 10.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [8. 8. 3. 0. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  5. 10.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 29.  8. 10.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8. 10.] 
expected returns: [[ 7.2382293]
 [ 9.421173 ]
 [13.718199 ]
 [10.671391 ]
 [ 9.421173 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  8. 10.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  5. 10.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  8.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.07332420349121



action possibilites: [-1. 10.  8. 10. 11.] 
expected returns: [[ 6.161139]
 [ 8.112173]
 [ 9.222691]
 [ 8.112173]
 [10.236427]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10. 11.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  5. 10.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  8.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.89082145690918



action possibilites: [-1] 
expected returns: [[-7.0203505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  5. 10.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  8.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 11.367507934570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-5.9397407]
 [-5.0194044]
 [-6.7430935]
 [-3.9688423]
 [-6.7430935]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  5. 10.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  8.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.020350456237793



buy possibilites: [-1] 
expected returns: [[-8.557173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  4. 10.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  8.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -39 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -3.968843460083008






Player: 1 
cards in hand: [ 3. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0.  0.] 
cards in discard: [ 8.  8.  3.  0.  0.  8.  0. 16.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  8.  6.  4. 10.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.  8. 29. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  8.  3.  0.  0.  8.  0. 16.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  4. 10.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.  8. 29. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  8.  3.  0.  0.  8.  0. 16.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  4. 10.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.  8. 29. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-17.955034]
 [-14.681236]
 [-14.681236]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.  8. 29. 11. 10.  0.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  4. 10.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.557172775268555



action possibilites: [-1] 
expected returns: [[-20.831223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.  8. 29. 11. 10.  0.  8. 10.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  4. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -13.876708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-20.315159]
 [-19.532953]
 [-20.987623]
 [-18.639463]
 [-20.987623]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.  8. 29. 11. 10.  0.  8. 10.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  4. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.831222534179688



buy possibilites: [-1] 
expected returns: [[-14.335262]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10.  0.  3.  0.  0. 10.  8. 29. 11. 10.  0.  8. 10.
 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -18.63946533203125






Player: 1 
cards in hand: [3. 6. 8. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  1  3 16  8  3  8  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.  8.] 
expected returns: [[1.5773368]
 [4.6735024]
 [3.5402498]
 [7.4619613]
 [4.6735024]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.335262298583984



action possibilites: [-1.  8. 10.  8. 29.] 
expected returns: [[10.313494]
 [13.58396 ]
 [12.387718]
 [13.58396 ]
 [16.512459]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 2.7709269523620605



action possibilites: [-1.  8. 10.  8.] 
expected returns: [[ 7.8877053]
 [10.990456 ]
 [ 9.859716 ]
 [10.990456 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.512454986572266



action possibilites: [-1] 
expected returns: [[15.520435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 13
Learning step: 0
desired expected reward: 11.890003204345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.179913]
 [20.403526]
 [18.14011 ]
 [21.830738]
 [18.14011 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  3. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.520435333251953



buy possibilites: [-1] 
expected returns: [[31.498165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 21.830745697021484






Player: 1 
cards in hand: [ 8.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 16.  3.] 
cards in discard: [8. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 16  8  3  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 10.  3. 10.  0.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.] 
cards in discard: [8. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 10.  3. 10.  0.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [8. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 10.  3. 10.  0.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [8. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 10.  3. 10.  0.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[20.866997]
 [22.998806]
 [22.998806]
 [22.998806]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 10.  0.] 
cards in discard: [ 8. 29. 29.  8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.498165130615234



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[4.7315574]
 [6.8661485]
 [6.8661485]
 [6.8661485]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0. 10.] 
cards in discard: [ 8. 29. 29.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 17.852619171142578



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[11.254868]
 [13.301914]
 [13.301914]
 [14.485441]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.  8.] 
cards in discard: [ 8. 29. 29.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3 29 11 29 10 11  0 11 10  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 6.866147518157959



action possibilites: [-1.] 
expected returns: [[-14.662888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8. 29. 29.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 16.048845291137695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.636681]
 [-13.56727 ]
 [-13.56727 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 29. 29.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.662887573242188



buy possibilites: [-1] 
expected returns: [[18.043564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 29. 29.  8. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   60.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -12.636678695678711






Player: 1 
cards in hand: [ 0. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  8.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11.  0.  8.  0. 11.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  8.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11.  0.  8.  0. 11.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  8.  0. 16. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  8.  0. 11.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  0.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[18.039463]
 [23.252293]
 [21.959084]
 [23.252293]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0. 11.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.043563842773438



action possibilites: [-1] 
expected returns: [[-5.793124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 16.60675811767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-3.5703282]
 [-2.5610185]
 [-4.450937 ]
 [-1.4054587]
 [-4.450937 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  2. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.793124198913574



buy possibilites: [-1] 
expected returns: [[1.7924676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  1. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -89 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -1.405458927154541






Player: 1 
cards in hand: [ 0. 16.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  8  3  8  8  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  8.  6.  1. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  6.  1. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  6.  1. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[-17.580542]
 [-14.80377 ]
 [-13.709417]
 [-14.80377 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 11.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8. 11.  0.  8.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  6.  1. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.7924675941467285



action possibilites: [-1. 11. 10.] 
expected returns: [[-18.368216]
 [-15.553408]
 [-17.02256 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8. 11.  0.  8.  0. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  6.  1. 10.  7. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -15.510494232177734



action possibilites: [-1] 
expected returns: [[-11.947135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8. 11.  0.  8.  0. 11. 11.
 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  6.  1. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -14.726776123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-10.9638195]
 [ -9.425339 ]
 [-10.224915 ]
 [-11.603693 ]
 [ -8.629    ]
 [ -9.386152 ]
 [-11.603693 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8. 11.  0.  8.  0. 11. 11.
 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  6.  1. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.947134971618652



buy possibilites: [-1] 
expected returns: [[-19.630184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 8. 29. 29.  8. 10.  0. 10. 10.  8.  0. 15.  8. 11.  0.  8.  0. 11. 11.
 15. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -31 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -8.628999710083008






Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 0. 16.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11. 11.  8. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11] -> size -> 26 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 16.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11. 11.  8. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11] -> size -> 26 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 16.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11. 11.  8. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11] -> size -> 26 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 11.  8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 29. 10.] 
expected returns: [[-10.130363 ]
 [ -5.5308347]
 [ -5.5308347]
 [ -6.677655 ]
 [ -3.5868025]
 [ -7.9285283]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8. 29. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8.  3. 16.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -19.630184173583984



action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[2.8315377]
 [7.086616 ]
 [7.086616 ]
 [4.8560386]
 [4.8560386]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8.  3. 16.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.259132385253906



action possibilites: [-1] 
expected returns: [[8.679466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [ 8. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8.  3. 16.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 8.414602279663086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.192003]
 [12.238232]
 [12.238232]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.] 
cards in discard: [ 8. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8.  3. 16.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.679466247558594



buy possibilites: [-1] 
expected returns: [[2.4340763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.] 
cards in discard: [ 8. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11 15  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8.  3. 16.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 13.192008972167969






Player: 1 
cards in hand: [ 0.  8.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 16.  3.] 
cards in discard: [ 0. 16.  0.  3.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  3 16  3  8  8  0 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0.  8. 15.  8.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11 15  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 0. 16.  0.  3.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0.  8. 15.  8.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11 15  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 0. 16.  0.  3.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0.  8. 15.  8.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11 15  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 0. 16.  0.  3.  3.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0.  8. 15.  8.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11 15  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0.  8. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.  8.] 
expected returns: [[-9.631974 ]
 [-7.580791 ]
 [-6.3759203]
 [-5.0520973]
 [-6.3759203]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 15.  8.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8
 15 11 15  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.4340763092041016



action possibilites: [-1] 
expected returns: [[9.07012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -8.747171401977539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[15.36006 ]
 [17.566284]
 [16.408878]
 [14.446341]
 [18.72749 ]
 [17.621105]
 [14.446341]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  5.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.070119857788086



buy possibilites: [-1] 
expected returns: [[3.0483994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 18.72749137878418






Player: 1 
cards in hand: [ 0.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  8.  0. 10.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.] 
adversary owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 16  3 16  3  8  8  0 10  0  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  8.  0. 10.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.] 
adversary owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  8.  0. 10.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.] 
adversary owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  8.  0. 10.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.] 
adversary owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[4.4504876]
 [9.760727 ]
 [7.245709 ]
 [6.235806 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  0. 10.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [16.  0.  0.  3. 16.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.0483994483947754



action possibilites: [-1. 10.] 
expected returns: [[11.844379]
 [13.615686]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [16.  0.  0.  3. 16.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.007093906402588



action possibilites: [-1. 10.] 
expected returns: [[6.5992293]
 [8.551968 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [16.  0.  0.  3. 16.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 13.615684509277344



action possibilites: [-1. 11.] 
expected returns: [[4.5766587]
 [8.130573 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11] -> size -> 28 
action values: 3 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  7.] 
adversary cards in hand: [16.  0.  0.  3. 16.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 8.551969528198242



action possibilites: [-1.] 
expected returns: [[-9.6058235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10. 10. 11.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11 15] -> size -> 29 
action values: 2 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  6.] 
adversary cards in hand: [16.  0.  0.  3. 16.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0  64   0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 9.10774040222168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[-8.933692 ]
 [-7.1876197]
 [-8.101803 ]
 [-9.660072 ]
 [-8.662785 ]
 [-6.2920628]
 [-7.1425047]
 [-4.937827 ]
 [-7.901272 ]
 [-6.134758 ]
 [-9.660072 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10. 10. 11.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  7. 10. 10.  0. 10.  6.] 
adversary cards in hand: [16.  0.  0.  3. 16.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -9.605823516845703



buy possibilites: [-1] 
expected returns: [[-18.806164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10. 10. 11.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11 15 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [16.  0.  0.  3. 16.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -4.93782901763916






Player: 1 
cards in hand: [16.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3. 16.] 
cards in discard: [10.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11. 15. 11. 29.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29. 29. 10.
 10. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11 15 29] -> size -> 30 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3. 16.] 
cards in discard: [10.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3 16  3  8  8  0 10  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11. 15. 11. 29.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29. 29. 10.
 10. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11 15 29] -> size -> 30 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3. 16.] 
cards in discard: [10.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3 16  3  8  8  0 10  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11. 15. 11. 29.] 
adversary cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29. 29. 10.
 10. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11 15 29] -> size -> 30 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 15. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 29.] 
expected returns: [[-13.190691 ]
 [-10.167634 ]
 [-10.026848 ]
 [-10.167634 ]
 [ -8.9576845]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 11. 29.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29. 29. 10.
 10. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11 15 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -18.806163787841797



action possibilites: [-1. 11. 15. 11.] 
expected returns: [[-9.75946  ]
 [-6.7457027]
 [-6.6081824]
 [-6.7457027]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 11.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29. 29. 10.
 10. 11.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15
 11 15  0 11 15 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -10.96725082397461



action possibilites: [-1] 
expected returns: [[-26.567127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29. 29. 10.
 10. 11.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -6.608184337615967





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[-25.678352]
 [-23.743183]
 [-24.751213]
 [-26.469398]
 [-25.37819 ]
 [-22.759365]
 [-23.693727]
 [-21.270008]
 [-24.529064]
 [-22.58615 ]
 [-26.469398]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29. 29. 10.
 10. 11.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  6. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.567127227783203



buy possibilites: [-1] 
expected returns: [[-18.758741]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [ 8. 15.  0. 29. 11. 11. 10. 10. 11. 15. 10.  8.  8.  8. 15. 29. 29. 10.
 10. 11.  0.  0.  0.  8. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3 16  3  8  8  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 103 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -21.27001190185547






Player: 1 
cards in hand: [ 0.  3. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3 16  3  8  8  0 10  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  1. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 11.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29] -> size -> 30 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16 16  3  8  8  0 10  0  0  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 11.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29] -> size -> 30 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16 16  3  8  8  0 10  0  0  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 11.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29] -> size -> 30 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 11.] 
expected returns: [[15.868105]
 [19.076189]
 [20.202974]
 [19.076189]
 [20.202974]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  4.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 8. 16.  0.  0.  8.] 
adversary owned cards: [ 0 16 16  3  8  8  0 10  0  0  0  8] -> size -> 12 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -18.75874137878418



action possibilites: [-1] 
expected returns: [[20.746311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  0.] 
cards in discard: [11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  3.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 8. 16.  0.  0.  8.] 
adversary owned cards: [ 0 16 16  3  8  8  0 10  0  0  0  8] -> size -> 12 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 15.203716278076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.601727]
 [26.564487]
 [26.564487]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11.  0.] 
cards in discard: [11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 28. 30.  8.  9.  8.  3.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 8. 16.  0.  0.  8.] 
adversary owned cards: [ 0 16 16  3  8  8  0 10  0  0  0  8] -> size -> 12 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.74631118774414



buy possibilites: [-1] 
expected returns: [[8.114403]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11.  0.] 
cards in discard: [11.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 28. 30.  8.  9.  8.  3.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 8. 16.  0.  0.  8.] 
adversary owned cards: [ 0 16 16  3  8  8  0 10  0  0  0  8] -> size -> 12 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 27.601726531982422






Player: 1 
cards in hand: [ 0.  0.  8. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10. 16.] 
cards in discard: [ 8. 16.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 16  3  8  8  0 10  0  0  0  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 28. 30.  8.  9.  8.  3.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 11.  0.  8. 10.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.] 
cards in discard: [ 8. 16.  0.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  3  8  8  0 10  0  0  0  8  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  9.  8.  3.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 11.  0.  8. 10.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.] 
cards in discard: [ 8. 16.  0.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  3  8  8  0 10  0  0  0  8  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  9.  8.  3.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 11.  0.  8. 10.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.] 
cards in discard: [ 8. 16.  0.  0.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  9.  8.  3.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 11.  0.  8. 10.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 10.] 
expected returns: [[1.5754523]
 [5.730065 ]
 [5.730065 ]
 [4.6931453]
 [3.5661988]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8. 10.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  9.  8.  3.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.114402770996094



action possibilites: [-1] 
expected returns: [[-7.7154894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 10.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 1.896308422088623





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-6.675143]
 [-7.569966]
 [-7.569966]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 10.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.715489387512207



buy possibilites: [-1] 
expected returns: [[-10.97483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 10.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 27. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -6.67514705657959






Player: 1 
cards in hand: [8. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 15. 10. 15. 10.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0] -> size -> 34 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 27. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 15. 10. 15. 10.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0] -> size -> 34 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 15. 10. 15. 10.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 10. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10. 15. 10.] 
expected returns: [[-13.7179985]
 [-11.42646  ]
 [-10.518434 ]
 [-12.253559 ]
 [-10.518434 ]
 [-12.253559 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10. 15. 10.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  8.  0.  3. 16.] 
adversary cards in discard: [3. 8. 8. 0. 0. 3.] 
adversary owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.97482967376709



action possibilites: [-1] 
expected returns: [[-21.55562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 15. 10.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  8.  0.  3. 16.] 
adversary cards in discard: [3. 8. 8. 0. 0. 3.] 
adversary owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -10.5184326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-20.949821]
 [-21.605934]
 [-21.605934]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 15. 10.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  8.  0.  3. 16.] 
adversary cards in discard: [3. 8. 8. 0. 0. 3.] 
adversary owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.555620193481445



buy possibilites: [-1] 
expected returns: [[-13.825747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 15. 10.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  8.  0.  3. 16.] 
adversary cards in discard: [3. 8. 8. 0. 0. 3.] 
adversary owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -20.94982147216797






Player: 1 
cards in hand: [ 0.  8.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 16.] 
cards in discard: [3. 8. 8. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  3  8  8  0 10  0  0  0  8  3  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  8. 10. 10. 29.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [3. 8. 8. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  8. 10. 10. 29.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3. 8. 8. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  8. 10. 10. 29.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 29.] 
expected returns: [[-24.545725]
 [-22.266594]
 [-23.087479]
 [-23.087479]
 [-20.296988]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 29.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.825746536254883



action possibilites: [-1.  8. 10.] 
expected returns: [[-17.889854]
 [-15.310205]
 [-16.245253]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 11  0 11  0 10 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11
 15  0 11 15 29 29 11  0 11  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -22.171236038208008



action possibilites: [-1] 
expected returns: [[-14.355925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -14.400274276733398





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-14.379658]
 [-13.64077 ]
 [-15.015408]
 [-15.015408]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 26. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.355924606323242



buy possibilites: [-1] 
expected returns: [[-18.465822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -13.640769958496094






Player: 1 
cards in hand: [ 0.  3.  0. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 15. 11. 29. 29.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3. 29.  8.  0.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 25. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 15. 11. 29. 29.] 
adversary cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3. 29.  8.  0.] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29. 29.] 
expected returns: [[-12.454294]
 [ -8.824565]
 [ -8.987167]
 [ -7.593858]
 [ -7.593858]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 29. 29.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3. 29.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 16.] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -18.465822219848633



action possibilites: [-1. 11. 29. 29.] 
expected returns: [[-23.369286]
 [-20.208887]
 [-18.940111]
 [-18.940111]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3. 29.  8.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 16.] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -9.742939949035645



action possibilites: [-1. 11.] 
expected returns: [[-17.60578]
 [-13.91802]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3. 29.  8.  0.  0. 15. 29. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 25. 30.  8.  9.  8.  2.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 16.] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.046844482421875



action possibilites: [-1] 
expected returns: [[-24.004501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3. 29.  8.  0.  0. 15. 29. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 25. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 16.] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 42 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: -14.72195816040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-23.29717 ]
 [-22.629436]
 [-23.864563]
 [-23.864563]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3. 29.  8.  0.  0. 15. 29. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 25. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 16.] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: -24.004501342773438



buy possibilites: [-1] 
expected returns: [[-22.50121]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0. 11.  8.  8. 11.  0. 11.  0. 11. 11.  0.  8. 10.  0. 15.  8. 10.
 15. 10. 10.  0.  3. 29.  8.  0.  0. 15. 29. 15. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 16.] 
adversary owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 51 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -22.629430770874023






Player: 1 
cards in hand: [3. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 0.] 
cards in discard: [ 0.  3.  0. 10. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  0 10  0  0  0  8  3  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11  3] -> size -> 37 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 0.  3.  0. 10. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8 10  0  0  0  8  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11  3] -> size -> 37 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 0.  3.  0. 10. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8 10  0  0  0  8  0  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 24. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11  3] -> size -> 37 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 0.  3.  0. 10. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8 10  0  0  0  8  0  3  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 24. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11  3] -> size -> 37 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
expected returns: [[18.52321 ]
 [21.675772]
 [22.720951]
 [24.464634]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 24. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 16.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8 10  0  0  0  8  0  3  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -22.501209259033203



action possibilites: [-1. 11. 11.] 
expected returns: [[ 6.3263774]
 [10.469566 ]
 [10.469566 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.] 
cards in discard: [8. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 24. 30.  8.  9.  8.  1.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 16.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8 10  0  0  0  8  0  3  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.53691864013672



Player 0 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 0 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 6 
Witch: 0 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 11.] 
cards in discard: [ 8.  0. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 29 11 29 11  0 11  0 11 10  8 10 29 10  8 10  8  8  0 15  8 15 11 15
  0 11 15 29 29 11  0 11  0  0  3 11  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 24. 30.  8.  9.  8.  0.  0. 10.  5. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 16.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8 10  0  0  0  8  0  3  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      40       0       0
       0       0     -30       0       0      27       0] 
sum of rewards: 3000062 

action type: gain_card_n - action 5
Learning step: 300005.21875
desired expected reward: 300014.875



